{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6eb96cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import glob \n",
    "from pyspark.sql import SparkSession\n",
    "import sqlite3\n",
    "from langdetect import detect\n",
    "from pyspark.sql.functions import when, lit, col, udf\n",
    "from mrjob.job import MRJob\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef39fc00",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/usr/local/spark/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/ubuntu/.ivy2/cache\n",
      "The jars for the packages stored in: /home/ubuntu/.ivy2/jars\n",
      "com.johnsnowlabs.nlp#spark-nlp_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-8f792b69-f079-4308-88f6-a2e222409e13;1.0\n",
      "\tconfs: [default]\n",
      "\tfound com.johnsnowlabs.nlp#spark-nlp_2.12;3.4.3 in central\n",
      "\tfound com.typesafe#config;1.4.1 in central\n",
      "\tfound org.rocksdb#rocksdbjni;6.5.3 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-bundle;1.11.603 in central\n",
      "\tfound com.github.universal-automata#liblevenshtein;3.0.0 in central\n",
      "\tfound com.google.code.findbugs#annotations;3.0.1 in central\n",
      "\tfound net.jcip#jcip-annotations;1.0 in central\n",
      "\tfound com.google.code.findbugs#jsr305;3.0.1 in central\n",
      "\tfound com.google.protobuf#protobuf-java-util;3.0.0-beta-3 in central\n",
      "\tfound com.google.protobuf#protobuf-java;3.0.0-beta-3 in central\n",
      "\tfound com.google.code.gson#gson;2.3 in central\n",
      "\tfound it.unimi.dsi#fastutil;7.0.12 in central\n",
      "\tfound org.projectlombok#lombok;1.16.8 in central\n",
      "\tfound org.slf4j#slf4j-api;1.7.21 in central\n",
      "\tfound com.navigamez#greex;1.0 in central\n",
      "\tfound dk.brics.automaton#automaton;1.11-8 in central\n",
      "\tfound org.json4s#json4s-ext_2.12;3.5.3 in central\n",
      "\tfound joda-time#joda-time;2.9.5 in central\n",
      "\tfound org.joda#joda-convert;1.8.1 in central\n",
      "\tfound com.johnsnowlabs.nlp#tensorflow-cpu_2.12;0.3.3 in central\n",
      "\tfound net.sf.trove4j#trove4j;3.0.3 in central\n",
      ":: resolution report :: resolve 611ms :: artifacts dl 22ms\n",
      "\t:: modules in use:\n",
      "\tcom.amazonaws#aws-java-sdk-bundle;1.11.603 from central in [default]\n",
      "\tcom.github.universal-automata#liblevenshtein;3.0.0 from central in [default]\n",
      "\tcom.google.code.findbugs#annotations;3.0.1 from central in [default]\n",
      "\tcom.google.code.findbugs#jsr305;3.0.1 from central in [default]\n",
      "\tcom.google.code.gson#gson;2.3 from central in [default]\n",
      "\tcom.google.protobuf#protobuf-java;3.0.0-beta-3 from central in [default]\n",
      "\tcom.google.protobuf#protobuf-java-util;3.0.0-beta-3 from central in [default]\n",
      "\tcom.johnsnowlabs.nlp#spark-nlp_2.12;3.4.3 from central in [default]\n",
      "\tcom.johnsnowlabs.nlp#tensorflow-cpu_2.12;0.3.3 from central in [default]\n",
      "\tcom.navigamez#greex;1.0 from central in [default]\n",
      "\tcom.typesafe#config;1.4.1 from central in [default]\n",
      "\tdk.brics.automaton#automaton;1.11-8 from central in [default]\n",
      "\tit.unimi.dsi#fastutil;7.0.12 from central in [default]\n",
      "\tjoda-time#joda-time;2.9.5 from central in [default]\n",
      "\tnet.jcip#jcip-annotations;1.0 from central in [default]\n",
      "\tnet.sf.trove4j#trove4j;3.0.3 from central in [default]\n",
      "\torg.joda#joda-convert;1.8.1 from central in [default]\n",
      "\torg.json4s#json4s-ext_2.12;3.5.3 from central in [default]\n",
      "\torg.projectlombok#lombok;1.16.8 from central in [default]\n",
      "\torg.rocksdb#rocksdbjni;6.5.3 from central in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.21 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   21  |   0   |   0   |   0   ||   21  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-8f792b69-f079-4308-88f6-a2e222409e13\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 21 already retrieved (0kB/15ms)\n",
      "2022-04-21 16:14:25,280 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "2022-04-21 16:14:27,086 WARN util.Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "2022-04-21 16:14:27,087 WARN util.Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "2022-04-21 16:14:28,850 WARN yarn.Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.\n",
      "2022-04-21 16:14:39,256 WARN yarn.Client: Same path resource file:///home/ubuntu/.ivy2/jars/com.johnsnowlabs.nlp_spark-nlp_2.12-3.4.3.jar added multiple times to distributed cache.\n",
      "2022-04-21 16:14:39,256 WARN yarn.Client: Same path resource file:///home/ubuntu/.ivy2/jars/com.typesafe_config-1.4.1.jar added multiple times to distributed cache.\n",
      "2022-04-21 16:14:39,256 WARN yarn.Client: Same path resource file:///home/ubuntu/.ivy2/jars/org.rocksdb_rocksdbjni-6.5.3.jar added multiple times to distributed cache.\n",
      "2022-04-21 16:14:39,256 WARN yarn.Client: Same path resource file:///home/ubuntu/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.11.603.jar added multiple times to distributed cache.\n",
      "2022-04-21 16:14:39,257 WARN yarn.Client: Same path resource file:///home/ubuntu/.ivy2/jars/com.github.universal-automata_liblevenshtein-3.0.0.jar added multiple times to distributed cache.\n",
      "2022-04-21 16:14:39,257 WARN yarn.Client: Same path resource file:///home/ubuntu/.ivy2/jars/com.navigamez_greex-1.0.jar added multiple times to distributed cache.\n",
      "2022-04-21 16:14:39,257 WARN yarn.Client: Same path resource file:///home/ubuntu/.ivy2/jars/org.json4s_json4s-ext_2.12-3.5.3.jar added multiple times to distributed cache.\n",
      "2022-04-21 16:14:39,257 WARN yarn.Client: Same path resource file:///home/ubuntu/.ivy2/jars/com.johnsnowlabs.nlp_tensorflow-cpu_2.12-0.3.3.jar added multiple times to distributed cache.\n",
      "2022-04-21 16:14:39,257 WARN yarn.Client: Same path resource file:///home/ubuntu/.ivy2/jars/net.sf.trove4j_trove4j-3.0.3.jar added multiple times to distributed cache.\n",
      "2022-04-21 16:14:39,258 WARN yarn.Client: Same path resource file:///home/ubuntu/.ivy2/jars/com.google.code.findbugs_annotations-3.0.1.jar added multiple times to distributed cache.\n",
      "2022-04-21 16:14:39,258 WARN yarn.Client: Same path resource file:///home/ubuntu/.ivy2/jars/com.google.protobuf_protobuf-java-util-3.0.0-beta-3.jar added multiple times to distributed cache.\n",
      "2022-04-21 16:14:39,258 WARN yarn.Client: Same path resource file:///home/ubuntu/.ivy2/jars/com.google.protobuf_protobuf-java-3.0.0-beta-3.jar added multiple times to distributed cache.\n",
      "2022-04-21 16:14:39,258 WARN yarn.Client: Same path resource file:///home/ubuntu/.ivy2/jars/it.unimi.dsi_fastutil-7.0.12.jar added multiple times to distributed cache.\n",
      "2022-04-21 16:14:39,259 WARN yarn.Client: Same path resource file:///home/ubuntu/.ivy2/jars/org.projectlombok_lombok-1.16.8.jar added multiple times to distributed cache.\n",
      "2022-04-21 16:14:39,259 WARN yarn.Client: Same path resource file:///home/ubuntu/.ivy2/jars/org.slf4j_slf4j-api-1.7.21.jar added multiple times to distributed cache.\n",
      "2022-04-21 16:14:39,259 WARN yarn.Client: Same path resource file:///home/ubuntu/.ivy2/jars/net.jcip_jcip-annotations-1.0.jar added multiple times to distributed cache.\n",
      "2022-04-21 16:14:39,259 WARN yarn.Client: Same path resource file:///home/ubuntu/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.1.jar added multiple times to distributed cache.\n",
      "2022-04-21 16:14:39,260 WARN yarn.Client: Same path resource file:///home/ubuntu/.ivy2/jars/com.google.code.gson_gson-2.3.jar added multiple times to distributed cache.\n",
      "2022-04-21 16:14:39,260 WARN yarn.Client: Same path resource file:///home/ubuntu/.ivy2/jars/dk.brics.automaton_automaton-1.11-8.jar added multiple times to distributed cache.\n",
      "2022-04-21 16:14:39,260 WARN yarn.Client: Same path resource file:///home/ubuntu/.ivy2/jars/joda-time_joda-time-2.9.5.jar added multiple times to distributed cache.\n",
      "2022-04-21 16:14:39,260 WARN yarn.Client: Same path resource file:///home/ubuntu/.ivy2/jars/org.joda_joda-convert-1.8.1.jar added multiple times to distributed cache.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Redit app\")\\\n",
    "    .master(\"yarn\")\\\n",
    "    .config(\"spark.driver.memory\",\"32G\")\\\n",
    "    .config(\"spark.driver.maxResultSize\", \"0\") \\\n",
    "    .config(\"spark.kryoserializer.buffer.max\", \"2000M\")\\\n",
    "    .config(\"spark.jars.packages\", \"com.johnsnowlabs.nlp:spark-nlp_2.12:3.4.3\")\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62e5b278",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc=spark.sparkContext.getConf().getAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f84642ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a spark section \n",
    "# spark = SparkSession.builder.master(\"local[1]\").appName('Reddit app').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d90f99de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.format(\"csv\").option(\"header\",\"true\").load(\"hdfs://namenode:9000/dis_materials/data_reddit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "074baf51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "261d7c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['created_utc', 'ups', 'subreddit_id', 'link_id', 'name', 'score_hidden', 'author_flair_css_class', 'author_flair_text', 'subreddit', 'id', 'removal_reason', 'gilded', 'downs', 'archived', 'author', 'score', 'retrieved_on', 'body', 'distinguished', 'edited', 'controversiality', 'parent_id']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create RDD from parallelize  \n",
    "K=list(df.columns) \n",
    "\n",
    "print(K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5feb6f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------+\n",
      "|                     created_utc|\n",
      "+--------------------------------+\n",
      "|                      1430438400|\n",
      "|読みたいが買ったら負けな気がする|\n",
      "|             図書館に出ねーかな\"|\n",
      "|                      1430438400|\n",
      "|                      1430438400|\n",
      "|                      1430438400|\n",
      "|                      1430438400|\n",
      "|                      1430438400|\n",
      "|                      1430438400|\n",
      "|            You and her simpl...|\n",
      "|                      1430438400|\n",
      "|                      1430438400|\n",
      "|                      1430438400|\n",
      "|                      1430438400|\n",
      "|                      1430438400|\n",
      "|                      1430438400|\n",
      "|                      1430438400|\n",
      "|                      1430438400|\n",
      "|            I shot my dog. I ...|\n",
      "|            Well I was loadin...|\n",
      "+--------------------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+----+\n",
      "| ups|\n",
      "+----+\n",
      "|   4|\n",
      "|null|\n",
      "|null|\n",
      "|   4|\n",
      "|   0|\n",
      "|   3|\n",
      "|   3|\n",
      "|   1|\n",
      "|   6|\n",
      "|null|\n",
      "|   2|\n",
      "|   6|\n",
      "|   5|\n",
      "|   4|\n",
      "|   1|\n",
      "|   1|\n",
      "|   3|\n",
      "|  14|\n",
      "|null|\n",
      "|null|\n",
      "+----+\n",
      "only showing top 20 rows\n",
      "\n",
      "+------------+\n",
      "|subreddit_id|\n",
      "+------------+\n",
      "|    t5_378oi|\n",
      "|        null|\n",
      "|           0|\n",
      "|    t5_2qo4s|\n",
      "|    t5_2cneq|\n",
      "|    t5_2qh1i|\n",
      "|    t5_2qh1i|\n",
      "|    t5_31k9i|\n",
      "|    t5_2qjvn|\n",
      "|           0|\n",
      "|    t5_2s5fm|\n",
      "|    t5_2r090|\n",
      "|    t5_2sqho|\n",
      "|    t5_2qi5w|\n",
      "|    t5_2qiep|\n",
      "|    t5_2sqw4|\n",
      "|    t5_32byj|\n",
      "|    t5_2ranw|\n",
      "|        null|\n",
      "|        null|\n",
      "+------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+---------+\n",
      "|  link_id|\n",
      "+---------+\n",
      "|t3_34di91|\n",
      "|     null|\n",
      "|        0|\n",
      "|t3_34g8mx|\n",
      "|t3_34f7mc|\n",
      "|t3_34f9rh|\n",
      "|t3_34fvry|\n",
      "|t3_34gitq|\n",
      "|t3_34fpen|\n",
      "|        0|\n",
      "|t3_34e7uq|\n",
      "|t3_34gcwh|\n",
      "|t3_34gmag|\n",
      "|t3_34gmq6|\n",
      "|t3_34eznn|\n",
      "|t3_3479aj|\n",
      "|t3_34g2ci|\n",
      "|t3_34f8k8|\n",
      "|     null|\n",
      "|     null|\n",
      "+---------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+----------+\n",
      "|      name|\n",
      "+----------+\n",
      "|t1_cqug90g|\n",
      "|      null|\n",
      "| t3_34di91|\n",
      "|t1_cqug90h|\n",
      "|t1_cqug90i|\n",
      "|t1_cqug90j|\n",
      "|t1_cqug90k|\n",
      "|t1_cqug90l|\n",
      "|t1_cqug90m|\n",
      "|t1_cqu8cmw|\n",
      "|t1_cqug90n|\n",
      "|t1_cqug90o|\n",
      "|t1_cqug90p|\n",
      "|t1_cqug90q|\n",
      "|t1_cqug90r|\n",
      "|t1_cqug90s|\n",
      "|t1_cqug90t|\n",
      "|t1_cqug90u|\n",
      "|      null|\n",
      "|      null|\n",
      "+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+------------+\n",
      "|score_hidden|\n",
      "+------------+\n",
      "|           0|\n",
      "|        null|\n",
      "|        null|\n",
      "|           0|\n",
      "|           0|\n",
      "|           0|\n",
      "|           0|\n",
      "|           0|\n",
      "|           0|\n",
      "|        null|\n",
      "|           0|\n",
      "|           0|\n",
      "|           0|\n",
      "|           0|\n",
      "|           0|\n",
      "|           0|\n",
      "|           0|\n",
      "|           0|\n",
      "|        null|\n",
      "|        null|\n",
      "+------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+----------------------+\n",
      "|author_flair_css_class|\n",
      "+----------------------+\n",
      "|                  null|\n",
      "|                  null|\n",
      "|                  null|\n",
      "|                  Heat|\n",
      "|                  null|\n",
      "|                  null|\n",
      "|                  null|\n",
      "|                  null|\n",
      "|                  null|\n",
      "|                  null|\n",
      "|                Titan3|\n",
      "|                T10B10|\n",
      "|                fan vp|\n",
      "|            modernbird|\n",
      "|             FZeroLogo|\n",
      "|                  null|\n",
      "|                  null|\n",
      "|                  null|\n",
      "|                  null|\n",
      "|                  null|\n",
      "+----------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+--------------------+\n",
      "|   author_flair_text|\n",
      "+--------------------+\n",
      "|                null|\n",
      "|                null|\n",
      "|                null|\n",
      "|                Heat|\n",
      "|                null|\n",
      "|                null|\n",
      "|                null|\n",
      "|                null|\n",
      "|                null|\n",
      "|                null|\n",
      "|                null|\n",
      "|            [Philly]|\n",
      "|      Virtus.pro Fan|\n",
      "|                null|\n",
      "|3024-7470-9499 NN...|\n",
      "|                null|\n",
      "|                null|\n",
      "|                null|\n",
      "|                null|\n",
      "|                null|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+---------------+\n",
      "|      subreddit|\n",
      "+---------------+\n",
      "|      soccer_jp|\n",
      "|           null|\n",
      "|           null|\n",
      "|            nba|\n",
      "|       politics|\n",
      "|      AskReddit|\n",
      "|      AskReddit|\n",
      "|     bloodborne|\n",
      "|  relationships|\n",
      "|           null|\n",
      "|Tennesseetitans|\n",
      "|         cigars|\n",
      "|GlobalOffensive|\n",
      "|         eagles|\n",
      "|      smashbros|\n",
      "|   makinghiphop|\n",
      "|GoogleCardboard|\n",
      "|     offmychest|\n",
      "|           null|\n",
      "|           null|\n",
      "+---------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-------+\n",
      "|     id|\n",
      "+-------+\n",
      "|cqug90g|\n",
      "|   null|\n",
      "|   null|\n",
      "|cqug90h|\n",
      "|cqug90i|\n",
      "|cqug90j|\n",
      "|cqug90k|\n",
      "|cqug90l|\n",
      "|cqug90m|\n",
      "|   null|\n",
      "|cqug90n|\n",
      "|cqug90o|\n",
      "|cqug90p|\n",
      "|cqug90q|\n",
      "|cqug90r|\n",
      "|cqug90s|\n",
      "|cqug90t|\n",
      "|cqug90u|\n",
      "|   null|\n",
      "|   null|\n",
      "+-------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+--------------+\n",
      "|removal_reason|\n",
      "+--------------+\n",
      "|          null|\n",
      "|          null|\n",
      "|          null|\n",
      "|          null|\n",
      "|          null|\n",
      "|          null|\n",
      "|          null|\n",
      "|          null|\n",
      "|          null|\n",
      "|          null|\n",
      "|          null|\n",
      "|          null|\n",
      "|          null|\n",
      "|          null|\n",
      "|          null|\n",
      "|          null|\n",
      "|          null|\n",
      "|          null|\n",
      "|          null|\n",
      "|          null|\n",
      "+--------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+------+\n",
      "|gilded|\n",
      "+------+\n",
      "|     0|\n",
      "|  null|\n",
      "|  null|\n",
      "|     0|\n",
      "|     0|\n",
      "|     0|\n",
      "|     0|\n",
      "|     0|\n",
      "|     0|\n",
      "|  null|\n",
      "|     0|\n",
      "|     0|\n",
      "|     0|\n",
      "|     0|\n",
      "|     0|\n",
      "|     0|\n",
      "|     0|\n",
      "|     0|\n",
      "|  null|\n",
      "|  null|\n",
      "+------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-----+\n",
      "|downs|\n",
      "+-----+\n",
      "|    0|\n",
      "| null|\n",
      "| null|\n",
      "|    0|\n",
      "|    0|\n",
      "|    0|\n",
      "|    0|\n",
      "|    0|\n",
      "|    0|\n",
      "| null|\n",
      "|    0|\n",
      "|    0|\n",
      "|    0|\n",
      "|    0|\n",
      "|    0|\n",
      "|    0|\n",
      "|    0|\n",
      "|    0|\n",
      "| null|\n",
      "| null|\n",
      "+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "+--------+\n",
      "|archived|\n",
      "+--------+\n",
      "|       0|\n",
      "|    null|\n",
      "|    null|\n",
      "|       0|\n",
      "|       0|\n",
      "|       0|\n",
      "|       0|\n",
      "|       0|\n",
      "|       0|\n",
      "|    null|\n",
      "|       0|\n",
      "|       0|\n",
      "|       0|\n",
      "|       0|\n",
      "|       0|\n",
      "|       0|\n",
      "|       0|\n",
      "|       0|\n",
      "|    null|\n",
      "|    null|\n",
      "+--------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+---------------+\n",
      "|         author|\n",
      "+---------------+\n",
      "|          rx109|\n",
      "|           null|\n",
      "|           null|\n",
      "|      WyaOfWade|\n",
      "|   Wicked_Truth|\n",
      "|       jesse9o3|\n",
      "| beltfedshooter|\n",
      "|     Rubenticus|\n",
      "|silverraven1189|\n",
      "|           null|\n",
      "|     Scrubtanic|\n",
      "|       burnmyiz|\n",
      "|      BEE_REAL_|\n",
      "|           SNVG|\n",
      "|       BiigLord|\n",
      "|        KingEze|\n",
      "|        cyborek|\n",
      "|     Zekkystyle|\n",
      "|           null|\n",
      "|           null|\n",
      "+---------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-----+\n",
      "|score|\n",
      "+-----+\n",
      "|    4|\n",
      "| null|\n",
      "| null|\n",
      "|    4|\n",
      "|    0|\n",
      "|    3|\n",
      "|    3|\n",
      "|    1|\n",
      "|    6|\n",
      "| null|\n",
      "|    2|\n",
      "|    6|\n",
      "|    5|\n",
      "|    4|\n",
      "|    1|\n",
      "|    1|\n",
      "|    3|\n",
      "|   14|\n",
      "| null|\n",
      "| null|\n",
      "+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "+------------+\n",
      "|retrieved_on|\n",
      "+------------+\n",
      "|  1432703079|\n",
      "|        null|\n",
      "|        null|\n",
      "|  1432703079|\n",
      "|  1432703079|\n",
      "|  1432703079|\n",
      "|  1432703079|\n",
      "|  1432703079|\n",
      "|  1432703079|\n",
      "|        null|\n",
      "|  1432703079|\n",
      "|  1432703079|\n",
      "|  1432703079|\n",
      "|  1432703079|\n",
      "|  1432703079|\n",
      "|  1432703079|\n",
      "|  1432703079|\n",
      "|  1432703079|\n",
      "|        null|\n",
      "|        null|\n",
      "+------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+--------------------+\n",
      "|                body|\n",
      "+--------------------+\n",
      "|                くそ|\n",
      "|                null|\n",
      "|                null|\n",
      "|gg this one's ove...|\n",
      "|Are you really im...|\n",
      "|No one has a Euro...|\n",
      "|\"That the kid \"\"....|\n",
      "|Haha, i was getti...|\n",
      "|After reading thi...|\n",
      "|                null|\n",
      "|Let's do this. Se...|\n",
      "|You can buy a mys...|\n",
      "|Nihilum and LG ar...|\n",
      "|      Fuck that what|\n",
      "|Don't diss the Gr...|\n",
      "|Your 16 bars seem...|\n",
      "|Trinus vr is amaz...|\n",
      "|It's not your fau...|\n",
      "|                null|\n",
      "|                null|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-------------+\n",
      "|distinguished|\n",
      "+-------------+\n",
      "|         null|\n",
      "|         null|\n",
      "|         null|\n",
      "|         null|\n",
      "|         null|\n",
      "|         null|\n",
      "|         null|\n",
      "|         null|\n",
      "|         null|\n",
      "|         null|\n",
      "|    moderator|\n",
      "|         null|\n",
      "|         null|\n",
      "|         null|\n",
      "|         null|\n",
      "|         null|\n",
      "|         null|\n",
      "|         null|\n",
      "|         null|\n",
      "|         null|\n",
      "+-------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+------+\n",
      "|edited|\n",
      "+------+\n",
      "|  null|\n",
      "|  null|\n",
      "|  null|\n",
      "|     0|\n",
      "|     0|\n",
      "|     0|\n",
      "|     0|\n",
      "|     0|\n",
      "|  null|\n",
      "|  null|\n",
      "|     0|\n",
      "|     0|\n",
      "|     0|\n",
      "|     0|\n",
      "|     0|\n",
      "|     0|\n",
      "|     0|\n",
      "|  null|\n",
      "|  null|\n",
      "|  null|\n",
      "+------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+----------------+\n",
      "|controversiality|\n",
      "+----------------+\n",
      "|            null|\n",
      "|            null|\n",
      "|            null|\n",
      "|               0|\n",
      "|               0|\n",
      "|               0|\n",
      "|               0|\n",
      "|               0|\n",
      "|            null|\n",
      "|            null|\n",
      "|               0|\n",
      "|               0|\n",
      "|               0|\n",
      "|               0|\n",
      "|               0|\n",
      "|               0|\n",
      "|               0|\n",
      "|            null|\n",
      "|            null|\n",
      "|            null|\n",
      "+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "| parent_id|\n",
      "+----------+\n",
      "|      null|\n",
      "|      null|\n",
      "|      null|\n",
      "| t3_34g8mx|\n",
      "|t1_cqufim0|\n",
      "|t1_cqug2sr|\n",
      "| t3_34fvry|\n",
      "|t1_cqug10q|\n",
      "|      null|\n",
      "|      null|\n",
      "| t3_34e7uq|\n",
      "| t3_34gcwh|\n",
      "| t3_34gmag|\n",
      "| t3_34gmq6|\n",
      "|t1_cqu4f8j|\n",
      "|t1_cqs3tw2|\n",
      "|t1_cqucws5|\n",
      "|      null|\n",
      "|      null|\n",
      "|      null|\n",
      "+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in K:\n",
    "    df[[i]].show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "733c6d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.dropDuplicates()\n",
    "df2 = df2.na.drop(subset=[\"subreddit\",\"subreddit_id\",\"body\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55d5bb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isEnglish(text):\n",
    "    try:\n",
    "        if detect(text) != 'en':\n",
    "            return \"No\"\n",
    "        return \"Yes\"\n",
    "    except:\n",
    "        return \"No\"\n",
    "    return \"No\"\n",
    "# Convert function to UDF\n",
    "isEnglishUDF = udf(lambda z: isEnglish(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c476fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_english = df2.withColumn(\"English\",isEnglishUDF(col(\"body\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "950b47ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_english = df2.drop(\"created_utc\",\"link_id\",\"name\",\"score_hidden\",\"id\",\"removal_reason\",\"gilded\",\"retrieved_on\",\"edited\",\"controversiality\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "53c268a9",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'countApproxDistinct'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m channels \u001b[38;5;241m=\u001b[39m \u001b[43mdf_english\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msubreddit\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcountApproxDistinct\u001b[49m()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pyspark/sql/dataframe.py:1643\u001b[0m, in \u001b[0;36mDataFrame.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1633\u001b[0m \u001b[38;5;124;03m\"\"\"Returns the :class:`Column` denoted by ``name``.\u001b[39;00m\n\u001b[1;32m   1634\u001b[0m \n\u001b[1;32m   1635\u001b[0m \u001b[38;5;124;03m.. versionadded:: 1.3.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1640\u001b[0m \u001b[38;5;124;03m[Row(age=2), Row(age=5)]\u001b[39;00m\n\u001b[1;32m   1641\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1642\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[0;32m-> 1643\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m   1644\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, name))\n\u001b[1;32m   1645\u001b[0m jc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jdf\u001b[38;5;241m.\u001b[39mapply(name)\n\u001b[1;32m   1646\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Column(jc)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'countApproxDistinct'"
     ]
    }
   ],
   "source": [
    "channels = df_english.select('subreddit').countApproxDistinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001ca61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "channels \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1a0ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pyspark.sql.functions as F\n",
    "# p=df_english[['subreddit']]\n",
    "# p.coalesce(1).write.format(\"text\").option(\"header\", \"false\").mode(\"append\").save(\"output.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d988e721",
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = df_english.select('subreddit').distinct().rdd.map(lambda r:r[0]).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7506a091",
   "metadata": {},
   "outputs": [],
   "source": [
    "#channels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe1f60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "def chanels():\n",
    "    pq=list(channels)\n",
    "    p=[]\n",
    "    for j, i in enumerate(pq):\n",
    "        re.compile(r\"[\\w']+\")\n",
    "#         print(i)\n",
    "        i=list(i)\n",
    "        if len(i)<20:\n",
    "                #print(i)\n",
    "                #df=(df_english.filter(df_english.subreddit==str(i)))\n",
    "                df=df_english.where(df_english.subreddit==str(i))\n",
    "                chanel=df.toPandas()\n",
    "                chanel.to_csv(r'pandas.txt', header=None, index=None, sep=' ', mode='a')\n",
    "        if j>4:\n",
    "            break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ac8c8c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "chanels()n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64692116",
   "metadata": {},
   "outputs": [],
   "source": [
    "PPS=chanels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6a5868",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_english.select('subreddit').distinct().collect()\n",
    "spark.sparkContext.parallelize(range(1000)).map(str).countApproxDistinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3389620",
   "metadata": {},
   "outputs": [],
   "source": [
    "    pq=list(channels)\n",
    "    p=[]\n",
    "    for j, i in enumerate(pq):\n",
    "        re.compile(r\"[\\w']+\")\n",
    "#         print(i)\n",
    "        if len(i)<20:\n",
    "                i=list(i)\n",
    "                df=(df_english.filter(df_english.subreddit==str(i)))\n",
    "                chanel=df.toPandas()\n",
    "                chanel.to_csv(r'pandas.txt', header=None, index=None, sep=' ', mode='a')\n",
    "                #p.append(df)\n",
    "        \n",
    "        if j>2:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2551a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_english.where(df_english.subreddit==str(anime).show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6520623f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_english.select('subreddit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45650e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd =spark.sparkContext.parallelize(df_english[[('subreddit')]].collect())\n",
    "\n",
    "#spark.sparkContext.parallelize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de2b145",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd.countByKey().items()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b89a8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pp=chanels() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad21afd9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rdd.countApproxDistinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8278d1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 map_red_pup.py hdfs://namenode:9000/dis_materials/data_reddit.csv> output2.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a625c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in chanels():\n",
    "#     print(type(i))\n",
    "# #     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895bf63c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sub=list(channels)\n",
    "def subst():\n",
    "    subs=[ ]\n",
    "    for i in sub:\n",
    "        if len(i)<10:\n",
    "            subs.append(i)\n",
    "    return subs \n",
    "rr=list(subst())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90d2c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#p=df_english[['subreddit']].show()\n",
    "p=df_english[['subreddit']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0560ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "K=list(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a5e907",
   "metadata": {},
   "outputs": [],
   "source": [
    "p.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d192d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "countApproxDistinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3b2d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "redit=list(rr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292b639d",
   "metadata": {},
   "outputs": [],
   "source": [
    "redit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969614c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from mapred import subreddit as rd \n",
    "\n",
    "# mr_job = rd()\n",
    "# with mr_job.make_runner() as runner:\n",
    "#     runner.run()\n",
    "#     for line in runner.stream_output():\n",
    "#         #handle each line however you like\n",
    "#         print(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508c9fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #p.agg(countDistinct('subreddit'))\n",
    "\n",
    "# class subreddit(MRJob):\n",
    "#     re.compile(r\"[\\w']+\")\n",
    "#     def mapper(self,channel,):\n",
    "#         words = list(channel)\n",
    "#         for word in words:\n",
    "#             word.lower()\n",
    "#             kb=list(word.split())\n",
    "#             if len(kb)<5:\n",
    "#                 yield kb ,1\n",
    "\n",
    "#     def reducer(self, key, values):\n",
    "#         return {key: sum(values)}\n",
    "# if __name__ == '__main__':\n",
    "#     subreddit.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97704ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mapred import subreddit as rd\n",
    "!python3 mapred.py hdfs://namenode:9000/dis_materials/data_reddit.csv > chanel.csv  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b116527",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = pd.DataFrame(redit)\n",
    "# df.to_csv('filename.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf7826e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pa=subreddit(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330b2906",
   "metadata": {},
   "outputs": [],
   "source": [
    "rd.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d776c079",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapper(channel,):\n",
    "    re.compile(r\"[\\w']+\")\n",
    "    words = list(channel)\n",
    "    cha=[]\n",
    "    for word in words:\n",
    "        word=word.lower()\n",
    "        kb=list(word.split())\n",
    "        if len(kb)<3:\n",
    "            cha.append(kb)\n",
    "    return cha\n",
    "                \n",
    "mapper(channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2914a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pp_chanel():\n",
    "    #create a list of distinct chanels\n",
    "    mem=sub\n",
    "    #mem=list(df_english.select('subreddit').distinct().rdd.map(lambda r:r[0]).collect())\n",
    "    for i in mem:\n",
    "        yield i.upper(), 1\n",
    "\n",
    "def reducer(subreddit,value):\n",
    "    yield subreddit, value \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09603d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 mapred.py /home/ubuntu/chanel.csv> red.txt \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7b892f",
   "metadata": {},
   "outputs": [],
   "source": [
    "p=pp_chanel()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb84b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "reducer(p,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfaf0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# #export PYSPARK_SUBMIT_ARGS=\"--master local[1] pyspark-shell\"\n",
    "# df = spark.read.format('jdbc').\\\n",
    "#      options(url='jdbc:sqlite:may2015.sqlite',\\\n",
    "#      dbtable='\"hdfs://namenode:9000\\dis_materials\\atabase.sqlite\"',driver='org.sqlite.JDBC').load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb3e6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "￼\n",
    "\n",
    "# pd2=spark.read.csv(\"hdfs://namenode:9000/dis_materials/data_reddit.csv\")\n",
    "# pd2.show \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
