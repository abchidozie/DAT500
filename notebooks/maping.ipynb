{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd4832cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyspark.sql import SparkSession\n",
    "from langdetect import detect\n",
    "from pyspark.sql.functions import when, udf, col\n",
    "import pyspark as ps\n",
    "import datetime\n",
    "from pyspark.sql import functions as f\n",
    "from pyspark.sql import types as t\n",
    "from pyspark.sql.types import DateType\n",
    "from sparknlp.pretrained import PretrainedPipeline\n",
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0711ac9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparkShape(dataFrame):\n",
    "    return (dataFrame.count(), len(dataFrame.columns))\n",
    "ps.sql.dataframe.DataFrame.shape = sparkShape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "523df738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/usr/local/spark/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/ubuntu/.ivy2/cache\n",
      "The jars for the packages stored in: /home/ubuntu/.ivy2/jars\n",
      "com.johnsnowlabs.nlp#spark-nlp_2.12 added as a dependency\n",
      "org.apache.hadoop#hadoop-aws added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-a9628a9a-c7ba-4a7c-81f2-c508f487b86d;1.0\n",
      "\tconfs: [default]\n",
      "\tfound com.johnsnowlabs.nlp#spark-nlp_2.12;3.2.3 in central\n",
      "\tfound com.typesafe#config;1.4.1 in central\n",
      "\tfound org.rocksdb#rocksdbjni;6.5.3 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-bundle;1.11.603 in central\n",
      "\tfound com.github.universal-automata#liblevenshtein;3.0.0 in central\n",
      "\tfound com.google.code.findbugs#annotations;3.0.1 in central\n",
      "\tfound net.jcip#jcip-annotations;1.0 in central\n",
      "\tfound com.google.code.findbugs#jsr305;3.0.1 in central\n",
      "\tfound com.google.protobuf#protobuf-java-util;3.0.0-beta-3 in central\n",
      "\tfound com.google.protobuf#protobuf-java;3.0.0-beta-3 in central\n",
      "\tfound com.google.code.gson#gson;2.3 in central\n",
      "\tfound it.unimi.dsi#fastutil;7.0.12 in central\n",
      "\tfound org.projectlombok#lombok;1.16.8 in central\n",
      "\tfound org.slf4j#slf4j-api;1.7.21 in central\n",
      "\tfound com.navigamez#greex;1.0 in central\n",
      "\tfound dk.brics.automaton#automaton;1.11-8 in central\n",
      "\tfound org.json4s#json4s-ext_2.12;3.5.3 in central\n",
      "\tfound joda-time#joda-time;2.9.5 in central\n",
      "\tfound org.joda#joda-convert;1.8.1 in central\n",
      "\tfound com.johnsnowlabs.nlp#tensorflow-cpu_2.12;0.3.3 in central\n",
      "\tfound net.sf.trove4j#trove4j;3.0.3 in central\n",
      "\tfound org.apache.hadoop#hadoop-aws;2.7.3 in central\n",
      "\tfound org.apache.hadoop#hadoop-common;2.7.3 in central\n",
      "\tfound org.apache.hadoop#hadoop-annotations;2.7.3 in central\n",
      "\tfound com.google.guava#guava;11.0.2 in central\n",
      "\tfound commons-cli#commons-cli;1.2 in central\n",
      "\tfound org.apache.commons#commons-math3;3.1.1 in central\n",
      "\tfound xmlenc#xmlenc;0.52 in central\n",
      "\tfound commons-httpclient#commons-httpclient;3.1 in central\n",
      "\tfound commons-logging#commons-logging;1.1.3 in central\n",
      "\tfound commons-codec#commons-codec;1.4 in central\n",
      "\tfound commons-io#commons-io;2.4 in central\n",
      "\tfound commons-net#commons-net;3.1 in central\n",
      "\tfound commons-collections#commons-collections;3.2.2 in central\n",
      "\tfound javax.servlet#servlet-api;2.5 in central\n",
      "\tfound org.mortbay.jetty#jetty;6.1.26 in central\n",
      "\tfound org.mortbay.jetty#jetty-util;6.1.26 in central\n",
      "\tfound com.sun.jersey#jersey-core;1.9 in central\n",
      "\tfound com.sun.jersey#jersey-json;1.9 in central\n",
      "\tfound org.codehaus.jettison#jettison;1.1 in central\n",
      "\tfound com.sun.xml.bind#jaxb-impl;2.2.3-1 in central\n",
      "\tfound javax.xml.bind#jaxb-api;2.2.2 in central\n",
      "\tfound javax.xml.stream#stax-api;1.0-2 in central\n",
      "\tfound javax.activation#activation;1.1 in central\n",
      "\tfound org.codehaus.jackson#jackson-core-asl;1.9.13 in central\n",
      "\tfound org.codehaus.jackson#jackson-mapper-asl;1.9.13 in central\n",
      "\tfound org.codehaus.jackson#jackson-jaxrs;1.9.13 in central\n",
      "\tfound org.codehaus.jackson#jackson-xc;1.9.13 in central\n",
      "\tfound com.sun.jersey#jersey-server;1.9 in central\n",
      "\tfound asm#asm;3.2 in central\n",
      "\tfound log4j#log4j;1.2.17 in central\n",
      "\tfound net.java.dev.jets3t#jets3t;0.9.0 in central\n",
      "\tfound org.apache.httpcomponents#httpclient;4.2.5 in central\n",
      "\tfound org.apache.httpcomponents#httpcore;4.2.5 in central\n",
      "\tfound com.jamesmurty.utils#java-xmlbuilder;0.4 in central\n",
      "\tfound commons-lang#commons-lang;2.6 in central\n",
      "\tfound commons-configuration#commons-configuration;1.6 in central\n",
      "\tfound commons-digester#commons-digester;1.8 in central\n",
      "\tfound commons-beanutils#commons-beanutils;1.7.0 in central\n",
      "\tfound commons-beanutils#commons-beanutils-core;1.8.0 in central\n",
      "\tfound org.apache.avro#avro;1.7.4 in central\n",
      "\tfound com.thoughtworks.paranamer#paranamer;2.3 in central\n",
      "\tfound org.xerial.snappy#snappy-java;1.0.4.1 in central\n",
      "\tfound org.apache.commons#commons-compress;1.4.1 in central\n",
      "\tfound org.tukaani#xz;1.0 in central\n",
      "\tfound org.apache.hadoop#hadoop-auth;2.7.3 in central\n",
      "\tfound org.apache.directory.server#apacheds-kerberos-codec;2.0.0-M15 in central\n",
      "\tfound org.apache.directory.server#apacheds-i18n;2.0.0-M15 in central\n",
      "\tfound org.apache.directory.api#api-asn1-api;1.0.0-M20 in central\n",
      "\tfound org.apache.directory.api#api-util;1.0.0-M20 in central\n",
      "\tfound org.apache.zookeeper#zookeeper;3.4.6 in central\n",
      "\tfound org.slf4j#slf4j-log4j12;1.7.10 in central\n",
      "\tfound io.netty#netty;3.6.2.Final in central\n",
      "\tfound org.apache.curator#curator-framework;2.7.1 in central\n",
      "\tfound org.apache.curator#curator-client;2.7.1 in central\n",
      "\tfound com.jcraft#jsch;0.1.42 in central\n",
      "\tfound org.apache.curator#curator-recipes;2.7.1 in central\n",
      "\tfound org.apache.htrace#htrace-core;3.1.0-incubating in central\n",
      "\tfound javax.servlet.jsp#jsp-api;2.1 in central\n",
      "\tfound jline#jline;0.9.94 in central\n",
      "\tfound com.fasterxml.jackson.core#jackson-databind;2.2.3 in central\n",
      "\tfound com.fasterxml.jackson.core#jackson-annotations;2.2.3 in central\n",
      "\tfound com.fasterxml.jackson.core#jackson-core;2.2.3 in central\n",
      "\tfound com.amazonaws#aws-java-sdk;1.7.4 in central\n",
      "\tfound joda-time#joda-time;2.10.14 in central\n",
      "\t[2.10.14] joda-time#joda-time;[2.2,)\n",
      ":: resolution report :: resolve 3629ms :: artifacts dl 57ms\n",
      "\t:: modules in use:\n",
      "\tasm#asm;3.2 from central in [default]\n",
      "\tcom.amazonaws#aws-java-sdk;1.7.4 from central in [default]\n",
      "\tcom.amazonaws#aws-java-sdk-bundle;1.11.603 from central in [default]\n",
      "\tcom.fasterxml.jackson.core#jackson-annotations;2.2.3 from central in [default]\n",
      "\tcom.fasterxml.jackson.core#jackson-core;2.2.3 from central in [default]\n",
      "\tcom.fasterxml.jackson.core#jackson-databind;2.2.3 from central in [default]\n",
      "\tcom.github.universal-automata#liblevenshtein;3.0.0 from central in [default]\n",
      "\tcom.google.code.findbugs#annotations;3.0.1 from central in [default]\n",
      "\tcom.google.code.findbugs#jsr305;3.0.1 from central in [default]\n",
      "\tcom.google.code.gson#gson;2.3 from central in [default]\n",
      "\tcom.google.guava#guava;11.0.2 from central in [default]\n",
      "\tcom.google.protobuf#protobuf-java;3.0.0-beta-3 from central in [default]\n",
      "\tcom.google.protobuf#protobuf-java-util;3.0.0-beta-3 from central in [default]\n",
      "\tcom.jamesmurty.utils#java-xmlbuilder;0.4 from central in [default]\n",
      "\tcom.jcraft#jsch;0.1.42 from central in [default]\n",
      "\tcom.johnsnowlabs.nlp#spark-nlp_2.12;3.2.3 from central in [default]\n",
      "\tcom.johnsnowlabs.nlp#tensorflow-cpu_2.12;0.3.3 from central in [default]\n",
      "\tcom.navigamez#greex;1.0 from central in [default]\n",
      "\tcom.sun.jersey#jersey-core;1.9 from central in [default]\n",
      "\tcom.sun.jersey#jersey-json;1.9 from central in [default]\n",
      "\tcom.sun.jersey#jersey-server;1.9 from central in [default]\n",
      "\tcom.sun.xml.bind#jaxb-impl;2.2.3-1 from central in [default]\n",
      "\tcom.thoughtworks.paranamer#paranamer;2.3 from central in [default]\n",
      "\tcom.typesafe#config;1.4.1 from central in [default]\n",
      "\tcommons-beanutils#commons-beanutils;1.7.0 from central in [default]\n",
      "\tcommons-beanutils#commons-beanutils-core;1.8.0 from central in [default]\n",
      "\tcommons-cli#commons-cli;1.2 from central in [default]\n",
      "\tcommons-codec#commons-codec;1.4 from central in [default]\n",
      "\tcommons-collections#commons-collections;3.2.2 from central in [default]\n",
      "\tcommons-configuration#commons-configuration;1.6 from central in [default]\n",
      "\tcommons-digester#commons-digester;1.8 from central in [default]\n",
      "\tcommons-httpclient#commons-httpclient;3.1 from central in [default]\n",
      "\tcommons-io#commons-io;2.4 from central in [default]\n",
      "\tcommons-lang#commons-lang;2.6 from central in [default]\n",
      "\tcommons-logging#commons-logging;1.1.3 from central in [default]\n",
      "\tcommons-net#commons-net;3.1 from central in [default]\n",
      "\tdk.brics.automaton#automaton;1.11-8 from central in [default]\n",
      "\tio.netty#netty;3.6.2.Final from central in [default]\n",
      "\tit.unimi.dsi#fastutil;7.0.12 from central in [default]\n",
      "\tjavax.activation#activation;1.1 from central in [default]\n",
      "\tjavax.servlet#servlet-api;2.5 from central in [default]\n",
      "\tjavax.servlet.jsp#jsp-api;2.1 from central in [default]\n",
      "\tjavax.xml.bind#jaxb-api;2.2.2 from central in [default]\n",
      "\tjavax.xml.stream#stax-api;1.0-2 from central in [default]\n",
      "\tjline#jline;0.9.94 from central in [default]\n",
      "\tjoda-time#joda-time;2.10.14 from central in [default]\n",
      "\tlog4j#log4j;1.2.17 from central in [default]\n",
      "\tnet.java.dev.jets3t#jets3t;0.9.0 from central in [default]\n",
      "\tnet.jcip#jcip-annotations;1.0 from central in [default]\n",
      "\tnet.sf.trove4j#trove4j;3.0.3 from central in [default]\n",
      "\torg.apache.avro#avro;1.7.4 from central in [default]\n",
      "\torg.apache.commons#commons-compress;1.4.1 from central in [default]\n",
      "\torg.apache.commons#commons-math3;3.1.1 from central in [default]\n",
      "\torg.apache.curator#curator-client;2.7.1 from central in [default]\n",
      "\torg.apache.curator#curator-framework;2.7.1 from central in [default]\n",
      "\torg.apache.curator#curator-recipes;2.7.1 from central in [default]\n",
      "\torg.apache.directory.api#api-asn1-api;1.0.0-M20 from central in [default]\n",
      "\torg.apache.directory.api#api-util;1.0.0-M20 from central in [default]\n",
      "\torg.apache.directory.server#apacheds-i18n;2.0.0-M15 from central in [default]\n",
      "\torg.apache.directory.server#apacheds-kerberos-codec;2.0.0-M15 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-annotations;2.7.3 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-auth;2.7.3 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-aws;2.7.3 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-common;2.7.3 from central in [default]\n",
      "\torg.apache.htrace#htrace-core;3.1.0-incubating from central in [default]\n",
      "\torg.apache.httpcomponents#httpclient;4.2.5 from central in [default]\n",
      "\torg.apache.httpcomponents#httpcore;4.2.5 from central in [default]\n",
      "\torg.apache.zookeeper#zookeeper;3.4.6 from central in [default]\n",
      "\torg.codehaus.jackson#jackson-core-asl;1.9.13 from central in [default]\n",
      "\torg.codehaus.jackson#jackson-jaxrs;1.9.13 from central in [default]\n",
      "\torg.codehaus.jackson#jackson-mapper-asl;1.9.13 from central in [default]\n",
      "\torg.codehaus.jackson#jackson-xc;1.9.13 from central in [default]\n",
      "\torg.codehaus.jettison#jettison;1.1 from central in [default]\n",
      "\torg.joda#joda-convert;1.8.1 from central in [default]\n",
      "\torg.json4s#json4s-ext_2.12;3.5.3 from central in [default]\n",
      "\torg.mortbay.jetty#jetty;6.1.26 from central in [default]\n",
      "\torg.mortbay.jetty#jetty-util;6.1.26 from central in [default]\n",
      "\torg.projectlombok#lombok;1.16.8 from central in [default]\n",
      "\torg.rocksdb#rocksdbjni;6.5.3 from central in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.21 from central in [default]\n",
      "\torg.slf4j#slf4j-log4j12;1.7.10 from central in [default]\n",
      "\torg.tukaani#xz;1.0 from central in [default]\n",
      "\torg.xerial.snappy#snappy-java;1.0.4.1 from central in [default]\n",
      "\txmlenc#xmlenc;0.52 from central in [default]\n",
      "\t:: evicted modules:\n",
      "\tjoda-time#joda-time;2.9.5 by [joda-time#joda-time;2.10.14] in [default]\n",
      "\tcom.google.code.findbugs#jsr305;3.0.0 by [com.google.code.findbugs#jsr305;3.0.1] in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.10 by [org.slf4j#slf4j-api;1.7.21] in [default]\n",
      "\tcom.google.protobuf#protobuf-java;2.5.0 by [com.google.protobuf#protobuf-java;3.0.0-beta-3] in [default]\n",
      "\tcom.google.code.gson#gson;2.2.4 by [com.google.code.gson#gson;2.3] in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   89  |   1   |   0   |   5   ||   84  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-a9628a9a-c7ba-4a7c-81f2-c508f487b86d\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 84 already retrieved (0kB/27ms)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-24 12:17:58,611 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "2022-04-24 12:18:00,643 WARN util.Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "2022-04-24 12:18:00,644 WARN util.Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "2022-04-24 12:18:02,477 WARN yarn.Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.\n",
      "2022-04-24 12:18:27,912 WARN yarn.Client: Same path resource file:///home/ubuntu/.ivy2/jars/com.johnsnowlabs.nlp_spark-nlp_2.12-3.2.3.jar added multiple times to distributed cache.\n",
      "2022-04-24 12:18:27,913 WARN yarn.Client: Same path resource file:///home/ubuntu/.ivy2/jars/org.apache.hadoop_hadoop-aws-2.7.3.jar added multiple times to distributed cache.\n",
      "2022-04-24 12:18:27,913 WARN yarn.Client: Same path resource file:///home/ubuntu/.ivy2/jars/com.typesafe_config-1.4.1.jar added multiple times to distributed cache.\n",
      "2022-04-24 12:18:27,914 WARN yarn.Client: Same path resource file:///home/ubuntu/.ivy2/jars/org.rocksdb_rocksdbjni-6.5.3.jar added multiple times to distributed cache.\n",
      "2022-04-24 12:18:27,915 WARN yarn.Client: Same path resource file:///home/ubuntu/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.11.603.jar added multiple times to distributed cache.\n",
      "2022-04-24 12:18:27,915 WARN yarn.Client: Same path resource file:///home/ubuntu/.ivy2/jars/com.github.universal-automata_liblevenshtein-3.0.0.jar added multiple times to distributed cache.\n",
      "2022-04-24 12:18:27,915 WARN yarn.Client: Same path resource file:///home/ubuntu/.ivy2/jars/com.navigamez_greex-1.0.jar added multiple times to distributed cache.\n",
      "2022-04-24 12:18:27,916 WARN yarn.Client: Same path resource file:///home/ubuntu/.ivy2/jars/org.json4s_json4s-ext_2.12-3.5.3.jar added multiple times to distributed cache.\n",
      "2022-04-24 12:18:27,916 WARN yarn.Client: Same path resource file:///home/ubuntu/.ivy2/jars/com.johnsnowlabs.nlp_tensorflow-cpu_2.12-0.3.3.jar added multiple times to distributed cache.\n",
      "2022-04-24 12:18:27,917 WARN yarn.Client: Same path resource file:///home/ubuntu/.ivy2/jars/net.sf.trove4j_trove4j-3.0.3.jar added multiple times to distributed cache.\n",
      "2022-04-24 12:18:27,917 WARN yarn.Client: Same path resource file:///home/ubuntu/.ivy2/jars/com.google.code.findbugs_annotations-3.0.1.jar added multiple times to distributed cache.\n",
      "2022-04-24 12:18:27,917 WARN yarn.Client: Same path resource file:///home/ubuntu/.ivy2/jars/com.google.protobuf_protobuf-java-util-3.0.0-beta-3.jar added multiple times to distributed cache.\n",
      "2022-04-24 12:18:27,918 WARN yarn.Client: Same path resource file:///home/ubuntu/.ivy2/jars/com.google.protobuf_protobuf-java-3.0.0-beta-3.jar added multiple times to distributed cache.\n",
      "2022-04-24 12:18:27,918 WARN yarn.Client: Same path resource file:///home/ubuntu/.ivy2/jars/it.unimi.dsi_fastutil-7.0.12.jar added multiple times to distributed cache.\n",
      "2022-04-24 12:18:27,918 WARN yarn.Client: Same path resource file:///home/ubuntu/.ivy2/jars/org.projectlombok_lombok-1.16.8.jar added multiple times to distributed cache.\n",
      "2022-04-24 12:18:27,919 WARN yarn.Client: Same path resource file:///home/ubuntu/.ivy2/jars/org.slf4j_slf4j-api-1.7.21.jar added multiple times to distributed cache.\n",
      "2022-04-24 12:18:27,919 WARN yarn.Client: Same path resource file:///home/ubuntu/.ivy2/jars/net.jcip_jcip-annotations-1.0.jar added multiple times to distributed cache.\n",
      "2022-04-24 12:18:27,920 WARN yarn.Client: Same path resource file:///home/ubuntu/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.1.jar added multiple times to distributed cache.\n",
      "2022-04-24 12:18:27,920 WARN yarn.Client: Same path resource file:///home/ubuntu/.ivy2/jars/com.google.code.gson_gson-2.3.jar added multiple times to distributed cache.\n",
      "2022-04-24 12:18:27,920 WARN yarn.Client: Same path resource file:///home/ubuntu/.ivy2/jars/dk.brics.automaton_automaton-1.11-8.jar added multiple times to distributed cache.\n",
      "2022-04-24 12:18:27,921 WARN yarn.Client: Same path resource file:///home/ubuntu/.ivy2/jars/org.joda_joda-convert-1.8.1.jar added multiple times to distributed cache.\n",
      "2022-04-24 12:18:27,921 WARN yarn.Client: Same path resource file:///home/ubuntu/.ivy2/jars/org.apache.hadoop_hadoop-common-2.7.3.jar added multiple times to distributed cache.\n",
      "2022-04-24 12:18:27,921 WARN yarn.Client: Same path resource file:///home/ubuntu/.ivy2/jars/com.fasterxml.jackson.core_jackson-databind-2.2.3.jar added multiple times to distributed cache.\n",
      "2022-04-24 12:18:27,921 WARN yarn.Client: Same path resource file:///home/ubuntu/.ivy2/jars/com.fasterxml.jackson.core_jackson-annotations-2.2.3.jar added multiple times to distributed cache.\n",
      "2022-04-24 12:18:27,921 WARN yarn.Client: Same path resource file:///home/ubuntu/.ivy2/jars/com.amazonaws_aws-java-sdk-1.7.4.jar added multiple times to distributed cache.\n",
      "2022-04-24 12:18:27,922 WARN yarn.Client: Same path resource file:///home/ubuntu/.ivy2/jars/org.apache.hadoop_hadoop-annotations-2.7.3.jar added multiple times to distributed cache.\n",
      "2022-04-24 12:18:27,922 WARN yarn.Client: Same path resource file:///home/ubuntu/.ivy2/jars/com.google.guava_guava-11.0.2.jar added multiple times to distributed cache.\n",
      "2022-04-24 12:18:27,922 WARN yarn.Client: Same path resource file:///home/ubuntu/.ivy2/jars/commons-cli_commons-cli-1.2.jar added multiple times to distributed cache.\n",
      "2022-04-24 12:18:27,922 WARN yarn.Client: Same path resource file:///home/ubuntu/.ivy2/jars/org.apache.commons_commons-math3-3.1.1.jar added multiple times to distributed cache.\n",
      "2022-04-24 12:18:27,922 WARN yarn.Client: Same path resource file:///home/ubuntu/.ivy2/jars/xmlenc_xmlenc-0.52.jar added multiple times to distributed cache.\n",
      "2022-04-24 12:18:27,923 WARN yarn.Client: Same path resource file:///home/ubuntu/.ivy2/jars/commons-httpclient_commons-httpclient-3.1.jar added multiple times to distributed cache.\n",
      "2022-04-24 12:18:27,923 WARN yarn.Client: Same path resource file:///home/ubuntu/.ivy2/jars/commons-codec_commons-codec-1.4.jar added multiple times to distributed cache.\n",
      "2022-04-24 12:18:27,923 WARN yarn.Client: Same path resource file:///home/ubuntu/.ivy2/jars/commons-io_commons-io-2.4.jar added multiple times to distributed cache.\n",
      "2022-04-24 12:18:27,923 WARN yarn.Client: Same path resource file:///home/ubuntu/.ivy2/jars/commons-net_commons-net-3.1.jar added multiple times to distributed cache.\n",
      "2022-04-24 12:18:27,923 WARN yarn.Client: Same path resource file:///home/ubuntu/.ivy2/jars/commons-collections_commons-collections-3.2.2.jar added multiple times to distributed cache.\n",
      "2022-04-24 12:18:27,924 WARN yarn.Client: Same path resource file:///home/ubuntu/.ivy2/jars/javax.servlet_servlet-api-2.5.jar added multiple times to distributed cache.\n",
      "2022-04-24 12:18:27,924 WARN yarn.Client: Same path resource file:///home/ubuntu/.ivy2/jars/org.mortbay.jetty_jetty-6.1.26.jar added multiple times to distributed cache.\n",
      "2022-04-24 12:18:27,924 WARN yarn.Client: Same path resource file:///home/ubuntu/.ivy2/jars/org.mortbay.jetty_jetty-util-6.1.26.jar added multiple times to distributed cache.\n",
      "2022-04-24 12:18:27,924 WARN yarn.Client: Same path resource file:///home/ubuntu/.ivy2/jars/com.sun.jersey_jersey-core-1.9.jar added multiple times to distributed cache.\n",
      "2022-04-24 12:18:27,924 WARN yarn.Client: Same path resource file:///home/ubuntu/.ivy2/jars/com.sun.jersey_jersey-json-1.9.jar added multiple times to distributed cache.\n",
      "2022-04-24 12:18:27,925 WARN yarn.Client: Same path resource file:///home/ubuntu/.ivy2/jars/com.sun.jersey_jersey-server-1.9.jar added multiple times to distributed cache.\n",
      "2022-04-24 12:18:27,925 WARN yarn.Client: Same path resource file:///home/ubuntu/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar added multiple times to distributed cache.\n",
      "2022-04-24 12:18:27,925 WARN yarn.Client: Same path resource file:///home/ubuntu/.ivy2/jars/log4j_log4j-1.2.17.jar added multiple times to distributed cache.\n",
      "2022-04-24 12:18:27,925 WARN yarn.Client: Same path resource file:///home/ubuntu/.ivy2/jars/net.java.dev.jets3t_jets3t-0.9.0.jar added multiple times to distributed cache.\n",
      "2022-04-24 12:18:27,925 WARN yarn.Client: Same path resource file:///home/ubuntu/.ivy2/jars/commons-lang_commons-lang-2.6.jar added multiple times to distributed cache.\n",
      "2022-04-24 12:18:27,925 WARN yarn.Client: Same path resource file:///home/ubuntu/.ivy2/jars/commons-configuration_commons-configuration-1.6.jar added multiple times to distributed cache.\n",
      "2022-04-24 12:18:27,926 WARN yarn.Client: Same path resource file:///home/ubuntu/.ivy2/jars/org.codehaus.jackson_jackson-core-asl-1.9.13.jar added multiple times to distributed cache.\n",
      "2022-04-24 12:18:27,926 WARN yarn.Client: Same path resource file:///home/ubuntu/.ivy2/jars/org.codehaus.jackson_jackson-mapper-asl-1.9.13.jar added multiple times to distributed cache.\n",
      "2022-04-24 12:18:27,926 WARN yarn.Client: Same path resource file:///home/ubuntu/.ivy2/jars/org.apache.avro_avro-1.7.4.jar added multiple times to distributed cache.\n",
      "2022-04-24 12:18:27,926 WARN yarn.Client: Same path resource file:///home/ubuntu/.ivy2/jars/org.apache.hadoop_hadoop-auth-2.7.3.jar added multiple times to distributed cache.\n",
      "2022-04-24 12:18:27,926 WARN yarn.Client: Same path resource file:///home/ubuntu/.ivy2/jars/com.jcraft_jsch-0.1.42.jar added multiple times to distributed cache.\n",
      "2022-04-24 12:18:27,927 WARN yarn.Client: Same path resource file:///home/ubuntu/.ivy2/jars/org.apache.curator_curator-client-2.7.1.jar added multiple times to distributed cache.\n",
      "2022-04-24 12:18:27,927 WARN yarn.Client: Same path resource file:///home/ubuntu/.ivy2/jars/org.apache.curator_curator-recipes-2.7.1.jar added multiple times to distributed cache.\n",
      "2022-04-24 12:18:27,927 WARN yarn.Client: Same path resource file:///home/ubuntu/.ivy2/jars/org.apache.htrace_htrace-core-3.1.0-incubating.jar added multiple times to distributed cache.\n",
      "2022-04-24 12:18:27,927 WARN yarn.Client: Same path resource file:///home/ubuntu/.ivy2/jars/org.apache.zookeeper_zookeeper-3.4.6.jar added multiple times to distributed cache.\n",
      "2022-04-24 12:18:27,927 WARN yarn.Client: Same path resource file:///home/ubuntu/.ivy2/jars/org.apache.commons_commons-compress-1.4.1.jar added multiple times to distributed cache.\n",
      "2022-04-24 12:18:27,928 WARN yarn.Client: Same path resource file:///home/ubuntu/.ivy2/jars/org.codehaus.jettison_jettison-1.1.jar added multiple times to distributed cache.\n",
      "2022-04-24 12:18:27,928 WARN yarn.Client: Same path resource file:///home/ubuntu/.ivy2/jars/com.sun.xml.bind_jaxb-impl-2.2.3-1.jar added multiple times to distributed cache.\n",
      "2022-04-24 12:18:27,928 WARN yarn.Client: Same path resource file:///home/ubuntu/.ivy2/jars/org.codehaus.jackson_jackson-jaxrs-1.9.13.jar added multiple times to distributed cache.\n",
      "2022-04-24 12:18:27,928 WARN yarn.Client: Same path resource file:///home/ubuntu/.ivy2/jars/org.codehaus.jackson_jackson-xc-1.9.13.jar added multiple times to distributed cache.\n",
      "2022-04-24 12:18:27,928 WARN yarn.Client: Same path resource file:///home/ubuntu/.ivy2/jars/javax.xml.bind_jaxb-api-2.2.2.jar added multiple times to distributed cache.\n",
      "2022-04-24 12:18:27,929 WARN yarn.Client: Same path resource file:///home/ubuntu/.ivy2/jars/javax.xml.stream_stax-api-1.0-2.jar added multiple times to distributed cache.\n",
      "2022-04-24 12:18:27,929 WARN yarn.Client: Same path resource file:///home/ubuntu/.ivy2/jars/javax.activation_activation-1.1.jar added multiple times to distributed cache.\n",
      "2022-04-24 12:18:27,929 WARN yarn.Client: Same path resource file:///home/ubuntu/.ivy2/jars/asm_asm-3.2.jar added multiple times to distributed cache.\n",
      "2022-04-24 12:18:27,929 WARN yarn.Client: Same path resource file:///home/ubuntu/.ivy2/jars/org.apache.httpcomponents_httpclient-4.2.5.jar added multiple times to distributed cache.\n",
      "2022-04-24 12:18:27,929 WARN yarn.Client: Same path resource file:///home/ubuntu/.ivy2/jars/org.apache.httpcomponents_httpcore-4.2.5.jar added multiple times to distributed cache.\n",
      "2022-04-24 12:18:27,930 WARN yarn.Client: Same path resource file:///home/ubuntu/.ivy2/jars/com.jamesmurty.utils_java-xmlbuilder-0.4.jar added multiple times to distributed cache.\n",
      "2022-04-24 12:18:27,930 WARN yarn.Client: Same path resource file:///home/ubuntu/.ivy2/jars/commons-digester_commons-digester-1.8.jar added multiple times to distributed cache.\n",
      "2022-04-24 12:18:27,930 WARN yarn.Client: Same path resource file:///home/ubuntu/.ivy2/jars/commons-beanutils_commons-beanutils-core-1.8.0.jar added multiple times to distributed cache.\n",
      "2022-04-24 12:18:27,930 WARN yarn.Client: Same path resource file:///home/ubuntu/.ivy2/jars/commons-beanutils_commons-beanutils-1.7.0.jar added multiple times to distributed cache.\n",
      "2022-04-24 12:18:27,931 WARN yarn.Client: Same path resource file:///home/ubuntu/.ivy2/jars/com.thoughtworks.paranamer_paranamer-2.3.jar added multiple times to distributed cache.\n",
      "2022-04-24 12:18:27,931 WARN yarn.Client: Same path resource file:///home/ubuntu/.ivy2/jars/org.xerial.snappy_snappy-java-1.0.4.1.jar added multiple times to distributed cache.\n",
      "2022-04-24 12:18:27,931 WARN yarn.Client: Same path resource file:///home/ubuntu/.ivy2/jars/org.tukaani_xz-1.0.jar added multiple times to distributed cache.\n",
      "2022-04-24 12:18:27,931 WARN yarn.Client: Same path resource file:///home/ubuntu/.ivy2/jars/org.apache.directory.server_apacheds-kerberos-codec-2.0.0-M15.jar added multiple times to distributed cache.\n",
      "2022-04-24 12:18:27,931 WARN yarn.Client: Same path resource file:///home/ubuntu/.ivy2/jars/org.apache.curator_curator-framework-2.7.1.jar added multiple times to distributed cache.\n",
      "2022-04-24 12:18:27,931 WARN yarn.Client: Same path resource file:///home/ubuntu/.ivy2/jars/org.apache.directory.server_apacheds-i18n-2.0.0-M15.jar added multiple times to distributed cache.\n",
      "2022-04-24 12:18:27,932 WARN yarn.Client: Same path resource file:///home/ubuntu/.ivy2/jars/org.apache.directory.api_api-asn1-api-1.0.0-M20.jar added multiple times to distributed cache.\n",
      "2022-04-24 12:18:27,932 WARN yarn.Client: Same path resource file:///home/ubuntu/.ivy2/jars/org.apache.directory.api_api-util-1.0.0-M20.jar added multiple times to distributed cache.\n",
      "2022-04-24 12:18:27,932 WARN yarn.Client: Same path resource file:///home/ubuntu/.ivy2/jars/org.slf4j_slf4j-log4j12-1.7.10.jar added multiple times to distributed cache.\n",
      "2022-04-24 12:18:27,932 WARN yarn.Client: Same path resource file:///home/ubuntu/.ivy2/jars/io.netty_netty-3.6.2.Final.jar added multiple times to distributed cache.\n",
      "2022-04-24 12:18:27,932 WARN yarn.Client: Same path resource file:///home/ubuntu/.ivy2/jars/javax.servlet.jsp_jsp-api-2.1.jar added multiple times to distributed cache.\n",
      "2022-04-24 12:18:27,933 WARN yarn.Client: Same path resource file:///home/ubuntu/.ivy2/jars/jline_jline-0.9.94.jar added multiple times to distributed cache.\n",
      "2022-04-24 12:18:27,933 WARN yarn.Client: Same path resource file:///home/ubuntu/.ivy2/jars/com.fasterxml.jackson.core_jackson-core-2.2.3.jar added multiple times to distributed cache.\n",
      "2022-04-24 12:18:27,933 WARN yarn.Client: Same path resource file:///home/ubuntu/.ivy2/jars/joda-time_joda-time-2.10.14.jar added multiple times to distributed cache.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"maping\")\\\n",
    "    .master(\"yarn\")\\\n",
    "    .config(\"spark.driver.spark.driver.cores\",\"4\")\\\n",
    "    .config(\"spark.executor.memoryOverhead\",\"2048\")\\\n",
    "    .config(\"spark.driver.maxResultSize\", \"0\") \\\n",
    "    .config(\"spark.kryoserializer.buffer.max\", \"2000M\")\\\n",
    "    .config(\"spark.jars.packages\", \"com.johnsnowlabs.nlp:spark-nlp_2.12:3.2.3,org.apache.hadoop:hadoop-aws:2.7.3\")\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81be5f3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.format(\"csv\").option(\"header\",\"true\").load(\"hdfs://namenode:9000/dis_materials/data_reddit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b47c454",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "No configs specified for spark runner\n",
      "Looking for hadoop binary in /usr/local/hadoop/bin...\n",
      "Found hadoop binary: /usr/local/hadoop/bin/hadoop\n",
      "Looking for spark-submit binary in /usr/local/spark/bin...\n",
      "Found spark-submit binary: /usr/local/spark/bin/spark-submit\n",
      "Running steps 1-2 of 2\n",
      "Creating temp directory /tmp/map_red_pup.ubuntu.20220429.155218.072012\n",
      "  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "  Running Spark version 3.2.0\n",
      "  ==============================================================\n",
      "  No custom resources configured for spark.driver.\n",
      "  ==============================================================\n",
      "  Submitted application: harness.py\n",
      "  Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)\n",
      "  Limiting resource is cpu\n",
      "  Added ResourceProfile id: 0\n",
      "  Changing view acls to: ubuntu\n",
      "  Changing modify acls to: ubuntu\n",
      "  Changing view acls groups to: \n",
      "  Changing modify acls groups to: \n",
      "  SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ubuntu); groups with view permissions: Set(); users  with modify permissions: Set(ubuntu); groups with modify permissions: Set()\n",
      "  Successfully started service 'sparkDriver' on port 37955.\n",
      "  Registering MapOutputTracker\n",
      "  Registering BlockManagerMaster\n",
      "  Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information\n",
      "  BlockManagerMasterEndpoint up\n",
      "  Registering BlockManagerMasterHeartbeat\n",
      "  Created local directory at /tmp/blockmgr-abb86a26-29ce-4e82-9925-6d671292187b\n",
      "  MemoryStore started with capacity 366.3 MiB\n",
      "  Registering OutputCommitCoordinator\n",
      "  Logging initialized @3961ms to org.sparkproject.jetty.util.log.Slf4jLog\n",
      "  jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_312-8u312-b07-0ubuntu1~20.04-b07\n",
      "  Started @4136ms\n",
      "  Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "  Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "  Started ServerConnector@49c49507{HTTP/1.1, (http/1.1)}{0.0.0.0:4042}\n",
      "  Successfully started service 'SparkUI' on port 4042.\n",
      "  Started o.s.j.s.ServletContextHandler@3b937a1{/jobs,null,AVAILABLE,@Spark}\n",
      "  Started o.s.j.s.ServletContextHandler@cedc0dd{/jobs/json,null,AVAILABLE,@Spark}\n",
      "  Started o.s.j.s.ServletContextHandler@5ba0c16c{/jobs/job,null,AVAILABLE,@Spark}\n",
      "  Started o.s.j.s.ServletContextHandler@4b132536{/jobs/job/json,null,AVAILABLE,@Spark}\n",
      "  Started o.s.j.s.ServletContextHandler@67d48530{/stages,null,AVAILABLE,@Spark}\n",
      "  Started o.s.j.s.ServletContextHandler@a0f3447{/stages/json,null,AVAILABLE,@Spark}\n",
      "  Started o.s.j.s.ServletContextHandler@217d7919{/stages/stage,null,AVAILABLE,@Spark}\n",
      "  Started o.s.j.s.ServletContextHandler@20eeac1{/stages/stage/json,null,AVAILABLE,@Spark}\n",
      "  Started o.s.j.s.ServletContextHandler@499e3cf{/stages/pool,null,AVAILABLE,@Spark}\n",
      "  Started o.s.j.s.ServletContextHandler@36b9d425{/stages/pool/json,null,AVAILABLE,@Spark}\n",
      "  Started o.s.j.s.ServletContextHandler@765bb279{/storage,null,AVAILABLE,@Spark}\n",
      "  Started o.s.j.s.ServletContextHandler@6efc2b1a{/storage/json,null,AVAILABLE,@Spark}\n",
      "  Started o.s.j.s.ServletContextHandler@454483cc{/storage/rdd,null,AVAILABLE,@Spark}\n",
      "  Started o.s.j.s.ServletContextHandler@3a6b7bf0{/storage/rdd/json,null,AVAILABLE,@Spark}\n",
      "  Started o.s.j.s.ServletContextHandler@cc0ebd2{/environment,null,AVAILABLE,@Spark}\n",
      "  Started o.s.j.s.ServletContextHandler@59f41d86{/environment/json,null,AVAILABLE,@Spark}\n",
      "  Started o.s.j.s.ServletContextHandler@65572044{/executors,null,AVAILABLE,@Spark}\n",
      "  Started o.s.j.s.ServletContextHandler@2e09832c{/executors/json,null,AVAILABLE,@Spark}\n",
      "  Started o.s.j.s.ServletContextHandler@a7b3a22{/executors/threadDump,null,AVAILABLE,@Spark}\n",
      "  Started o.s.j.s.ServletContextHandler@7a90acb8{/executors/threadDump/json,null,AVAILABLE,@Spark}\n",
      "  Started o.s.j.s.ServletContextHandler@6cf3ce1e{/static,null,AVAILABLE,@Spark}\n",
      "  Started o.s.j.s.ServletContextHandler@537f7b24{/,null,AVAILABLE,@Spark}\n",
      "  Started o.s.j.s.ServletContextHandler@54b89dcd{/api,null,AVAILABLE,@Spark}\n",
      "  Started o.s.j.s.ServletContextHandler@281da6f5{/jobs/job/kill,null,AVAILABLE,@Spark}\n",
      "  Started o.s.j.s.ServletContextHandler@5eaa959b{/stages/stage/kill,null,AVAILABLE,@Spark}\n",
      "  Bound SparkUI to 0.0.0.0, and started at http://namenode:4042\n",
      "  Added file file:///tmp/map_red_pup.ubuntu.20220429.155218.072012/mrjob.zip at file:///tmp/map_red_pup.ubuntu.20220429.155218.072012/mrjob.zip with timestamp 1651247546047\n",
      "  Copying /tmp/map_red_pup.ubuntu.20220429.155218.072012/mrjob.zip to /tmp/spark-f2056e2b-8841-4a05-9b71-b76fce8f504f/userFiles-3e6ffe4e-5e93-430a-93a8-8eaae37aaf17/mrjob.zip\n",
      "  Added file file:///tmp/map_red_pup.ubuntu.20220429.155218.072012/script.zip at file:///tmp/map_red_pup.ubuntu.20220429.155218.072012/script.zip with timestamp 1651247546047\n",
      "  Copying /tmp/map_red_pup.ubuntu.20220429.155218.072012/script.zip to /tmp/spark-f2056e2b-8841-4a05-9b71-b76fce8f504f/userFiles-3e6ffe4e-5e93-430a-93a8-8eaae37aaf17/script.zip\n",
      "  Starting executor ID driver on host namenode\n",
      "  Fetching file:///tmp/map_red_pup.ubuntu.20220429.155218.072012/mrjob.zip with timestamp 1651247546047\n",
      "  /tmp/map_red_pup.ubuntu.20220429.155218.072012/mrjob.zip has been previously copied to /tmp/spark-f2056e2b-8841-4a05-9b71-b76fce8f504f/userFiles-3e6ffe4e-5e93-430a-93a8-8eaae37aaf17/mrjob.zip\n",
      "  Fetching file:///tmp/map_red_pup.ubuntu.20220429.155218.072012/script.zip with timestamp 1651247546047\n",
      "  /tmp/map_red_pup.ubuntu.20220429.155218.072012/script.zip has been previously copied to /tmp/spark-f2056e2b-8841-4a05-9b71-b76fce8f504f/userFiles-3e6ffe4e-5e93-430a-93a8-8eaae37aaf17/script.zip\n",
      "  Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45181.\n",
      "  Server created on namenode:45181\n",
      "  Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy\n",
      "  Registering BlockManager BlockManagerId(driver, namenode, 45181, None)\n",
      "  Registering block manager namenode:45181 with 366.3 MiB RAM, BlockManagerId(driver, namenode, 45181, None)\n",
      "  Registered BlockManager BlockManagerId(driver, namenode, 45181, None)\n",
      "  Initialized BlockManager: BlockManagerId(driver, namenode, 45181, None)\n",
      "  Started o.s.j.s.ServletContextHandler@4ba9264c{/metrics/json,null,AVAILABLE,@Spark}\n",
      "  Block broadcast_0 stored as values in memory (estimated size 410.9 KiB, free 365.9 MiB)\n",
      "  Block broadcast_0_piece0 stored as bytes in memory (estimated size 42.1 KiB, free 365.9 MiB)\n",
      "  Added broadcast_0_piece0 in memory on namenode:45181 (size: 42.1 KiB, free: 366.3 MiB)\n",
      "  Created broadcast 0 from textFile at NativeMethodAccessorImpl.java:0\n",
      "  Total input files to process : 1\n",
      "  mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Starting job: runJob at SparkHadoopWriter.scala:83\n",
      "  Registering RDD 3 (groupBy at /home/ubuntu/.local/lib/python3.8/site-packages/mrjob/spark/harness.py:539) as input to shuffle 1\n",
      "  Registering RDD 7 (groupBy at /home/ubuntu/.local/lib/python3.8/site-packages/mrjob/spark/harness.py:539) as input to shuffle 0\n",
      "  Got job 0 (runJob at SparkHadoopWriter.scala:83) with 121 output partitions\n",
      "  Final stage: ResultStage 2 (runJob at SparkHadoopWriter.scala:83)\n",
      "  Parents of final stage: List(ShuffleMapStage 1)\n",
      "  Missing parents: List(ShuffleMapStage 1)\n",
      "  Submitting ShuffleMapStage 0 (PairwiseRDD[3] at groupBy at /home/ubuntu/.local/lib/python3.8/site-packages/mrjob/spark/harness.py:539), which has no missing parents\n",
      "  Block broadcast_1 stored as values in memory (estimated size 15.8 KiB, free 365.8 MiB)\n",
      "  Block broadcast_1_piece0 stored as bytes in memory (estimated size 9.5 KiB, free 365.8 MiB)\n",
      "  Added broadcast_1_piece0 in memory on namenode:45181 (size: 9.5 KiB, free: 366.2 MiB)\n",
      "  Created broadcast 1 from broadcast at DAGScheduler.scala:1427\n",
      "  Submitting 121 missing tasks from ShuffleMapStage 0 (PairwiseRDD[3] at groupBy at /home/ubuntu/.local/lib/python3.8/site-packages/mrjob/spark/harness.py:539) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Adding task set 0.0 with 121 tasks resource profile 0\n",
      "  Starting task 0.0 in stage 0.0 (TID 0) (namenode, executor driver, partition 0, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Starting task 1.0 in stage 0.0 (TID 1) (namenode, executor driver, partition 1, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Starting task 2.0 in stage 0.0 (TID 2) (namenode, executor driver, partition 2, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Starting task 3.0 in stage 0.0 (TID 3) (namenode, executor driver, partition 3, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 2.0 in stage 0.0 (TID 2)\n",
      "  Running task 0.0 in stage 0.0 (TID 0)\n",
      "  Running task 3.0 in stage 0.0 (TID 3)\n",
      "  Running task 1.0 in stage 0.0 (TID 1)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:134217728+134217728\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:402653184+134217728\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:268435456+134217728\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:0+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 7237, boot = 420, init = 283, finish = 6534\n",
      "  Times: total = 7211, boot = 333, init = 352, finish = 6526\n",
      "  Times: total = 7669, boot = 550, init = 542, finish = 6577\n",
      "  Finished task 0.0 in stage 0.0 (TID 0). 1943 bytes result sent to driver\n",
      "  Finished task 1.0 in stage 0.0 (TID 1). 1900 bytes result sent to driver\n",
      "  Finished task 2.0 in stage 0.0 (TID 2). 1943 bytes result sent to driver\n",
      "  Starting task 4.0 in stage 0.0 (TID 4) (namenode, executor driver, partition 4, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 4.0 in stage 0.0 (TID 4)\n",
      "  Starting task 5.0 in stage 0.0 (TID 5) (namenode, executor driver, partition 5, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 5.0 in stage 0.0 (TID 5)\n",
      "  Times: total = 7612, boot = 403, init = 305, finish = 6904\n",
      "  Starting task 6.0 in stage 0.0 (TID 6) (namenode, executor driver, partition 6, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 6.0 in stage 0.0 (TID 6)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:671088640+134217728\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:536870912+134217728\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:805306368+134217728\n",
      "  Finished task 1.0 in stage 0.0 (TID 1) in 8817 ms on namenode (executor driver) (1/121)\n",
      "  Finished task 2.0 in stage 0.0 (TID 2) in 8833 ms on namenode (executor driver) (2/121)\n",
      "  Finished task 0.0 in stage 0.0 (TID 0) in 8860 ms on namenode (executor driver) (3/121)\n",
      "  Connected to AccumulatorServer at host: 127.0.0.1 port: 48355\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Finished task 3.0 in stage 0.0 (TID 3). 1900 bytes result sent to driver\n",
      "  Starting task 7.0 in stage 0.0 (TID 7) (namenode, executor driver, partition 7, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 7.0 in stage 0.0 (TID 7)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:939524096+134217728\n",
      "  Finished task 3.0 in stage 0.0 (TID 3) in 8880 ms on namenode (executor driver) (4/121)\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6157, boot = -819, init = 837, finish = 6139\n",
      "  Finished task 4.0 in stage 0.0 (TID 4). 1900 bytes result sent to driver\n",
      "  Starting task 8.0 in stage 0.0 (TID 8) (namenode, executor driver, partition 8, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 4.0 in stage 0.0 (TID 4) in 6546 ms on namenode (executor driver) (5/121)\n",
      "  Running task 8.0 in stage 0.0 (TID 8)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:1073741824+134217728\n",
      "  Times: total = 6438, boot = -794, init = 807, finish = 6425\n",
      "  Finished task 6.0 in stage 0.0 (TID 6). 1900 bytes result sent to driver\n",
      "  Starting task 9.0 in stage 0.0 (TID 9) (namenode, executor driver, partition 9, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 9.0 in stage 0.0 (TID 9)\n",
      "  Finished task 6.0 in stage 0.0 (TID 6) in 6811 ms on namenode (executor driver) (6/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:1207959552+134217728\n",
      "  Times: total = 6554, boot = -596, init = 603, finish = 6547\n",
      "  Finished task 5.0 in stage 0.0 (TID 5). 1900 bytes result sent to driver\n",
      "  Starting task 10.0 in stage 0.0 (TID 10) (namenode, executor driver, partition 10, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 10.0 in stage 0.0 (TID 10)\n",
      "  Finished task 5.0 in stage 0.0 (TID 5) in 6982 ms on namenode (executor driver) (7/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:1342177280+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6701, boot = -544, init = 552, finish = 6693\n",
      "  Finished task 7.0 in stage 0.0 (TID 7). 1900 bytes result sent to driver\n",
      "  Starting task 11.0 in stage 0.0 (TID 11) (namenode, executor driver, partition 11, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 7.0 in stage 0.0 (TID 7) in 7149 ms on namenode (executor driver) (8/121)\n",
      "  Running task 11.0 in stage 0.0 (TID 11)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:1476395008+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6149, boot = -403, init = 411, finish = 6141\n",
      "  Finished task 8.0 in stage 0.0 (TID 8). 1900 bytes result sent to driver\n",
      "  Starting task 12.0 in stage 0.0 (TID 12) (namenode, executor driver, partition 12, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 12.0 in stage 0.0 (TID 12)\n",
      "  Finished task 8.0 in stage 0.0 (TID 8) in 6335 ms on namenode (executor driver) (9/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:1610612736+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 5978, boot = -340, init = 358, finish = 5960\n",
      "  Finished task 9.0 in stage 0.0 (TID 9). 1900 bytes result sent to driver\n",
      "  Starting task 13.0 in stage 0.0 (TID 13) (namenode, executor driver, partition 13, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 9.0 in stage 0.0 (TID 9) in 6185 ms on namenode (executor driver) (10/121)\n",
      "  Running task 13.0 in stage 0.0 (TID 13)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:1744830464+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6342, boot = -341, init = 350, finish = 6333\n",
      "  Finished task 10.0 in stage 0.0 (TID 10). 1900 bytes result sent to driver\n",
      "  Starting task 14.0 in stage 0.0 (TID 14) (namenode, executor driver, partition 14, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 10.0 in stage 0.0 (TID 10) in 6567 ms on namenode (executor driver) (11/121)\n",
      "  Running task 14.0 in stage 0.0 (TID 14)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:1879048192+134217728\n",
      "  Times: total = 6752, boot = -466, init = 481, finish = 6737\n",
      "  Finished task 11.0 in stage 0.0 (TID 11). 1900 bytes result sent to driver\n",
      "  Starting task 15.0 in stage 0.0 (TID 15) (namenode, executor driver, partition 15, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 11.0 in stage 0.0 (TID 11) in 6976 ms on namenode (executor driver) (12/121)\n",
      "  Running task 15.0 in stage 0.0 (TID 15)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:2013265920+134217728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 5771, boot = -104, init = 126, finish = 5749\n",
      "  Finished task 12.0 in stage 0.0 (TID 12). 1900 bytes result sent to driver\n",
      "  Starting task 16.0 in stage 0.0 (TID 16) (namenode, executor driver, partition 16, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 12.0 in stage 0.0 (TID 12) in 5925 ms on namenode (executor driver) (13/121)\n",
      "  Running task 16.0 in stage 0.0 (TID 16)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:2147483648+134217728\n",
      "  Times: total = 5698, boot = -176, init = 190, finish = 5684\n",
      "  Finished task 13.0 in stage 0.0 (TID 13). 1900 bytes result sent to driver\n",
      "  Starting task 17.0 in stage 0.0 (TID 17) (namenode, executor driver, partition 17, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 17.0 in stage 0.0 (TID 17)\n",
      "  Finished task 13.0 in stage 0.0 (TID 13) in 5933 ms on namenode (executor driver) (14/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:2281701376+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6258, boot = -186, init = 189, finish = 6255\n",
      "  Finished task 14.0 in stage 0.0 (TID 14). 1900 bytes result sent to driver\n",
      "  Starting task 18.0 in stage 0.0 (TID 18) (namenode, executor driver, partition 18, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 14.0 in stage 0.0 (TID 14) in 6322 ms on namenode (executor driver) (15/121)\n",
      "  Running task 18.0 in stage 0.0 (TID 18)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:2415919104+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6014, boot = -152, init = 156, finish = 6010\n",
      "  Finished task 15.0 in stage 0.0 (TID 15). 1900 bytes result sent to driver\n",
      "  Starting task 19.0 in stage 0.0 (TID 19) (namenode, executor driver, partition 19, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 15.0 in stage 0.0 (TID 15) in 6147 ms on namenode (executor driver) (16/121)\n",
      "  Running task 19.0 in stage 0.0 (TID 19)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:2550136832+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 5945, boot = -187, init = 201, finish = 5931\n",
      "  Finished task 17.0 in stage 0.0 (TID 17). 1900 bytes result sent to driver\n",
      "  Starting task 20.0 in stage 0.0 (TID 20) (namenode, executor driver, partition 20, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 20.0 in stage 0.0 (TID 20)\n",
      "  Finished task 17.0 in stage 0.0 (TID 17) in 6075 ms on namenode (executor driver) (17/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:2684354560+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6129, boot = -138, init = 146, finish = 6121\n",
      "  Finished task 16.0 in stage 0.0 (TID 16). 1900 bytes result sent to driver\n",
      "  Starting task 21.0 in stage 0.0 (TID 21) (namenode, executor driver, partition 21, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 21.0 in stage 0.0 (TID 21)\n",
      "  Finished task 16.0 in stage 0.0 (TID 16) in 6351 ms on namenode (executor driver) (18/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:2818572288+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 5902, boot = -97, init = 103, finish = 5896\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Finished task 18.0 in stage 0.0 (TID 18). 1900 bytes result sent to driver\n",
      "  Starting task 22.0 in stage 0.0 (TID 22) (namenode, executor driver, partition 22, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 22.0 in stage 0.0 (TID 22)\n",
      "  Finished task 18.0 in stage 0.0 (TID 18) in 6243 ms on namenode (executor driver) (19/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:2952790016+134217728\n",
      "  Times: total = 6224, boot = -106, init = 109, finish = 6221\n",
      "  Finished task 19.0 in stage 0.0 (TID 19). 1900 bytes result sent to driver\n",
      "  Starting task 23.0 in stage 0.0 (TID 23) (namenode, executor driver, partition 23, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 23.0 in stage 0.0 (TID 23)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:3087007744+134217728\n",
      "  Finished task 19.0 in stage 0.0 (TID 19) in 6320 ms on namenode (executor driver) (20/121)\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 5812, boot = -90, init = 110, finish = 5792\n",
      "  Finished task 20.0 in stage 0.0 (TID 20). 1900 bytes result sent to driver\n",
      "  Starting task 24.0 in stage 0.0 (TID 24) (namenode, executor driver, partition 24, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 20.0 in stage 0.0 (TID 20) in 5940 ms on namenode (executor driver) (21/121)\n",
      "  Running task 24.0 in stage 0.0 (TID 24)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:3221225472+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6139, boot = -218, init = 230, finish = 6127\n",
      "  Finished task 21.0 in stage 0.0 (TID 21). 1900 bytes result sent to driver\n",
      "  Starting task 25.0 in stage 0.0 (TID 25) (namenode, executor driver, partition 25, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 21.0 in stage 0.0 (TID 21) in 6323 ms on namenode (executor driver) (22/121)\n",
      "  Running task 25.0 in stage 0.0 (TID 25)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:3355443200+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6218, boot = -294, init = 300, finish = 6212\n",
      "  Finished task 22.0 in stage 0.0 (TID 22). 1900 bytes result sent to driver\n",
      "  Starting task 26.0 in stage 0.0 (TID 26) (namenode, executor driver, partition 26, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 22.0 in stage 0.0 (TID 22) in 6388 ms on namenode (executor driver) (23/121)\n",
      "  Running task 26.0 in stage 0.0 (TID 26)\n",
      "  Times: total = 5863, boot = -35, init = 69, finish = 5829\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:3489660928+134217728\n",
      "  Finished task 23.0 in stage 0.0 (TID 23). 1900 bytes result sent to driver\n",
      "  Starting task 27.0 in stage 0.0 (TID 27) (namenode, executor driver, partition 27, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 23.0 in stage 0.0 (TID 23) in 5972 ms on namenode (executor driver) (24/121)\n",
      "  Running task 27.0 in stage 0.0 (TID 27)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:3623878656+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 5820, boot = -157, init = 172, finish = 5805\n",
      "  Finished task 24.0 in stage 0.0 (TID 24). 1900 bytes result sent to driver\n",
      "  Starting task 28.0 in stage 0.0 (TID 28) (namenode, executor driver, partition 28, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 28.0 in stage 0.0 (TID 28)\n",
      "  Finished task 24.0 in stage 0.0 (TID 24) in 6016 ms on namenode (executor driver) (25/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:3758096384+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 5694, boot = -168, init = 173, finish = 5689\n",
      "  Finished task 25.0 in stage 0.0 (TID 25). 1900 bytes result sent to driver\n",
      "  Starting task 29.0 in stage 0.0 (TID 29) (namenode, executor driver, partition 29, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 25.0 in stage 0.0 (TID 25) in 5954 ms on namenode (executor driver) (26/121)\n",
      "  Running task 29.0 in stage 0.0 (TID 29)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:3892314112+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 5901, boot = -138, init = 159, finish = 5880\n",
      "  Finished task 27.0 in stage 0.0 (TID 27). 1900 bytes result sent to driver\n",
      "  Starting task 30.0 in stage 0.0 (TID 30) (namenode, executor driver, partition 30, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 30.0 in stage 0.0 (TID 30)\n",
      "  Finished task 27.0 in stage 0.0 (TID 27) in 6035 ms on namenode (executor driver) (27/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:4026531840+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6704, boot = -196, init = 222, finish = 6678\n",
      "  Finished task 26.0 in stage 0.0 (TID 26). 1900 bytes result sent to driver\n",
      "  Starting task 31.0 in stage 0.0 (TID 31) (namenode, executor driver, partition 31, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 31.0 in stage 0.0 (TID 31)\n",
      "  Finished task 26.0 in stage 0.0 (TID 26) in 6994 ms on namenode (executor driver) (28/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:4160749568+134217728\n",
      "  Times: total = 5771, boot = -144, init = 146, finish = 5769\n",
      "  Finished task 28.0 in stage 0.0 (TID 28). 1900 bytes result sent to driver\n",
      "  Starting task 32.0 in stage 0.0 (TID 32) (namenode, executor driver, partition 32, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 32.0 in stage 0.0 (TID 32)\n",
      "  Finished task 28.0 in stage 0.0 (TID 28) in 5920 ms on namenode (executor driver) (29/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:4294967296+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6046, boot = -187, init = 206, finish = 6027\n",
      "  Finished task 29.0 in stage 0.0 (TID 29). 1900 bytes result sent to driver\n",
      "  Starting task 33.0 in stage 0.0 (TID 33) (namenode, executor driver, partition 33, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 29.0 in stage 0.0 (TID 29) in 6239 ms on namenode (executor driver) (30/121)\n",
      "  Running task 33.0 in stage 0.0 (TID 33)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:4429185024+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6011, boot = -129, init = 163, finish = 5977\n",
      "  Finished task 30.0 in stage 0.0 (TID 30). 1943 bytes result sent to driver\n",
      "  Starting task 34.0 in stage 0.0 (TID 34) (namenode, executor driver, partition 34, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 30.0 in stage 0.0 (TID 30) in 6169 ms on namenode (executor driver) (31/121)\n",
      "  Running task 34.0 in stage 0.0 (TID 34)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:4563402752+134217728\n",
      "  Times: total = 6039, boot = -170, init = 195, finish = 6014\n",
      "  Finished task 31.0 in stage 0.0 (TID 31). 1900 bytes result sent to driver\n",
      "  Starting task 35.0 in stage 0.0 (TID 35) (namenode, executor driver, partition 35, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 31.0 in stage 0.0 (TID 31) in 6166 ms on namenode (executor driver) (32/121)\n",
      "  Running task 35.0 in stage 0.0 (TID 35)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:4697620480+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6038, boot = -159, init = 162, finish = 6035\n",
      "  Finished task 32.0 in stage 0.0 (TID 32). 1900 bytes result sent to driver\n",
      "  Starting task 36.0 in stage 0.0 (TID 36) (namenode, executor driver, partition 36, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 36.0 in stage 0.0 (TID 36)\n",
      "  Finished task 32.0 in stage 0.0 (TID 32) in 6222 ms on namenode (executor driver) (33/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:4831838208+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 5732, boot = -175, init = 186, finish = 5721\n",
      "  Finished task 33.0 in stage 0.0 (TID 33). 1900 bytes result sent to driver\n",
      "  Starting task 37.0 in stage 0.0 (TID 37) (namenode, executor driver, partition 37, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 33.0 in stage 0.0 (TID 33) in 5853 ms on namenode (executor driver) (34/121)\n",
      "  Running task 37.0 in stage 0.0 (TID 37)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:4966055936+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6211, boot = -136, init = 144, finish = 6203\n",
      "  Finished task 34.0 in stage 0.0 (TID 34). 1900 bytes result sent to driver\n",
      "  Starting task 38.0 in stage 0.0 (TID 38) (namenode, executor driver, partition 38, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 38.0 in stage 0.0 (TID 38)\n",
      "  Finished task 34.0 in stage 0.0 (TID 34) in 6299 ms on namenode (executor driver) (35/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:5100273664+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6345, boot = -187, init = 192, finish = 6340\n",
      "  Finished task 35.0 in stage 0.0 (TID 35). 1900 bytes result sent to driver\n",
      "  Starting task 39.0 in stage 0.0 (TID 39) (namenode, executor driver, partition 39, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 39.0 in stage 0.0 (TID 39)\n",
      "  Finished task 35.0 in stage 0.0 (TID 35) in 6496 ms on namenode (executor driver) (36/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:5234491392+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 5905, boot = -165, init = 177, finish = 5893\n",
      "  Finished task 36.0 in stage 0.0 (TID 36). 1900 bytes result sent to driver\n",
      "  Starting task 40.0 in stage 0.0 (TID 40) (namenode, executor driver, partition 40, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 40.0 in stage 0.0 (TID 40)\n",
      "  Finished task 36.0 in stage 0.0 (TID 36) in 6022 ms on namenode (executor driver) (37/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:5368709120+134217728\n",
      "  Times: total = 5837, boot = -78, init = 85, finish = 5830\n",
      "  Finished task 37.0 in stage 0.0 (TID 37). 1900 bytes result sent to driver\n",
      "  Starting task 41.0 in stage 0.0 (TID 41) (namenode, executor driver, partition 41, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 41.0 in stage 0.0 (TID 41)\n",
      "  Finished task 37.0 in stage 0.0 (TID 37) in 5995 ms on namenode (executor driver) (38/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:5502926848+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 5870, boot = -110, init = 116, finish = 5864\n",
      "  Finished task 38.0 in stage 0.0 (TID 38). 1900 bytes result sent to driver\n",
      "  Starting task 42.0 in stage 0.0 (TID 42) (namenode, executor driver, partition 42, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 38.0 in stage 0.0 (TID 38) in 6041 ms on namenode (executor driver) (39/121)\n",
      "  Running task 42.0 in stage 0.0 (TID 42)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:5637144576+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 5377, boot = -94, init = 96, finish = 5375\n",
      "  Finished task 39.0 in stage 0.0 (TID 39). 1900 bytes result sent to driver\n",
      "  Starting task 43.0 in stage 0.0 (TID 43) (namenode, executor driver, partition 43, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 43.0 in stage 0.0 (TID 43)\n",
      "  Finished task 39.0 in stage 0.0 (TID 39) in 5472 ms on namenode (executor driver) (40/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:5771362304+134217728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 5993, boot = -92, init = 101, finish = 5984\n",
      "  Finished task 40.0 in stage 0.0 (TID 40). 1900 bytes result sent to driver\n",
      "  Starting task 44.0 in stage 0.0 (TID 44) (namenode, executor driver, partition 44, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 40.0 in stage 0.0 (TID 40) in 6103 ms on namenode (executor driver) (41/121)\n",
      "  Running task 44.0 in stage 0.0 (TID 44)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:5905580032+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 5930, boot = -182, init = 185, finish = 5927\n",
      "  Finished task 41.0 in stage 0.0 (TID 41). 1900 bytes result sent to driver\n",
      "  Starting task 45.0 in stage 0.0 (TID 45) (namenode, executor driver, partition 45, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 41.0 in stage 0.0 (TID 41) in 6138 ms on namenode (executor driver) (42/121)\n",
      "  Running task 45.0 in stage 0.0 (TID 45)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:6039797760+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 5055, boot = -87, init = 96, finish = 5046\n",
      "  Finished task 43.0 in stage 0.0 (TID 43). 1900 bytes result sent to driver\n",
      "  Starting task 46.0 in stage 0.0 (TID 46) (namenode, executor driver, partition 46, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 43.0 in stage 0.0 (TID 43) in 5235 ms on namenode (executor driver) (43/121)\n",
      "  Running task 46.0 in stage 0.0 (TID 46)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:6174015488+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 5873, boot = -119, init = 130, finish = 5862\n",
      "  Finished task 42.0 in stage 0.0 (TID 42). 1900 bytes result sent to driver\n",
      "  Starting task 47.0 in stage 0.0 (TID 47) (namenode, executor driver, partition 47, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 42.0 in stage 0.0 (TID 42) in 6173 ms on namenode (executor driver) (44/121)\n",
      "  Running task 47.0 in stage 0.0 (TID 47)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:6308233216+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 5892, boot = -121, init = 129, finish = 5884\n",
      "  Finished task 44.0 in stage 0.0 (TID 44). 1900 bytes result sent to driver\n",
      "  Starting task 48.0 in stage 0.0 (TID 48) (namenode, executor driver, partition 48, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 44.0 in stage 0.0 (TID 44) in 6040 ms on namenode (executor driver) (45/121)\n",
      "  Running task 48.0 in stage 0.0 (TID 48)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:6442450944+134217728\n",
      "  Times: total = 5902, boot = -156, init = 170, finish = 5888\n",
      "  Finished task 45.0 in stage 0.0 (TID 45). 1900 bytes result sent to driver\n",
      "  Starting task 49.0 in stage 0.0 (TID 49) (namenode, executor driver, partition 49, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 45.0 in stage 0.0 (TID 45) in 6062 ms on namenode (executor driver) (46/121)\n",
      "  Running task 49.0 in stage 0.0 (TID 49)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:6576668672+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 5582, boot = -153, init = 164, finish = 5571\n",
      "  Finished task 46.0 in stage 0.0 (TID 46). 1900 bytes result sent to driver\n",
      "  Starting task 50.0 in stage 0.0 (TID 50) (namenode, executor driver, partition 50, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 46.0 in stage 0.0 (TID 46) in 5687 ms on namenode (executor driver) (47/121)\n",
      "  Running task 50.0 in stage 0.0 (TID 50)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:6710886400+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6227, boot = -335, init = 349, finish = 6213\n",
      "  Finished task 47.0 in stage 0.0 (TID 47). 1900 bytes result sent to driver\n",
      "  Starting task 51.0 in stage 0.0 (TID 51) (namenode, executor driver, partition 51, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 51.0 in stage 0.0 (TID 51)\n",
      "  Finished task 47.0 in stage 0.0 (TID 47) in 6448 ms on namenode (executor driver) (48/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:6845104128+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 5699, boot = -145, init = 153, finish = 5691\n",
      "  Finished task 48.0 in stage 0.0 (TID 48). 1900 bytes result sent to driver\n",
      "  Starting task 52.0 in stage 0.0 (TID 52) (namenode, executor driver, partition 52, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 52.0 in stage 0.0 (TID 52)\n",
      "  Finished task 48.0 in stage 0.0 (TID 48) in 5842 ms on namenode (executor driver) (49/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:6979321856+134217728\n",
      "  Times: total = 5731, boot = -183, init = 195, finish = 5719\n",
      "  Finished task 49.0 in stage 0.0 (TID 49). 1900 bytes result sent to driver\n",
      "  Starting task 53.0 in stage 0.0 (TID 53) (namenode, executor driver, partition 53, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 53.0 in stage 0.0 (TID 53)\n",
      "  Finished task 49.0 in stage 0.0 (TID 49) in 5984 ms on namenode (executor driver) (50/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:7113539584+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6255, boot = -139, init = 142, finish = 6252\n",
      "  Finished task 50.0 in stage 0.0 (TID 50). 1900 bytes result sent to driver\n",
      "  Starting task 54.0 in stage 0.0 (TID 54) (namenode, executor driver, partition 54, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 50.0 in stage 0.0 (TID 50) in 6446 ms on namenode (executor driver) (51/121)\n",
      "  Running task 54.0 in stage 0.0 (TID 54)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:7247757312+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6000, boot = -160, init = 162, finish = 5998\n",
      "  Finished task 51.0 in stage 0.0 (TID 51). 1900 bytes result sent to driver\n",
      "  Starting task 55.0 in stage 0.0 (TID 55) (namenode, executor driver, partition 55, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 51.0 in stage 0.0 (TID 51) in 6103 ms on namenode (executor driver) (52/121)\n",
      "  Running task 55.0 in stage 0.0 (TID 55)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:7381975040+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 5449, boot = -126, init = 146, finish = 5429\n",
      "  Finished task 52.0 in stage 0.0 (TID 52). 1900 bytes result sent to driver\n",
      "  Starting task 56.0 in stage 0.0 (TID 56) (namenode, executor driver, partition 56, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 52.0 in stage 0.0 (TID 52) in 5584 ms on namenode (executor driver) (53/121)\n",
      "  Running task 56.0 in stage 0.0 (TID 56)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:7516192768+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 5287, boot = -220, init = 232, finish = 5275\n",
      "  Finished task 53.0 in stage 0.0 (TID 53). 1900 bytes result sent to driver\n",
      "  Starting task 57.0 in stage 0.0 (TID 57) (namenode, executor driver, partition 57, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 53.0 in stage 0.0 (TID 53) in 5389 ms on namenode (executor driver) (54/121)\n",
      "  Running task 57.0 in stage 0.0 (TID 57)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:7650410496+134217728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 5703, boot = -169, init = 172, finish = 5700\n",
      "  Finished task 54.0 in stage 0.0 (TID 54). 1900 bytes result sent to driver\n",
      "  Starting task 58.0 in stage 0.0 (TID 58) (namenode, executor driver, partition 58, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 54.0 in stage 0.0 (TID 54) in 5840 ms on namenode (executor driver) (55/121)\n",
      "  Running task 58.0 in stage 0.0 (TID 58)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:7784628224+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6729, boot = -90, init = 102, finish = 6717\n",
      "  Finished task 55.0 in stage 0.0 (TID 55). 1900 bytes result sent to driver\n",
      "  Starting task 59.0 in stage 0.0 (TID 59) (namenode, executor driver, partition 59, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 59.0 in stage 0.0 (TID 59)\n",
      "  Finished task 55.0 in stage 0.0 (TID 55) in 6899 ms on namenode (executor driver) (56/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:7918845952+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 5933, boot = -117, init = 119, finish = 5931\n",
      "  Finished task 56.0 in stage 0.0 (TID 56). 1900 bytes result sent to driver\n",
      "  Starting task 60.0 in stage 0.0 (TID 60) (namenode, executor driver, partition 60, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 60.0 in stage 0.0 (TID 60)\n",
      "  Finished task 56.0 in stage 0.0 (TID 56) in 6123 ms on namenode (executor driver) (57/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:8053063680+134217728\n",
      "  Times: total = 5945, boot = -79, init = 93, finish = 5931\n",
      "  Finished task 57.0 in stage 0.0 (TID 57). 1900 bytes result sent to driver\n",
      "  Starting task 61.0 in stage 0.0 (TID 61) (namenode, executor driver, partition 61, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 61.0 in stage 0.0 (TID 61)\n",
      "  Finished task 57.0 in stage 0.0 (TID 57) in 6225 ms on namenode (executor driver) (58/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:8187281408+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 5879, boot = -88, init = 93, finish = 5874\n",
      "  Finished task 58.0 in stage 0.0 (TID 58). 1900 bytes result sent to driver\n",
      "  Starting task 62.0 in stage 0.0 (TID 62) (namenode, executor driver, partition 62, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 58.0 in stage 0.0 (TID 58) in 5983 ms on namenode (executor driver) (59/121)\n",
      "  Running task 62.0 in stage 0.0 (TID 62)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:8321499136+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6507, boot = -158, init = 168, finish = 6497\n",
      "  Finished task 59.0 in stage 0.0 (TID 59). 1900 bytes result sent to driver\n",
      "  Starting task 63.0 in stage 0.0 (TID 63) (namenode, executor driver, partition 63, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 63.0 in stage 0.0 (TID 63)\n",
      "  Finished task 59.0 in stage 0.0 (TID 59) in 6700 ms on namenode (executor driver) (60/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:8455716864+134217728\n",
      "  Times: total = 5781, boot = -179, init = 194, finish = 5766\n",
      "  Finished task 60.0 in stage 0.0 (TID 60). 1900 bytes result sent to driver\n",
      "  Starting task 64.0 in stage 0.0 (TID 64) (namenode, executor driver, partition 64, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 64.0 in stage 0.0 (TID 64)\n",
      "  Finished task 60.0 in stage 0.0 (TID 60) in 5920 ms on namenode (executor driver) (61/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:8589934592+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6037, boot = -256, init = 267, finish = 6026\n",
      "  Finished task 61.0 in stage 0.0 (TID 61). 1900 bytes result sent to driver\n",
      "  Starting task 65.0 in stage 0.0 (TID 65) (namenode, executor driver, partition 65, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 61.0 in stage 0.0 (TID 61) in 6163 ms on namenode (executor driver) (62/121)\n",
      "  Running task 65.0 in stage 0.0 (TID 65)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:8724152320+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6265, boot = -116, init = 126, finish = 6255\n",
      "  Finished task 62.0 in stage 0.0 (TID 62). 1900 bytes result sent to driver\n",
      "  Starting task 66.0 in stage 0.0 (TID 66) (namenode, executor driver, partition 66, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 62.0 in stage 0.0 (TID 62) in 6391 ms on namenode (executor driver) (63/121)\n",
      "  Running task 66.0 in stage 0.0 (TID 66)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:8858370048+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 5552, boot = -162, init = 165, finish = 5549\n",
      "  Finished task 63.0 in stage 0.0 (TID 63). 1900 bytes result sent to driver\n",
      "  Starting task 67.0 in stage 0.0 (TID 67) (namenode, executor driver, partition 67, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 67.0 in stage 0.0 (TID 67)\n",
      "  Finished task 63.0 in stage 0.0 (TID 63) in 5659 ms on namenode (executor driver) (64/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:8992587776+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6182, boot = -132, init = 135, finish = 6179\n",
      "  Finished task 64.0 in stage 0.0 (TID 64). 1900 bytes result sent to driver\n",
      "  Starting task 68.0 in stage 0.0 (TID 68) (namenode, executor driver, partition 68, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 64.0 in stage 0.0 (TID 64) in 6385 ms on namenode (executor driver) (65/121)\n",
      "  Running task 68.0 in stage 0.0 (TID 68)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:9126805504+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 5804, boot = -92, init = 96, finish = 5800\n",
      "  Finished task 65.0 in stage 0.0 (TID 65). 1900 bytes result sent to driver\n",
      "  Starting task 69.0 in stage 0.0 (TID 69) (namenode, executor driver, partition 69, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 65.0 in stage 0.0 (TID 65) in 5927 ms on namenode (executor driver) (66/121)\n",
      "  Running task 69.0 in stage 0.0 (TID 69)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:9261023232+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6406, boot = -103, init = 109, finish = 6400\n",
      "  Finished task 66.0 in stage 0.0 (TID 66). 1900 bytes result sent to driver\n",
      "  Starting task 70.0 in stage 0.0 (TID 70) (namenode, executor driver, partition 70, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 70.0 in stage 0.0 (TID 70)\n",
      "  Finished task 66.0 in stage 0.0 (TID 66) in 6568 ms on namenode (executor driver) (67/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:9395240960+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 5570, boot = -111, init = 115, finish = 5566\n",
      "  Finished task 67.0 in stage 0.0 (TID 67). 1900 bytes result sent to driver\n",
      "  Starting task 71.0 in stage 0.0 (TID 71) (namenode, executor driver, partition 71, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 67.0 in stage 0.0 (TID 67) in 5693 ms on namenode (executor driver) (68/121)\n",
      "  Running task 71.0 in stage 0.0 (TID 71)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:9529458688+134217728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 5350, boot = -222, init = 234, finish = 5338\n",
      "  Finished task 68.0 in stage 0.0 (TID 68). 1900 bytes result sent to driver\n",
      "  Starting task 72.0 in stage 0.0 (TID 72) (namenode, executor driver, partition 72, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 72.0 in stage 0.0 (TID 72)\n",
      "  Finished task 68.0 in stage 0.0 (TID 68) in 5472 ms on namenode (executor driver) (69/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:9663676416+134217728\n",
      "  Times: total = 5602, boot = -129, init = 132, finish = 5599\n",
      "  Finished task 69.0 in stage 0.0 (TID 69). 1900 bytes result sent to driver\n",
      "  Starting task 73.0 in stage 0.0 (TID 73) (namenode, executor driver, partition 73, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 69.0 in stage 0.0 (TID 69) in 5750 ms on namenode (executor driver) (70/121)\n",
      "  Running task 73.0 in stage 0.0 (TID 73)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:9797894144+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 5086, boot = -93, init = 137, finish = 5042\n",
      "  Finished task 71.0 in stage 0.0 (TID 71). 1900 bytes result sent to driver\n",
      "  Starting task 74.0 in stage 0.0 (TID 74) (namenode, executor driver, partition 74, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 74.0 in stage 0.0 (TID 74)\n",
      "  Finished task 71.0 in stage 0.0 (TID 71) in 5180 ms on namenode (executor driver) (71/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:9932111872+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6870, boot = -142, init = 158, finish = 6854\n",
      "  Finished task 70.0 in stage 0.0 (TID 70). 1900 bytes result sent to driver\n",
      "  Starting task 75.0 in stage 0.0 (TID 75) (namenode, executor driver, partition 75, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 70.0 in stage 0.0 (TID 70) in 6949 ms on namenode (executor driver) (72/121)\n",
      "  Running task 75.0 in stage 0.0 (TID 75)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:10066329600+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 5225, boot = -56, init = 67, finish = 5214\n",
      "  Finished task 72.0 in stage 0.0 (TID 72). 1900 bytes result sent to driver\n",
      "  Starting task 76.0 in stage 0.0 (TID 76) (namenode, executor driver, partition 76, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 72.0 in stage 0.0 (TID 72) in 5326 ms on namenode (executor driver) (73/121)\n",
      "  Running task 76.0 in stage 0.0 (TID 76)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:10200547328+134217728\n",
      "  Times: total = 5823, boot = -159, init = 164, finish = 5818\n",
      "  Finished task 73.0 in stage 0.0 (TID 73). 1900 bytes result sent to driver\n",
      "  Starting task 77.0 in stage 0.0 (TID 77) (namenode, executor driver, partition 77, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 73.0 in stage 0.0 (TID 73) in 6004 ms on namenode (executor driver) (74/121)\n",
      "  Running task 77.0 in stage 0.0 (TID 77)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:10334765056+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 5979, boot = -172, init = 175, finish = 5976\n",
      "  Finished task 74.0 in stage 0.0 (TID 74). 1900 bytes result sent to driver\n",
      "  Starting task 78.0 in stage 0.0 (TID 78) (namenode, executor driver, partition 78, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 78.0 in stage 0.0 (TID 78)\n",
      "  Finished task 74.0 in stage 0.0 (TID 74) in 6196 ms on namenode (executor driver) (75/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:10468982784+134217728\n",
      "  Times: total = 5904, boot = -68, init = 75, finish = 5897\n",
      "  Finished task 75.0 in stage 0.0 (TID 75). 1900 bytes result sent to driver\n",
      "  Starting task 79.0 in stage 0.0 (TID 79) (namenode, executor driver, partition 79, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 75.0 in stage 0.0 (TID 75) in 6035 ms on namenode (executor driver) (76/121)\n",
      "  Running task 79.0 in stage 0.0 (TID 79)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:10603200512+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 5642, boot = -93, init = 114, finish = 5621\n",
      "  Finished task 76.0 in stage 0.0 (TID 76). 1900 bytes result sent to driver\n",
      "  Starting task 80.0 in stage 0.0 (TID 80) (namenode, executor driver, partition 80, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 80.0 in stage 0.0 (TID 80)\n",
      "  Finished task 76.0 in stage 0.0 (TID 76) in 5768 ms on namenode (executor driver) (77/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:10737418240+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 5870, boot = -148, init = 151, finish = 5867\n",
      "  Finished task 77.0 in stage 0.0 (TID 77). 1900 bytes result sent to driver\n",
      "  Starting task 81.0 in stage 0.0 (TID 81) (namenode, executor driver, partition 81, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 77.0 in stage 0.0 (TID 77) in 6013 ms on namenode (executor driver) (78/121)\n",
      "  Running task 81.0 in stage 0.0 (TID 81)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:10871635968+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 5724, boot = -115, init = 130, finish = 5709\n",
      "  Finished task 78.0 in stage 0.0 (TID 78). 1900 bytes result sent to driver\n",
      "  Starting task 82.0 in stage 0.0 (TID 82) (namenode, executor driver, partition 82, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 78.0 in stage 0.0 (TID 78) in 5840 ms on namenode (executor driver) (79/121)\n",
      "  Running task 82.0 in stage 0.0 (TID 82)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:11005853696+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 5998, boot = -111, init = 124, finish = 5985\n",
      "  Finished task 79.0 in stage 0.0 (TID 79). 1900 bytes result sent to driver\n",
      "  Starting task 83.0 in stage 0.0 (TID 83) (namenode, executor driver, partition 83, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 79.0 in stage 0.0 (TID 79) in 6140 ms on namenode (executor driver) (80/121)\n",
      "  Running task 83.0 in stage 0.0 (TID 83)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:11140071424+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 5495, boot = -136, init = 149, finish = 5482\n",
      "  Finished task 80.0 in stage 0.0 (TID 80). 1900 bytes result sent to driver\n",
      "  Starting task 84.0 in stage 0.0 (TID 84) (namenode, executor driver, partition 84, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 80.0 in stage 0.0 (TID 80) in 5581 ms on namenode (executor driver) (81/121)\n",
      "  Running task 84.0 in stage 0.0 (TID 84)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:11274289152+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 5914, boot = -152, init = 170, finish = 5896\n",
      "  Finished task 81.0 in stage 0.0 (TID 81). 1900 bytes result sent to driver\n",
      "  Starting task 85.0 in stage 0.0 (TID 85) (namenode, executor driver, partition 85, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 85.0 in stage 0.0 (TID 85)\n",
      "  Finished task 81.0 in stage 0.0 (TID 81) in 6051 ms on namenode (executor driver) (82/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:11408506880+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6686, boot = -112, init = 114, finish = 6684\n",
      "  Finished task 82.0 in stage 0.0 (TID 82). 1900 bytes result sent to driver\n",
      "  Starting task 86.0 in stage 0.0 (TID 86) (namenode, executor driver, partition 86, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 82.0 in stage 0.0 (TID 82) in 6906 ms on namenode (executor driver) (83/121)\n",
      "  Running task 86.0 in stage 0.0 (TID 86)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:11542724608+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 5799, boot = -51, init = 66, finish = 5784\n",
      "  Finished task 84.0 in stage 0.0 (TID 84). 1900 bytes result sent to driver\n",
      "  Starting task 87.0 in stage 0.0 (TID 87) (namenode, executor driver, partition 87, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 84.0 in stage 0.0 (TID 84) in 5936 ms on namenode (executor driver) (84/121)\n",
      "  Running task 87.0 in stage 0.0 (TID 87)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:11676942336+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 7262, boot = -153, init = 155, finish = 7260\n",
      "  Finished task 83.0 in stage 0.0 (TID 83). 1900 bytes result sent to driver\n",
      "  Starting task 88.0 in stage 0.0 (TID 88) (namenode, executor driver, partition 88, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 88.0 in stage 0.0 (TID 88)\n",
      "  Finished task 83.0 in stage 0.0 (TID 83) in 7387 ms on namenode (executor driver) (85/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:11811160064+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6720, boot = -64, init = 85, finish = 6699\n",
      "  Finished task 85.0 in stage 0.0 (TID 85). 1900 bytes result sent to driver\n",
      "  Finished task 85.0 in stage 0.0 (TID 85) in 6907 ms on namenode (executor driver) (86/121)\n",
      "  Starting task 89.0 in stage 0.0 (TID 89) (namenode, executor driver, partition 89, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 89.0 in stage 0.0 (TID 89)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:11945377792+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6514, boot = -204, init = 224, finish = 6494\n",
      "  Finished task 86.0 in stage 0.0 (TID 86). 1900 bytes result sent to driver\n",
      "  Starting task 90.0 in stage 0.0 (TID 90) (namenode, executor driver, partition 90, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 90.0 in stage 0.0 (TID 90)\n",
      "  Finished task 86.0 in stage 0.0 (TID 86) in 6650 ms on namenode (executor driver) (87/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:12079595520+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6632, boot = -117, init = 131, finish = 6618\n",
      "  Finished task 87.0 in stage 0.0 (TID 87). 1900 bytes result sent to driver\n",
      "  Starting task 91.0 in stage 0.0 (TID 91) (namenode, executor driver, partition 91, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 87.0 in stage 0.0 (TID 87) in 6833 ms on namenode (executor driver) (88/121)\n",
      "  Running task 91.0 in stage 0.0 (TID 91)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:12213813248+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6609, boot = -59, init = 70, finish = 6598\n",
      "  Finished task 88.0 in stage 0.0 (TID 88). 1900 bytes result sent to driver\n",
      "  Starting task 92.0 in stage 0.0 (TID 92) (namenode, executor driver, partition 92, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 88.0 in stage 0.0 (TID 88) in 6780 ms on namenode (executor driver) (89/121)\n",
      "  Running task 92.0 in stage 0.0 (TID 92)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:12348030976+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6677, boot = -180, init = 200, finish = 6657\n",
      "  Finished task 89.0 in stage 0.0 (TID 89). 1900 bytes result sent to driver\n",
      "  Starting task 93.0 in stage 0.0 (TID 93) (namenode, executor driver, partition 93, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 93.0 in stage 0.0 (TID 93)\n",
      "  Finished task 89.0 in stage 0.0 (TID 89) in 6785 ms on namenode (executor driver) (90/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:12482248704+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 5709, boot = -120, init = 125, finish = 5704\n",
      "  Finished task 90.0 in stage 0.0 (TID 90). 1900 bytes result sent to driver\n",
      "  Starting task 94.0 in stage 0.0 (TID 94) (namenode, executor driver, partition 94, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 94.0 in stage 0.0 (TID 94)\n",
      "  Finished task 90.0 in stage 0.0 (TID 90) in 5819 ms on namenode (executor driver) (91/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:12616466432+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 5842, boot = -208, init = 210, finish = 5840\n",
      "  Finished task 91.0 in stage 0.0 (TID 91). 1900 bytes result sent to driver\n",
      "  Starting task 95.0 in stage 0.0 (TID 95) (namenode, executor driver, partition 95, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 95.0 in stage 0.0 (TID 95)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:12750684160+134217728\n",
      "  Finished task 91.0 in stage 0.0 (TID 91) in 5974 ms on namenode (executor driver) (92/121)\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6152, boot = -162, init = 176, finish = 6138\n",
      "  Finished task 92.0 in stage 0.0 (TID 92). 1900 bytes result sent to driver\n",
      "  Starting task 96.0 in stage 0.0 (TID 96) (namenode, executor driver, partition 96, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 92.0 in stage 0.0 (TID 92) in 6294 ms on namenode (executor driver) (93/121)\n",
      "  Running task 96.0 in stage 0.0 (TID 96)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:12884901888+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 5826, boot = -93, init = 103, finish = 5816\n",
      "  Finished task 93.0 in stage 0.0 (TID 93). 1900 bytes result sent to driver\n",
      "  Starting task 97.0 in stage 0.0 (TID 97) (namenode, executor driver, partition 97, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 93.0 in stage 0.0 (TID 93) in 5901 ms on namenode (executor driver) (94/121)\n",
      "  Running task 97.0 in stage 0.0 (TID 97)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:13019119616+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 5688, boot = -101, init = 103, finish = 5686\n",
      "  Finished task 94.0 in stage 0.0 (TID 94). 1900 bytes result sent to driver\n",
      "  Starting task 98.0 in stage 0.0 (TID 98) (namenode, executor driver, partition 98, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 94.0 in stage 0.0 (TID 94) in 5809 ms on namenode (executor driver) (95/121)\n",
      "  Running task 98.0 in stage 0.0 (TID 98)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:13153337344+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6005, boot = -102, init = 105, finish = 6002\n",
      "  Finished task 95.0 in stage 0.0 (TID 95). 1900 bytes result sent to driver\n",
      "  Starting task 99.0 in stage 0.0 (TID 99) (namenode, executor driver, partition 99, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 99.0 in stage 0.0 (TID 99)\n",
      "  Finished task 95.0 in stage 0.0 (TID 95) in 6133 ms on namenode (executor driver) (96/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:13287555072+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 5865, boot = -127, init = 139, finish = 5853\n",
      "  Finished task 96.0 in stage 0.0 (TID 96). 1900 bytes result sent to driver\n",
      "  Starting task 100.0 in stage 0.0 (TID 100) (namenode, executor driver, partition 100, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 96.0 in stage 0.0 (TID 96) in 5931 ms on namenode (executor driver) (97/121)\n",
      "  Running task 100.0 in stage 0.0 (TID 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:13421772800+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6035, boot = -89, init = 126, finish = 5998\n",
      "  Finished task 97.0 in stage 0.0 (TID 97). 1900 bytes result sent to driver\n",
      "  Starting task 101.0 in stage 0.0 (TID 101) (namenode, executor driver, partition 101, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 97.0 in stage 0.0 (TID 97) in 6180 ms on namenode (executor driver) (98/121)\n",
      "  Running task 101.0 in stage 0.0 (TID 101)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:13555990528+134217728\n",
      "  Times: total = 5434, boot = -96, init = 113, finish = 5417\n",
      "  Finished task 98.0 in stage 0.0 (TID 98). 1900 bytes result sent to driver\n",
      "  Starting task 102.0 in stage 0.0 (TID 102) (namenode, executor driver, partition 102, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 102.0 in stage 0.0 (TID 102)\n",
      "  Finished task 98.0 in stage 0.0 (TID 98) in 5524 ms on namenode (executor driver) (99/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:13690208256+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 5672, boot = -170, init = 176, finish = 5666\n",
      "  Finished task 99.0 in stage 0.0 (TID 99). 1900 bytes result sent to driver\n",
      "  Starting task 103.0 in stage 0.0 (TID 103) (namenode, executor driver, partition 103, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 99.0 in stage 0.0 (TID 99) in 5897 ms on namenode (executor driver) (100/121)\n",
      "  Running task 103.0 in stage 0.0 (TID 103)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:13824425984+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 5205, boot = -53, init = 65, finish = 5193\n",
      "  Finished task 100.0 in stage 0.0 (TID 100). 1900 bytes result sent to driver\n",
      "  Starting task 104.0 in stage 0.0 (TID 104) (namenode, executor driver, partition 104, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 104.0 in stage 0.0 (TID 104)\n",
      "  Finished task 100.0 in stage 0.0 (TID 100) in 5340 ms on namenode (executor driver) (101/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:13958643712+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6687, boot = -122, init = 125, finish = 6684\n",
      "  Finished task 101.0 in stage 0.0 (TID 101). 1900 bytes result sent to driver\n",
      "  Starting task 105.0 in stage 0.0 (TID 105) (namenode, executor driver, partition 105, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 101.0 in stage 0.0 (TID 101) in 6836 ms on namenode (executor driver) (102/121)\n",
      "  Running task 105.0 in stage 0.0 (TID 105)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:14092861440+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 5685, boot = -84, init = 96, finish = 5673\n",
      "  Finished task 102.0 in stage 0.0 (TID 102). 1900 bytes result sent to driver\n",
      "  Starting task 106.0 in stage 0.0 (TID 106) (namenode, executor driver, partition 106, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 106.0 in stage 0.0 (TID 106)\n",
      "  Finished task 102.0 in stage 0.0 (TID 102) in 5824 ms on namenode (executor driver) (103/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:14227079168+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 5112, boot = -160, init = 164, finish = 5108\n",
      "  Finished task 103.0 in stage 0.0 (TID 103). 1900 bytes result sent to driver\n",
      "  Starting task 107.0 in stage 0.0 (TID 107) (namenode, executor driver, partition 107, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 103.0 in stage 0.0 (TID 103) in 5256 ms on namenode (executor driver) (104/121)\n",
      "  Running task 107.0 in stage 0.0 (TID 107)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:14361296896+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 5992, boot = -142, init = 152, finish = 5982\n",
      "  Finished task 104.0 in stage 0.0 (TID 104). 1900 bytes result sent to driver\n",
      "  Starting task 108.0 in stage 0.0 (TID 108) (namenode, executor driver, partition 108, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 104.0 in stage 0.0 (TID 104) in 6111 ms on namenode (executor driver) (105/121)\n",
      "  Running task 108.0 in stage 0.0 (TID 108)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:14495514624+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6145, boot = -101, init = 103, finish = 6143\n",
      "  Finished task 105.0 in stage 0.0 (TID 105). 1900 bytes result sent to driver\n",
      "  Starting task 109.0 in stage 0.0 (TID 109) (namenode, executor driver, partition 109, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 105.0 in stage 0.0 (TID 105) in 6270 ms on namenode (executor driver) (106/121)\n",
      "  Running task 109.0 in stage 0.0 (TID 109)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:14629732352+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6075, boot = -106, init = 111, finish = 6070\n",
      "  Times: total = 5517, boot = -112, init = 123, finish = 5506\n",
      "  Finished task 106.0 in stage 0.0 (TID 106). 1900 bytes result sent to driver\n",
      "  Starting task 110.0 in stage 0.0 (TID 110) (namenode, executor driver, partition 110, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 106.0 in stage 0.0 (TID 106) in 6313 ms on namenode (executor driver) (107/121)\n",
      "  Running task 110.0 in stage 0.0 (TID 110)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:14763950080+134217728\n",
      "  Finished task 107.0 in stage 0.0 (TID 107). 1900 bytes result sent to driver\n",
      "  Starting task 111.0 in stage 0.0 (TID 111) (namenode, executor driver, partition 111, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 107.0 in stage 0.0 (TID 107) in 5639 ms on namenode (executor driver) (108/121)\n",
      "  Running task 111.0 in stage 0.0 (TID 111)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:14898167808+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 5226, boot = -107, init = 112, finish = 5221\n",
      "  Finished task 108.0 in stage 0.0 (TID 108). 1900 bytes result sent to driver\n",
      "  Starting task 112.0 in stage 0.0 (TID 112) (namenode, executor driver, partition 112, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 108.0 in stage 0.0 (TID 108) in 5372 ms on namenode (executor driver) (109/121)\n",
      "  Running task 112.0 in stage 0.0 (TID 112)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:15032385536+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6108, boot = -130, init = 132, finish = 6106\n",
      "  Finished task 109.0 in stage 0.0 (TID 109). 1900 bytes result sent to driver\n",
      "  Starting task 113.0 in stage 0.0 (TID 113) (namenode, executor driver, partition 113, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 113.0 in stage 0.0 (TID 113)\n",
      "  Finished task 109.0 in stage 0.0 (TID 109) in 6226 ms on namenode (executor driver) (110/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:15166603264+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 5766, boot = -134, init = 146, finish = 5754\n",
      "  Finished task 111.0 in stage 0.0 (TID 111). 1900 bytes result sent to driver\n",
      "  Starting task 114.0 in stage 0.0 (TID 114) (namenode, executor driver, partition 114, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 111.0 in stage 0.0 (TID 111) in 5886 ms on namenode (executor driver) (111/121)\n",
      "  Running task 114.0 in stage 0.0 (TID 114)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:15300820992+134217728\n",
      "  Times: total = 6217, boot = -231, init = 233, finish = 6215\n",
      "  Finished task 110.0 in stage 0.0 (TID 110). 1900 bytes result sent to driver\n",
      "  Starting task 115.0 in stage 0.0 (TID 115) (namenode, executor driver, partition 115, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 115.0 in stage 0.0 (TID 115)\n",
      "  Finished task 110.0 in stage 0.0 (TID 110) in 6299 ms on namenode (executor driver) (112/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:15435038720+134217728\n",
      "  Times: total = 5403, boot = -124, init = 127, finish = 5400\n",
      "  Finished task 112.0 in stage 0.0 (TID 112). 1900 bytes result sent to driver\n",
      "  Starting task 116.0 in stage 0.0 (TID 116) (namenode, executor driver, partition 116, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 112.0 in stage 0.0 (TID 112) in 5566 ms on namenode (executor driver) (113/121)\n",
      "  Running task 116.0 in stage 0.0 (TID 116)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:15569256448+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 5767, boot = -72, init = 75, finish = 5764\n",
      "  Finished task 113.0 in stage 0.0 (TID 113). 1900 bytes result sent to driver\n",
      "  Starting task 117.0 in stage 0.0 (TID 117) (namenode, executor driver, partition 117, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 113.0 in stage 0.0 (TID 113) in 5820 ms on namenode (executor driver) (114/121)\n",
      "  Running task 117.0 in stage 0.0 (TID 117)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:15703474176+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 5979, boot = -92, init = 101, finish = 5970\n",
      "  Finished task 114.0 in stage 0.0 (TID 114). 1900 bytes result sent to driver\n",
      "  Starting task 118.0 in stage 0.0 (TID 118) (namenode, executor driver, partition 118, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 118.0 in stage 0.0 (TID 118)\n",
      "  Finished task 114.0 in stage 0.0 (TID 114) in 6105 ms on namenode (executor driver) (115/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:15837691904+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6187, boot = -74, init = 76, finish = 6185\n",
      "  Finished task 115.0 in stage 0.0 (TID 115). 1900 bytes result sent to driver\n",
      "  Starting task 119.0 in stage 0.0 (TID 119) (namenode, executor driver, partition 119, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 115.0 in stage 0.0 (TID 115) in 6352 ms on namenode (executor driver) (116/121)\n",
      "  Running task 119.0 in stage 0.0 (TID 119)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:15971909632+134217728\n",
      "  Times: total = 5809, boot = -168, init = 195, finish = 5782\n",
      "  Finished task 116.0 in stage 0.0 (TID 116). 1900 bytes result sent to driver\n",
      "  Starting task 120.0 in stage 0.0 (TID 120) (namenode, executor driver, partition 120, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 116.0 in stage 0.0 (TID 116) in 5900 ms on namenode (executor driver) (117/121)\n",
      "  Running task 120.0 in stage 0.0 (TID 120)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:16106127360+79598254\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 3295, boot = -59, init = 65, finish = 3289\n",
      "  Finished task 120.0 in stage 0.0 (TID 120). 1900 bytes result sent to driver\n",
      "  Finished task 120.0 in stage 0.0 (TID 120) in 3420 ms on namenode (executor driver) (118/121)\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6351, boot = -63, init = 75, finish = 6339\n",
      "  Finished task 117.0 in stage 0.0 (TID 117). 1900 bytes result sent to driver\n",
      "  Finished task 117.0 in stage 0.0 (TID 117) in 6433 ms on namenode (executor driver) (119/121)\n",
      "  Times: total = 5644, boot = -132, init = 134, finish = 5642\n",
      "  Finished task 118.0 in stage 0.0 (TID 118). 1900 bytes result sent to driver\n",
      "  Finished task 118.0 in stage 0.0 (TID 118) in 5732 ms on namenode (executor driver) (120/121)\n",
      "  Times: total = 5286, boot = -179, init = 182, finish = 5283\n",
      "  Finished task 119.0 in stage 0.0 (TID 119). 1900 bytes result sent to driver\n",
      "  Finished task 119.0 in stage 0.0 (TID 119) in 5391 ms on namenode (executor driver) (121/121)\n",
      "  Removed TaskSet 0.0, whose tasks have all completed, from pool \n",
      "  ShuffleMapStage 0 (groupBy at /home/ubuntu/.local/lib/python3.8/site-packages/mrjob/spark/harness.py:539) finished in 187.926 s\n",
      "  looking for newly runnable stages\n",
      "  running: Set()\n",
      "  waiting: Set(ShuffleMapStage 1, ResultStage 2)\n",
      "  failed: Set()\n",
      "  Submitting ShuffleMapStage 1 (PairwiseRDD[7] at groupBy at /home/ubuntu/.local/lib/python3.8/site-packages/mrjob/spark/harness.py:539), which has no missing parents\n",
      "  Block broadcast_2 stored as values in memory (estimated size 17.5 KiB, free 365.8 MiB)\n",
      "  Block broadcast_2_piece0 stored as bytes in memory (estimated size 10.0 KiB, free 365.8 MiB)\n",
      "  Added broadcast_2_piece0 in memory on namenode:45181 (size: 10.0 KiB, free: 366.2 MiB)\n",
      "  Created broadcast 2 from broadcast at DAGScheduler.scala:1427\n",
      "  Submitting 121 missing tasks from ShuffleMapStage 1 (PairwiseRDD[7] at groupBy at /home/ubuntu/.local/lib/python3.8/site-packages/mrjob/spark/harness.py:539) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))\n",
      "  Adding task set 1.0 with 121 tasks resource profile 0\n",
      "  Starting task 0.0 in stage 1.0 (TID 121) (namenode, executor driver, partition 0, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Starting task 1.0 in stage 1.0 (TID 122) (namenode, executor driver, partition 1, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Starting task 2.0 in stage 1.0 (TID 123) (namenode, executor driver, partition 2, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Starting task 3.0 in stage 1.0 (TID 124) (namenode, executor driver, partition 3, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 1.0 in stage 1.0 (TID 122)\n",
      "  Running task 0.0 in stage 1.0 (TID 121)\n",
      "  Running task 2.0 in stage 1.0 (TID 123)\n",
      "  Running task 3.0 in stage 1.0 (TID 124)\n",
      "  Getting 121 (224.8 KiB) non-empty blocks including 121 (224.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Getting 121 (241.6 KiB) non-empty blocks including 121 (241.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Getting 121 (279.1 KiB) non-empty blocks including 121 (279.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 25 ms\n",
      "  Getting 121 (216.8 KiB) non-empty blocks including 121 (216.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 27 ms\n",
      "  Started 0 remote fetches in 29 ms\n",
      "  Started 0 remote fetches in 30 ms\n",
      "  Times: total = 297, boot = -2175, init = 2190, finish = 282\n",
      "  Finished task 2.0 in stage 1.0 (TID 123). 2072 bytes result sent to driver\n",
      "  Starting task 4.0 in stage 1.0 (TID 125) (namenode, executor driver, partition 4, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 2.0 in stage 1.0 (TID 123) in 404 ms on namenode (executor driver) (1/121)\n",
      "  Running task 4.0 in stage 1.0 (TID 125)\n",
      "  Getting 121 (251.5 KiB) non-empty blocks including 121 (251.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Started 0 remote fetches in 1 ms\n",
      "  Times: total = 470, boot = -508, init = 538, finish = 440\n",
      "  Finished task 0.0 in stage 1.0 (TID 121). 2072 bytes result sent to driver\n",
      "  Starting task 5.0 in stage 1.0 (TID 126) (namenode, executor driver, partition 5, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 0.0 in stage 1.0 (TID 121) in 596 ms on namenode (executor driver) (2/121)\n",
      "  Running task 5.0 in stage 1.0 (TID 126)\n",
      "  Getting 121 (234.1 KiB) non-empty blocks including 121 (234.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Times: total = 926, boot = -557, init = 595, finish = 888\n",
      "  Finished task 1.0 in stage 1.0 (TID 122). 2072 bytes result sent to driver\n",
      "  Starting task 6.0 in stage 1.0 (TID 127) (namenode, executor driver, partition 6, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 1.0 in stage 1.0 (TID 122) in 1042 ms on namenode (executor driver) (3/121)\n",
      "  Running task 6.0 in stage 1.0 (TID 127)\n",
      "  Getting 121 (301.5 KiB) non-empty blocks including 121 (301.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 4 ms\n",
      "  Times: total = 620, boot = -21, init = 32, finish = 609\n",
      "  Finished task 4.0 in stage 1.0 (TID 125). 2072 bytes result sent to driver\n",
      "  Starting task 7.0 in stage 1.0 (TID 128) (namenode, executor driver, partition 7, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 7.0 in stage 1.0 (TID 128)\n",
      "  Finished task 4.0 in stage 1.0 (TID 125) in 653 ms on namenode (executor driver) (4/121)\n",
      "  Getting 121 (227.3 KiB) non-empty blocks including 121 (227.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Times: total = 528, boot = -16, init = 19, finish = 525\n",
      "  Finished task 5.0 in stage 1.0 (TID 126). 2029 bytes result sent to driver\n",
      "  Starting task 8.0 in stage 1.0 (TID 129) (namenode, executor driver, partition 8, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 8.0 in stage 1.0 (TID 129)\n",
      "  Finished task 5.0 in stage 1.0 (TID 126) in 554 ms on namenode (executor driver) (5/121)\n",
      "  Getting 121 (244.9 KiB) non-empty blocks including 121 (244.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Times: total = 1184, boot = -225, init = 227, finish = 1182\n",
      "  Finished task 3.0 in stage 1.0 (TID 124). 2072 bytes result sent to driver\n",
      "  Starting task 9.0 in stage 1.0 (TID 130) (namenode, executor driver, partition 9, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 9.0 in stage 1.0 (TID 130)\n",
      "  Finished task 3.0 in stage 1.0 (TID 124) in 1326 ms on namenode (executor driver) (6/121)\n",
      "  Getting 121 (229.5 KiB) non-empty blocks including 121 (229.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Times: total = 455, boot = 5, init = 11, finish = 439\n",
      "  Finished task 8.0 in stage 1.0 (TID 129). 2072 bytes result sent to driver\n",
      "  Starting task 10.0 in stage 1.0 (TID 131) (namenode, executor driver, partition 10, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 10.0 in stage 1.0 (TID 131)\n",
      "  Finished task 8.0 in stage 1.0 (TID 129) in 482 ms on namenode (executor driver) (7/121)\n",
      "  Getting 121 (263.4 KiB) non-empty blocks including 121 (263.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Times: total = 596, boot = -4, init = 23, finish = 577\n",
      "  Finished task 7.0 in stage 1.0 (TID 128). 2072 bytes result sent to driver\n",
      "  Starting task 11.0 in stage 1.0 (TID 132) (namenode, executor driver, partition 11, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 11.0 in stage 1.0 (TID 132)\n",
      "  Finished task 7.0 in stage 1.0 (TID 128) in 611 ms on namenode (executor driver) (8/121)\n",
      "  Getting 121 (254.0 KiB) non-empty blocks including 121 (254.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Times: total = 718, boot = -7, init = 20, finish = 705\n",
      "  Finished task 9.0 in stage 1.0 (TID 130). 2072 bytes result sent to driver\n",
      "  Starting task 12.0 in stage 1.0 (TID 133) (namenode, executor driver, partition 12, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 9.0 in stage 1.0 (TID 130) in 736 ms on namenode (executor driver) (9/121)\n",
      "  Running task 12.0 in stage 1.0 (TID 133)\n",
      "  Getting 121 (257.4 KiB) non-empty blocks including 121 (257.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Times: total = 519, boot = 14, init = 29, finish = 476\n",
      "  Finished task 11.0 in stage 1.0 (TID 132). 2072 bytes result sent to driver\n",
      "  Starting task 13.0 in stage 1.0 (TID 134) (namenode, executor driver, partition 13, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 11.0 in stage 1.0 (TID 132) in 531 ms on namenode (executor driver) (10/121)\n",
      "  Running task 13.0 in stage 1.0 (TID 134)\n",
      "  Getting 121 (221.5 KiB) non-empty blocks including 121 (221.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 1040, boot = 7, init = 7, finish = 1026\n",
      "  Finished task 10.0 in stage 1.0 (TID 131). 2072 bytes result sent to driver\n",
      "  Starting task 14.0 in stage 1.0 (TID 135) (namenode, executor driver, partition 14, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 14.0 in stage 1.0 (TID 135)\n",
      "  Finished task 10.0 in stage 1.0 (TID 131) in 1055 ms on namenode (executor driver) (11/121)\n",
      "  Getting 121 (221.5 KiB) non-empty blocks including 121 (221.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Times: total = 704, boot = 5, init = 3, finish = 696\n",
      "  Finished task 12.0 in stage 1.0 (TID 133). 2072 bytes result sent to driver\n",
      "  Starting task 15.0 in stage 1.0 (TID 136) (namenode, executor driver, partition 15, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 15.0 in stage 1.0 (TID 136)\n",
      "  Finished task 12.0 in stage 1.0 (TID 133) in 717 ms on namenode (executor driver) (12/121)\n",
      "  Getting 121 (245.0 KiB) non-empty blocks including 121 (245.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Times: total = 692, boot = 14, init = 1, finish = 677\n",
      "  Finished task 13.0 in stage 1.0 (TID 134). 2072 bytes result sent to driver\n",
      "  Starting task 16.0 in stage 1.0 (TID 137) (namenode, executor driver, partition 16, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 16.0 in stage 1.0 (TID 137)\n",
      "  Getting 121 (231.0 KiB) non-empty blocks including 121 (231.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Finished task 13.0 in stage 1.0 (TID 134) in 711 ms on namenode (executor driver) (13/121)\n",
      "  Times: total = 433, boot = -7, init = 10, finish = 430\n",
      "  Finished task 14.0 in stage 1.0 (TID 135). 2072 bytes result sent to driver\n",
      "  Starting task 17.0 in stage 1.0 (TID 138) (namenode, executor driver, partition 17, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 17.0 in stage 1.0 (TID 138)\n",
      "  Finished task 14.0 in stage 1.0 (TID 135) in 452 ms on namenode (executor driver) (14/121)\n",
      "  Getting 121 (272.0 KiB) non-empty blocks including 121 (272.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 394, boot = 4, init = 11, finish = 379\n",
      "  Finished task 15.0 in stage 1.0 (TID 136). 2072 bytes result sent to driver\n",
      "  Starting task 18.0 in stage 1.0 (TID 139) (namenode, executor driver, partition 18, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 18.0 in stage 1.0 (TID 139)\n",
      "  Finished task 15.0 in stage 1.0 (TID 136) in 406 ms on namenode (executor driver) (15/121)\n",
      "  Getting 121 (233.5 KiB) non-empty blocks including 121 (233.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 2556, boot = -10, init = 27, finish = 2539\n",
      "  Finished task 6.0 in stage 1.0 (TID 127). 2072 bytes result sent to driver\n",
      "  Starting task 19.0 in stage 1.0 (TID 140) (namenode, executor driver, partition 19, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 19.0 in stage 1.0 (TID 140)\n",
      "  Finished task 6.0 in stage 1.0 (TID 127) in 2576 ms on namenode (executor driver) (16/121)\n",
      "  Getting 121 (253.1 KiB) non-empty blocks including 121 (253.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Times: total = 879, boot = -1, init = 19, finish = 861\n",
      "  Finished task 16.0 in stage 1.0 (TID 137). 2072 bytes result sent to driver\n",
      "  Starting task 20.0 in stage 1.0 (TID 141) (namenode, executor driver, partition 20, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 16.0 in stage 1.0 (TID 137) in 891 ms on namenode (executor driver) (17/121)\n",
      "  Running task 20.0 in stage 1.0 (TID 141)\n",
      "  Getting 121 (250.2 KiB) non-empty blocks including 121 (250.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Times: total = 751, boot = 0, init = 10, finish = 741\n",
      "  Finished task 18.0 in stage 1.0 (TID 139). 2115 bytes result sent to driver\n",
      "  Starting task 21.0 in stage 1.0 (TID 142) (namenode, executor driver, partition 21, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 21.0 in stage 1.0 (TID 142)\n",
      "  Finished task 18.0 in stage 1.0 (TID 139) in 765 ms on namenode (executor driver) (18/121)\n",
      "  Getting 121 (245.4 KiB) non-empty blocks including 121 (245.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 932, boot = 2, init = 8, finish = 922\n",
      "  Finished task 19.0 in stage 1.0 (TID 140). 2115 bytes result sent to driver\n",
      "  Starting task 22.0 in stage 1.0 (TID 143) (namenode, executor driver, partition 22, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 19.0 in stage 1.0 (TID 140) in 956 ms on namenode (executor driver) (19/121)\n",
      "  Running task 22.0 in stage 1.0 (TID 143)\n",
      "  Getting 121 (284.2 KiB) non-empty blocks including 121 (284.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Times: total = 620, boot = 7, init = 5, finish = 608\n",
      "  Finished task 21.0 in stage 1.0 (TID 142). 2072 bytes result sent to driver\n",
      "  Starting task 23.0 in stage 1.0 (TID 144) (namenode, executor driver, partition 23, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 23.0 in stage 1.0 (TID 144)\n",
      "  Finished task 21.0 in stage 1.0 (TID 142) in 638 ms on namenode (executor driver) (20/121)\n",
      "  Getting 121 (216.8 KiB) non-empty blocks including 121 (216.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 909, boot = 0, init = 18, finish = 891\n",
      "  Finished task 20.0 in stage 1.0 (TID 141). 2072 bytes result sent to driver\n",
      "  Starting task 24.0 in stage 1.0 (TID 145) (namenode, executor driver, partition 24, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 20.0 in stage 1.0 (TID 141) in 922 ms on namenode (executor driver) (21/121)\n",
      "  Running task 24.0 in stage 1.0 (TID 145)\n",
      "  Getting 121 (246.1 KiB) non-empty blocks including 121 (246.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 439, boot = 26, init = 4, finish = 409\n",
      "  Finished task 23.0 in stage 1.0 (TID 144). 2029 bytes result sent to driver\n",
      "  Starting task 25.0 in stage 1.0 (TID 146) (namenode, executor driver, partition 25, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 25.0 in stage 1.0 (TID 146)\n",
      "  Finished task 23.0 in stage 1.0 (TID 144) in 450 ms on namenode (executor driver) (22/121)\n",
      "  Getting 121 (229.6 KiB) non-empty blocks including 121 (229.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 2284, boot = 4, init = 2, finish = 2278\n",
      "  Finished task 17.0 in stage 1.0 (TID 138). 2115 bytes result sent to driver\n",
      "  Starting task 26.0 in stage 1.0 (TID 147) (namenode, executor driver, partition 26, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 26.0 in stage 1.0 (TID 147)\n",
      "  Finished task 17.0 in stage 1.0 (TID 138) in 2297 ms on namenode (executor driver) (23/121)\n",
      "  Getting 121 (236.2 KiB) non-empty blocks including 121 (236.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 4 ms\n",
      "  Times: total = 404, boot = 13, init = 3, finish = 388\n",
      "  Finished task 25.0 in stage 1.0 (TID 146). 2029 bytes result sent to driver\n",
      "  Starting task 27.0 in stage 1.0 (TID 148) (namenode, executor driver, partition 27, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 27.0 in stage 1.0 (TID 148)\n",
      "  Finished task 25.0 in stage 1.0 (TID 146) in 434 ms on namenode (executor driver) (24/121)\n",
      "  Getting 121 (201.8 KiB) non-empty blocks including 121 (201.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 823, boot = 15, init = 1, finish = 807\n",
      "  Finished task 24.0 in stage 1.0 (TID 145). 2072 bytes result sent to driver\n",
      "  Starting task 28.0 in stage 1.0 (TID 149) (namenode, executor driver, partition 28, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 24.0 in stage 1.0 (TID 145) in 836 ms on namenode (executor driver) (25/121)\n",
      "  Running task 28.0 in stage 1.0 (TID 149)\n",
      "  Getting 121 (178.6 KiB) non-empty blocks including 121 (178.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 492, boot = 26, init = 1, finish = 465\n",
      "  Finished task 28.0 in stage 1.0 (TID 149). 2072 bytes result sent to driver\n",
      "  Starting task 29.0 in stage 1.0 (TID 150) (namenode, executor driver, partition 29, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 29.0 in stage 1.0 (TID 150)\n",
      "  Finished task 28.0 in stage 1.0 (TID 149) in 505 ms on namenode (executor driver) (26/121)\n",
      "  Getting 121 (242.1 KiB) non-empty blocks including 121 (242.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 1025, boot = -13, init = 28, finish = 1010\n",
      "  Finished task 27.0 in stage 1.0 (TID 148). 2072 bytes result sent to driver\n",
      "  Starting task 30.0 in stage 1.0 (TID 151) (namenode, executor driver, partition 30, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 30.0 in stage 1.0 (TID 151)\n",
      "  Finished task 27.0 in stage 1.0 (TID 148) in 1036 ms on namenode (executor driver) (27/121)\n",
      "  Getting 121 (195.6 KiB) non-empty blocks including 121 (195.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 1944, boot = 18, init = 9, finish = 1917\n",
      "  Finished task 22.0 in stage 1.0 (TID 143). 2072 bytes result sent to driver\n",
      "  Starting task 31.0 in stage 1.0 (TID 152) (namenode, executor driver, partition 31, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 22.0 in stage 1.0 (TID 143) in 1965 ms on namenode (executor driver) (28/121)\n",
      "  Running task 31.0 in stage 1.0 (TID 152)\n",
      "  Getting 121 (264.3 KiB) non-empty blocks including 121 (264.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 566, boot = -1, init = 13, finish = 554\n",
      "  Finished task 29.0 in stage 1.0 (TID 150). 2072 bytes result sent to driver\n",
      "  Starting task 32.0 in stage 1.0 (TID 153) (namenode, executor driver, partition 32, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 29.0 in stage 1.0 (TID 150) in 577 ms on namenode (executor driver) (29/121)\n",
      "  Running task 32.0 in stage 1.0 (TID 153)\n",
      "  Getting 121 (239.1 KiB) non-empty blocks including 121 (239.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 1628, boot = -3, init = 16, finish = 1615\n",
      "  Finished task 26.0 in stage 1.0 (TID 147). 2072 bytes result sent to driver\n",
      "  Starting task 33.0 in stage 1.0 (TID 154) (namenode, executor driver, partition 33, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 33.0 in stage 1.0 (TID 154)\n",
      "  Finished task 26.0 in stage 1.0 (TID 147) in 1642 ms on namenode (executor driver) (30/121)\n",
      "  Getting 121 (294.6 KiB) non-empty blocks including 121 (294.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Times: total = 475, boot = 5, init = 7, finish = 463\n",
      "  Finished task 32.0 in stage 1.0 (TID 153). 2072 bytes result sent to driver\n",
      "  Starting task 34.0 in stage 1.0 (TID 155) (namenode, executor driver, partition 34, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 34.0 in stage 1.0 (TID 155)\n",
      "  Finished task 32.0 in stage 1.0 (TID 153) in 488 ms on namenode (executor driver) (31/121)\n",
      "  Getting 121 (223.4 KiB) non-empty blocks including 121 (223.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 653, boot = 6, init = 6, finish = 641\n",
      "  Finished task 30.0 in stage 1.0 (TID 151). 2029 bytes result sent to driver\n",
      "  Starting task 35.0 in stage 1.0 (TID 156) (namenode, executor driver, partition 35, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 30.0 in stage 1.0 (TID 151) in 663 ms on namenode (executor driver) (32/121)\n",
      "  Running task 35.0 in stage 1.0 (TID 156)\n",
      "  Getting 121 (200.6 KiB) non-empty blocks including 121 (200.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 759, boot = 4, init = 13, finish = 742\n",
      "  Finished task 34.0 in stage 1.0 (TID 155). 2072 bytes result sent to driver\n",
      "  Starting task 36.0 in stage 1.0 (TID 157) (namenode, executor driver, partition 36, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 34.0 in stage 1.0 (TID 155) in 771 ms on namenode (executor driver) (33/121)\n",
      "  Running task 36.0 in stage 1.0 (TID 157)\n",
      "  Getting 121 (277.5 KiB) non-empty blocks including 121 (277.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Times: total = 997, boot = 6, init = 7, finish = 984\n",
      "  Finished task 35.0 in stage 1.0 (TID 156). 2072 bytes result sent to driver\n",
      "  Starting task 37.0 in stage 1.0 (TID 158) (namenode, executor driver, partition 37, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 37.0 in stage 1.0 (TID 158)\n",
      "  Getting 121 (209.3 KiB) non-empty blocks including 121 (209.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Finished task 35.0 in stage 1.0 (TID 156) in 1013 ms on namenode (executor driver) (34/121)\n",
      "  Times: total = 3183, boot = 12, init = 1, finish = 3170\n",
      "  Finished task 31.0 in stage 1.0 (TID 152). 2072 bytes result sent to driver\n",
      "  Starting task 38.0 in stage 1.0 (TID 159) (namenode, executor driver, partition 38, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 31.0 in stage 1.0 (TID 152) in 3197 ms on namenode (executor driver) (35/121)\n",
      "  Running task 38.0 in stage 1.0 (TID 159)\n",
      "  Getting 121 (254.8 KiB) non-empty blocks including 121 (254.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 2005, boot = 34, init = 1, finish = 1970\n",
      "  Finished task 37.0 in stage 1.0 (TID 158). 2072 bytes result sent to driver\n",
      "  Starting task 39.0 in stage 1.0 (TID 160) (namenode, executor driver, partition 39, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 39.0 in stage 1.0 (TID 160)\n",
      "  Finished task 37.0 in stage 1.0 (TID 158) in 2057 ms on namenode (executor driver) (36/121)\n",
      "  Getting 121 (217.4 KiB) non-empty blocks including 121 (217.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 2411, boot = 3, init = 3, finish = 2405\n",
      "  Finished task 36.0 in stage 1.0 (TID 157). 2072 bytes result sent to driver\n",
      "  Starting task 40.0 in stage 1.0 (TID 161) (namenode, executor driver, partition 40, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 36.0 in stage 1.0 (TID 157) in 2426 ms on namenode (executor driver) (37/121)\n",
      "  Running task 40.0 in stage 1.0 (TID 161)\n",
      "  Getting 121 (227.8 KiB) non-empty blocks including 121 (227.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 1429, boot = 5, init = 2, finish = 1422\n",
      "  Finished task 40.0 in stage 1.0 (TID 161). 2072 bytes result sent to driver\n",
      "  Starting task 41.0 in stage 1.0 (TID 162) (namenode, executor driver, partition 41, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 40.0 in stage 1.0 (TID 161) in 1441 ms on namenode (executor driver) (38/121)\n",
      "  Running task 41.0 in stage 1.0 (TID 162)\n",
      "  Getting 121 (255.2 KiB) non-empty blocks including 121 (255.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Times: total = 1741, boot = -31, init = 41, finish = 1731\n",
      "  Finished task 39.0 in stage 1.0 (TID 160). 2029 bytes result sent to driver\n",
      "  Starting task 42.0 in stage 1.0 (TID 163) (namenode, executor driver, partition 42, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 39.0 in stage 1.0 (TID 160) in 1758 ms on namenode (executor driver) (39/121)\n",
      "  Running task 42.0 in stage 1.0 (TID 163)\n",
      "  Getting 121 (230.9 KiB) non-empty blocks including 121 (230.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 2466, boot = 7, init = 40, finish = 2419\n",
      "  Finished task 38.0 in stage 1.0 (TID 159). 2072 bytes result sent to driver\n",
      "  Starting task 43.0 in stage 1.0 (TID 164) (namenode, executor driver, partition 43, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 38.0 in stage 1.0 (TID 159) in 2480 ms on namenode (executor driver) (40/121)\n",
      "  Running task 43.0 in stage 1.0 (TID 164)\n",
      "  Getting 121 (222.0 KiB) non-empty blocks including 121 (222.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Times: total = 5249, boot = 5, init = 12, finish = 5232\n",
      "  Finished task 33.0 in stage 1.0 (TID 154). 2072 bytes result sent to driver\n",
      "  Starting task 44.0 in stage 1.0 (TID 165) (namenode, executor driver, partition 44, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 44.0 in stage 1.0 (TID 165)\n",
      "  Finished task 33.0 in stage 1.0 (TID 154) in 5264 ms on namenode (executor driver) (41/121)\n",
      "  Getting 121 (249.5 KiB) non-empty blocks including 121 (249.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 1133, boot = 36, init = 1, finish = 1096\n",
      "  Finished task 41.0 in stage 1.0 (TID 162). 2029 bytes result sent to driver\n",
      "  Starting task 45.0 in stage 1.0 (TID 166) (namenode, executor driver, partition 45, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 41.0 in stage 1.0 (TID 162) in 1146 ms on namenode (executor driver) (42/121)\n",
      "  Running task 45.0 in stage 1.0 (TID 166)\n",
      "  Getting 121 (247.8 KiB) non-empty blocks including 121 (247.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 5 ms\n",
      "  Times: total = 980, boot = 29, init = 1, finish = 950\n",
      "  Finished task 42.0 in stage 1.0 (TID 163). 2072 bytes result sent to driver\n",
      "  Starting task 46.0 in stage 1.0 (TID 167) (namenode, executor driver, partition 46, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 46.0 in stage 1.0 (TID 167)\n",
      "  Finished task 42.0 in stage 1.0 (TID 163) in 998 ms on namenode (executor driver) (43/121)\n",
      "  Getting 121 (191.5 KiB) non-empty blocks including 121 (191.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 856, boot = 7, init = 5, finish = 844\n",
      "  Finished task 43.0 in stage 1.0 (TID 164). 2072 bytes result sent to driver\n",
      "  Starting task 47.0 in stage 1.0 (TID 168) (namenode, executor driver, partition 47, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 43.0 in stage 1.0 (TID 164) in 869 ms on namenode (executor driver) (44/121)\n",
      "  Running task 47.0 in stage 1.0 (TID 168)\n",
      "  Getting 121 (233.0 KiB) non-empty blocks including 121 (233.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 1289, boot = 10, init = 5, finish = 1274\n",
      "  Finished task 44.0 in stage 1.0 (TID 165). 2072 bytes result sent to driver\n",
      "  Starting task 48.0 in stage 1.0 (TID 169) (namenode, executor driver, partition 48, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 48.0 in stage 1.0 (TID 169)\n",
      "  Finished task 44.0 in stage 1.0 (TID 165) in 1301 ms on namenode (executor driver) (45/121)\n",
      "  Getting 121 (171.1 KiB) non-empty blocks including 121 (171.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 953, boot = 7, init = 18, finish = 928\n",
      "  Finished task 47.0 in stage 1.0 (TID 168). 2072 bytes result sent to driver\n",
      "  Starting task 49.0 in stage 1.0 (TID 170) (namenode, executor driver, partition 49, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 47.0 in stage 1.0 (TID 168) in 965 ms on namenode (executor driver) (46/121)\n",
      "  Running task 49.0 in stage 1.0 (TID 170)\n",
      "  Getting 121 (247.9 KiB) non-empty blocks including 121 (247.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 481, boot = 4, init = 11, finish = 466\n",
      "  Finished task 48.0 in stage 1.0 (TID 169). 2029 bytes result sent to driver\n",
      "  Starting task 50.0 in stage 1.0 (TID 171) (namenode, executor driver, partition 50, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 50.0 in stage 1.0 (TID 171)\n",
      "  Finished task 48.0 in stage 1.0 (TID 169) in 492 ms on namenode (executor driver) (47/121)\n",
      "  Getting 121 (249.9 KiB) non-empty blocks including 121 (249.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 1239, boot = 8, init = 3, finish = 1228\n",
      "  Finished task 46.0 in stage 1.0 (TID 167). 2072 bytes result sent to driver\n",
      "  Starting task 51.0 in stage 1.0 (TID 172) (namenode, executor driver, partition 51, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 46.0 in stage 1.0 (TID 167) in 1249 ms on namenode (executor driver) (48/121)\n",
      "  Running task 51.0 in stage 1.0 (TID 172)\n",
      "  Getting 121 (238.5 KiB) non-empty blocks including 121 (238.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 1832, boot = 33, init = 1, finish = 1798\n",
      "  Finished task 45.0 in stage 1.0 (TID 166). 2072 bytes result sent to driver\n",
      "  Starting task 52.0 in stage 1.0 (TID 173) (namenode, executor driver, partition 52, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 52.0 in stage 1.0 (TID 173)\n",
      "  Finished task 45.0 in stage 1.0 (TID 166) in 1858 ms on namenode (executor driver) (49/121)\n",
      "  Getting 121 (227.7 KiB) non-empty blocks including 121 (227.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 806, boot = 18, init = 5, finish = 783\n",
      "  Finished task 50.0 in stage 1.0 (TID 171). 2115 bytes result sent to driver\n",
      "  Starting task 53.0 in stage 1.0 (TID 174) (namenode, executor driver, partition 53, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 50.0 in stage 1.0 (TID 171) in 818 ms on namenode (executor driver) (50/121)\n",
      "  Running task 53.0 in stage 1.0 (TID 174)\n",
      "  Getting 121 (221.6 KiB) non-empty blocks including 121 (221.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 757, boot = 10, init = 21, finish = 726\n",
      "  Finished task 51.0 in stage 1.0 (TID 172). 2115 bytes result sent to driver\n",
      "  Starting task 54.0 in stage 1.0 (TID 175) (namenode, executor driver, partition 54, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 54.0 in stage 1.0 (TID 175)\n",
      "  Finished task 51.0 in stage 1.0 (TID 172) in 770 ms on namenode (executor driver) (51/121)\n",
      "  Getting 121 (278.0 KiB) non-empty blocks including 121 (278.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 866, boot = 0, init = 18, finish = 848\n",
      "  Finished task 53.0 in stage 1.0 (TID 174). 2072 bytes result sent to driver\n",
      "  Starting task 55.0 in stage 1.0 (TID 176) (namenode, executor driver, partition 55, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 55.0 in stage 1.0 (TID 176)\n",
      "  Finished task 53.0 in stage 1.0 (TID 174) in 882 ms on namenode (executor driver) (52/121)\n",
      "  Getting 121 (241.4 KiB) non-empty blocks including 121 (241.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Times: total = 1252, boot = -14, init = 29, finish = 1237\n",
      "  Finished task 52.0 in stage 1.0 (TID 173). 2115 bytes result sent to driver\n",
      "  Starting task 56.0 in stage 1.0 (TID 177) (namenode, executor driver, partition 56, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 56.0 in stage 1.0 (TID 177)\n",
      "  Finished task 52.0 in stage 1.0 (TID 173) in 1306 ms on namenode (executor driver) (53/121)\n",
      "  Getting 121 (286.9 KiB) non-empty blocks including 121 (286.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 1403, boot = 21, init = 7, finish = 1375\n",
      "  Finished task 54.0 in stage 1.0 (TID 175). 2029 bytes result sent to driver\n",
      "  Starting task 57.0 in stage 1.0 (TID 178) (namenode, executor driver, partition 57, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 54.0 in stage 1.0 (TID 175) in 1413 ms on namenode (executor driver) (54/121)\n",
      "  Running task 57.0 in stage 1.0 (TID 178)\n",
      "  Getting 121 (241.0 KiB) non-empty blocks including 121 (241.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 2731, boot = 9, init = 1, finish = 2721\n",
      "  Finished task 49.0 in stage 1.0 (TID 170). 2115 bytes result sent to driver\n",
      "  Starting task 58.0 in stage 1.0 (TID 179) (namenode, executor driver, partition 58, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 49.0 in stage 1.0 (TID 170) in 2745 ms on namenode (executor driver) (55/121)\n",
      "  Running task 58.0 in stage 1.0 (TID 179)\n",
      "  Getting 121 (237.4 KiB) non-empty blocks including 121 (237.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 1336, boot = 16, init = 17, finish = 1303\n",
      "  Finished task 55.0 in stage 1.0 (TID 176). 2072 bytes result sent to driver\n",
      "  Starting task 59.0 in stage 1.0 (TID 180) (namenode, executor driver, partition 59, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 59.0 in stage 1.0 (TID 180)\n",
      "  Finished task 55.0 in stage 1.0 (TID 176) in 1354 ms on namenode (executor driver) (56/121)\n",
      "  Getting 121 (251.2 KiB) non-empty blocks including 121 (251.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 1428, boot = 50, init = 1, finish = 1377\n",
      "  Finished task 57.0 in stage 1.0 (TID 178). 2029 bytes result sent to driver\n",
      "  Starting task 60.0 in stage 1.0 (TID 181) (namenode, executor driver, partition 60, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 60.0 in stage 1.0 (TID 181)\n",
      "  Finished task 57.0 in stage 1.0 (TID 178) in 1439 ms on namenode (executor driver) (57/121)\n",
      "  Getting 121 (283.1 KiB) non-empty blocks including 121 (283.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 1255, boot = 22, init = 1, finish = 1232\n",
      "  Finished task 58.0 in stage 1.0 (TID 179). 2029 bytes result sent to driver\n",
      "  Starting task 61.0 in stage 1.0 (TID 182) (namenode, executor driver, partition 61, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 58.0 in stage 1.0 (TID 179) in 1269 ms on namenode (executor driver) (58/121)\n",
      "  Running task 61.0 in stage 1.0 (TID 182)\n",
      "  Getting 121 (270.6 KiB) non-empty blocks including 121 (270.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 2086, boot = 9, init = 10, finish = 2067\n",
      "  Finished task 59.0 in stage 1.0 (TID 180). 2072 bytes result sent to driver\n",
      "  Starting task 62.0 in stage 1.0 (TID 183) (namenode, executor driver, partition 62, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 62.0 in stage 1.0 (TID 183)\n",
      "  Finished task 59.0 in stage 1.0 (TID 180) in 2099 ms on namenode (executor driver) (59/121)\n",
      "  Getting 121 (239.3 KiB) non-empty blocks including 121 (239.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 1818, boot = 9, init = 20, finish = 1789\n",
      "  Finished task 60.0 in stage 1.0 (TID 181). 2072 bytes result sent to driver\n",
      "  Starting task 63.0 in stage 1.0 (TID 184) (namenode, executor driver, partition 63, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 63.0 in stage 1.0 (TID 184)\n",
      "  Finished task 60.0 in stage 1.0 (TID 181) in 1829 ms on namenode (executor driver) (60/121)\n",
      "  Getting 121 (253.8 KiB) non-empty blocks including 121 (253.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 568, boot = 10, init = 8, finish = 550\n",
      "  Finished task 62.0 in stage 1.0 (TID 183). 2072 bytes result sent to driver\n",
      "  Starting task 64.0 in stage 1.0 (TID 185) (namenode, executor driver, partition 64, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 64.0 in stage 1.0 (TID 185)\n",
      "  Finished task 62.0 in stage 1.0 (TID 183) in 583 ms on namenode (executor driver) (61/121)\n",
      "  Getting 121 (235.7 KiB) non-empty blocks including 121 (235.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 2226, boot = 9, init = 15, finish = 2202\n",
      "  Finished task 61.0 in stage 1.0 (TID 182). 2072 bytes result sent to driver\n",
      "  Starting task 65.0 in stage 1.0 (TID 186) (namenode, executor driver, partition 65, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 65.0 in stage 1.0 (TID 186)\n",
      "  Finished task 61.0 in stage 1.0 (TID 182) in 2242 ms on namenode (executor driver) (62/121)\n",
      "  Getting 121 (268.7 KiB) non-empty blocks including 121 (268.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 4840, boot = 4, init = 11, finish = 4825\n",
      "  Finished task 56.0 in stage 1.0 (TID 177). 2029 bytes result sent to driver\n",
      "  Starting task 66.0 in stage 1.0 (TID 187) (namenode, executor driver, partition 66, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 66.0 in stage 1.0 (TID 187)\n",
      "  Finished task 56.0 in stage 1.0 (TID 177) in 4851 ms on namenode (executor driver) (63/121)\n",
      "  Getting 121 (244.6 KiB) non-empty blocks including 121 (244.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 1750, boot = 8, init = 9, finish = 1733\n",
      "  Finished task 63.0 in stage 1.0 (TID 184). 2072 bytes result sent to driver\n",
      "  Starting task 67.0 in stage 1.0 (TID 188) (namenode, executor driver, partition 67, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 67.0 in stage 1.0 (TID 188)\n",
      "  Finished task 63.0 in stage 1.0 (TID 184) in 1761 ms on namenode (executor driver) (64/121)\n",
      "  Getting 121 (298.4 KiB) non-empty blocks including 121 (298.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 749, boot = 30, init = 2, finish = 717\n",
      "  Finished task 66.0 in stage 1.0 (TID 187). 2072 bytes result sent to driver\n",
      "  Starting task 68.0 in stage 1.0 (TID 189) (namenode, executor driver, partition 68, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 66.0 in stage 1.0 (TID 187) in 762 ms on namenode (executor driver) (65/121)\n",
      "  Running task 68.0 in stage 1.0 (TID 189)\n",
      "  Getting 121 (293.4 KiB) non-empty blocks including 121 (293.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Times: total = 1938, boot = 1, init = 9, finish = 1928\n",
      "  Finished task 65.0 in stage 1.0 (TID 186). 2072 bytes result sent to driver\n",
      "  Starting task 69.0 in stage 1.0 (TID 190) (namenode, executor driver, partition 69, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 69.0 in stage 1.0 (TID 190)\n",
      "  Finished task 65.0 in stage 1.0 (TID 186) in 1951 ms on namenode (executor driver) (66/121)\n",
      "  Getting 121 (277.8 KiB) non-empty blocks including 121 (277.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 2690, boot = 37, init = 1, finish = 2652\n",
      "  Finished task 64.0 in stage 1.0 (TID 185). 2072 bytes result sent to driver\n",
      "  Starting task 70.0 in stage 1.0 (TID 191) (namenode, executor driver, partition 70, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 70.0 in stage 1.0 (TID 191)\n",
      "  Finished task 64.0 in stage 1.0 (TID 185) in 2702 ms on namenode (executor driver) (67/121)\n",
      "  Getting 121 (242.8 KiB) non-empty blocks including 121 (242.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 1655, boot = 18, init = 11, finish = 1626\n",
      "  Finished task 68.0 in stage 1.0 (TID 189). 2072 bytes result sent to driver\n",
      "  Starting task 71.0 in stage 1.0 (TID 192) (namenode, executor driver, partition 71, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 71.0 in stage 1.0 (TID 192)\n",
      "  Finished task 68.0 in stage 1.0 (TID 189) in 1667 ms on namenode (executor driver) (68/121)\n",
      "  Getting 121 (213.6 KiB) non-empty blocks including 121 (213.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 906, boot = 5, init = 4, finish = 897\n",
      "  Finished task 70.0 in stage 1.0 (TID 191). 2072 bytes result sent to driver\n",
      "  Starting task 72.0 in stage 1.0 (TID 193) (namenode, executor driver, partition 72, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 70.0 in stage 1.0 (TID 191) in 918 ms on namenode (executor driver) (69/121)\n",
      "  Running task 72.0 in stage 1.0 (TID 193)\n",
      "  Getting 121 (309.7 KiB) non-empty blocks including 121 (309.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 1407, boot = 17, init = 1, finish = 1389\n",
      "  Finished task 69.0 in stage 1.0 (TID 190). 2072 bytes result sent to driver\n",
      "  Starting task 73.0 in stage 1.0 (TID 194) (namenode, executor driver, partition 73, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 73.0 in stage 1.0 (TID 194)\n",
      "  Finished task 69.0 in stage 1.0 (TID 190) in 1427 ms on namenode (executor driver) (70/121)\n",
      "  Getting 121 (251.7 KiB) non-empty blocks including 121 (251.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 535, boot = 32, init = 13, finish = 490\n",
      "  Finished task 71.0 in stage 1.0 (TID 192). 2072 bytes result sent to driver\n",
      "  Starting task 74.0 in stage 1.0 (TID 195) (namenode, executor driver, partition 74, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 71.0 in stage 1.0 (TID 192) in 546 ms on namenode (executor driver) (71/121)\n",
      "  Running task 74.0 in stage 1.0 (TID 195)\n",
      "  Getting 121 (251.5 KiB) non-empty blocks including 121 (251.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 2977, boot = 18, init = 1, finish = 2958\n",
      "  Finished task 67.0 in stage 1.0 (TID 188). 2072 bytes result sent to driver\n",
      "  Starting task 75.0 in stage 1.0 (TID 196) (namenode, executor driver, partition 75, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 75.0 in stage 1.0 (TID 196)\n",
      "  Finished task 67.0 in stage 1.0 (TID 188) in 2987 ms on namenode (executor driver) (72/121)\n",
      "  Getting 121 (268.8 KiB) non-empty blocks including 121 (268.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 1460, boot = -5, init = 8, finish = 1457\n",
      "  Finished task 73.0 in stage 1.0 (TID 194). 2072 bytes result sent to driver\n",
      "  Starting task 76.0 in stage 1.0 (TID 197) (namenode, executor driver, partition 76, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 73.0 in stage 1.0 (TID 194) in 1472 ms on namenode (executor driver) (73/121)\n",
      "  Running task 76.0 in stage 1.0 (TID 197)\n",
      "  Getting 121 (238.8 KiB) non-empty blocks including 121 (238.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Times: total = 1672, boot = 20, init = 1, finish = 1651\n",
      "  Finished task 72.0 in stage 1.0 (TID 193). 2072 bytes result sent to driver\n",
      "  Starting task 77.0 in stage 1.0 (TID 198) (namenode, executor driver, partition 77, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 77.0 in stage 1.0 (TID 198)\n",
      "  Finished task 72.0 in stage 1.0 (TID 193) in 1682 ms on namenode (executor driver) (74/121)\n",
      "  Getting 121 (273.3 KiB) non-empty blocks including 121 (273.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 735, boot = 19, init = 1, finish = 715\n",
      "  Finished task 75.0 in stage 1.0 (TID 196). 2072 bytes result sent to driver\n",
      "  Starting task 78.0 in stage 1.0 (TID 199) (namenode, executor driver, partition 78, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 78.0 in stage 1.0 (TID 199)\n",
      "  Finished task 75.0 in stage 1.0 (TID 196) in 783 ms on namenode (executor driver) (75/121)\n",
      "  Getting 121 (250.7 KiB) non-empty blocks including 121 (250.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 1763, boot = 15, init = 3, finish = 1745\n",
      "  Finished task 74.0 in stage 1.0 (TID 195). 2072 bytes result sent to driver\n",
      "  Starting task 79.0 in stage 1.0 (TID 200) (namenode, executor driver, partition 79, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 79.0 in stage 1.0 (TID 200)\n",
      "  Finished task 74.0 in stage 1.0 (TID 195) in 1773 ms on namenode (executor driver) (76/121)\n",
      "  Getting 121 (257.8 KiB) non-empty blocks including 121 (257.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 986, boot = 7, init = 13, finish = 966\n",
      "  Finished task 76.0 in stage 1.0 (TID 197). 2072 bytes result sent to driver\n",
      "  Starting task 80.0 in stage 1.0 (TID 201) (namenode, executor driver, partition 80, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 76.0 in stage 1.0 (TID 197) in 1001 ms on namenode (executor driver) (77/121)\n",
      "  Running task 80.0 in stage 1.0 (TID 201)\n",
      "  Getting 121 (194.9 KiB) non-empty blocks including 121 (194.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 1539, boot = 3, init = 14, finish = 1522\n",
      "  Finished task 77.0 in stage 1.0 (TID 198). 2115 bytes result sent to driver\n",
      "  Starting task 81.0 in stage 1.0 (TID 202) (namenode, executor driver, partition 81, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 81.0 in stage 1.0 (TID 202)\n",
      "  Finished task 77.0 in stage 1.0 (TID 198) in 1550 ms on namenode (executor driver) (78/121)\n",
      "  Getting 121 (234.2 KiB) non-empty blocks including 121 (234.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 570, boot = 20, init = 12, finish = 538\n",
      "  Finished task 80.0 in stage 1.0 (TID 201). 2115 bytes result sent to driver\n",
      "  Starting task 82.0 in stage 1.0 (TID 203) (namenode, executor driver, partition 82, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 80.0 in stage 1.0 (TID 201) in 622 ms on namenode (executor driver) (79/121)\n",
      "  Running task 82.0 in stage 1.0 (TID 203)\n",
      "  Getting 121 (229.6 KiB) non-empty blocks including 121 (229.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 1265, boot = 10, init = 15, finish = 1240\n",
      "  Finished task 79.0 in stage 1.0 (TID 200). 2115 bytes result sent to driver\n",
      "  Starting task 83.0 in stage 1.0 (TID 204) (namenode, executor driver, partition 83, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 83.0 in stage 1.0 (TID 204)\n",
      "  Finished task 79.0 in stage 1.0 (TID 200) in 1275 ms on namenode (executor driver) (80/121)\n",
      "  Getting 121 (292.0 KiB) non-empty blocks including 121 (292.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 607, boot = 2, init = 7, finish = 598\n",
      "  Finished task 81.0 in stage 1.0 (TID 202). 2029 bytes result sent to driver\n",
      "  Starting task 84.0 in stage 1.0 (TID 205) (namenode, executor driver, partition 84, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 81.0 in stage 1.0 (TID 202) in 619 ms on namenode (executor driver) (81/121)\n",
      "  Running task 84.0 in stage 1.0 (TID 205)\n",
      "  Getting 121 (242.9 KiB) non-empty blocks including 121 (242.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 2178, boot = -26, init = 48, finish = 2156\n",
      "  Finished task 78.0 in stage 1.0 (TID 199). 2115 bytes result sent to driver\n",
      "  Starting task 85.0 in stage 1.0 (TID 206) (namenode, executor driver, partition 85, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 85.0 in stage 1.0 (TID 206)\n",
      "  Finished task 78.0 in stage 1.0 (TID 199) in 2187 ms on namenode (executor driver) (82/121)\n",
      "  Getting 121 (198.9 KiB) non-empty blocks including 121 (198.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 467, boot = 15, init = 1, finish = 451\n",
      "  Finished task 85.0 in stage 1.0 (TID 206). 2029 bytes result sent to driver\n",
      "  Starting task 86.0 in stage 1.0 (TID 207) (namenode, executor driver, partition 86, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 86.0 in stage 1.0 (TID 207)\n",
      "  Finished task 85.0 in stage 1.0 (TID 206) in 478 ms on namenode (executor driver) (83/121)\n",
      "  Getting 121 (233.6 KiB) non-empty blocks including 121 (233.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 691, boot = 2, init = 14, finish = 675\n",
      "  Finished task 84.0 in stage 1.0 (TID 205). 2029 bytes result sent to driver\n",
      "  Starting task 87.0 in stage 1.0 (TID 208) (namenode, executor driver, partition 87, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 84.0 in stage 1.0 (TID 205) in 702 ms on namenode (executor driver) (84/121)\n",
      "  Running task 87.0 in stage 1.0 (TID 208)\n",
      "  Getting 121 (292.5 KiB) non-empty blocks including 121 (292.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 1299, boot = -27, init = 39, finish = 1287\n",
      "  Finished task 82.0 in stage 1.0 (TID 203). 2072 bytes result sent to driver\n",
      "  Starting task 88.0 in stage 1.0 (TID 209) (namenode, executor driver, partition 88, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 82.0 in stage 1.0 (TID 203) in 1311 ms on namenode (executor driver) (85/121)\n",
      "  Running task 88.0 in stage 1.0 (TID 209)\n",
      "  Getting 121 (246.5 KiB) non-empty blocks including 121 (246.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Started 0 remote fetches in 3 ms\n",
      "  Times: total = 1544, boot = 18, init = 1, finish = 1525\n",
      "  Finished task 83.0 in stage 1.0 (TID 204). 2072 bytes result sent to driver\n",
      "  Starting task 89.0 in stage 1.0 (TID 210) (namenode, executor driver, partition 89, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 83.0 in stage 1.0 (TID 204) in 1554 ms on namenode (executor driver) (86/121)\n",
      "  Running task 89.0 in stage 1.0 (TID 210)\n",
      "  Getting 121 (199.7 KiB) non-empty blocks including 121 (199.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 607, boot = 19, init = 1, finish = 587\n",
      "  Finished task 89.0 in stage 1.0 (TID 210). 2072 bytes result sent to driver\n",
      "  Starting task 90.0 in stage 1.0 (TID 211) (namenode, executor driver, partition 90, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 90.0 in stage 1.0 (TID 211)\n",
      "  Finished task 89.0 in stage 1.0 (TID 210) in 619 ms on namenode (executor driver) (87/121)\n",
      "  Getting 121 (206.5 KiB) non-empty blocks including 121 (206.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 1344, boot = 5, init = 14, finish = 1325\n",
      "  Finished task 86.0 in stage 1.0 (TID 207). 2072 bytes result sent to driver\n",
      "  Starting task 91.0 in stage 1.0 (TID 212) (namenode, executor driver, partition 91, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 91.0 in stage 1.0 (TID 212)\n",
      "  Finished task 86.0 in stage 1.0 (TID 207) in 1359 ms on namenode (executor driver) (88/121)\n",
      "  Getting 121 (257.3 KiB) non-empty blocks including 121 (257.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 1460, boot = -3, init = 11, finish = 1452\n",
      "  Finished task 88.0 in stage 1.0 (TID 209). 2072 bytes result sent to driver\n",
      "  Starting task 92.0 in stage 1.0 (TID 213) (namenode, executor driver, partition 92, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 88.0 in stage 1.0 (TID 209) in 1475 ms on namenode (executor driver) (89/121)\n",
      "  Running task 92.0 in stage 1.0 (TID 213)\n",
      "  Getting 121 (253.3 KiB) non-empty blocks including 121 (253.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 515, boot = 16, init = 1, finish = 498\n",
      "  Finished task 90.0 in stage 1.0 (TID 211). 2029 bytes result sent to driver\n",
      "  Starting task 93.0 in stage 1.0 (TID 214) (namenode, executor driver, partition 93, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 90.0 in stage 1.0 (TID 211) in 525 ms on namenode (executor driver) (90/121)\n",
      "  Running task 93.0 in stage 1.0 (TID 214)\n",
      "  Getting 121 (260.3 KiB) non-empty blocks including 121 (260.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 2267, boot = 20, init = 0, finish = 2247\n",
      "  Finished task 87.0 in stage 1.0 (TID 208). 2072 bytes result sent to driver\n",
      "  Starting task 94.0 in stage 1.0 (TID 215) (namenode, executor driver, partition 94, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 94.0 in stage 1.0 (TID 215)\n",
      "  Finished task 87.0 in stage 1.0 (TID 208) in 2277 ms on namenode (executor driver) (91/121)\n",
      "  Getting 121 (250.3 KiB) non-empty blocks including 121 (250.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 960, boot = 10, init = 5, finish = 945\n",
      "  Finished task 92.0 in stage 1.0 (TID 213). 2072 bytes result sent to driver\n",
      "  Starting task 95.0 in stage 1.0 (TID 216) (namenode, executor driver, partition 95, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 92.0 in stage 1.0 (TID 213) in 974 ms on namenode (executor driver) (92/121)\n",
      "  Running task 95.0 in stage 1.0 (TID 216)\n",
      "  Getting 121 (488.5 KiB) non-empty blocks including 121 (488.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Times: total = 955, boot = 11, init = 8, finish = 936\n",
      "  Finished task 94.0 in stage 1.0 (TID 215). 2072 bytes result sent to driver\n",
      "  Starting task 96.0 in stage 1.0 (TID 217) (namenode, executor driver, partition 96, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 96.0 in stage 1.0 (TID 217)\n",
      "  Finished task 94.0 in stage 1.0 (TID 215) in 964 ms on namenode (executor driver) (93/121)\n",
      "  Getting 121 (207.0 KiB) non-empty blocks including 121 (207.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 594, boot = 7, init = 13, finish = 574\n",
      "  Finished task 96.0 in stage 1.0 (TID 217). 2029 bytes result sent to driver\n",
      "  Starting task 97.0 in stage 1.0 (TID 218) (namenode, executor driver, partition 97, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 97.0 in stage 1.0 (TID 218)\n",
      "  Getting 121 (255.0 KiB) non-empty blocks including 121 (255.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Finished task 96.0 in stage 1.0 (TID 217) in 610 ms on namenode (executor driver) (94/121)\n",
      "  Times: total = 2332, boot = 0, init = 10, finish = 2322\n",
      "  Finished task 93.0 in stage 1.0 (TID 214). 2072 bytes result sent to driver\n",
      "  Starting task 98.0 in stage 1.0 (TID 219) (namenode, executor driver, partition 98, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 98.0 in stage 1.0 (TID 219)\n",
      "  Finished task 93.0 in stage 1.0 (TID 214) in 2343 ms on namenode (executor driver) (95/121)\n",
      "  Getting 121 (206.1 KiB) non-empty blocks including 121 (206.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 656, boot = 16, init = 1, finish = 639\n",
      "  Finished task 98.0 in stage 1.0 (TID 219). 2029 bytes result sent to driver\n",
      "  Starting task 99.0 in stage 1.0 (TID 220) (namenode, executor driver, partition 99, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 98.0 in stage 1.0 (TID 219) in 667 ms on namenode (executor driver) (96/121)\n",
      "  Running task 99.0 in stage 1.0 (TID 220)\n",
      "  Getting 121 (229.7 KiB) non-empty blocks including 121 (229.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Times: total = 3555, boot = 17, init = 1, finish = 3537\n",
      "  Finished task 91.0 in stage 1.0 (TID 212). 2072 bytes result sent to driver\n",
      "  Starting task 100.0 in stage 1.0 (TID 221) (namenode, executor driver, partition 100, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 100.0 in stage 1.0 (TID 221)\n",
      "  Finished task 91.0 in stage 1.0 (TID 212) in 3567 ms on namenode (executor driver) (97/121)\n",
      "  Getting 121 (254.1 KiB) non-empty blocks including 121 (254.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 1137, boot = 13, init = 14, finish = 1110\n",
      "  Finished task 97.0 in stage 1.0 (TID 218). 2072 bytes result sent to driver\n",
      "  Starting task 101.0 in stage 1.0 (TID 222) (namenode, executor driver, partition 101, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 97.0 in stage 1.0 (TID 218) in 1148 ms on namenode (executor driver) (98/121)\n",
      "  Running task 101.0 in stage 1.0 (TID 222)\n",
      "  Getting 121 (250.5 KiB) non-empty blocks including 121 (250.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 629, boot = 3, init = 9, finish = 617\n",
      "  Finished task 99.0 in stage 1.0 (TID 220). 2072 bytes result sent to driver\n",
      "  Starting task 102.0 in stage 1.0 (TID 223) (namenode, executor driver, partition 102, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 102.0 in stage 1.0 (TID 223)\n",
      "  Finished task 99.0 in stage 1.0 (TID 220) in 641 ms on namenode (executor driver) (99/121)\n",
      "  Getting 121 (233.7 KiB) non-empty blocks including 121 (233.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 742, boot = 4, init = 1, finish = 737\n",
      "  Finished task 100.0 in stage 1.0 (TID 221). 2072 bytes result sent to driver\n",
      "  Starting task 103.0 in stage 1.0 (TID 224) (namenode, executor driver, partition 103, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 103.0 in stage 1.0 (TID 224)\n",
      "  Finished task 100.0 in stage 1.0 (TID 221) in 753 ms on namenode (executor driver) (100/121)\n",
      "  Getting 121 (247.6 KiB) non-empty blocks including 121 (247.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 541, boot = 4, init = 8, finish = 529\n",
      "  Finished task 102.0 in stage 1.0 (TID 223). 2072 bytes result sent to driver\n",
      "  Starting task 104.0 in stage 1.0 (TID 225) (namenode, executor driver, partition 104, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 102.0 in stage 1.0 (TID 223) in 552 ms on namenode (executor driver) (101/121)\n",
      "  Running task 104.0 in stage 1.0 (TID 225)\n",
      "  Getting 121 (266.1 KiB) non-empty blocks including 121 (266.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 626, boot = 4, init = 9, finish = 613\n",
      "  Finished task 103.0 in stage 1.0 (TID 224). 2029 bytes result sent to driver\n",
      "  Starting task 105.0 in stage 1.0 (TID 226) (namenode, executor driver, partition 105, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 103.0 in stage 1.0 (TID 224) in 635 ms on namenode (executor driver) (102/121)\n",
      "  Running task 105.0 in stage 1.0 (TID 226)\n",
      "  Getting 121 (270.2 KiB) non-empty blocks including 121 (270.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 873, boot = 7, init = 27, finish = 839\n",
      "  Finished task 104.0 in stage 1.0 (TID 225). 2072 bytes result sent to driver\n",
      "  Starting task 106.0 in stage 1.0 (TID 227) (namenode, executor driver, partition 106, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 106.0 in stage 1.0 (TID 227)\n",
      "  Finished task 104.0 in stage 1.0 (TID 225) in 884 ms on namenode (executor driver) (103/121)\n",
      "  Getting 121 (302.0 KiB) non-empty blocks including 121 (302.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 2076, boot = 10, init = 6, finish = 2060\n",
      "  Finished task 101.0 in stage 1.0 (TID 222). 2029 bytes result sent to driver\n",
      "  Starting task 107.0 in stage 1.0 (TID 228) (namenode, executor driver, partition 107, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 107.0 in stage 1.0 (TID 228)\n",
      "  Finished task 101.0 in stage 1.0 (TID 222) in 2086 ms on namenode (executor driver) (104/121)\n",
      "  Getting 121 (229.3 KiB) non-empty blocks including 121 (229.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 2 ms\n",
      "  Times: total = 1173, boot = 5, init = 3, finish = 1165\n",
      "  Finished task 105.0 in stage 1.0 (TID 226). 2115 bytes result sent to driver\n",
      "  Starting task 108.0 in stage 1.0 (TID 229) (namenode, executor driver, partition 108, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 108.0 in stage 1.0 (TID 229)\n",
      "  Finished task 105.0 in stage 1.0 (TID 226) in 1184 ms on namenode (executor driver) (105/121)\n",
      "  Getting 121 (226.8 KiB) non-empty blocks including 121 (226.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 485, boot = 10, init = 8, finish = 467\n",
      "  Finished task 107.0 in stage 1.0 (TID 228). 2072 bytes result sent to driver\n",
      "  Starting task 109.0 in stage 1.0 (TID 230) (namenode, executor driver, partition 109, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 107.0 in stage 1.0 (TID 228) in 497 ms on namenode (executor driver) (106/121)\n",
      "  Running task 109.0 in stage 1.0 (TID 230)\n",
      "  Getting 121 (244.9 KiB) non-empty blocks including 121 (244.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 1041, boot = 16, init = 1, finish = 1024\n",
      "  Finished task 109.0 in stage 1.0 (TID 230). 2072 bytes result sent to driver\n",
      "  Starting task 110.0 in stage 1.0 (TID 231) (namenode, executor driver, partition 110, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 110.0 in stage 1.0 (TID 231)\n",
      "  Finished task 109.0 in stage 1.0 (TID 230) in 1052 ms on namenode (executor driver) (107/121)\n",
      "  Getting 121 (240.7 KiB) non-empty blocks including 121 (240.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 2117, boot = 3, init = 4, finish = 2110\n",
      "  Finished task 108.0 in stage 1.0 (TID 229). 2072 bytes result sent to driver\n",
      "  Starting task 111.0 in stage 1.0 (TID 232) (namenode, executor driver, partition 111, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 108.0 in stage 1.0 (TID 229) in 2128 ms on namenode (executor driver) (108/121)\n",
      "  Running task 111.0 in stage 1.0 (TID 232)\n",
      "  Getting 121 (220.6 KiB) non-empty blocks including 121 (220.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 921, boot = 6, init = 22, finish = 893\n",
      "  Finished task 110.0 in stage 1.0 (TID 231). 2029 bytes result sent to driver\n",
      "  Starting task 112.0 in stage 1.0 (TID 233) (namenode, executor driver, partition 112, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 112.0 in stage 1.0 (TID 233)\n",
      "  Finished task 110.0 in stage 1.0 (TID 231) in 931 ms on namenode (executor driver) (109/121)\n",
      "  Getting 121 (241.1 KiB) non-empty blocks including 121 (241.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 442, boot = 3, init = 8, finish = 431\n",
      "  Finished task 111.0 in stage 1.0 (TID 232). 2072 bytes result sent to driver\n",
      "  Starting task 113.0 in stage 1.0 (TID 234) (namenode, executor driver, partition 113, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 111.0 in stage 1.0 (TID 232) in 456 ms on namenode (executor driver) (110/121)\n",
      "  Running task 113.0 in stage 1.0 (TID 234)\n",
      "  Getting 121 (282.0 KiB) non-empty blocks including 121 (282.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 1179, boot = 16, init = 6, finish = 1157\n",
      "  Finished task 112.0 in stage 1.0 (TID 233). 2072 bytes result sent to driver\n",
      "  Starting task 114.0 in stage 1.0 (TID 235) (namenode, executor driver, partition 114, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 114.0 in stage 1.0 (TID 235)\n",
      "  Finished task 112.0 in stage 1.0 (TID 233) in 1189 ms on namenode (executor driver) (111/121)\n",
      "  Getting 121 (250.3 KiB) non-empty blocks including 121 (250.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 4395, boot = 0, init = 11, finish = 4384\n",
      "  Finished task 106.0 in stage 1.0 (TID 227). 2115 bytes result sent to driver\n",
      "  Starting task 115.0 in stage 1.0 (TID 236) (namenode, executor driver, partition 115, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 115.0 in stage 1.0 (TID 236)\n",
      "  Getting 121 (251.6 KiB) non-empty blocks including 121 (251.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Finished task 106.0 in stage 1.0 (TID 227) in 4408 ms on namenode (executor driver) (112/121)\n",
      "  Times: total = 1290, boot = 1, init = 10, finish = 1279\n",
      "  Finished task 113.0 in stage 1.0 (TID 234). 2072 bytes result sent to driver\n",
      "  Starting task 116.0 in stage 1.0 (TID 237) (namenode, executor driver, partition 116, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 116.0 in stage 1.0 (TID 237)\n",
      "  Finished task 113.0 in stage 1.0 (TID 234) in 1305 ms on namenode (executor driver) (113/121)\n",
      "  Getting 121 (248.3 KiB) non-empty blocks including 121 (248.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 857, boot = 3, init = 12, finish = 842\n",
      "  Finished task 114.0 in stage 1.0 (TID 235). 2072 bytes result sent to driver\n",
      "  Starting task 117.0 in stage 1.0 (TID 238) (namenode, executor driver, partition 117, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 114.0 in stage 1.0 (TID 235) in 867 ms on namenode (executor driver) (114/121)\n",
      "  Running task 117.0 in stage 1.0 (TID 238)\n",
      "  Getting 121 (280.1 KiB) non-empty blocks including 121 (280.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 884, boot = 6, init = 9, finish = 869\n",
      "  Finished task 116.0 in stage 1.0 (TID 237). 2072 bytes result sent to driver\n",
      "  Starting task 118.0 in stage 1.0 (TID 239) (namenode, executor driver, partition 118, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 118.0 in stage 1.0 (TID 239)\n",
      "  Finished task 116.0 in stage 1.0 (TID 237) in 894 ms on namenode (executor driver) (115/121)\n",
      "  Getting 121 (195.2 KiB) non-empty blocks including 121 (195.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 307, boot = 2, init = 2, finish = 303\n",
      "  Finished task 118.0 in stage 1.0 (TID 239). 2072 bytes result sent to driver\n",
      "  Starting task 119.0 in stage 1.0 (TID 240) (namenode, executor driver, partition 119, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 119.0 in stage 1.0 (TID 240)\n",
      "  Finished task 118.0 in stage 1.0 (TID 239) in 317 ms on namenode (executor driver) (116/121)\n",
      "  Getting 121 (220.3 KiB) non-empty blocks including 121 (220.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 936, boot = 7, init = 9, finish = 920\n",
      "  Finished task 117.0 in stage 1.0 (TID 238). 2029 bytes result sent to driver\n",
      "  Starting task 120.0 in stage 1.0 (TID 241) (namenode, executor driver, partition 120, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 117.0 in stage 1.0 (TID 238) in 946 ms on namenode (executor driver) (117/121)\n",
      "  Running task 120.0 in stage 1.0 (TID 241)\n",
      "  Getting 121 (261.0 KiB) non-empty blocks including 121 (261.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 1773, boot = 26, init = 1, finish = 1746\n",
      "  Finished task 115.0 in stage 1.0 (TID 236). 2072 bytes result sent to driver\n",
      "  Finished task 115.0 in stage 1.0 (TID 236) in 1785 ms on namenode (executor driver) (118/121)\n",
      "  Times: total = 337, boot = 4, init = 14, finish = 319\n",
      "  Finished task 120.0 in stage 1.0 (TID 241). 2072 bytes result sent to driver\n",
      "  Finished task 120.0 in stage 1.0 (TID 241) in 347 ms on namenode (executor driver) (119/121)\n",
      "  Times: total = 716, boot = 12, init = 9, finish = 695\n",
      "  Finished task 119.0 in stage 1.0 (TID 240). 2029 bytes result sent to driver\n",
      "  Finished task 119.0 in stage 1.0 (TID 240) in 727 ms on namenode (executor driver) (120/121)\n",
      "  Times: total = 12305, boot = 18, init = 1, finish = 12286\n",
      "  Finished task 95.0 in stage 1.0 (TID 216). 2115 bytes result sent to driver\n",
      "  Finished task 95.0 in stage 1.0 (TID 216) in 12322 ms on namenode (executor driver) (121/121)\n",
      "  Removed TaskSet 1.0, whose tasks have all completed, from pool \n",
      "  ShuffleMapStage 1 (groupBy at /home/ubuntu/.local/lib/python3.8/site-packages/mrjob/spark/harness.py:539) finished in 42.865 s\n",
      "  looking for newly runnable stages\n",
      "  running: Set()\n",
      "  waiting: Set(ResultStage 2)\n",
      "  failed: Set()\n",
      "  Submitting ResultStage 2 (MapPartitionsRDD[12] at saveAsTextFile at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "  Block broadcast_3 stored as values in memory (estimated size 134.7 KiB, free 365.7 MiB)\n",
      "  Block broadcast_3_piece0 stored as bytes in memory (estimated size 52.9 KiB, free 365.6 MiB)\n",
      "  Added broadcast_3_piece0 in memory on namenode:45181 (size: 52.9 KiB, free: 366.2 MiB)\n",
      "  Created broadcast 3 from broadcast at DAGScheduler.scala:1427\n",
      "  Submitting 121 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at saveAsTextFile at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))\n",
      "  Adding task set 2.0 with 121 tasks resource profile 0\n",
      "  Starting task 69.0 in stage 2.0 (TID 242) (namenode, executor driver, partition 69, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Starting task 0.0 in stage 2.0 (TID 243) (namenode, executor driver, partition 0, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Starting task 1.0 in stage 2.0 (TID 244) (namenode, executor driver, partition 1, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Starting task 2.0 in stage 2.0 (TID 245) (namenode, executor driver, partition 2, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 1.0 in stage 2.0 (TID 244)\n",
      "  Running task 0.0 in stage 2.0 (TID 243)\n",
      "  Running task 69.0 in stage 2.0 (TID 242)\n",
      "  Running task 2.0 in stage 2.0 (TID 245)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Getting 121 (1023.2 KiB) non-empty blocks including 121 (1023.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 12, boot = -2274, init = 2278, finish = 8\n",
      "  Times: total = 19, boot = -2247, init = 2260, finish = 6\n",
      "  Times: total = 22, boot = -1993, init = 2007, finish = 8\n",
      "  Times: total = 451, boot = -493, init = 516, finish = 428\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000001_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000001\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000069_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000069\n",
      "  attempt_202204291552304462589629084801761_0012_m_000069_0: Committed\n",
      "  attempt_202204291552304462589629084801761_0012_m_000001_0: Committed\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000000_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000000\n",
      "  attempt_202204291552304462589629084801761_0012_m_000000_0: Committed\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000002_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000002\n",
      "  attempt_202204291552304462589629084801761_0012_m_000002_0: Committed\n",
      "  Finished task 2.0 in stage 2.0 (TID 245). 1996 bytes result sent to driver\n",
      "  Finished task 0.0 in stage 2.0 (TID 243). 2039 bytes result sent to driver\n",
      "  Finished task 1.0 in stage 2.0 (TID 244). 2039 bytes result sent to driver\n",
      "  Finished task 69.0 in stage 2.0 (TID 242). 2125 bytes result sent to driver\n",
      "  Starting task 3.0 in stage 2.0 (TID 246) (namenode, executor driver, partition 3, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 3.0 in stage 2.0 (TID 246)\n",
      "  Starting task 4.0 in stage 2.0 (TID 247) (namenode, executor driver, partition 4, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 4.0 in stage 2.0 (TID 247)\n",
      "  Starting task 5.0 in stage 2.0 (TID 248) (namenode, executor driver, partition 5, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 5.0 in stage 2.0 (TID 248)\n",
      "  Starting task 6.0 in stage 2.0 (TID 249) (namenode, executor driver, partition 6, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 2.0 in stage 2.0 (TID 245) in 996 ms on namenode (executor driver) (1/121)\n",
      "  Running task 6.0 in stage 2.0 (TID 249)\n",
      "  Finished task 0.0 in stage 2.0 (TID 243) in 999 ms on namenode (executor driver) (2/121)\n",
      "  Finished task 1.0 in stage 2.0 (TID 244) in 1007 ms on namenode (executor driver) (3/121)\n",
      "  Finished task 69.0 in stage 2.0 (TID 242) in 1021 ms on namenode (executor driver) (4/121)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Started 0 remote fetches in 0 ms\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 4 ms\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 38, boot = -190, init = 221, finish = 7\n",
      "  Times: total = 18, boot = -735, init = 737, finish = 16\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000005_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000005\n",
      "  attempt_202204291552304462589629084801761_0012_m_000005_0: Committed\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000004_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000004\n",
      "  attempt_202204291552304462589629084801761_0012_m_000004_0: Committed\n",
      "  Finished task 4.0 in stage 2.0 (TID 247). 1996 bytes result sent to driver\n",
      "  Finished task 5.0 in stage 2.0 (TID 248). 1996 bytes result sent to driver\n",
      "  Starting task 7.0 in stage 2.0 (TID 250) (namenode, executor driver, partition 7, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Times: total = 28, boot = -755, init = 777, finish = 6\n",
      "  Finished task 4.0 in stage 2.0 (TID 247) in 149 ms on namenode (executor driver) (5/121)\n",
      "  Running task 7.0 in stage 2.0 (TID 250)\n",
      "  Finished task 5.0 in stage 2.0 (TID 248) in 148 ms on namenode (executor driver) (6/121)\n",
      "  Starting task 8.0 in stage 2.0 (TID 251) (namenode, executor driver, partition 8, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 8.0 in stage 2.0 (TID 251)\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000006_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000006\n",
      "  attempt_202204291552304462589629084801761_0012_m_000006_0: Committed\n",
      "  Finished task 6.0 in stage 2.0 (TID 249). 1996 bytes result sent to driver\n",
      "  Starting task 9.0 in stage 2.0 (TID 252) (namenode, executor driver, partition 9, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Times: total = 16, boot = -774, init = 784, finish = 6\n",
      "  Finished task 6.0 in stage 2.0 (TID 249) in 158 ms on namenode (executor driver) (7/121)\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000003_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000003\n",
      "  attempt_202204291552304462589629084801761_0012_m_000003_0: Committed\n",
      "  Finished task 3.0 in stage 2.0 (TID 246). 1996 bytes result sent to driver\n",
      "  Starting task 10.0 in stage 2.0 (TID 253) (namenode, executor driver, partition 10, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 3.0 in stage 2.0 (TID 246) in 169 ms on namenode (executor driver) (8/121)\n",
      "  Running task 9.0 in stage 2.0 (TID 252)\n",
      "  Running task 10.0 in stage 2.0 (TID 253)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 11 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 7, boot = -55, init = 56, finish = 6\n",
      "  Times: total = 16, boot = -99, init = 109, finish = 6\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000010_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000010\n",
      "  attempt_202204291552304462589629084801761_0012_m_000010_0: Committed\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000008_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000008\n",
      "  attempt_202204291552304462589629084801761_0012_m_000008_0: Committed\n",
      "  Times: total = 7, boot = -96, init = 97, finish = 6\n",
      "  Finished task 8.0 in stage 2.0 (TID 251). 1996 bytes result sent to driver\n",
      "  Finished task 10.0 in stage 2.0 (TID 253). 1996 bytes result sent to driver\n",
      "  Times: total = 15, boot = -124, init = 134, finish = 5\n",
      "  Starting task 11.0 in stage 2.0 (TID 254) (namenode, executor driver, partition 11, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000009_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000009\n",
      "  attempt_202204291552304462589629084801761_0012_m_000009_0: Committed\n",
      "  Finished task 8.0 in stage 2.0 (TID 251) in 93 ms on namenode (executor driver) (9/121)\n",
      "  Finished task 9.0 in stage 2.0 (TID 252). 1996 bytes result sent to driver\n",
      "  Running task 11.0 in stage 2.0 (TID 254)\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000007_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000007\n",
      "  attempt_202204291552304462589629084801761_0012_m_000007_0: Committed\n",
      "  Starting task 12.0 in stage 2.0 (TID 255) (namenode, executor driver, partition 12, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 7.0 in stage 2.0 (TID 250). 1996 bytes result sent to driver\n",
      "  Running task 12.0 in stage 2.0 (TID 255)\n",
      "  Finished task 10.0 in stage 2.0 (TID 253) in 87 ms on namenode (executor driver) (10/121)\n",
      "  Finished task 9.0 in stage 2.0 (TID 252) in 95 ms on namenode (executor driver) (11/121)\n",
      "  Starting task 13.0 in stage 2.0 (TID 256) (namenode, executor driver, partition 13, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Starting task 14.0 in stage 2.0 (TID 257) (namenode, executor driver, partition 14, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 13.0 in stage 2.0 (TID 256)\n",
      "  Finished task 7.0 in stage 2.0 (TID 250) in 112 ms on namenode (executor driver) (12/121)\n",
      "  Running task 14.0 in stage 2.0 (TID 257)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 10, boot = -64, init = 66, finish = 8\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000011_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000011\n",
      "  attempt_202204291552304462589629084801761_0012_m_000011_0: Committed\n",
      "  Finished task 11.0 in stage 2.0 (TID 254). 1996 bytes result sent to driver\n",
      "  Starting task 15.0 in stage 2.0 (TID 258) (namenode, executor driver, partition 15, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 11.0 in stage 2.0 (TID 254) in 59 ms on namenode (executor driver) (13/121)\n",
      "  Running task 15.0 in stage 2.0 (TID 258)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 52, boot = -68, init = 114, finish = 6\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000013_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000013\n",
      "  attempt_202204291552304462589629084801761_0012_m_000013_0: Committed\n",
      "  Finished task 13.0 in stage 2.0 (TID 256). 1996 bytes result sent to driver\n",
      "  Starting task 16.0 in stage 2.0 (TID 259) (namenode, executor driver, partition 16, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 13.0 in stage 2.0 (TID 256) in 72 ms on namenode (executor driver) (14/121)\n",
      "  Running task 16.0 in stage 2.0 (TID 259)\n",
      "  Times: total = 57, boot = -54, init = 105, finish = 6\n",
      "  Times: total = 64, boot = -40, init = 90, finish = 14\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000014_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000014\n",
      "  attempt_202204291552304462589629084801761_0012_m_000014_0: Committed\n",
      "  Finished task 14.0 in stage 2.0 (TID 257). 1996 bytes result sent to driver\n",
      "  Starting task 17.0 in stage 2.0 (TID 260) (namenode, executor driver, partition 17, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 2 ms\n",
      "  Finished task 14.0 in stage 2.0 (TID 257) in 83 ms on namenode (executor driver) (15/121)\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000012_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000012\n",
      "  attempt_202204291552304462589629084801761_0012_m_000012_0: Committed\n",
      "  Finished task 12.0 in stage 2.0 (TID 255). 1996 bytes result sent to driver\n",
      "  Starting task 18.0 in stage 2.0 (TID 261) (namenode, executor driver, partition 18, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 18.0 in stage 2.0 (TID 261)\n",
      "  Running task 17.0 in stage 2.0 (TID 260)\n",
      "  Finished task 12.0 in stage 2.0 (TID 255) in 88 ms on namenode (executor driver) (16/121)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 9 ms\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 5 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 52, boot = -29, init = 75, finish = 6\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000015_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000015\n",
      "  attempt_202204291552304462589629084801761_0012_m_000015_0: Committed\n",
      "  Times: total = 20, boot = 4, init = 9, finish = 7\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000018_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000018\n",
      "  attempt_202204291552304462589629084801761_0012_m_000018_0: Committed\n",
      "  Finished task 18.0 in stage 2.0 (TID 261). 1996 bytes result sent to driver\n",
      "  Finished task 15.0 in stage 2.0 (TID 258). 1996 bytes result sent to driver\n",
      "  Starting task 19.0 in stage 2.0 (TID 262) (namenode, executor driver, partition 19, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 19.0 in stage 2.0 (TID 262)\n",
      "  Starting task 20.0 in stage 2.0 (TID 263) (namenode, executor driver, partition 20, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 18.0 in stage 2.0 (TID 261) in 69 ms on namenode (executor driver) (17/121)\n",
      "  Finished task 15.0 in stage 2.0 (TID 258) in 106 ms on namenode (executor driver) (18/121)\n",
      "  Times: total = 22, boot = 15, init = 1, finish = 6\n",
      "  Times: total = 12, boot = -12, init = 17, finish = 7\n",
      "  Running task 20.0 in stage 2.0 (TID 263)\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000016_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000016\n",
      "  attempt_202204291552304462589629084801761_0012_m_000016_0: Committed\n",
      "  Finished task 16.0 in stage 2.0 (TID 259). 1996 bytes result sent to driver\n",
      "  Starting task 21.0 in stage 2.0 (TID 264) (namenode, executor driver, partition 21, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 21.0 in stage 2.0 (TID 264)\n",
      "  Finished task 16.0 in stage 2.0 (TID 259) in 87 ms on namenode (executor driver) (19/121)\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000017_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000017\n",
      "  attempt_202204291552304462589629084801761_0012_m_000017_0: Committed\n",
      "  Finished task 17.0 in stage 2.0 (TID 260). 1996 bytes result sent to driver\n",
      "  Starting task 22.0 in stage 2.0 (TID 265) (namenode, executor driver, partition 22, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 17.0 in stage 2.0 (TID 260) in 78 ms on namenode (executor driver) (20/121)\n",
      "  Running task 22.0 in stage 2.0 (TID 265)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 3 ms\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 7, boot = -45, init = 46, finish = 6\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000021_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000021\n",
      "  attempt_202204291552304462589629084801761_0012_m_000021_0: Committed\n",
      "  Finished task 21.0 in stage 2.0 (TID 264). 1996 bytes result sent to driver\n",
      "  Starting task 23.0 in stage 2.0 (TID 266) (namenode, executor driver, partition 23, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 21.0 in stage 2.0 (TID 264) in 61 ms on namenode (executor driver) (21/121)\n",
      "  Running task 23.0 in stage 2.0 (TID 266)\n",
      "  Times: total = 16, boot = -45, init = 55, finish = 6\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000019_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000019\n",
      "  attempt_202204291552304462589629084801761_0012_m_000019_0: Committed\n",
      "  Finished task 19.0 in stage 2.0 (TID 262). 1996 bytes result sent to driver\n",
      "  Starting task 24.0 in stage 2.0 (TID 267) (namenode, executor driver, partition 24, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 19.0 in stage 2.0 (TID 262) in 73 ms on namenode (executor driver) (22/121)\n",
      "  Times: total = 24, boot = -61, init = 79, finish = 6\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000020_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000020\n",
      "  attempt_202204291552304462589629084801761_0012_m_000020_0: Committed\n",
      "  Finished task 20.0 in stage 2.0 (TID 263). 1996 bytes result sent to driver\n",
      "  Running task 24.0 in stage 2.0 (TID 267)\n",
      "  Starting task 25.0 in stage 2.0 (TID 268) (namenode, executor driver, partition 25, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 20.0 in stage 2.0 (TID 263) in 75 ms on namenode (executor driver) (23/121)\n",
      "  Running task 25.0 in stage 2.0 (TID 268)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 32, boot = -34, init = 60, finish = 6\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000022_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000022\n",
      "  attempt_202204291552304462589629084801761_0012_m_000022_0: Committed\n",
      "  Finished task 22.0 in stage 2.0 (TID 265). 1996 bytes result sent to driver\n",
      "  Starting task 26.0 in stage 2.0 (TID 269) (namenode, executor driver, partition 26, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 26.0 in stage 2.0 (TID 269)\n",
      "  Finished task 22.0 in stage 2.0 (TID 265) in 92 ms on namenode (executor driver) (24/121)\n",
      "  Times: total = 50, boot = -36, init = 80, finish = 6\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000024_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000024\n",
      "  attempt_202204291552304462589629084801761_0012_m_000024_0: Committed\n",
      "  Finished task 24.0 in stage 2.0 (TID 267). 2039 bytes result sent to driver\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Starting task 27.0 in stage 2.0 (TID 270) (namenode, executor driver, partition 27, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 27.0 in stage 2.0 (TID 270)\n",
      "  Finished task 24.0 in stage 2.0 (TID 267) in 81 ms on namenode (executor driver) (25/121)\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 77, boot = -33, init = 82, finish = 28\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000025_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000025\n",
      "  attempt_202204291552304462589629084801761_0012_m_000025_0: Committed\n",
      "  Times: total = 9, boot = -47, init = 49, finish = 7\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000023_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000023\n",
      "  attempt_202204291552304462589629084801761_0012_m_000023_0: Committed\n",
      "  Finished task 23.0 in stage 2.0 (TID 266). 2039 bytes result sent to driver\n",
      "  Finished task 25.0 in stage 2.0 (TID 268). 2039 bytes result sent to driver\n",
      "  Starting task 28.0 in stage 2.0 (TID 271) (namenode, executor driver, partition 28, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 28.0 in stage 2.0 (TID 271)\n",
      "  Starting task 29.0 in stage 2.0 (TID 272) (namenode, executor driver, partition 29, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 23.0 in stage 2.0 (TID 266) in 104 ms on namenode (executor driver) (26/121)\n",
      "  Running task 29.0 in stage 2.0 (TID 272)\n",
      "  Finished task 25.0 in stage 2.0 (TID 268) in 95 ms on namenode (executor driver) (27/121)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Started 0 remote fetches in 4 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 60, boot = -89, init = 142, finish = 7\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000026_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000026\n",
      "  attempt_202204291552304462589629084801761_0012_m_000026_0: Committed\n",
      "  Finished task 26.0 in stage 2.0 (TID 269). 2039 bytes result sent to driver\n",
      "  Starting task 30.0 in stage 2.0 (TID 273) (namenode, executor driver, partition 30, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 30.0 in stage 2.0 (TID 273)\n",
      "  Finished task 26.0 in stage 2.0 (TID 269) in 115 ms on namenode (executor driver) (28/121)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 10, boot = -39, init = 43, finish = 6\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000029_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000029\n",
      "  attempt_202204291552304462589629084801761_0012_m_000029_0: Committed\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Finished task 29.0 in stage 2.0 (TID 272). 1996 bytes result sent to driver\n",
      "  Starting task 31.0 in stage 2.0 (TID 274) (namenode, executor driver, partition 31, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 29.0 in stage 2.0 (TID 272) in 61 ms on namenode (executor driver) (29/121)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Running task 31.0 in stage 2.0 (TID 274)\n",
      "  Times: total = 56, boot = -86, init = 135, finish = 7\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000028_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000028\n",
      "  attempt_202204291552304462589629084801761_0012_m_000028_0: Committed\n",
      "  Finished task 28.0 in stage 2.0 (TID 271). 1996 bytes result sent to driver\n",
      "  Starting task 32.0 in stage 2.0 (TID 275) (namenode, executor driver, partition 32, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 32.0 in stage 2.0 (TID 275)\n",
      "  Finished task 28.0 in stage 2.0 (TID 271) in 74 ms on namenode (executor driver) (30/121)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 26, boot = 12, init = 8, finish = 6\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000027_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000027\n",
      "  attempt_202204291552304462589629084801761_0012_m_000027_0: Committed\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Finished task 27.0 in stage 2.0 (TID 270). 1996 bytes result sent to driver\n",
      "  Starting task 33.0 in stage 2.0 (TID 276) (namenode, executor driver, partition 33, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 33.0 in stage 2.0 (TID 276)\n",
      "  Finished task 27.0 in stage 2.0 (TID 270) in 105 ms on namenode (executor driver) (31/121)\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 9, boot = -43, init = 46, finish = 6\n",
      "  Times: total = 13, boot = 6, init = 1, finish = 6\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000030_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000030\n",
      "  attempt_202204291552304462589629084801761_0012_m_000030_0: Committed\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000031_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000031\n",
      "  attempt_202204291552304462589629084801761_0012_m_000031_0: Committed\n",
      "  Finished task 31.0 in stage 2.0 (TID 274). 1996 bytes result sent to driver\n",
      "  Starting task 34.0 in stage 2.0 (TID 277) (namenode, executor driver, partition 34, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 34.0 in stage 2.0 (TID 277)\n",
      "  Finished task 31.0 in stage 2.0 (TID 274) in 60 ms on namenode (executor driver) (32/121)\n",
      "  Finished task 30.0 in stage 2.0 (TID 273). 1996 bytes result sent to driver\n",
      "  Starting task 35.0 in stage 2.0 (TID 278) (namenode, executor driver, partition 35, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 35.0 in stage 2.0 (TID 278)\n",
      "  Finished task 30.0 in stage 2.0 (TID 273) in 78 ms on namenode (executor driver) (33/121)\n",
      "  Times: total = 13, boot = 4, init = 4, finish = 5\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000032_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000032\n",
      "  attempt_202204291552304462589629084801761_0012_m_000032_0: Committed\n",
      "  Finished task 32.0 in stage 2.0 (TID 275). 1996 bytes result sent to driver\n",
      "  Starting task 36.0 in stage 2.0 (TID 279) (namenode, executor driver, partition 36, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 32.0 in stage 2.0 (TID 275) in 57 ms on namenode (executor driver) (34/121)\n",
      "  Running task 36.0 in stage 2.0 (TID 279)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 10, boot = -44, init = 46, finish = 8\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000033_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000033\n",
      "  attempt_202204291552304462589629084801761_0012_m_000033_0: Committed\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Finished task 33.0 in stage 2.0 (TID 276). 1996 bytes result sent to driver\n",
      "  Starting task 37.0 in stage 2.0 (TID 280) (namenode, executor driver, partition 37, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 33.0 in stage 2.0 (TID 276) in 60 ms on namenode (executor driver) (35/121)\n",
      "  Running task 37.0 in stage 2.0 (TID 280)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 12, boot = -31, init = 37, finish = 6\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000036_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000036\n",
      "  attempt_202204291552304462589629084801761_0012_m_000036_0: Committed\n",
      "  Finished task 36.0 in stage 2.0 (TID 279). 1996 bytes result sent to driver\n",
      "  Starting task 38.0 in stage 2.0 (TID 281) (namenode, executor driver, partition 38, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 36.0 in stage 2.0 (TID 279) in 51 ms on namenode (executor driver) (36/121)\n",
      "  Running task 38.0 in stage 2.0 (TID 281)\n",
      "  Times: total = 21, boot = -57, init = 67, finish = 11\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000034_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000034\n",
      "  attempt_202204291552304462589629084801761_0012_m_000034_0: Committed\n",
      "  Finished task 34.0 in stage 2.0 (TID 277). 1996 bytes result sent to driver\n",
      "  Starting task 39.0 in stage 2.0 (TID 282) (namenode, executor driver, partition 39, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 34.0 in stage 2.0 (TID 277) in 61 ms on namenode (executor driver) (37/121)\n",
      "  Running task 39.0 in stage 2.0 (TID 282)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 63, boot = -34, init = 89, finish = 8\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000035_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000035\n",
      "  attempt_202204291552304462589629084801761_0012_m_000035_0: Committed\n",
      "  Finished task 35.0 in stage 2.0 (TID 278). 1996 bytes result sent to driver\n",
      "  Starting task 40.0 in stage 2.0 (TID 283) (namenode, executor driver, partition 40, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 40.0 in stage 2.0 (TID 283)\n",
      "  Finished task 35.0 in stage 2.0 (TID 278) in 82 ms on namenode (executor driver) (38/121)\n",
      "  Times: total = 55, boot = -39, init = 88, finish = 6\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000037_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000037\n",
      "  attempt_202204291552304462589629084801761_0012_m_000037_0: Committed\n",
      "  Finished task 37.0 in stage 2.0 (TID 280). 1996 bytes result sent to driver\n",
      "  Starting task 41.0 in stage 2.0 (TID 284) (namenode, executor driver, partition 41, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 41.0 in stage 2.0 (TID 284)\n",
      "  Finished task 37.0 in stage 2.0 (TID 280) in 68 ms on namenode (executor driver) (39/121)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 57, boot = -29, init = 77, finish = 9\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000039_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000039\n",
      "  attempt_202204291552304462589629084801761_0012_m_000039_0: Committed\n",
      "  Finished task 39.0 in stage 2.0 (TID 282). 1996 bytes result sent to driver\n",
      "  Starting task 42.0 in stage 2.0 (TID 285) (namenode, executor driver, partition 42, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 42.0 in stage 2.0 (TID 285)\n",
      "  Finished task 39.0 in stage 2.0 (TID 282) in 71 ms on namenode (executor driver) (40/121)\n",
      "  Times: total = 59, boot = -26, init = 74, finish = 11\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000038_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000038\n",
      "  attempt_202204291552304462589629084801761_0012_m_000038_0: Committed\n",
      "  Finished task 38.0 in stage 2.0 (TID 281). 1996 bytes result sent to driver\n",
      "  Starting task 43.0 in stage 2.0 (TID 286) (namenode, executor driver, partition 43, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 38.0 in stage 2.0 (TID 281) in 80 ms on namenode (executor driver) (41/121)\n",
      "  Running task 43.0 in stage 2.0 (TID 286)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 13, boot = -1, init = 7, finish = 7\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000040_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000040\n",
      "  attempt_202204291552304462589629084801761_0012_m_000040_0: Committed\n",
      "  Finished task 40.0 in stage 2.0 (TID 283). 1996 bytes result sent to driver\n",
      "  Starting task 44.0 in stage 2.0 (TID 287) (namenode, executor driver, partition 44, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 40.0 in stage 2.0 (TID 283) in 74 ms on namenode (executor driver) (42/121)\n",
      "  Running task 44.0 in stage 2.0 (TID 287)\n",
      "  Times: total = 10, boot = -7, init = 11, finish = 6\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000042_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000042\n",
      "  attempt_202204291552304462589629084801761_0012_m_000042_0: Committed\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 20, boot = 13, init = 2, finish = 5\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000041_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000041\n",
      "  attempt_202204291552304462589629084801761_0012_m_000041_0: Committed\n",
      "  Finished task 41.0 in stage 2.0 (TID 284). 1996 bytes result sent to driver\n",
      "  Starting task 45.0 in stage 2.0 (TID 288) (namenode, executor driver, partition 45, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 45.0 in stage 2.0 (TID 288)\n",
      "  Finished task 41.0 in stage 2.0 (TID 284) in 77 ms on namenode (executor driver) (43/121)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Finished task 42.0 in stage 2.0 (TID 285). 1996 bytes result sent to driver\n",
      "  Starting task 46.0 in stage 2.0 (TID 289) (namenode, executor driver, partition 46, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 46.0 in stage 2.0 (TID 289)\n",
      "  Finished task 42.0 in stage 2.0 (TID 285) in 53 ms on namenode (executor driver) (44/121)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 26, boot = -4, init = 8, finish = 22\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000043_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000043\n",
      "  attempt_202204291552304462589629084801761_0012_m_000043_0: Committed\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Finished task 43.0 in stage 2.0 (TID 286). 1996 bytes result sent to driver\n",
      "  Starting task 47.0 in stage 2.0 (TID 290) (namenode, executor driver, partition 47, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 47.0 in stage 2.0 (TID 290)\n",
      "  Finished task 43.0 in stage 2.0 (TID 286) in 77 ms on namenode (executor driver) (45/121)\n",
      "  Times: total = 14, boot = -53, init = 60, finish = 7\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000044_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000044\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  attempt_202204291552304462589629084801761_0012_m_000044_0: Committed\n",
      "  Times: total = 14, boot = -58, init = 66, finish = 6\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000046_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000046\n",
      "  attempt_202204291552304462589629084801761_0012_m_000046_0: Committed\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Finished task 44.0 in stage 2.0 (TID 287). 1996 bytes result sent to driver\n",
      "  Starting task 48.0 in stage 2.0 (TID 291) (namenode, executor driver, partition 48, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 48.0 in stage 2.0 (TID 291)\n",
      "  Finished task 44.0 in stage 2.0 (TID 287) in 72 ms on namenode (executor driver) (46/121)\n",
      "  Finished task 46.0 in stage 2.0 (TID 289). 1996 bytes result sent to driver\n",
      "  Times: total = 18, boot = -8, init = 20, finish = 6\n",
      "  Starting task 49.0 in stage 2.0 (TID 292) (namenode, executor driver, partition 49, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000045_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000045\n",
      "  Finished task 46.0 in stage 2.0 (TID 289) in 51 ms on namenode (executor driver) (47/121)\n",
      "  attempt_202204291552304462589629084801761_0012_m_000045_0: Committed\n",
      "  Finished task 45.0 in stage 2.0 (TID 288). 1996 bytes result sent to driver\n",
      "  Starting task 50.0 in stage 2.0 (TID 293) (namenode, executor driver, partition 50, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 50.0 in stage 2.0 (TID 293)\n",
      "  Finished task 45.0 in stage 2.0 (TID 288) in 64 ms on namenode (executor driver) (48/121)\n",
      "  Running task 49.0 in stage 2.0 (TID 292)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 9, boot = -44, init = 46, finish = 7\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000047_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000047\n",
      "  attempt_202204291552304462589629084801761_0012_m_000047_0: Committed\n",
      "  Finished task 47.0 in stage 2.0 (TID 290). 1996 bytes result sent to driver\n",
      "  Starting task 51.0 in stage 2.0 (TID 294) (namenode, executor driver, partition 51, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 47.0 in stage 2.0 (TID 290) in 69 ms on namenode (executor driver) (49/121)\n",
      "  Running task 51.0 in stage 2.0 (TID 294)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Times: total = 58, boot = -50, init = 102, finish = 6\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000048_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000048\n",
      "  attempt_202204291552304462589629084801761_0012_m_000048_0: Committed\n",
      "  Times: total = 61, boot = -38, init = 93, finish = 6\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000049_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000049\n",
      "  attempt_202204291552304462589629084801761_0012_m_000049_0: Committed\n",
      "  Times: total = 58, boot = -28, init = 80, finish = 6\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000050_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000050\n",
      "  attempt_202204291552304462589629084801761_0012_m_000050_0: Committed\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Finished task 50.0 in stage 2.0 (TID 293). 1996 bytes result sent to driver\n",
      "  Finished task 48.0 in stage 2.0 (TID 291). 1996 bytes result sent to driver\n",
      "  Starting task 52.0 in stage 2.0 (TID 295) (namenode, executor driver, partition 52, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 52.0 in stage 2.0 (TID 295)\n",
      "  Starting task 53.0 in stage 2.0 (TID 296) (namenode, executor driver, partition 53, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 53.0 in stage 2.0 (TID 296)\n",
      "  Finished task 48.0 in stage 2.0 (TID 291) in 90 ms on namenode (executor driver) (50/121)\n",
      "  Finished task 50.0 in stage 2.0 (TID 293) in 84 ms on namenode (executor driver) (51/121)\n",
      "  Finished task 49.0 in stage 2.0 (TID 292). 1996 bytes result sent to driver\n",
      "  Starting task 54.0 in stage 2.0 (TID 297) (namenode, executor driver, partition 54, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 49.0 in stage 2.0 (TID 292) in 93 ms on namenode (executor driver) (52/121)\n",
      "  Running task 54.0 in stage 2.0 (TID 297)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 70, boot = -40, init = 102, finish = 8\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000051_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000051\n",
      "  attempt_202204291552304462589629084801761_0012_m_000051_0: Committed\n",
      "  Finished task 51.0 in stage 2.0 (TID 294). 1996 bytes result sent to driver\n",
      "  Starting task 55.0 in stage 2.0 (TID 298) (namenode, executor driver, partition 55, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 55.0 in stage 2.0 (TID 298)\n",
      "  Finished task 51.0 in stage 2.0 (TID 294) in 96 ms on namenode (executor driver) (53/121)\n",
      "  Times: total = 10, boot = -1, init = 4, finish = 7\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000052_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000052\n",
      "  attempt_202204291552304462589629084801761_0012_m_000052_0: Committed\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 19, boot = -26, init = 39, finish = 6\n",
      "  Finished task 52.0 in stage 2.0 (TID 295). 1996 bytes result sent to driver\n",
      "  Starting task 56.0 in stage 2.0 (TID 299) (namenode, executor driver, partition 56, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 52.0 in stage 2.0 (TID 295) in 69 ms on namenode (executor driver) (54/121)\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000054_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000054\n",
      "  attempt_202204291552304462589629084801761_0012_m_000054_0: Committed\n",
      "  Running task 56.0 in stage 2.0 (TID 299)\n",
      "  Times: total = 13, boot = -16, init = 22, finish = 7\n",
      "  Finished task 54.0 in stage 2.0 (TID 297). 1996 bytes result sent to driver\n",
      "  Starting task 57.0 in stage 2.0 (TID 300) (namenode, executor driver, partition 57, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 57.0 in stage 2.0 (TID 300)\n",
      "  Finished task 54.0 in stage 2.0 (TID 297) in 67 ms on namenode (executor driver) (55/121)\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000053_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000053\n",
      "  attempt_202204291552304462589629084801761_0012_m_000053_0: Committed\n",
      "  Finished task 53.0 in stage 2.0 (TID 296). 1996 bytes result sent to driver\n",
      "  Starting task 58.0 in stage 2.0 (TID 301) (namenode, executor driver, partition 58, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 53.0 in stage 2.0 (TID 296) in 82 ms on namenode (executor driver) (56/121)\n",
      "  Running task 58.0 in stage 2.0 (TID 301)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 11, boot = -51, init = 56, finish = 6\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000057_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000057\n",
      "  attempt_202204291552304462589629084801761_0012_m_000057_0: Committed\n",
      "  Finished task 57.0 in stage 2.0 (TID 300). 1996 bytes result sent to driver\n",
      "  Starting task 59.0 in stage 2.0 (TID 302) (namenode, executor driver, partition 59, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 57.0 in stage 2.0 (TID 300) in 66 ms on namenode (executor driver) (57/121)\n",
      "  Running task 59.0 in stage 2.0 (TID 302)\n",
      "  Times: total = 29, boot = -61, init = 84, finish = 6\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000058_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000058\n",
      "  attempt_202204291552304462589629084801761_0012_m_000058_0: Committed\n",
      "  Finished task 58.0 in stage 2.0 (TID 301). 1996 bytes result sent to driver\n",
      "  Starting task 60.0 in stage 2.0 (TID 303) (namenode, executor driver, partition 60, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 60.0 in stage 2.0 (TID 303)\n",
      "  Finished task 58.0 in stage 2.0 (TID 301) in 62 ms on namenode (executor driver) (58/121)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 14, boot = -41, init = 49, finish = 6\n",
      "  Times: total = 14, boot = -9, init = 16, finish = 7\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000055_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000055\n",
      "  attempt_202204291552304462589629084801761_0012_m_000055_0: Committed\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000056_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000056\n",
      "  attempt_202204291552304462589629084801761_0012_m_000056_0: Committed\n",
      "  Finished task 55.0 in stage 2.0 (TID 298). 1996 bytes result sent to driver\n",
      "  Finished task 56.0 in stage 2.0 (TID 299). 1996 bytes result sent to driver\n",
      "  Starting task 61.0 in stage 2.0 (TID 304) (namenode, executor driver, partition 61, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 61.0 in stage 2.0 (TID 304)\n",
      "  Starting task 62.0 in stage 2.0 (TID 305) (namenode, executor driver, partition 62, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 55.0 in stage 2.0 (TID 298) in 105 ms on namenode (executor driver) (59/121)\n",
      "  Finished task 56.0 in stage 2.0 (TID 299) in 95 ms on namenode (executor driver) (60/121)\n",
      "  Running task 62.0 in stage 2.0 (TID 305)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 8, boot = -87, init = 89, finish = 6\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000062_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000062\n",
      "  attempt_202204291552304462589629084801761_0012_m_000062_0: Committed\n",
      "  Times: total = 56, boot = -39, init = 89, finish = 6\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000059_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000059\n",
      "  attempt_202204291552304462589629084801761_0012_m_000059_0: Committed\n",
      "  Finished task 62.0 in stage 2.0 (TID 305). 1996 bytes result sent to driver\n",
      "  Starting task 63.0 in stage 2.0 (TID 306) (namenode, executor driver, partition 63, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 63.0 in stage 2.0 (TID 306)\n",
      "  Finished task 62.0 in stage 2.0 (TID 305) in 51 ms on namenode (executor driver) (61/121)\n",
      "  Finished task 59.0 in stage 2.0 (TID 302). 1996 bytes result sent to driver\n",
      "  Starting task 64.0 in stage 2.0 (TID 307) (namenode, executor driver, partition 64, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 59.0 in stage 2.0 (TID 302) in 80 ms on namenode (executor driver) (62/121)\n",
      "  Running task 64.0 in stage 2.0 (TID 307)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 61, boot = -56, init = 111, finish = 6\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000061_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000061\n",
      "  attempt_202204291552304462589629084801761_0012_m_000061_0: Committed\n",
      "  Finished task 61.0 in stage 2.0 (TID 304). 1996 bytes result sent to driver\n",
      "  Starting task 65.0 in stage 2.0 (TID 308) (namenode, executor driver, partition 65, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 61.0 in stage 2.0 (TID 304) in 72 ms on namenode (executor driver) (63/121)\n",
      "  Running task 65.0 in stage 2.0 (TID 308)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 4 ms\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 78, boot = -20, init = 92, finish = 6\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000060_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000060\n",
      "  attempt_202204291552304462589629084801761_0012_m_000060_0: Committed\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Finished task 60.0 in stage 2.0 (TID 303). 1996 bytes result sent to driver\n",
      "  Starting task 66.0 in stage 2.0 (TID 309) (namenode, executor driver, partition 66, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 66.0 in stage 2.0 (TID 309)\n",
      "  Finished task 60.0 in stage 2.0 (TID 303) in 125 ms on namenode (executor driver) (64/121)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 54, boot = -27, init = 74, finish = 7\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000063_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000063\n",
      "  attempt_202204291552304462589629084801761_0012_m_000063_0: Committed\n",
      "  Finished task 63.0 in stage 2.0 (TID 306). 1996 bytes result sent to driver\n",
      "  Starting task 67.0 in stage 2.0 (TID 310) (namenode, executor driver, partition 67, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 67.0 in stage 2.0 (TID 310)\n",
      "  Finished task 63.0 in stage 2.0 (TID 306) in 106 ms on namenode (executor driver) (65/121)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 21, boot = -24, init = 39, finish = 6\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000064_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000064\n",
      "  attempt_202204291552304462589629084801761_0012_m_000064_0: Committed\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Finished task 64.0 in stage 2.0 (TID 307). 1996 bytes result sent to driver\n",
      "  Starting task 68.0 in stage 2.0 (TID 311) (namenode, executor driver, partition 68, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 68.0 in stage 2.0 (TID 311)\n",
      "  Finished task 64.0 in stage 2.0 (TID 307) in 129 ms on namenode (executor driver) (66/121)\n",
      "  Times: total = 8, boot = -39, init = 40, finish = 7\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000066_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000066\n",
      "  attempt_202204291552304462589629084801761_0012_m_000066_0: Committed\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Finished task 66.0 in stage 2.0 (TID 309). 1996 bytes result sent to driver\n",
      "  Times: total = 20, boot = 6, init = 1, finish = 13\n",
      "  Starting task 70.0 in stage 2.0 (TID 312) (namenode, executor driver, partition 70, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 66.0 in stage 2.0 (TID 309) in 104 ms on namenode (executor driver) (67/121)\n",
      "  Running task 70.0 in stage 2.0 (TID 312)\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000065_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000065\n",
      "  attempt_202204291552304462589629084801761_0012_m_000065_0: Committed\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Finished task 65.0 in stage 2.0 (TID 308). 1996 bytes result sent to driver\n",
      "  Starting task 71.0 in stage 2.0 (TID 313) (namenode, executor driver, partition 71, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 65.0 in stage 2.0 (TID 308) in 148 ms on namenode (executor driver) (68/121)\n",
      "  Running task 71.0 in stage 2.0 (TID 313)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 17, boot = -31, init = 42, finish = 6\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000067_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000067\n",
      "  attempt_202204291552304462589629084801761_0012_m_000067_0: Committed\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Finished task 67.0 in stage 2.0 (TID 310). 1996 bytes result sent to driver\n",
      "  Starting task 72.0 in stage 2.0 (TID 314) (namenode, executor driver, partition 72, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 72.0 in stage 2.0 (TID 314)\n",
      "  Finished task 67.0 in stage 2.0 (TID 310) in 116 ms on namenode (executor driver) (69/121)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 51, boot = -81, init = 126, finish = 6\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000070_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000070\n",
      "  attempt_202204291552304462589629084801761_0012_m_000070_0: Committed\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 21, boot = -115, init = 130, finish = 6\n",
      "  Times: total = 25, boot = -58, init = 78, finish = 5\n",
      "  Finished task 70.0 in stage 2.0 (TID 312). 1996 bytes result sent to driver\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000068_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000068\n",
      "  attempt_202204291552304462589629084801761_0012_m_000068_0: Committed\n",
      "  Finished task 68.0 in stage 2.0 (TID 311). 1996 bytes result sent to driver\n",
      "  Starting task 73.0 in stage 2.0 (TID 315) (namenode, executor driver, partition 73, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 70.0 in stage 2.0 (TID 312) in 98 ms on namenode (executor driver) (70/121)\n",
      "  Finished task 68.0 in stage 2.0 (TID 311) in 123 ms on namenode (executor driver) (71/121)\n",
      "  Starting task 74.0 in stage 2.0 (TID 316) (namenode, executor driver, partition 74, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 74.0 in stage 2.0 (TID 316)\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000071_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000071\n",
      "  attempt_202204291552304462589629084801761_0012_m_000071_0: Committed\n",
      "  Finished task 71.0 in stage 2.0 (TID 313). 1996 bytes result sent to driver\n",
      "  Running task 73.0 in stage 2.0 (TID 315)\n",
      "  Starting task 75.0 in stage 2.0 (TID 317) (namenode, executor driver, partition 75, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 71.0 in stage 2.0 (TID 313) in 93 ms on namenode (executor driver) (72/121)\n",
      "  Running task 75.0 in stage 2.0 (TID 317)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 13, boot = -72, init = 78, finish = 7\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000072_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000072\n",
      "  attempt_202204291552304462589629084801761_0012_m_000072_0: Committed\n",
      "  Finished task 72.0 in stage 2.0 (TID 314). 1996 bytes result sent to driver\n",
      "  Starting task 76.0 in stage 2.0 (TID 318) (namenode, executor driver, partition 76, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 76.0 in stage 2.0 (TID 318)\n",
      "  Finished task 72.0 in stage 2.0 (TID 314) in 76 ms on namenode (executor driver) (73/121)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 49, boot = -41, init = 84, finish = 6\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000073_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000073\n",
      "  attempt_202204291552304462589629084801761_0012_m_000073_0: Committed\n",
      "  Times: total = 51, boot = -82, init = 128, finish = 5\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000074_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000074\n",
      "  attempt_202204291552304462589629084801761_0012_m_000074_0: Committed\n",
      "  Finished task 73.0 in stage 2.0 (TID 315). 1996 bytes result sent to driver\n",
      "  Finished task 74.0 in stage 2.0 (TID 316). 1996 bytes result sent to driver\n",
      "  Starting task 77.0 in stage 2.0 (TID 319) (namenode, executor driver, partition 77, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Starting task 78.0 in stage 2.0 (TID 320) (namenode, executor driver, partition 78, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 77.0 in stage 2.0 (TID 319)\n",
      "  Finished task 74.0 in stage 2.0 (TID 316) in 69 ms on namenode (executor driver) (74/121)\n",
      "  Running task 78.0 in stage 2.0 (TID 320)\n",
      "  Times: total = 63, boot = -60, init = 117, finish = 6\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Finished task 73.0 in stage 2.0 (TID 315) in 85 ms on namenode (executor driver) (75/121)\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000075_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000075\n",
      "  attempt_202204291552304462589629084801761_0012_m_000075_0: Committed\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Finished task 75.0 in stage 2.0 (TID 317). 1996 bytes result sent to driver\n",
      "  Starting task 79.0 in stage 2.0 (TID 321) (namenode, executor driver, partition 79, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 75.0 in stage 2.0 (TID 317) in 91 ms on namenode (executor driver) (76/121)\n",
      "  Running task 79.0 in stage 2.0 (TID 321)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 54, boot = -53, init = 100, finish = 7\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000076_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000076\n",
      "  attempt_202204291552304462589629084801761_0012_m_000076_0: Committed\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 3 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Finished task 76.0 in stage 2.0 (TID 318). 1996 bytes result sent to driver\n",
      "  Starting task 80.0 in stage 2.0 (TID 322) (namenode, executor driver, partition 80, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 76.0 in stage 2.0 (TID 318) in 77 ms on namenode (executor driver) (77/121)\n",
      "  Running task 80.0 in stage 2.0 (TID 322)\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 39, boot = 6, init = 1, finish = 32\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000077_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000077\n",
      "  attempt_202204291552304462589629084801761_0012_m_000077_0: Committed\n",
      "  Finished task 77.0 in stage 2.0 (TID 319). 2039 bytes result sent to driver\n",
      "  Starting task 81.0 in stage 2.0 (TID 323) (namenode, executor driver, partition 81, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 77.0 in stage 2.0 (TID 319) in 155 ms on namenode (executor driver) (78/121)\n",
      "  Running task 81.0 in stage 2.0 (TID 323)\n",
      "  Times: total = 29, boot = 3, init = 21, finish = 5\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000079_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000079\n",
      "  attempt_202204291552304462589629084801761_0012_m_000079_0: Committed\n",
      "  Finished task 79.0 in stage 2.0 (TID 321). 2039 bytes result sent to driver\n",
      "  Starting task 82.0 in stage 2.0 (TID 324) (namenode, executor driver, partition 82, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 79.0 in stage 2.0 (TID 321) in 133 ms on namenode (executor driver) (79/121)\n",
      "  Running task 82.0 in stage 2.0 (TID 324)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 26, boot = -12, init = 23, finish = 15\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000078_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000078\n",
      "  attempt_202204291552304462589629084801761_0012_m_000078_0: Committed\n",
      "  Finished task 78.0 in stage 2.0 (TID 320). 2039 bytes result sent to driver\n",
      "  Starting task 83.0 in stage 2.0 (TID 325) (namenode, executor driver, partition 83, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 78.0 in stage 2.0 (TID 320) in 173 ms on namenode (executor driver) (80/121)\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Running task 83.0 in stage 2.0 (TID 325)\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 66, boot = -6, init = 67, finish = 5\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000080_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000080\n",
      "  attempt_202204291552304462589629084801761_0012_m_000080_0: Committed\n",
      "  Finished task 80.0 in stage 2.0 (TID 322). 2039 bytes result sent to driver\n",
      "  Starting task 84.0 in stage 2.0 (TID 326) (namenode, executor driver, partition 84, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 80.0 in stage 2.0 (TID 322) in 147 ms on namenode (executor driver) (81/121)\n",
      "  Running task 84.0 in stage 2.0 (TID 326)\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 16, boot = -102, init = 111, finish = 7\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000081_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000081\n",
      "  attempt_202204291552304462589629084801761_0012_m_000081_0: Committed\n",
      "  Finished task 81.0 in stage 2.0 (TID 323). 1996 bytes result sent to driver\n",
      "  Starting task 85.0 in stage 2.0 (TID 327) (namenode, executor driver, partition 85, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Finished task 81.0 in stage 2.0 (TID 323) in 87 ms on namenode (executor driver) (82/121)\n",
      "  Running task 85.0 in stage 2.0 (TID 327)\n",
      "  Times: total = 14, boot = -61, init = 63, finish = 12\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000084_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000084\n",
      "  attempt_202204291552304462589629084801761_0012_m_000084_0: Committed\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 16, boot = -86, init = 92, finish = 10\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000082_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000082\n",
      "  attempt_202204291552304462589629084801761_0012_m_000082_0: Committed\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Finished task 84.0 in stage 2.0 (TID 326). 1996 bytes result sent to driver\n",
      "  Starting task 86.0 in stage 2.0 (TID 328) (namenode, executor driver, partition 86, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 86.0 in stage 2.0 (TID 328)\n",
      "  Finished task 84.0 in stage 2.0 (TID 326) in 63 ms on namenode (executor driver) (83/121)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 20, boot = -118, init = 131, finish = 7\n",
      "  Finished task 82.0 in stage 2.0 (TID 324). 1996 bytes result sent to driver\n",
      "  Starting task 87.0 in stage 2.0 (TID 329) (namenode, executor driver, partition 87, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 82.0 in stage 2.0 (TID 324) in 110 ms on namenode (executor driver) (84/121)\n",
      "  Running task 87.0 in stage 2.0 (TID 329)\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000083_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000083\n",
      "  attempt_202204291552304462589629084801761_0012_m_000083_0: Committed\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Finished task 83.0 in stage 2.0 (TID 325). 1996 bytes result sent to driver\n",
      "  Starting task 88.0 in stage 2.0 (TID 330) (namenode, executor driver, partition 88, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 83.0 in stage 2.0 (TID 325) in 106 ms on namenode (executor driver) (85/121)\n",
      "  Running task 88.0 in stage 2.0 (TID 330)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 50, boot = -58, init = 102, finish = 6\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000085_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000085\n",
      "  attempt_202204291552304462589629084801761_0012_m_000085_0: Committed\n",
      "  Finished task 85.0 in stage 2.0 (TID 327). 1996 bytes result sent to driver\n",
      "  Starting task 89.0 in stage 2.0 (TID 331) (namenode, executor driver, partition 89, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 89.0 in stage 2.0 (TID 331)\n",
      "  Finished task 85.0 in stage 2.0 (TID 327) in 92 ms on namenode (executor driver) (86/121)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 64, boot = -71, init = 129, finish = 6\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000087_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000087\n",
      "  attempt_202204291552304462589629084801761_0012_m_000087_0: Committed\n",
      "  Finished task 87.0 in stage 2.0 (TID 329). 1996 bytes result sent to driver\n",
      "  Starting task 90.0 in stage 2.0 (TID 332) (namenode, executor driver, partition 90, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 87.0 in stage 2.0 (TID 329) in 97 ms on namenode (executor driver) (87/121)\n",
      "  Running task 90.0 in stage 2.0 (TID 332)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 65, boot = -37, init = 96, finish = 6\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000086_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000086\n",
      "  attempt_202204291552304462589629084801761_0012_m_000086_0: Committed\n",
      "  Finished task 86.0 in stage 2.0 (TID 328). 1996 bytes result sent to driver\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Starting task 91.0 in stage 2.0 (TID 333) (namenode, executor driver, partition 91, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 86.0 in stage 2.0 (TID 328) in 127 ms on namenode (executor driver) (88/121)\n",
      "  Running task 91.0 in stage 2.0 (TID 333)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 64, boot = -70, init = 126, finish = 8\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000088_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000088\n",
      "  attempt_202204291552304462589629084801761_0012_m_000088_0: Committed\n",
      "  Finished task 88.0 in stage 2.0 (TID 330). 1996 bytes result sent to driver\n",
      "  Starting task 92.0 in stage 2.0 (TID 334) (namenode, executor driver, partition 92, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 88.0 in stage 2.0 (TID 330) in 141 ms on namenode (executor driver) (89/121)\n",
      "  Running task 92.0 in stage 2.0 (TID 334)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 8, boot = -18, init = 21, finish = 5\n",
      "  Times: total = 16, boot = -48, init = 58, finish = 6\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000091_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000091\n",
      "  attempt_202204291552304462589629084801761_0012_m_000091_0: Committed\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000090_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000090\n",
      "  attempt_202204291552304462589629084801761_0012_m_000090_0: Committed\n",
      "  Finished task 91.0 in stage 2.0 (TID 333). 1996 bytes result sent to driver\n",
      "  Finished task 90.0 in stage 2.0 (TID 332). 1996 bytes result sent to driver\n",
      "  Starting task 93.0 in stage 2.0 (TID 335) (namenode, executor driver, partition 93, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Starting task 94.0 in stage 2.0 (TID 336) (namenode, executor driver, partition 94, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 90.0 in stage 2.0 (TID 332) in 95 ms on namenode (executor driver) (90/121)\n",
      "  Finished task 91.0 in stage 2.0 (TID 333) in 78 ms on namenode (executor driver) (91/121)\n",
      "  Running task 93.0 in stage 2.0 (TID 335)\n",
      "  Running task 94.0 in stage 2.0 (TID 336)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 45, boot = -28, init = 67, finish = 6\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000089_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000089\n",
      "  attempt_202204291552304462589629084801761_0012_m_000089_0: Committed\n",
      "  Finished task 89.0 in stage 2.0 (TID 331). 1996 bytes result sent to driver\n",
      "  Starting task 95.0 in stage 2.0 (TID 337) (namenode, executor driver, partition 95, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 95.0 in stage 2.0 (TID 337)\n",
      "  Finished task 89.0 in stage 2.0 (TID 331) in 162 ms on namenode (executor driver) (92/121)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 12, boot = -69, init = 75, finish = 6\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000092_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000092\n",
      "  attempt_202204291552304462589629084801761_0012_m_000092_0: Committed\n",
      "  Finished task 92.0 in stage 2.0 (TID 334). 1996 bytes result sent to driver\n",
      "  Starting task 96.0 in stage 2.0 (TID 338) (namenode, executor driver, partition 96, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 92.0 in stage 2.0 (TID 334) in 98 ms on namenode (executor driver) (93/121)\n",
      "  Running task 96.0 in stage 2.0 (TID 338)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 12, boot = -77, init = 83, finish = 6\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000093_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000093\n",
      "  attempt_202204291552304462589629084801761_0012_m_000093_0: Committed\n",
      "  Finished task 93.0 in stage 2.0 (TID 335). 1996 bytes result sent to driver\n",
      "  Times: total = 28, boot = -57, init = 78, finish = 7\n",
      "  Finished task 93.0 in stage 2.0 (TID 335) in 92 ms on namenode (executor driver) (94/121)\n",
      "  Starting task 97.0 in stage 2.0 (TID 339) (namenode, executor driver, partition 97, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 97.0 in stage 2.0 (TID 339)\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000094_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000094\n",
      "  attempt_202204291552304462589629084801761_0012_m_000094_0: Committed\n",
      "  Finished task 94.0 in stage 2.0 (TID 336). 1996 bytes result sent to driver\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Starting task 98.0 in stage 2.0 (TID 340) (namenode, executor driver, partition 98, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 98.0 in stage 2.0 (TID 340)\n",
      "  Finished task 94.0 in stage 2.0 (TID 336) in 101 ms on namenode (executor driver) (95/121)\n",
      "  Times: total = 33, boot = -103, init = 130, finish = 6\n",
      "  Times: total = 15, boot = -69, init = 78, finish = 6\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000095_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000095\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000096_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000096\n",
      "  attempt_202204291552304462589629084801761_0012_m_000095_0: Committed\n",
      "  attempt_202204291552304462589629084801761_0012_m_000096_0: Committed\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Finished task 96.0 in stage 2.0 (TID 338). 1996 bytes result sent to driver\n",
      "  Finished task 95.0 in stage 2.0 (TID 337). 1996 bytes result sent to driver\n",
      "  Starting task 99.0 in stage 2.0 (TID 341) (namenode, executor driver, partition 99, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 99.0 in stage 2.0 (TID 341)\n",
      "  Starting task 100.0 in stage 2.0 (TID 342) (namenode, executor driver, partition 100, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 95.0 in stage 2.0 (TID 337) in 78 ms on namenode (executor driver) (96/121)\n",
      "  Running task 100.0 in stage 2.0 (TID 342)\n",
      "  Finished task 96.0 in stage 2.0 (TID 338) in 54 ms on namenode (executor driver) (97/121)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 60, boot = -70, init = 122, finish = 8\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000097_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000097\n",
      "  attempt_202204291552304462589629084801761_0012_m_000097_0: Committed\n",
      "  Finished task 97.0 in stage 2.0 (TID 339). 1996 bytes result sent to driver\n",
      "  Starting task 101.0 in stage 2.0 (TID 343) (namenode, executor driver, partition 101, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 101.0 in stage 2.0 (TID 343)\n",
      "  Finished task 97.0 in stage 2.0 (TID 339) in 70 ms on namenode (executor driver) (98/121)\n",
      "  Times: total = 56, boot = -63, init = 108, finish = 11\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000099_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000099\n",
      "  attempt_202204291552304462589629084801761_0012_m_000099_0: Committed\n",
      "  Finished task 99.0 in stage 2.0 (TID 341). 1996 bytes result sent to driver\n",
      "  Starting task 102.0 in stage 2.0 (TID 344) (namenode, executor driver, partition 102, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 102.0 in stage 2.0 (TID 344)\n",
      "  Finished task 99.0 in stage 2.0 (TID 341) in 65 ms on namenode (executor driver) (99/121)\n",
      "  Times: total = 59, boot = -35, init = 82, finish = 12\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000098_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000098\n",
      "  attempt_202204291552304462589629084801761_0012_m_000098_0: Committed\n",
      "  Finished task 98.0 in stage 2.0 (TID 340). 1996 bytes result sent to driver\n",
      "  Starting task 103.0 in stage 2.0 (TID 345) (namenode, executor driver, partition 103, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Times: total = 58, boot = -21, init = 67, finish = 12\n",
      "  Running task 103.0 in stage 2.0 (TID 345)\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000100_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000100\n",
      "  attempt_202204291552304462589629084801761_0012_m_000100_0: Committed\n",
      "  Finished task 100.0 in stage 2.0 (TID 342). 1996 bytes result sent to driver\n",
      "  Finished task 98.0 in stage 2.0 (TID 340) in 81 ms on namenode (executor driver) (100/121)\n",
      "  Starting task 104.0 in stage 2.0 (TID 346) (namenode, executor driver, partition 104, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 100.0 in stage 2.0 (TID 342) in 77 ms on namenode (executor driver) (101/121)\n",
      "  Running task 104.0 in stage 2.0 (TID 346)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 2 ms\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 17, boot = 8, init = 4, finish = 5\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000101_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000101\n",
      "  attempt_202204291552304462589629084801761_0012_m_000101_0: Committed\n",
      "  Times: total = 18, boot = 12, init = 0, finish = 6\n",
      "  Finished task 101.0 in stage 2.0 (TID 343). 1996 bytes result sent to driver\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000103_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000103\n",
      "  attempt_202204291552304462589629084801761_0012_m_000103_0: Committed\n",
      "  Starting task 105.0 in stage 2.0 (TID 347) (namenode, executor driver, partition 105, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Times: total = 18, boot = 11, init = 1, finish = 6\n",
      "  Finished task 103.0 in stage 2.0 (TID 345). 1996 bytes result sent to driver\n",
      "  Starting task 106.0 in stage 2.0 (TID 348) (namenode, executor driver, partition 106, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 101.0 in stage 2.0 (TID 343) in 78 ms on namenode (executor driver) (102/121)\n",
      "  Finished task 103.0 in stage 2.0 (TID 345) in 61 ms on namenode (executor driver) (103/121)\n",
      "  Running task 106.0 in stage 2.0 (TID 348)\n",
      "  Running task 105.0 in stage 2.0 (TID 347)\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000102_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000102\n",
      "  attempt_202204291552304462589629084801761_0012_m_000102_0: Committed\n",
      "  Finished task 102.0 in stage 2.0 (TID 344). 1996 bytes result sent to driver\n",
      "  Starting task 107.0 in stage 2.0 (TID 349) (namenode, executor driver, partition 107, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 102.0 in stage 2.0 (TID 344) in 76 ms on namenode (executor driver) (104/121)\n",
      "  Running task 107.0 in stage 2.0 (TID 349)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 2 ms\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 38, boot = 4, init = 28, finish = 6\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000104_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000104\n",
      "  attempt_202204291552304462589629084801761_0012_m_000104_0: Committed\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Finished task 104.0 in stage 2.0 (TID 346). 1996 bytes result sent to driver\n",
      "  Finished task 104.0 in stage 2.0 (TID 346) in 100 ms on namenode (executor driver) (105/121)\n",
      "  Starting task 108.0 in stage 2.0 (TID 350) (namenode, executor driver, partition 108, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Running task 108.0 in stage 2.0 (TID 350)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 13, boot = -33, init = 40, finish = 6\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000105_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000105\n",
      "  attempt_202204291552304462589629084801761_0012_m_000105_0: Committed\n",
      "  Times: total = 13, boot = -41, init = 43, finish = 11\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000106_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000106\n",
      "  attempt_202204291552304462589629084801761_0012_m_000106_0: Committed\n",
      "  Finished task 105.0 in stage 2.0 (TID 347). 1996 bytes result sent to driver\n",
      "  Starting task 109.0 in stage 2.0 (TID 351) (namenode, executor driver, partition 109, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 106.0 in stage 2.0 (TID 348). 1996 bytes result sent to driver\n",
      "  Running task 109.0 in stage 2.0 (TID 351)\n",
      "  Starting task 110.0 in stage 2.0 (TID 352) (namenode, executor driver, partition 110, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 110.0 in stage 2.0 (TID 352)\n",
      "  Finished task 106.0 in stage 2.0 (TID 348) in 68 ms on namenode (executor driver) (106/121)\n",
      "  Finished task 105.0 in stage 2.0 (TID 347) in 68 ms on namenode (executor driver) (107/121)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 20, boot = -36, init = 50, finish = 6\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000107_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000107\n",
      "  attempt_202204291552304462589629084801761_0012_m_000107_0: Committed\n",
      "  Finished task 107.0 in stage 2.0 (TID 349). 1996 bytes result sent to driver\n",
      "  Starting task 111.0 in stage 2.0 (TID 353) (namenode, executor driver, partition 111, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 111.0 in stage 2.0 (TID 353)\n",
      "  Finished task 107.0 in stage 2.0 (TID 349) in 76 ms on namenode (executor driver) (108/121)\n",
      "  Times: total = 8, boot = -50, init = 51, finish = 7\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000108_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000108\n",
      "  attempt_202204291552304462589629084801761_0012_m_000108_0: Committed\n",
      "  Finished task 108.0 in stage 2.0 (TID 350). 1996 bytes result sent to driver\n",
      "  Starting task 112.0 in stage 2.0 (TID 354) (namenode, executor driver, partition 112, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 108.0 in stage 2.0 (TID 350) in 48 ms on namenode (executor driver) (109/121)\n",
      "  Running task 112.0 in stage 2.0 (TID 354)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 50, boot = -34, init = 79, finish = 5\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000109_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000109\n",
      "  attempt_202204291552304462589629084801761_0012_m_000109_0: Committed\n",
      "  Finished task 109.0 in stage 2.0 (TID 351). 1996 bytes result sent to driver\n",
      "  Starting task 113.0 in stage 2.0 (TID 355) (namenode, executor driver, partition 113, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 113.0 in stage 2.0 (TID 355)\n",
      "  Finished task 109.0 in stage 2.0 (TID 351) in 63 ms on namenode (executor driver) (110/121)\n",
      "  Times: total = 56, boot = -35, init = 83, finish = 8\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000110_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000110\n",
      "  attempt_202204291552304462589629084801761_0012_m_000110_0: Committed\n",
      "  Finished task 110.0 in stage 2.0 (TID 352). 1996 bytes result sent to driver\n",
      "  Starting task 114.0 in stage 2.0 (TID 356) (namenode, executor driver, partition 114, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 110.0 in stage 2.0 (TID 352) in 71 ms on namenode (executor driver) (111/121)\n",
      "  Running task 114.0 in stage 2.0 (TID 356)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 56, boot = -45, init = 95, finish = 6\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000111_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000111\n",
      "  attempt_202204291552304462589629084801761_0012_m_000111_0: Committed\n",
      "  Times: total = 56, boot = -24, init = 73, finish = 7\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000112_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000112\n",
      "  attempt_202204291552304462589629084801761_0012_m_000112_0: Committed\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Finished task 112.0 in stage 2.0 (TID 354). 1996 bytes result sent to driver\n",
      "  Finished task 111.0 in stage 2.0 (TID 353). 1996 bytes result sent to driver\n",
      "  Starting task 115.0 in stage 2.0 (TID 357) (namenode, executor driver, partition 115, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Starting task 116.0 in stage 2.0 (TID 358) (namenode, executor driver, partition 116, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 115.0 in stage 2.0 (TID 357)\n",
      "  Finished task 111.0 in stage 2.0 (TID 353) in 94 ms on namenode (executor driver) (112/121)\n",
      "  Running task 116.0 in stage 2.0 (TID 358)\n",
      "  Finished task 112.0 in stage 2.0 (TID 354) in 88 ms on namenode (executor driver) (113/121)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 23, boot = -11, init = 19, finish = 15\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000114_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000114\n",
      "  attempt_202204291552304462589629084801761_0012_m_000114_0: Committed\n",
      "  Finished task 114.0 in stage 2.0 (TID 356). 1996 bytes result sent to driver\n",
      "  Starting task 117.0 in stage 2.0 (TID 359) (namenode, executor driver, partition 117, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 114.0 in stage 2.0 (TID 356) in 73 ms on namenode (executor driver) (114/121)\n",
      "  Running task 117.0 in stage 2.0 (TID 359)\n",
      "  Times: total = 13, boot = -7, init = 10, finish = 10\n",
      "  Times: total = 11, boot = -18, init = 21, finish = 8\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000113_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000113\n",
      "  attempt_202204291552304462589629084801761_0012_m_000113_0: Committed\n",
      "  Finished task 113.0 in stage 2.0 (TID 355). 1996 bytes result sent to driver\n",
      "  Starting task 118.0 in stage 2.0 (TID 360) (namenode, executor driver, partition 118, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 113.0 in stage 2.0 (TID 355) in 89 ms on namenode (executor driver) (115/121)\n",
      "  Running task 118.0 in stage 2.0 (TID 360)\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000116_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000116\n",
      "  attempt_202204291552304462589629084801761_0012_m_000116_0: Committed\n",
      "  Finished task 116.0 in stage 2.0 (TID 358). 1996 bytes result sent to driver\n",
      "  Starting task 119.0 in stage 2.0 (TID 361) (namenode, executor driver, partition 119, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 116.0 in stage 2.0 (TID 358) in 45 ms on namenode (executor driver) (116/121)\n",
      "  Running task 119.0 in stage 2.0 (TID 361)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 3 ms\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Times: total = 16, boot = -14, init = 23, finish = 7\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000115_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000115\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  attempt_202204291552304462589629084801761_0012_m_000115_0: Committed\n",
      "  Finished task 115.0 in stage 2.0 (TID 357). 1996 bytes result sent to driver\n",
      "  Starting task 120.0 in stage 2.0 (TID 362) (namenode, executor driver, partition 120, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 120.0 in stage 2.0 (TID 362)\n",
      "  Finished task 115.0 in stage 2.0 (TID 357) in 65 ms on namenode (executor driver) (117/121)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 8 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 28, boot = -14, init = 36, finish = 6\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000119_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000119\n",
      "  attempt_202204291552304462589629084801761_0012_m_000119_0: Committed\n",
      "  Times: total = 8, boot = -49, init = 51, finish = 6\n",
      "  Finished task 119.0 in stage 2.0 (TID 361). 1996 bytes result sent to driver\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000118_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000118\n",
      "  attempt_202204291552304462589629084801761_0012_m_000118_0: Committed\n",
      "  Finished task 119.0 in stage 2.0 (TID 361) in 89 ms on namenode (executor driver) (118/121)\n",
      "  Finished task 118.0 in stage 2.0 (TID 360). 1996 bytes result sent to driver\n",
      "  Finished task 118.0 in stage 2.0 (TID 360) in 92 ms on namenode (executor driver) (119/121)\n",
      "  Times: total = 27, boot = -45, init = 66, finish = 6\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000120_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000120\n",
      "  attempt_202204291552304462589629084801761_0012_m_000120_0: Committed\n",
      "  Finished task 120.0 in stage 2.0 (TID 362). 1996 bytes result sent to driver\n",
      "  Finished task 120.0 in stage 2.0 (TID 362) in 75 ms on namenode (executor driver) (120/121)\n",
      "  Times: total = 48, boot = -55, init = 96, finish = 7\n",
      "  Saved output of task 'attempt_202204291552304462589629084801761_0012_m_000117_0' to file:/tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output/_temporary/0/task_202204291552304462589629084801761_0012_m_000117\n",
      "  attempt_202204291552304462589629084801761_0012_m_000117_0: Committed\n",
      "  Finished task 117.0 in stage 2.0 (TID 359). 1996 bytes result sent to driver\n",
      "  Finished task 117.0 in stage 2.0 (TID 359) in 111 ms on namenode (executor driver) (121/121)\n",
      "  Removed TaskSet 2.0, whose tasks have all completed, from pool \n",
      "  ResultStage 2 (runJob at SparkHadoopWriter.scala:83) finished in 3.636 s\n",
      "  Job 0 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "  Killing all running tasks in stage 2: Stage finished\n",
      "  Job 0 finished: runJob at SparkHadoopWriter.scala:83, took 234.728027 s\n",
      "  Start to commit write Job job_202204291552304462589629084801761_0012.\n",
      "  Write Job job_202204291552304462589629084801761_0012 committed. Elapsed time: 71 ms.\n",
      "  Invoking stop() from shutdown hook\n",
      "  Stopped Spark@49c49507{HTTP/1.1, (http/1.1)}{0.0.0.0:4042}\n",
      "  Stopped Spark web UI at http://namenode:4042\n",
      "  MapOutputTrackerMasterEndpoint stopped!\n",
      "  MemoryStore cleared\n",
      "  BlockManager stopped\n",
      "  BlockManagerMaster stopped\n",
      "  OutputCommitCoordinator stopped!\n",
      "  Successfully stopped SparkContext\n",
      "  Shutdown hook called\n",
      "  Deleting directory /tmp/spark-f2056e2b-8841-4a05-9b71-b76fce8f504f\n",
      "  Deleting directory /tmp/spark-f2056e2b-8841-4a05-9b71-b76fce8f504f/pyspark-7c5c34b1-4a82-4538-875c-eab6f9eb5467\n",
      "  Deleting directory /tmp/spark-0f703639-00e2-4e82-839d-cb866ffb1e8f\n",
      "job output is in /tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output\n",
      "Streaming final output from /tmp/map_red_pup.ubuntu.20220429.155218.072012-spark/output...\n",
      "Removing temp directory /tmp/map_red_pup.ubuntu.20220429.155218.072012...\n"
     ]
    }
   ],
   "source": [
    "!python3 /home/ubuntu/map_red_pup.py -r spark hdfs://namenode:9000/dis_materials/data_reddit.csv >outt.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f86e8b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python3: can't open file 'popular_comment.py': [Errno 2] No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!python3 popular_comment.py -r spark hdfs://namenode:9000/dis_materials/data_reddit.csv >outth.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1caf21b3",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "No configs specified for spark runner\n",
      "Looking for hadoop binary in /usr/local/hadoop/bin...\n",
      "Found hadoop binary: /usr/local/hadoop/bin/hadoop\n",
      "Looking for spark-submit binary in /usr/local/spark/bin...\n",
      "Found spark-submit binary: /usr/local/spark/bin/spark-submit\n",
      "Running steps 1-2 of 2\n",
      "Creating temp directory /tmp/popular_comment.ubuntu.20220424.134700.657971\n",
      "  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "  Running Spark version 3.2.0\n",
      "  ==============================================================\n",
      "  No custom resources configured for spark.driver.\n",
      "  ==============================================================\n",
      "  Submitted application: harness.py\n",
      "  Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)\n",
      "  Limiting resource is cpu\n",
      "  Added ResourceProfile id: 0\n",
      "  Changing view acls to: ubuntu\n",
      "  Changing modify acls to: ubuntu\n",
      "  Changing view acls groups to: \n",
      "  Changing modify acls groups to: \n",
      "  SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ubuntu); groups with view permissions: Set(); users  with modify permissions: Set(ubuntu); groups with modify permissions: Set()\n",
      "  Successfully started service 'sparkDriver' on port 34557.\n",
      "  Registering MapOutputTracker\n",
      "  Registering BlockManagerMaster\n",
      "  Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information\n",
      "  BlockManagerMasterEndpoint up\n",
      "  Registering BlockManagerMasterHeartbeat\n",
      "  Created local directory at /tmp/blockmgr-343f1747-388e-46e2-a41b-cad0f4a89a55\n",
      "  MemoryStore started with capacity 366.3 MiB\n",
      "  Registering OutputCommitCoordinator\n",
      "  Logging initialized @4187ms to org.sparkproject.jetty.util.log.Slf4jLog\n",
      "  jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_312-8u312-b07-0ubuntu1~20.04-b07\n",
      "  Started @4363ms\n",
      "  Started ServerConnector@2af70df9{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}\n",
      "  Successfully started service 'SparkUI' on port 4040.\n",
      "  Started o.s.j.s.ServletContextHandler@47c5172c{/jobs,null,AVAILABLE,@Spark}\n",
      "  Started o.s.j.s.ServletContextHandler@689b4f7b{/jobs/json,null,AVAILABLE,@Spark}\n",
      "  Started o.s.j.s.ServletContextHandler@6f1b3996{/jobs/job,null,AVAILABLE,@Spark}\n",
      "  Started o.s.j.s.ServletContextHandler@5d1f14d7{/jobs/job/json,null,AVAILABLE,@Spark}\n",
      "  Started o.s.j.s.ServletContextHandler@7cc990e1{/stages,null,AVAILABLE,@Spark}\n",
      "  Started o.s.j.s.ServletContextHandler@400f2ae9{/stages/json,null,AVAILABLE,@Spark}\n",
      "  Started o.s.j.s.ServletContextHandler@59415b85{/stages/stage,null,AVAILABLE,@Spark}\n",
      "  Started o.s.j.s.ServletContextHandler@5a345a53{/stages/stage/json,null,AVAILABLE,@Spark}\n",
      "  Started o.s.j.s.ServletContextHandler@6a940f64{/stages/pool,null,AVAILABLE,@Spark}\n",
      "  Started o.s.j.s.ServletContextHandler@4e00031b{/stages/pool/json,null,AVAILABLE,@Spark}\n",
      "  Started o.s.j.s.ServletContextHandler@452538e0{/storage,null,AVAILABLE,@Spark}\n",
      "  Started o.s.j.s.ServletContextHandler@4c209e7a{/storage/json,null,AVAILABLE,@Spark}\n",
      "  Started o.s.j.s.ServletContextHandler@286caec0{/storage/rdd,null,AVAILABLE,@Spark}\n",
      "  Started o.s.j.s.ServletContextHandler@50de41f8{/storage/rdd/json,null,AVAILABLE,@Spark}\n",
      "  Started o.s.j.s.ServletContextHandler@4a582534{/environment,null,AVAILABLE,@Spark}\n",
      "  Started o.s.j.s.ServletContextHandler@5e26b7b7{/environment/json,null,AVAILABLE,@Spark}\n",
      "  Started o.s.j.s.ServletContextHandler@2e25878b{/executors,null,AVAILABLE,@Spark}\n",
      "  Started o.s.j.s.ServletContextHandler@16115657{/executors/json,null,AVAILABLE,@Spark}\n",
      "  Started o.s.j.s.ServletContextHandler@4ab7173a{/executors/threadDump,null,AVAILABLE,@Spark}\n",
      "  Started o.s.j.s.ServletContextHandler@25708a7a{/executors/threadDump/json,null,AVAILABLE,@Spark}\n",
      "  Started o.s.j.s.ServletContextHandler@794da924{/static,null,AVAILABLE,@Spark}\n",
      "  Started o.s.j.s.ServletContextHandler@68958330{/,null,AVAILABLE,@Spark}\n",
      "  Started o.s.j.s.ServletContextHandler@44d0d992{/api,null,AVAILABLE,@Spark}\n",
      "  Started o.s.j.s.ServletContextHandler@6a6c36e5{/jobs/job/kill,null,AVAILABLE,@Spark}\n",
      "  Started o.s.j.s.ServletContextHandler@56bb312a{/stages/stage/kill,null,AVAILABLE,@Spark}\n",
      "  Bound SparkUI to 0.0.0.0, and started at http://namenode:4040\n",
      "  Added file file:///tmp/popular_comment.ubuntu.20220424.134700.657971/mrjob.zip at file:///tmp/popular_comment.ubuntu.20220424.134700.657971/mrjob.zip with timestamp 1650808026440\n",
      "  Copying /tmp/popular_comment.ubuntu.20220424.134700.657971/mrjob.zip to /tmp/spark-ca1e997a-5ee3-4d39-8154-af65d38bd92e/userFiles-7c5d771b-7997-4c43-8a59-252fdd98fee0/mrjob.zip\n",
      "  Added file file:///tmp/popular_comment.ubuntu.20220424.134700.657971/script.zip at file:///tmp/popular_comment.ubuntu.20220424.134700.657971/script.zip with timestamp 1650808026440\n",
      "  Copying /tmp/popular_comment.ubuntu.20220424.134700.657971/script.zip to /tmp/spark-ca1e997a-5ee3-4d39-8154-af65d38bd92e/userFiles-7c5d771b-7997-4c43-8a59-252fdd98fee0/script.zip\n",
      "  Starting executor ID driver on host namenode\n",
      "  Fetching file:///tmp/popular_comment.ubuntu.20220424.134700.657971/mrjob.zip with timestamp 1650808026440\n",
      "  /tmp/popular_comment.ubuntu.20220424.134700.657971/mrjob.zip has been previously copied to /tmp/spark-ca1e997a-5ee3-4d39-8154-af65d38bd92e/userFiles-7c5d771b-7997-4c43-8a59-252fdd98fee0/mrjob.zip\n",
      "  Fetching file:///tmp/popular_comment.ubuntu.20220424.134700.657971/script.zip with timestamp 1650808026440\n",
      "  /tmp/popular_comment.ubuntu.20220424.134700.657971/script.zip has been previously copied to /tmp/spark-ca1e997a-5ee3-4d39-8154-af65d38bd92e/userFiles-7c5d771b-7997-4c43-8a59-252fdd98fee0/script.zip\n",
      "  Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43301.\n",
      "  Server created on namenode:43301\n",
      "  Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy\n",
      "  Registering BlockManager BlockManagerId(driver, namenode, 43301, None)\n",
      "  Registering block manager namenode:43301 with 366.3 MiB RAM, BlockManagerId(driver, namenode, 43301, None)\n",
      "  Registered BlockManager BlockManagerId(driver, namenode, 43301, None)\n",
      "  Initialized BlockManager: BlockManagerId(driver, namenode, 43301, None)\n",
      "  Started o.s.j.s.ServletContextHandler@4b78e87d{/metrics/json,null,AVAILABLE,@Spark}\n",
      "  Block broadcast_0 stored as values in memory (estimated size 410.9 KiB, free 365.9 MiB)\n",
      "  Block broadcast_0_piece0 stored as bytes in memory (estimated size 42.1 KiB, free 365.9 MiB)\n",
      "  Added broadcast_0_piece0 in memory on namenode:43301 (size: 42.1 KiB, free: 366.3 MiB)\n",
      "  Created broadcast 0 from textFile at NativeMethodAccessorImpl.java:0\n",
      "  Total input files to process : 1\n",
      "  mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Starting job: runJob at SparkHadoopWriter.scala:83\n",
      "  Registering RDD 3 (groupBy at /home/ubuntu/.local/lib/python3.8/site-packages/mrjob/spark/harness.py:539) as input to shuffle 1\n",
      "  Registering RDD 7 (groupBy at /home/ubuntu/.local/lib/python3.8/site-packages/mrjob/spark/harness.py:539) as input to shuffle 0\n",
      "  Got job 0 (runJob at SparkHadoopWriter.scala:83) with 121 output partitions\n",
      "  Final stage: ResultStage 2 (runJob at SparkHadoopWriter.scala:83)\n",
      "  Parents of final stage: List(ShuffleMapStage 1)\n",
      "  Missing parents: List(ShuffleMapStage 1)\n",
      "  Submitting ShuffleMapStage 0 (PairwiseRDD[3] at groupBy at /home/ubuntu/.local/lib/python3.8/site-packages/mrjob/spark/harness.py:539), which has no missing parents\n",
      "  Block broadcast_1 stored as values in memory (estimated size 15.8 KiB, free 365.8 MiB)\n",
      "  Block broadcast_1_piece0 stored as bytes in memory (estimated size 9.5 KiB, free 365.8 MiB)\n",
      "  Added broadcast_1_piece0 in memory on namenode:43301 (size: 9.5 KiB, free: 366.2 MiB)\n",
      "  Created broadcast 1 from broadcast at DAGScheduler.scala:1427\n",
      "  Submitting 121 missing tasks from ShuffleMapStage 0 (PairwiseRDD[3] at groupBy at /home/ubuntu/.local/lib/python3.8/site-packages/mrjob/spark/harness.py:539) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Adding task set 0.0 with 121 tasks resource profile 0\n",
      "  Starting task 0.0 in stage 0.0 (TID 0) (namenode, executor driver, partition 0, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Starting task 1.0 in stage 0.0 (TID 1) (namenode, executor driver, partition 1, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Starting task 2.0 in stage 0.0 (TID 2) (namenode, executor driver, partition 2, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Starting task 3.0 in stage 0.0 (TID 3) (namenode, executor driver, partition 3, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 2.0 in stage 0.0 (TID 2)\n",
      "  Running task 1.0 in stage 0.0 (TID 1)\n",
      "  Running task 0.0 in stage 0.0 (TID 0)\n",
      "  Running task 3.0 in stage 0.0 (TID 3)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:134217728+134217728\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:0+134217728\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:268435456+134217728\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:402653184+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 8538, boot = 402, init = 434, finish = 7702\n",
      "  Finished task 2.0 in stage 0.0 (TID 2). 1943 bytes result sent to driver\n",
      "  Starting task 4.0 in stage 0.0 (TID 4) (namenode, executor driver, partition 4, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 4.0 in stage 0.0 (TID 4)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:536870912+134217728\n",
      "  Finished task 2.0 in stage 0.0 (TID 2) in 9377 ms on namenode (executor driver) (1/121)\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 8733, boot = 446, init = 409, finish = 7878\n",
      "  Connected to AccumulatorServer at host: 127.0.0.1 port: 46173\n",
      "  Times: total = 8778, boot = 433, init = 358, finish = 7987\n",
      "  Finished task 3.0 in stage 0.0 (TID 3). 1900 bytes result sent to driver\n",
      "  Starting task 5.0 in stage 0.0 (TID 5) (namenode, executor driver, partition 5, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 5.0 in stage 0.0 (TID 5)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:671088640+134217728\n",
      "  Finished task 3.0 in stage 0.0 (TID 3) in 9533 ms on namenode (executor driver) (2/121)\n",
      "  Finished task 1.0 in stage 0.0 (TID 1). 1900 bytes result sent to driver\n",
      "  Starting task 6.0 in stage 0.0 (TID 6) (namenode, executor driver, partition 6, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 6.0 in stage 0.0 (TID 6)\n",
      "  Finished task 1.0 in stage 0.0 (TID 1) in 9550 ms on namenode (executor driver) (3/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:805306368+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 9142, boot = 589, init = 434, finish = 8119\n",
      "  Finished task 0.0 in stage 0.0 (TID 0). 1900 bytes result sent to driver\n",
      "  Starting task 7.0 in stage 0.0 (TID 7) (namenode, executor driver, partition 7, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 7.0 in stage 0.0 (TID 7)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:939524096+134217728\n",
      "  Finished task 0.0 in stage 0.0 (TID 0) in 9721 ms on namenode (executor driver) (4/121)\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 7121, boot = -139, init = 148, finish = 7112\n",
      "  Times: total = 7565, boot = -167, init = 200, finish = 7532\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Finished task 5.0 in stage 0.0 (TID 5). 1900 bytes result sent to driver\n",
      "  Starting task 8.0 in stage 0.0 (TID 8) (namenode, executor driver, partition 8, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 8.0 in stage 0.0 (TID 8)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:1073741824+134217728\n",
      "  Finished task 5.0 in stage 0.0 (TID 5) in 7618 ms on namenode (executor driver) (5/121)\n",
      "  Finished task 4.0 in stage 0.0 (TID 4). 1900 bytes result sent to driver\n",
      "  Starting task 9.0 in stage 0.0 (TID 9) (namenode, executor driver, partition 9, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 4.0 in stage 0.0 (TID 4) in 7787 ms on namenode (executor driver) (6/121)\n",
      "  Running task 9.0 in stage 0.0 (TID 9)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:1207959552+134217728\n",
      "  Times: total = 7651, boot = -162, init = 170, finish = 7643\n",
      "  Finished task 6.0 in stage 0.0 (TID 6). 1900 bytes result sent to driver\n",
      "  Starting task 10.0 in stage 0.0 (TID 10) (namenode, executor driver, partition 10, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 10.0 in stage 0.0 (TID 10)\n",
      "  Finished task 6.0 in stage 0.0 (TID 6) in 7839 ms on namenode (executor driver) (7/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:1342177280+134217728\n",
      "  Times: total = 8555, boot = -71, init = 90, finish = 8536\n",
      "  Finished task 7.0 in stage 0.0 (TID 7). 1943 bytes result sent to driver\n",
      "  Starting task 11.0 in stage 0.0 (TID 11) (namenode, executor driver, partition 11, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 7.0 in stage 0.0 (TID 7) in 8638 ms on namenode (executor driver) (8/121)\n",
      "  Running task 11.0 in stage 0.0 (TID 11)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:1476395008+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 7081, boot = -214, init = 231, finish = 7064\n",
      "  Finished task 9.0 in stage 0.0 (TID 9). 1900 bytes result sent to driver\n",
      "  Starting task 12.0 in stage 0.0 (TID 12) (namenode, executor driver, partition 12, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 12.0 in stage 0.0 (TID 12)\n",
      "  Finished task 9.0 in stage 0.0 (TID 9) in 7177 ms on namenode (executor driver) (9/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:1610612736+134217728\n",
      "  Times: total = 7215, boot = -462, init = 475, finish = 7202\n",
      "  Finished task 8.0 in stage 0.0 (TID 8). 1900 bytes result sent to driver\n",
      "  Starting task 13.0 in stage 0.0 (TID 13) (namenode, executor driver, partition 13, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 13.0 in stage 0.0 (TID 13)\n",
      "  Finished task 8.0 in stage 0.0 (TID 8) in 7279 ms on namenode (executor driver) (10/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:1744830464+134217728\n",
      "  Times: total = 7419, boot = -179, init = 198, finish = 7400\n",
      "  Finished task 10.0 in stage 0.0 (TID 10). 1900 bytes result sent to driver\n",
      "  Starting task 14.0 in stage 0.0 (TID 14) (namenode, executor driver, partition 14, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 14.0 in stage 0.0 (TID 14)\n",
      "  Finished task 10.0 in stage 0.0 (TID 10) in 7598 ms on namenode (executor driver) (11/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:1879048192+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 7129, boot = -113, init = 115, finish = 7127\n",
      "  Finished task 11.0 in stage 0.0 (TID 11). 1900 bytes result sent to driver\n",
      "  Starting task 15.0 in stage 0.0 (TID 15) (namenode, executor driver, partition 15, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 11.0 in stage 0.0 (TID 11) in 7236 ms on namenode (executor driver) (12/121)\n",
      "  Running task 15.0 in stage 0.0 (TID 15)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:2013265920+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6778, boot = -49, init = 60, finish = 6767\n",
      "  Finished task 13.0 in stage 0.0 (TID 13). 1900 bytes result sent to driver\n",
      "  Starting task 16.0 in stage 0.0 (TID 16) (namenode, executor driver, partition 16, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 13.0 in stage 0.0 (TID 13) in 6852 ms on namenode (executor driver) (13/121)\n",
      "  Running task 16.0 in stage 0.0 (TID 16)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:2147483648+134217728\n",
      "  Times: total = 6958, boot = -64, init = 81, finish = 6941\n",
      "  Finished task 12.0 in stage 0.0 (TID 12). 1900 bytes result sent to driver\n",
      "  Starting task 17.0 in stage 0.0 (TID 17) (namenode, executor driver, partition 17, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 17.0 in stage 0.0 (TID 17)\n",
      "  Finished task 12.0 in stage 0.0 (TID 12) in 7096 ms on namenode (executor driver) (14/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:2281701376+134217728\n",
      "  Times: total = 6366, boot = -157, init = 160, finish = 6363\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Finished task 14.0 in stage 0.0 (TID 14). 1900 bytes result sent to driver\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Starting task 18.0 in stage 0.0 (TID 18) (namenode, executor driver, partition 18, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 14.0 in stage 0.0 (TID 14) in 6551 ms on namenode (executor driver) (15/121)\n",
      "  Running task 18.0 in stage 0.0 (TID 18)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:2415919104+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 7476, boot = -82, init = 85, finish = 7473\n",
      "  Finished task 15.0 in stage 0.0 (TID 15). 1900 bytes result sent to driver\n",
      "  Starting task 19.0 in stage 0.0 (TID 19) (namenode, executor driver, partition 19, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 15.0 in stage 0.0 (TID 15) in 7648 ms on namenode (executor driver) (16/121)\n",
      "  Running task 19.0 in stage 0.0 (TID 19)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:2550136832+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6380, boot = -44, init = 49, finish = 6375\n",
      "  Finished task 16.0 in stage 0.0 (TID 16). 1900 bytes result sent to driver\n",
      "  Starting task 20.0 in stage 0.0 (TID 20) (namenode, executor driver, partition 20, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 16.0 in stage 0.0 (TID 16) in 6453 ms on namenode (executor driver) (17/121)\n",
      "  Running task 20.0 in stage 0.0 (TID 20)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:2684354560+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6573, boot = -112, init = 127, finish = 6558\n",
      "  Finished task 17.0 in stage 0.0 (TID 17). 1900 bytes result sent to driver\n",
      "  Starting task 21.0 in stage 0.0 (TID 21) (namenode, executor driver, partition 21, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 21.0 in stage 0.0 (TID 21)\n",
      "  Finished task 17.0 in stage 0.0 (TID 17) in 6649 ms on namenode (executor driver) (18/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:2818572288+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 7643, boot = -60, init = 75, finish = 7628\n",
      "  Finished task 18.0 in stage 0.0 (TID 18). 1900 bytes result sent to driver\n",
      "  Starting task 22.0 in stage 0.0 (TID 22) (namenode, executor driver, partition 22, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 18.0 in stage 0.0 (TID 18) in 7760 ms on namenode (executor driver) (19/121)\n",
      "  Running task 22.0 in stage 0.0 (TID 22)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:2952790016+134217728\n",
      "  Times: total = 6634, boot = -154, init = 173, finish = 6615\n",
      "  Finished task 19.0 in stage 0.0 (TID 19). 1900 bytes result sent to driver\n",
      "  Starting task 23.0 in stage 0.0 (TID 23) (namenode, executor driver, partition 23, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 19.0 in stage 0.0 (TID 19) in 6753 ms on namenode (executor driver) (20/121)\n",
      "  Running task 23.0 in stage 0.0 (TID 23)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:3087007744+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6384, boot = -62, init = 65, finish = 6381\n",
      "  Times: total = 6688, boot = -57, init = 68, finish = 6677\n",
      "  Finished task 21.0 in stage 0.0 (TID 21). 1900 bytes result sent to driver\n",
      "  Starting task 24.0 in stage 0.0 (TID 24) (namenode, executor driver, partition 24, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 21.0 in stage 0.0 (TID 21) in 6494 ms on namenode (executor driver) (21/121)\n",
      "  Running task 24.0 in stage 0.0 (TID 24)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:3221225472+134217728\n",
      "  Finished task 20.0 in stage 0.0 (TID 20). 1900 bytes result sent to driver\n",
      "  Starting task 25.0 in stage 0.0 (TID 25) (namenode, executor driver, partition 25, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 20.0 in stage 0.0 (TID 20) in 6899 ms on namenode (executor driver) (22/121)\n",
      "  Running task 25.0 in stage 0.0 (TID 25)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:3355443200+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 7603, boot = -121, init = 132, finish = 7592\n",
      "  Finished task 22.0 in stage 0.0 (TID 22). 1900 bytes result sent to driver\n",
      "  Starting task 26.0 in stage 0.0 (TID 26) (namenode, executor driver, partition 26, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 22.0 in stage 0.0 (TID 22) in 7747 ms on namenode (executor driver) (23/121)\n",
      "  Running task 26.0 in stage 0.0 (TID 26)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:3489660928+134217728\n",
      "  Times: total = 7091, boot = -98, init = 122, finish = 7067\n",
      "  Finished task 23.0 in stage 0.0 (TID 23). 1900 bytes result sent to driver\n",
      "  Starting task 27.0 in stage 0.0 (TID 27) (namenode, executor driver, partition 27, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 27.0 in stage 0.0 (TID 27)\n",
      "  Finished task 23.0 in stage 0.0 (TID 23) in 7232 ms on namenode (executor driver) (24/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:3623878656+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6613, boot = -170, init = 188, finish = 6595\n",
      "  Finished task 25.0 in stage 0.0 (TID 25). 1900 bytes result sent to driver\n",
      "  Starting task 28.0 in stage 0.0 (TID 28) (namenode, executor driver, partition 28, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 25.0 in stage 0.0 (TID 25) in 6662 ms on namenode (executor driver) (25/121)\n",
      "  Running task 28.0 in stage 0.0 (TID 28)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:3758096384+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 7099, boot = -98, init = 114, finish = 7083\n",
      "  Finished task 24.0 in stage 0.0 (TID 24). 1900 bytes result sent to driver\n",
      "  Starting task 29.0 in stage 0.0 (TID 29) (namenode, executor driver, partition 29, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 24.0 in stage 0.0 (TID 24) in 7200 ms on namenode (executor driver) (26/121)\n",
      "  Running task 29.0 in stage 0.0 (TID 29)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:3892314112+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6737, boot = -111, init = 133, finish = 6715\n",
      "  Finished task 26.0 in stage 0.0 (TID 26). 1900 bytes result sent to driver\n",
      "  Starting task 30.0 in stage 0.0 (TID 30) (namenode, executor driver, partition 30, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 26.0 in stage 0.0 (TID 26) in 6795 ms on namenode (executor driver) (27/121)\n",
      "  Running task 30.0 in stage 0.0 (TID 30)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:4026531840+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 7015, boot = -82, init = 118, finish = 6979\n",
      "  Finished task 27.0 in stage 0.0 (TID 27). 1900 bytes result sent to driver\n",
      "  Starting task 31.0 in stage 0.0 (TID 31) (namenode, executor driver, partition 31, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 31.0 in stage 0.0 (TID 31)\n",
      "  Finished task 27.0 in stage 0.0 (TID 27) in 7083 ms on namenode (executor driver) (28/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:4160749568+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6853, boot = -41, init = 44, finish = 6850\n",
      "  Finished task 28.0 in stage 0.0 (TID 28). 1900 bytes result sent to driver\n",
      "  Starting task 32.0 in stage 0.0 (TID 32) (namenode, executor driver, partition 32, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 32.0 in stage 0.0 (TID 32)\n",
      "  Finished task 28.0 in stage 0.0 (TID 28) in 6956 ms on namenode (executor driver) (29/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:4294967296+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6964, boot = -38, init = 47, finish = 6955\n",
      "  Finished task 29.0 in stage 0.0 (TID 29). 1900 bytes result sent to driver\n",
      "  Starting task 33.0 in stage 0.0 (TID 33) (namenode, executor driver, partition 33, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 29.0 in stage 0.0 (TID 29) in 7073 ms on namenode (executor driver) (30/121)\n",
      "  Running task 33.0 in stage 0.0 (TID 33)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:4429185024+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6468, boot = -70, init = 88, finish = 6450\n",
      "  Finished task 30.0 in stage 0.0 (TID 30). 1900 bytes result sent to driver\n",
      "  Starting task 34.0 in stage 0.0 (TID 34) (namenode, executor driver, partition 34, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 30.0 in stage 0.0 (TID 30) in 6546 ms on namenode (executor driver) (31/121)\n",
      "  Running task 34.0 in stage 0.0 (TID 34)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:4563402752+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 7269, boot = -21, init = 33, finish = 7257\n",
      "  Finished task 31.0 in stage 0.0 (TID 31). 1900 bytes result sent to driver\n",
      "  Starting task 35.0 in stage 0.0 (TID 35) (namenode, executor driver, partition 35, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 31.0 in stage 0.0 (TID 31) in 7358 ms on namenode (executor driver) (32/121)\n",
      "  Running task 35.0 in stage 0.0 (TID 35)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:4697620480+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 7252, boot = -80, init = 99, finish = 7233\n",
      "  Finished task 32.0 in stage 0.0 (TID 32). 1900 bytes result sent to driver\n",
      "  Starting task 36.0 in stage 0.0 (TID 36) (namenode, executor driver, partition 36, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 36.0 in stage 0.0 (TID 36)\n",
      "  Finished task 32.0 in stage 0.0 (TID 32) in 7316 ms on namenode (executor driver) (33/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:4831838208+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6943, boot = -85, init = 88, finish = 6940\n",
      "  Finished task 33.0 in stage 0.0 (TID 33). 1900 bytes result sent to driver\n",
      "  Starting task 37.0 in stage 0.0 (TID 37) (namenode, executor driver, partition 37, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 33.0 in stage 0.0 (TID 33) in 7023 ms on namenode (executor driver) (34/121)\n",
      "  Running task 37.0 in stage 0.0 (TID 37)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:4966055936+134217728\n",
      "  Times: total = 6562, boot = -26, init = 30, finish = 6558\n",
      "  Finished task 34.0 in stage 0.0 (TID 34). 1900 bytes result sent to driver\n",
      "  Starting task 38.0 in stage 0.0 (TID 38) (namenode, executor driver, partition 38, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 34.0 in stage 0.0 (TID 34) in 6658 ms on namenode (executor driver) (35/121)\n",
      "  Running task 38.0 in stage 0.0 (TID 38)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:5100273664+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 7128, boot = -27, init = 41, finish = 7114\n",
      "  Finished task 35.0 in stage 0.0 (TID 35). 1900 bytes result sent to driver\n",
      "  Starting task 39.0 in stage 0.0 (TID 39) (namenode, executor driver, partition 39, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 35.0 in stage 0.0 (TID 35) in 7190 ms on namenode (executor driver) (36/121)\n",
      "  Running task 39.0 in stage 0.0 (TID 39)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:5234491392+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6598, boot = -66, init = 68, finish = 6596\n",
      "  Finished task 37.0 in stage 0.0 (TID 37). 1900 bytes result sent to driver\n",
      "  Starting task 40.0 in stage 0.0 (TID 40) (namenode, executor driver, partition 40, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 40.0 in stage 0.0 (TID 40)\n",
      "  Finished task 37.0 in stage 0.0 (TID 37) in 6680 ms on namenode (executor driver) (37/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:5368709120+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 7489, boot = -35, init = 40, finish = 7484\n",
      "  Finished task 36.0 in stage 0.0 (TID 36). 1900 bytes result sent to driver\n",
      "  Starting task 41.0 in stage 0.0 (TID 41) (namenode, executor driver, partition 41, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 36.0 in stage 0.0 (TID 36) in 7556 ms on namenode (executor driver) (38/121)\n",
      "  Running task 41.0 in stage 0.0 (TID 41)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:5502926848+134217728\n",
      "  Times: total = 6898, boot = -86, init = 88, finish = 6896\n",
      "  Finished task 38.0 in stage 0.0 (TID 38). 1900 bytes result sent to driver\n",
      "  Starting task 42.0 in stage 0.0 (TID 42) (namenode, executor driver, partition 42, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 42.0 in stage 0.0 (TID 42)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:5637144576+134217728\n",
      "  Finished task 38.0 in stage 0.0 (TID 38) in 6973 ms on namenode (executor driver) (39/121)\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6661, boot = -61, init = 63, finish = 6659\n",
      "  Finished task 39.0 in stage 0.0 (TID 39). 1900 bytes result sent to driver\n",
      "  Starting task 43.0 in stage 0.0 (TID 43) (namenode, executor driver, partition 43, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 43.0 in stage 0.0 (TID 43)\n",
      "  Finished task 39.0 in stage 0.0 (TID 39) in 6750 ms on namenode (executor driver) (40/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:5771362304+134217728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6440, boot = -58, init = 76, finish = 6422\n",
      "  Finished task 40.0 in stage 0.0 (TID 40). 1900 bytes result sent to driver\n",
      "  Starting task 44.0 in stage 0.0 (TID 44) (namenode, executor driver, partition 44, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 44.0 in stage 0.0 (TID 44)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:5905580032+134217728\n",
      "  Finished task 40.0 in stage 0.0 (TID 40) in 6506 ms on namenode (executor driver) (41/121)\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6614, boot = -58, init = 68, finish = 6604\n",
      "  Finished task 41.0 in stage 0.0 (TID 41). 1900 bytes result sent to driver\n",
      "  Starting task 45.0 in stage 0.0 (TID 45) (namenode, executor driver, partition 45, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 41.0 in stage 0.0 (TID 41) in 6679 ms on namenode (executor driver) (42/121)\n",
      "  Running task 45.0 in stage 0.0 (TID 45)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:6039797760+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6957, boot = -116, init = 128, finish = 6945\n",
      "  Finished task 42.0 in stage 0.0 (TID 42). 1900 bytes result sent to driver\n",
      "  Starting task 46.0 in stage 0.0 (TID 46) (namenode, executor driver, partition 46, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 42.0 in stage 0.0 (TID 42) in 7146 ms on namenode (executor driver) (43/121)\n",
      "  Running task 46.0 in stage 0.0 (TID 46)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:6174015488+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 7334, boot = -82, init = 88, finish = 7328\n",
      "  Finished task 43.0 in stage 0.0 (TID 43). 1900 bytes result sent to driver\n",
      "  Starting task 47.0 in stage 0.0 (TID 47) (namenode, executor driver, partition 47, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 43.0 in stage 0.0 (TID 43) in 7398 ms on namenode (executor driver) (44/121)\n",
      "  Running task 47.0 in stage 0.0 (TID 47)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:6308233216+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6158, boot = -35, init = 40, finish = 6153\n",
      "  Finished task 44.0 in stage 0.0 (TID 44). 1900 bytes result sent to driver\n",
      "  Starting task 48.0 in stage 0.0 (TID 48) (namenode, executor driver, partition 48, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 44.0 in stage 0.0 (TID 44) in 6200 ms on namenode (executor driver) (45/121)\n",
      "  Running task 48.0 in stage 0.0 (TID 48)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:6442450944+134217728\n",
      "  Times: total = 6437, boot = -47, init = 49, finish = 6435\n",
      "  Finished task 45.0 in stage 0.0 (TID 45). 1900 bytes result sent to driver\n",
      "  Starting task 49.0 in stage 0.0 (TID 49) (namenode, executor driver, partition 49, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 49.0 in stage 0.0 (TID 49)\n",
      "  Finished task 45.0 in stage 0.0 (TID 45) in 6505 ms on namenode (executor driver) (46/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:6576668672+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 7426, boot = -97, init = 105, finish = 7418\n",
      "  Finished task 46.0 in stage 0.0 (TID 46). 1900 bytes result sent to driver\n",
      "  Starting task 50.0 in stage 0.0 (TID 50) (namenode, executor driver, partition 50, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 46.0 in stage 0.0 (TID 46) in 7501 ms on namenode (executor driver) (47/121)\n",
      "  Running task 50.0 in stage 0.0 (TID 50)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:6710886400+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6869, boot = -31, init = 33, finish = 6867\n",
      "  Finished task 47.0 in stage 0.0 (TID 47). 1900 bytes result sent to driver\n",
      "  Starting task 51.0 in stage 0.0 (TID 51) (namenode, executor driver, partition 51, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 51.0 in stage 0.0 (TID 51)\n",
      "  Finished task 47.0 in stage 0.0 (TID 47) in 6948 ms on namenode (executor driver) (48/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:6845104128+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6912, boot = -52, init = 59, finish = 6905\n",
      "  Finished task 48.0 in stage 0.0 (TID 48). 1900 bytes result sent to driver\n",
      "  Starting task 52.0 in stage 0.0 (TID 52) (namenode, executor driver, partition 52, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 52.0 in stage 0.0 (TID 52)\n",
      "  Finished task 48.0 in stage 0.0 (TID 48) in 6989 ms on namenode (executor driver) (49/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:6979321856+134217728\n",
      "  Times: total = 7148, boot = -46, init = 64, finish = 7130\n",
      "  Finished task 49.0 in stage 0.0 (TID 49). 1900 bytes result sent to driver\n",
      "  Starting task 53.0 in stage 0.0 (TID 53) (namenode, executor driver, partition 53, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 53.0 in stage 0.0 (TID 53)\n",
      "  Finished task 49.0 in stage 0.0 (TID 49) in 7214 ms on namenode (executor driver) (50/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:7113539584+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 7131, boot = -39, init = 41, finish = 7129\n",
      "  Finished task 50.0 in stage 0.0 (TID 50). 1900 bytes result sent to driver\n",
      "  Starting task 54.0 in stage 0.0 (TID 54) (namenode, executor driver, partition 54, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 50.0 in stage 0.0 (TID 50) in 7181 ms on namenode (executor driver) (51/121)\n",
      "  Running task 54.0 in stage 0.0 (TID 54)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:7247757312+134217728\n",
      "  Times: total = 7077, boot = -56, init = 68, finish = 7065\n",
      "  Finished task 51.0 in stage 0.0 (TID 51). 1900 bytes result sent to driver\n",
      "  Starting task 55.0 in stage 0.0 (TID 55) (namenode, executor driver, partition 55, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 55.0 in stage 0.0 (TID 55)\n",
      "  Finished task 51.0 in stage 0.0 (TID 51) in 7134 ms on namenode (executor driver) (52/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:7381975040+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6287, boot = -17, init = 36, finish = 6268\n",
      "  Finished task 52.0 in stage 0.0 (TID 52). 1900 bytes result sent to driver\n",
      "  Starting task 56.0 in stage 0.0 (TID 56) (namenode, executor driver, partition 56, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 56.0 in stage 0.0 (TID 56)\n",
      "  Finished task 52.0 in stage 0.0 (TID 52) in 6382 ms on namenode (executor driver) (53/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:7516192768+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6307, boot = -50, init = 54, finish = 6303\n",
      "  Finished task 53.0 in stage 0.0 (TID 53). 1900 bytes result sent to driver\n",
      "  Starting task 57.0 in stage 0.0 (TID 57) (namenode, executor driver, partition 57, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 57.0 in stage 0.0 (TID 57)\n",
      "  Finished task 53.0 in stage 0.0 (TID 53) in 6387 ms on namenode (executor driver) (54/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:7650410496+134217728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6305, boot = -29, init = 63, finish = 6271\n",
      "  Finished task 54.0 in stage 0.0 (TID 54). 1900 bytes result sent to driver\n",
      "  Starting task 58.0 in stage 0.0 (TID 58) (namenode, executor driver, partition 58, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 58.0 in stage 0.0 (TID 58)\n",
      "  Finished task 54.0 in stage 0.0 (TID 54) in 6372 ms on namenode (executor driver) (55/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:7784628224+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 7433, boot = -39, init = 52, finish = 7420\n",
      "  Finished task 55.0 in stage 0.0 (TID 55). 1900 bytes result sent to driver\n",
      "  Starting task 59.0 in stage 0.0 (TID 59) (namenode, executor driver, partition 59, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 55.0 in stage 0.0 (TID 55) in 7567 ms on namenode (executor driver) (56/121)\n",
      "  Running task 59.0 in stage 0.0 (TID 59)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:7918845952+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 7078, boot = -101, init = 109, finish = 7070\n",
      "  Finished task 56.0 in stage 0.0 (TID 56). 1900 bytes result sent to driver\n",
      "  Starting task 60.0 in stage 0.0 (TID 60) (namenode, executor driver, partition 60, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 60.0 in stage 0.0 (TID 60)\n",
      "  Finished task 56.0 in stage 0.0 (TID 56) in 7176 ms on namenode (executor driver) (57/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:8053063680+134217728\n",
      "  Times: total = 6448, boot = -27, init = 33, finish = 6442\n",
      "  Finished task 57.0 in stage 0.0 (TID 57). 1900 bytes result sent to driver\n",
      "  Starting task 61.0 in stage 0.0 (TID 61) (namenode, executor driver, partition 61, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 57.0 in stage 0.0 (TID 57) in 6504 ms on namenode (executor driver) (58/121)\n",
      "  Running task 61.0 in stage 0.0 (TID 61)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:8187281408+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 7063, boot = -61, init = 67, finish = 7057\n",
      "  Finished task 58.0 in stage 0.0 (TID 58). 1900 bytes result sent to driver\n",
      "  Starting task 62.0 in stage 0.0 (TID 62) (namenode, executor driver, partition 62, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 58.0 in stage 0.0 (TID 58) in 7133 ms on namenode (executor driver) (59/121)\n",
      "  Running task 62.0 in stage 0.0 (TID 62)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:8321499136+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6619, boot = -55, init = 70, finish = 6604\n",
      "  Times: total = 7799, boot = -109, init = 127, finish = 7781\n",
      "  Finished task 60.0 in stage 0.0 (TID 60). 1900 bytes result sent to driver\n",
      "  Starting task 63.0 in stage 0.0 (TID 63) (namenode, executor driver, partition 63, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 63.0 in stage 0.0 (TID 63)\n",
      "  Finished task 60.0 in stage 0.0 (TID 60) in 6675 ms on namenode (executor driver) (60/121)\n",
      "  Finished task 59.0 in stage 0.0 (TID 59). 1900 bytes result sent to driver\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:8455716864+134217728\n",
      "  Starting task 64.0 in stage 0.0 (TID 64) (namenode, executor driver, partition 64, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 59.0 in stage 0.0 (TID 59) in 7860 ms on namenode (executor driver) (61/121)\n",
      "  Running task 64.0 in stage 0.0 (TID 64)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:8589934592+134217728\n",
      "  Times: total = 6409, boot = -45, init = 50, finish = 6404\n",
      "  Finished task 61.0 in stage 0.0 (TID 61). 1900 bytes result sent to driver\n",
      "  Starting task 65.0 in stage 0.0 (TID 65) (namenode, executor driver, partition 65, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 61.0 in stage 0.0 (TID 61) in 6471 ms on namenode (executor driver) (62/121)\n",
      "  Running task 65.0 in stage 0.0 (TID 65)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:8724152320+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6840, boot = -65, init = 82, finish = 6823\n",
      "  Finished task 62.0 in stage 0.0 (TID 62). 1900 bytes result sent to driver\n",
      "  Starting task 66.0 in stage 0.0 (TID 66) (namenode, executor driver, partition 66, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 62.0 in stage 0.0 (TID 62) in 6926 ms on namenode (executor driver) (63/121)\n",
      "  Running task 66.0 in stage 0.0 (TID 66)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:8858370048+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6884, boot = -36, init = 39, finish = 6881\n",
      "  Finished task 63.0 in stage 0.0 (TID 63). 1900 bytes result sent to driver\n",
      "  Starting task 67.0 in stage 0.0 (TID 67) (namenode, executor driver, partition 67, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 63.0 in stage 0.0 (TID 63) in 7182 ms on namenode (executor driver) (64/121)\n",
      "  Running task 67.0 in stage 0.0 (TID 67)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:8992587776+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 7149, boot = -47, init = 51, finish = 7145\n",
      "  Finished task 64.0 in stage 0.0 (TID 64). 1900 bytes result sent to driver\n",
      "  Starting task 68.0 in stage 0.0 (TID 68) (namenode, executor driver, partition 68, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 64.0 in stage 0.0 (TID 64) in 7219 ms on namenode (executor driver) (65/121)\n",
      "  Running task 68.0 in stage 0.0 (TID 68)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:9126805504+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 7383, boot = -37, init = 48, finish = 7372\n",
      "  Finished task 65.0 in stage 0.0 (TID 65). 1900 bytes result sent to driver\n",
      "  Starting task 69.0 in stage 0.0 (TID 69) (namenode, executor driver, partition 69, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 65.0 in stage 0.0 (TID 65) in 7440 ms on namenode (executor driver) (66/121)\n",
      "  Running task 69.0 in stage 0.0 (TID 69)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:9261023232+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 7797, boot = -43, init = 59, finish = 7781\n",
      "  Finished task 66.0 in stage 0.0 (TID 66). 1900 bytes result sent to driver\n",
      "  Starting task 70.0 in stage 0.0 (TID 70) (namenode, executor driver, partition 70, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 66.0 in stage 0.0 (TID 66) in 7896 ms on namenode (executor driver) (67/121)\n",
      "  Running task 70.0 in stage 0.0 (TID 70)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:9395240960+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6480, boot = -273, init = 285, finish = 6468\n",
      "  Finished task 67.0 in stage 0.0 (TID 67). 1900 bytes result sent to driver\n",
      "  Starting task 71.0 in stage 0.0 (TID 71) (namenode, executor driver, partition 71, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 71.0 in stage 0.0 (TID 71)\n",
      "  Finished task 67.0 in stage 0.0 (TID 67) in 6539 ms on namenode (executor driver) (68/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:9529458688+134217728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6820, boot = -53, init = 84, finish = 6789\n",
      "  Finished task 68.0 in stage 0.0 (TID 68). 1900 bytes result sent to driver\n",
      "  Starting task 72.0 in stage 0.0 (TID 72) (namenode, executor driver, partition 72, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 72.0 in stage 0.0 (TID 72)\n",
      "  Finished task 68.0 in stage 0.0 (TID 68) in 6894 ms on namenode (executor driver) (69/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:9663676416+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6457, boot = -59, init = 77, finish = 6439\n",
      "  Finished task 69.0 in stage 0.0 (TID 69). 1900 bytes result sent to driver\n",
      "  Starting task 73.0 in stage 0.0 (TID 73) (namenode, executor driver, partition 73, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 73.0 in stage 0.0 (TID 73)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:9797894144+134217728\n",
      "  Finished task 69.0 in stage 0.0 (TID 69) in 6563 ms on namenode (executor driver) (70/121)\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 7152, boot = -44, init = 53, finish = 7143\n",
      "  Finished task 70.0 in stage 0.0 (TID 70). 1900 bytes result sent to driver\n",
      "  Starting task 74.0 in stage 0.0 (TID 74) (namenode, executor driver, partition 74, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 70.0 in stage 0.0 (TID 70) in 7205 ms on namenode (executor driver) (71/121)\n",
      "  Running task 74.0 in stage 0.0 (TID 74)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:9932111872+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6441, boot = -48, init = 67, finish = 6422\n",
      "  Finished task 71.0 in stage 0.0 (TID 71). 1900 bytes result sent to driver\n",
      "  Starting task 75.0 in stage 0.0 (TID 75) (namenode, executor driver, partition 75, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 75.0 in stage 0.0 (TID 75)\n",
      "  Finished task 71.0 in stage 0.0 (TID 71) in 6503 ms on namenode (executor driver) (72/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:10066329600+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6634, boot = -55, init = 64, finish = 6625\n",
      "  Finished task 72.0 in stage 0.0 (TID 72). 1900 bytes result sent to driver\n",
      "  Starting task 76.0 in stage 0.0 (TID 76) (namenode, executor driver, partition 76, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 72.0 in stage 0.0 (TID 72) in 6685 ms on namenode (executor driver) (73/121)\n",
      "  Running task 76.0 in stage 0.0 (TID 76)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:10200547328+134217728\n",
      "  Times: total = 6402, boot = -71, init = 82, finish = 6391\n",
      "  Finished task 73.0 in stage 0.0 (TID 73). 1900 bytes result sent to driver\n",
      "  Starting task 77.0 in stage 0.0 (TID 77) (namenode, executor driver, partition 77, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 77.0 in stage 0.0 (TID 77)\n",
      "  Finished task 73.0 in stage 0.0 (TID 73) in 6544 ms on namenode (executor driver) (74/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:10334765056+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6463, boot = -31, init = 42, finish = 6452\n",
      "  Finished task 75.0 in stage 0.0 (TID 75). 1900 bytes result sent to driver\n",
      "  Starting task 78.0 in stage 0.0 (TID 78) (namenode, executor driver, partition 78, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 75.0 in stage 0.0 (TID 75) in 6526 ms on namenode (executor driver) (75/121)\n",
      "  Running task 78.0 in stage 0.0 (TID 78)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:10468982784+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 7854, boot = -55, init = 62, finish = 7847\n",
      "  Finished task 74.0 in stage 0.0 (TID 74). 1900 bytes result sent to driver\n",
      "  Starting task 79.0 in stage 0.0 (TID 79) (namenode, executor driver, partition 79, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 74.0 in stage 0.0 (TID 74) in 7972 ms on namenode (executor driver) (76/121)\n",
      "  Running task 79.0 in stage 0.0 (TID 79)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:10603200512+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6219, boot = -118, init = 142, finish = 6195\n",
      "  Finished task 77.0 in stage 0.0 (TID 77). 1900 bytes result sent to driver\n",
      "  Starting task 80.0 in stage 0.0 (TID 80) (namenode, executor driver, partition 80, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 77.0 in stage 0.0 (TID 77) in 6272 ms on namenode (executor driver) (77/121)\n",
      "  Running task 80.0 in stage 0.0 (TID 80)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:10737418240+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6606, boot = -44, init = 55, finish = 6595\n",
      "  Finished task 76.0 in stage 0.0 (TID 76). 1900 bytes result sent to driver\n",
      "  Starting task 81.0 in stage 0.0 (TID 81) (namenode, executor driver, partition 81, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 76.0 in stage 0.0 (TID 76) in 6713 ms on namenode (executor driver) (78/121)\n",
      "  Running task 81.0 in stage 0.0 (TID 81)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:10871635968+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6720, boot = -47, init = 63, finish = 6704\n",
      "  Finished task 78.0 in stage 0.0 (TID 78). 1900 bytes result sent to driver\n",
      "  Starting task 82.0 in stage 0.0 (TID 82) (namenode, executor driver, partition 82, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 82.0 in stage 0.0 (TID 82)\n",
      "  Finished task 78.0 in stage 0.0 (TID 78) in 6775 ms on namenode (executor driver) (79/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:11005853696+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6861, boot = -72, init = 90, finish = 6843\n",
      "  Finished task 79.0 in stage 0.0 (TID 79). 1900 bytes result sent to driver\n",
      "  Starting task 83.0 in stage 0.0 (TID 83) (namenode, executor driver, partition 83, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 83.0 in stage 0.0 (TID 83)\n",
      "  Finished task 79.0 in stage 0.0 (TID 79) in 6936 ms on namenode (executor driver) (80/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:11140071424+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6862, boot = -40, init = 42, finish = 6860\n",
      "  Finished task 80.0 in stage 0.0 (TID 80). 1900 bytes result sent to driver\n",
      "  Starting task 84.0 in stage 0.0 (TID 84) (namenode, executor driver, partition 84, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 84.0 in stage 0.0 (TID 84)\n",
      "  Finished task 80.0 in stage 0.0 (TID 80) in 6999 ms on namenode (executor driver) (81/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:11274289152+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 7026, boot = -81, init = 93, finish = 7014\n",
      "  Finished task 81.0 in stage 0.0 (TID 81). 1900 bytes result sent to driver\n",
      "  Starting task 85.0 in stage 0.0 (TID 85) (namenode, executor driver, partition 85, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 81.0 in stage 0.0 (TID 81) in 7089 ms on namenode (executor driver) (82/121)\n",
      "  Running task 85.0 in stage 0.0 (TID 85)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:11408506880+134217728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6648, boot = -43, init = 88, finish = 6603\n",
      "  Finished task 82.0 in stage 0.0 (TID 82). 1900 bytes result sent to driver\n",
      "  Starting task 86.0 in stage 0.0 (TID 86) (namenode, executor driver, partition 86, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 82.0 in stage 0.0 (TID 82) in 6692 ms on namenode (executor driver) (83/121)\n",
      "  Running task 86.0 in stage 0.0 (TID 86)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:11542724608+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 7228, boot = -96, init = 105, finish = 7219\n",
      "  Finished task 83.0 in stage 0.0 (TID 83). 1900 bytes result sent to driver\n",
      "  Starting task 87.0 in stage 0.0 (TID 87) (namenode, executor driver, partition 87, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 83.0 in stage 0.0 (TID 83) in 7324 ms on namenode (executor driver) (84/121)\n",
      "  Running task 87.0 in stage 0.0 (TID 87)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:11676942336+134217728\n",
      "  Times: total = 6488, boot = -91, init = 118, finish = 6461\n",
      "  Times: total = 6999, boot = -126, init = 150, finish = 6975\n",
      "  Finished task 85.0 in stage 0.0 (TID 85). 1900 bytes result sent to driver\n",
      "  Starting task 88.0 in stage 0.0 (TID 88) (namenode, executor driver, partition 88, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 85.0 in stage 0.0 (TID 85) in 6628 ms on namenode (executor driver) (85/121)\n",
      "  Running task 88.0 in stage 0.0 (TID 88)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:11811160064+134217728\n",
      "  Finished task 84.0 in stage 0.0 (TID 84). 1900 bytes result sent to driver\n",
      "  Starting task 89.0 in stage 0.0 (TID 89) (namenode, executor driver, partition 89, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 89.0 in stage 0.0 (TID 89)\n",
      "  Finished task 84.0 in stage 0.0 (TID 84) in 7118 ms on namenode (executor driver) (86/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:11945377792+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6510, boot = -28, init = 32, finish = 6506\n",
      "  Finished task 86.0 in stage 0.0 (TID 86). 1900 bytes result sent to driver\n",
      "  Starting task 90.0 in stage 0.0 (TID 90) (namenode, executor driver, partition 90, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 90.0 in stage 0.0 (TID 90)\n",
      "  Finished task 86.0 in stage 0.0 (TID 86) in 6570 ms on namenode (executor driver) (87/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:12079595520+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6616, boot = -17, init = 19, finish = 6614\n",
      "  Finished task 87.0 in stage 0.0 (TID 87). 1900 bytes result sent to driver\n",
      "  Starting task 91.0 in stage 0.0 (TID 91) (namenode, executor driver, partition 91, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 87.0 in stage 0.0 (TID 87) in 6667 ms on namenode (executor driver) (88/121)\n",
      "  Running task 91.0 in stage 0.0 (TID 91)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:12213813248+134217728\n",
      "  Times: total = 7007, boot = -163, init = 174, finish = 6996\n",
      "  Finished task 89.0 in stage 0.0 (TID 89). 1900 bytes result sent to driver\n",
      "  Starting task 92.0 in stage 0.0 (TID 92) (namenode, executor driver, partition 92, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 89.0 in stage 0.0 (TID 89) in 7165 ms on namenode (executor driver) (89/121)\n",
      "  Running task 92.0 in stage 0.0 (TID 92)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:12348030976+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 7367, boot = -52, init = 65, finish = 7354\n",
      "  Finished task 88.0 in stage 0.0 (TID 88). 1900 bytes result sent to driver\n",
      "  Starting task 93.0 in stage 0.0 (TID 93) (namenode, executor driver, partition 93, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 93.0 in stage 0.0 (TID 93)\n",
      "  Finished task 88.0 in stage 0.0 (TID 88) in 7435 ms on namenode (executor driver) (90/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:12482248704+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6800, boot = -25, init = 31, finish = 6794\n",
      "  Finished task 90.0 in stage 0.0 (TID 90). 1900 bytes result sent to driver\n",
      "  Starting task 94.0 in stage 0.0 (TID 94) (namenode, executor driver, partition 94, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 94.0 in stage 0.0 (TID 94)\n",
      "  Finished task 90.0 in stage 0.0 (TID 90) in 6840 ms on namenode (executor driver) (91/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:12616466432+134217728\n",
      "  Times: total = 6419, boot = -40, init = 58, finish = 6401\n",
      "  Finished task 91.0 in stage 0.0 (TID 91). 1900 bytes result sent to driver\n",
      "  Starting task 95.0 in stage 0.0 (TID 95) (namenode, executor driver, partition 95, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 91.0 in stage 0.0 (TID 91) in 6472 ms on namenode (executor driver) (92/121)\n",
      "  Running task 95.0 in stage 0.0 (TID 95)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:12750684160+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 7023, boot = -70, init = 110, finish = 6983\n",
      "  Finished task 92.0 in stage 0.0 (TID 92). 1900 bytes result sent to driver\n",
      "  Starting task 96.0 in stage 0.0 (TID 96) (namenode, executor driver, partition 96, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 96.0 in stage 0.0 (TID 96)\n",
      "  Finished task 92.0 in stage 0.0 (TID 92) in 7096 ms on namenode (executor driver) (93/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:12884901888+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 7203, boot = -34, init = 51, finish = 7186\n",
      "  Finished task 93.0 in stage 0.0 (TID 93). 1900 bytes result sent to driver\n",
      "  Starting task 97.0 in stage 0.0 (TID 97) (namenode, executor driver, partition 97, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 97.0 in stage 0.0 (TID 97)\n",
      "  Finished task 93.0 in stage 0.0 (TID 93) in 7271 ms on namenode (executor driver) (94/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:13019119616+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6650, boot = -27, init = 30, finish = 6647\n",
      "  Finished task 94.0 in stage 0.0 (TID 94). 1900 bytes result sent to driver\n",
      "  Starting task 98.0 in stage 0.0 (TID 98) (namenode, executor driver, partition 98, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 94.0 in stage 0.0 (TID 94) in 6748 ms on namenode (executor driver) (95/121)\n",
      "  Running task 98.0 in stage 0.0 (TID 98)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:13153337344+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6612, boot = -37, init = 43, finish = 6606\n",
      "  Finished task 95.0 in stage 0.0 (TID 95). 1900 bytes result sent to driver\n",
      "  Starting task 99.0 in stage 0.0 (TID 99) (namenode, executor driver, partition 99, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 99.0 in stage 0.0 (TID 99)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:13287555072+134217728\n",
      "  Finished task 95.0 in stage 0.0 (TID 95) in 6678 ms on namenode (executor driver) (96/121)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 7353, boot = -43, init = 47, finish = 7349\n",
      "  Finished task 96.0 in stage 0.0 (TID 96). 1900 bytes result sent to driver\n",
      "  Starting task 100.0 in stage 0.0 (TID 100) (namenode, executor driver, partition 100, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 96.0 in stage 0.0 (TID 96) in 7433 ms on namenode (executor driver) (97/121)\n",
      "  Running task 100.0 in stage 0.0 (TID 100)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:13421772800+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 7152, boot = -57, init = 68, finish = 7141\n",
      "  Finished task 97.0 in stage 0.0 (TID 97). 1900 bytes result sent to driver\n",
      "  Starting task 101.0 in stage 0.0 (TID 101) (namenode, executor driver, partition 101, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 97.0 in stage 0.0 (TID 97) in 7267 ms on namenode (executor driver) (98/121)\n",
      "  Running task 101.0 in stage 0.0 (TID 101)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:13555990528+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 5852, boot = -49, init = 63, finish = 5838\n",
      "  Finished task 99.0 in stage 0.0 (TID 99). 1900 bytes result sent to driver\n",
      "  Starting task 102.0 in stage 0.0 (TID 102) (namenode, executor driver, partition 102, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 99.0 in stage 0.0 (TID 99) in 5901 ms on namenode (executor driver) (99/121)\n",
      "  Running task 102.0 in stage 0.0 (TID 102)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:13690208256+134217728\n",
      "  Times: total = 6808, boot = -104, init = 106, finish = 6806\n",
      "  Finished task 98.0 in stage 0.0 (TID 98). 1900 bytes result sent to driver\n",
      "  Starting task 103.0 in stage 0.0 (TID 103) (namenode, executor driver, partition 103, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 103.0 in stage 0.0 (TID 103)\n",
      "  Finished task 98.0 in stage 0.0 (TID 98) in 6914 ms on namenode (executor driver) (100/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:13824425984+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6847, boot = -51, init = 56, finish = 6842\n",
      "  Finished task 100.0 in stage 0.0 (TID 100). 1900 bytes result sent to driver\n",
      "  Starting task 104.0 in stage 0.0 (TID 104) (namenode, executor driver, partition 104, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 100.0 in stage 0.0 (TID 100) in 6892 ms on namenode (executor driver) (101/121)\n",
      "  Running task 104.0 in stage 0.0 (TID 104)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:13958643712+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6835, boot = -87, init = 110, finish = 6812\n",
      "  Finished task 101.0 in stage 0.0 (TID 101). 1900 bytes result sent to driver\n",
      "  Starting task 105.0 in stage 0.0 (TID 105) (namenode, executor driver, partition 105, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 101.0 in stage 0.0 (TID 101) in 6936 ms on namenode (executor driver) (102/121)\n",
      "  Running task 105.0 in stage 0.0 (TID 105)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:14092861440+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6135, boot = -17, init = 21, finish = 6131\n",
      "  Finished task 103.0 in stage 0.0 (TID 103). 1900 bytes result sent to driver\n",
      "  Starting task 106.0 in stage 0.0 (TID 106) (namenode, executor driver, partition 106, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 106.0 in stage 0.0 (TID 106)\n",
      "  Finished task 103.0 in stage 0.0 (TID 103) in 6184 ms on namenode (executor driver) (103/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:14227079168+134217728\n",
      "  Times: total = 6863, boot = -75, init = 89, finish = 6849\n",
      "  Finished task 102.0 in stage 0.0 (TID 102). 1900 bytes result sent to driver\n",
      "  Starting task 107.0 in stage 0.0 (TID 107) (namenode, executor driver, partition 107, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 102.0 in stage 0.0 (TID 102) in 6965 ms on namenode (executor driver) (104/121)\n",
      "  Running task 107.0 in stage 0.0 (TID 107)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:14361296896+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6345, boot = -24, init = 26, finish = 6343\n",
      "  Finished task 104.0 in stage 0.0 (TID 104). 1900 bytes result sent to driver\n",
      "  Starting task 108.0 in stage 0.0 (TID 108) (namenode, executor driver, partition 108, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 108.0 in stage 0.0 (TID 108)\n",
      "  Finished task 104.0 in stage 0.0 (TID 104) in 6408 ms on namenode (executor driver) (105/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:14495514624+134217728\n",
      "  Times: total = 7846, boot = -46, init = 58, finish = 7834\n",
      "  Finished task 105.0 in stage 0.0 (TID 105). 1900 bytes result sent to driver\n",
      "  Starting task 109.0 in stage 0.0 (TID 109) (namenode, executor driver, partition 109, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 109.0 in stage 0.0 (TID 109)\n",
      "  Finished task 105.0 in stage 0.0 (TID 105) in 7890 ms on namenode (executor driver) (106/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:14629732352+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6680, boot = -85, init = 87, finish = 6678\n",
      "  Finished task 107.0 in stage 0.0 (TID 107). 1900 bytes result sent to driver\n",
      "  Starting task 110.0 in stage 0.0 (TID 110) (namenode, executor driver, partition 110, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 107.0 in stage 0.0 (TID 107) in 6768 ms on namenode (executor driver) (107/121)\n",
      "  Running task 110.0 in stage 0.0 (TID 110)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:14763950080+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 7243, boot = -38, init = 45, finish = 7236\n",
      "  Finished task 106.0 in stage 0.0 (TID 106). 1900 bytes result sent to driver\n",
      "  Starting task 111.0 in stage 0.0 (TID 111) (namenode, executor driver, partition 111, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 106.0 in stage 0.0 (TID 106) in 7312 ms on namenode (executor driver) (108/121)\n",
      "  Running task 111.0 in stage 0.0 (TID 111)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:14898167808+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6543, boot = -63, init = 65, finish = 6541\n",
      "  Finished task 108.0 in stage 0.0 (TID 108). 1900 bytes result sent to driver\n",
      "  Starting task 112.0 in stage 0.0 (TID 112) (namenode, executor driver, partition 112, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 112.0 in stage 0.0 (TID 112)\n",
      "  Finished task 108.0 in stage 0.0 (TID 108) in 6641 ms on namenode (executor driver) (109/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:15032385536+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6349, boot = -45, init = 68, finish = 6326\n",
      "  Finished task 109.0 in stage 0.0 (TID 109). 1900 bytes result sent to driver\n",
      "  Starting task 113.0 in stage 0.0 (TID 113) (namenode, executor driver, partition 113, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 113.0 in stage 0.0 (TID 113)\n",
      "  Finished task 109.0 in stage 0.0 (TID 109) in 6445 ms on namenode (executor driver) (110/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:15166603264+134217728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6208, boot = -27, init = 46, finish = 6189\n",
      "  Finished task 111.0 in stage 0.0 (TID 111). 1900 bytes result sent to driver\n",
      "  Starting task 114.0 in stage 0.0 (TID 114) (namenode, executor driver, partition 114, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 114.0 in stage 0.0 (TID 114)\n",
      "  Finished task 111.0 in stage 0.0 (TID 111) in 6266 ms on namenode (executor driver) (111/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:15300820992+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 7301, boot = -41, init = 47, finish = 7295\n",
      "  Finished task 110.0 in stage 0.0 (TID 110). 1900 bytes result sent to driver\n",
      "  Starting task 115.0 in stage 0.0 (TID 115) (namenode, executor driver, partition 115, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 110.0 in stage 0.0 (TID 110) in 7376 ms on namenode (executor driver) (112/121)\n",
      "  Running task 115.0 in stage 0.0 (TID 115)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:15435038720+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6875, boot = -69, init = 74, finish = 6870\n",
      "  Finished task 112.0 in stage 0.0 (TID 112). 1900 bytes result sent to driver\n",
      "  Starting task 116.0 in stage 0.0 (TID 116) (namenode, executor driver, partition 116, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 116.0 in stage 0.0 (TID 116)\n",
      "  Finished task 112.0 in stage 0.0 (TID 112) in 7028 ms on namenode (executor driver) (113/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:15569256448+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6959, boot = -14, init = 16, finish = 6957\n",
      "  Finished task 113.0 in stage 0.0 (TID 113). 1900 bytes result sent to driver\n",
      "  Starting task 117.0 in stage 0.0 (TID 117) (namenode, executor driver, partition 117, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 113.0 in stage 0.0 (TID 113) in 7006 ms on namenode (executor driver) (114/121)\n",
      "  Running task 117.0 in stage 0.0 (TID 117)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:15703474176+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 7126, boot = -85, init = 119, finish = 7092\n",
      "  Finished task 114.0 in stage 0.0 (TID 114). 1900 bytes result sent to driver\n",
      "  Starting task 118.0 in stage 0.0 (TID 118) (namenode, executor driver, partition 118, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 114.0 in stage 0.0 (TID 114) in 7228 ms on namenode (executor driver) (115/121)\n",
      "  Running task 118.0 in stage 0.0 (TID 118)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:15837691904+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6695, boot = -31, init = 37, finish = 6689\n",
      "  Finished task 115.0 in stage 0.0 (TID 115). 1900 bytes result sent to driver\n",
      "  Starting task 119.0 in stage 0.0 (TID 119) (namenode, executor driver, partition 119, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 119.0 in stage 0.0 (TID 119)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:15971909632+134217728\n",
      "  Finished task 115.0 in stage 0.0 (TID 115) in 6753 ms on namenode (executor driver) (116/121)\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 7463, boot = -131, init = 149, finish = 7445\n",
      "  Finished task 116.0 in stage 0.0 (TID 116). 1900 bytes result sent to driver\n",
      "  Starting task 120.0 in stage 0.0 (TID 120) (namenode, executor driver, partition 120, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 120.0 in stage 0.0 (TID 120)\n",
      "  Finished task 116.0 in stage 0.0 (TID 116) in 7521 ms on namenode (executor driver) (117/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:16106127360+79598254\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 7057, boot = -9, init = 26, finish = 7040\n",
      "  Finished task 117.0 in stage 0.0 (TID 117). 1943 bytes result sent to driver\n",
      "  Finished task 117.0 in stage 0.0 (TID 117) in 7121 ms on namenode (executor driver) (118/121)\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6631, boot = -26, init = 28, finish = 6629\n",
      "  Finished task 118.0 in stage 0.0 (TID 118). 1900 bytes result sent to driver\n",
      "  Finished task 118.0 in stage 0.0 (TID 118) in 6669 ms on namenode (executor driver) (119/121)\n",
      "  Times: total = 6270, boot = -38, init = 55, finish = 6253\n",
      "  Finished task 119.0 in stage 0.0 (TID 119). 1900 bytes result sent to driver\n",
      "  Finished task 119.0 in stage 0.0 (TID 119) in 6352 ms on namenode (executor driver) (120/121)\n",
      "  Times: total = 3615, boot = -32, init = 44, finish = 3603\n",
      "  Finished task 120.0 in stage 0.0 (TID 120). 1900 bytes result sent to driver\n",
      "  Finished task 120.0 in stage 0.0 (TID 120) in 3654 ms on namenode (executor driver) (121/121)\n",
      "  Removed TaskSet 0.0, whose tasks have all completed, from pool \n",
      "  ShuffleMapStage 0 (groupBy at /home/ubuntu/.local/lib/python3.8/site-packages/mrjob/spark/harness.py:539) finished in 213.811 s\n",
      "  looking for newly runnable stages\n",
      "  running: Set()\n",
      "  waiting: Set(ShuffleMapStage 1, ResultStage 2)\n",
      "  failed: Set()\n",
      "  Submitting ShuffleMapStage 1 (PairwiseRDD[7] at groupBy at /home/ubuntu/.local/lib/python3.8/site-packages/mrjob/spark/harness.py:539), which has no missing parents\n",
      "  Block broadcast_2 stored as values in memory (estimated size 17.5 KiB, free 365.8 MiB)\n",
      "  Block broadcast_2_piece0 stored as bytes in memory (estimated size 10.0 KiB, free 365.8 MiB)\n",
      "  Added broadcast_2_piece0 in memory on namenode:43301 (size: 10.0 KiB, free: 366.2 MiB)\n",
      "  Created broadcast 2 from broadcast at DAGScheduler.scala:1427\n",
      "  Submitting 121 missing tasks from ShuffleMapStage 1 (PairwiseRDD[7] at groupBy at /home/ubuntu/.local/lib/python3.8/site-packages/mrjob/spark/harness.py:539) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))\n",
      "  Adding task set 1.0 with 121 tasks resource profile 0\n",
      "  Starting task 0.0 in stage 1.0 (TID 121) (namenode, executor driver, partition 0, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Starting task 1.0 in stage 1.0 (TID 122) (namenode, executor driver, partition 1, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Starting task 2.0 in stage 1.0 (TID 123) (namenode, executor driver, partition 2, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Starting task 3.0 in stage 1.0 (TID 124) (namenode, executor driver, partition 3, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 0.0 in stage 1.0 (TID 121)\n",
      "  Running task 2.0 in stage 1.0 (TID 123)\n",
      "  Running task 1.0 in stage 1.0 (TID 122)\n",
      "  Running task 3.0 in stage 1.0 (TID 124)\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 16 ms\n",
      "  Started 0 remote fetches in 23 ms\n",
      "  Started 0 remote fetches in 19 ms\n",
      "  Started 0 remote fetches in 35 ms\n",
      "  Times: total = 5622, boot = -334, init = 383, finish = 5573\n",
      "  Times: total = 5648, boot = -429, init = 448, finish = 5629\n",
      "  Finished task 1.0 in stage 1.0 (TID 122). 2115 bytes result sent to driver\n",
      "  Starting task 4.0 in stage 1.0 (TID 125) (namenode, executor driver, partition 4, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 4.0 in stage 1.0 (TID 125)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Finished task 1.0 in stage 1.0 (TID 122) in 5777 ms on namenode (executor driver) (1/121)\n",
      "  Finished task 2.0 in stage 1.0 (TID 123). 2072 bytes result sent to driver\n",
      "  Starting task 5.0 in stage 1.0 (TID 126) (namenode, executor driver, partition 5, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 2.0 in stage 1.0 (TID 123) in 5787 ms on namenode (executor driver) (2/121)\n",
      "  Running task 5.0 in stage 1.0 (TID 126)\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 5 ms\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 16 ms\n",
      "  Times: total = 5839, boot = -2772, init = 2792, finish = 5819\n",
      "  Finished task 3.0 in stage 1.0 (TID 124). 2072 bytes result sent to driver\n",
      "  Starting task 6.0 in stage 1.0 (TID 127) (namenode, executor driver, partition 6, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 3.0 in stage 1.0 (TID 124) in 5958 ms on namenode (executor driver) (3/121)\n",
      "  Running task 6.0 in stage 1.0 (TID 127)\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 10 ms\n",
      "  Times: total = 6228, boot = -209, init = 225, finish = 6212\n",
      "  Finished task 0.0 in stage 1.0 (TID 121). 2072 bytes result sent to driver\n",
      "  Starting task 7.0 in stage 1.0 (TID 128) (namenode, executor driver, partition 7, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 0.0 in stage 1.0 (TID 121) in 6366 ms on namenode (executor driver) (4/121)\n",
      "  Running task 7.0 in stage 1.0 (TID 128)\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Times: total = 5703, boot = -49, init = 77, finish = 5675\n",
      "  Finished task 5.0 in stage 1.0 (TID 126). 2072 bytes result sent to driver\n",
      "  Starting task 8.0 in stage 1.0 (TID 129) (namenode, executor driver, partition 8, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 5.0 in stage 1.0 (TID 126) in 5757 ms on namenode (executor driver) (5/121)\n",
      "  Running task 8.0 in stage 1.0 (TID 129)\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 2 ms\n",
      "  Times: total = 5653, boot = -35, init = 49, finish = 5639\n",
      "  Finished task 6.0 in stage 1.0 (TID 127). 2072 bytes result sent to driver\n",
      "  Starting task 9.0 in stage 1.0 (TID 130) (namenode, executor driver, partition 9, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 9.0 in stage 1.0 (TID 130)\n",
      "  Finished task 6.0 in stage 1.0 (TID 127) in 5719 ms on namenode (executor driver) (6/121)\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 7 ms\n",
      "  Times: total = 6198, boot = -60, init = 67, finish = 6191\n",
      "  Finished task 4.0 in stage 1.0 (TID 125). 2072 bytes result sent to driver\n",
      "  Starting task 10.0 in stage 1.0 (TID 131) (namenode, executor driver, partition 10, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 4.0 in stage 1.0 (TID 125) in 6267 ms on namenode (executor driver) (7/121)\n",
      "  Running task 10.0 in stage 1.0 (TID 131)\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Times: total = 5692, boot = -42, init = 53, finish = 5681\n",
      "  Finished task 7.0 in stage 1.0 (TID 128). 2072 bytes result sent to driver\n",
      "  Starting task 11.0 in stage 1.0 (TID 132) (namenode, executor driver, partition 11, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 7.0 in stage 1.0 (TID 128) in 5740 ms on namenode (executor driver) (8/121)\n",
      "  Running task 11.0 in stage 1.0 (TID 132)\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Times: total = 5744, boot = -27, init = 31, finish = 5740\n",
      "  Finished task 8.0 in stage 1.0 (TID 129). 2072 bytes result sent to driver\n",
      "  Starting task 12.0 in stage 1.0 (TID 133) (namenode, executor driver, partition 12, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 8.0 in stage 1.0 (TID 129) in 5783 ms on namenode (executor driver) (9/121)\n",
      "  Running task 12.0 in stage 1.0 (TID 133)\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Times: total = 5706, boot = -29, init = 38, finish = 5697\n",
      "  Finished task 9.0 in stage 1.0 (TID 130). 2072 bytes result sent to driver\n",
      "  Starting task 13.0 in stage 1.0 (TID 134) (namenode, executor driver, partition 13, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 9.0 in stage 1.0 (TID 130) in 5746 ms on namenode (executor driver) (10/121)\n",
      "  Running task 13.0 in stage 1.0 (TID 134)\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 5838, boot = 6, init = 6, finish = 5826\n",
      "  Finished task 11.0 in stage 1.0 (TID 132). 2115 bytes result sent to driver\n",
      "  Starting task 14.0 in stage 1.0 (TID 135) (namenode, executor driver, partition 14, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 11.0 in stage 1.0 (TID 132) in 5882 ms on namenode (executor driver) (11/121)\n",
      "  Running task 14.0 in stage 1.0 (TID 135)\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 11 ms\n",
      "  Times: total = 6021, boot = -55, init = 66, finish = 6010\n",
      "  Finished task 10.0 in stage 1.0 (TID 131). 2158 bytes result sent to driver\n",
      "  Starting task 15.0 in stage 1.0 (TID 136) (namenode, executor driver, partition 15, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 15.0 in stage 1.0 (TID 136)\n",
      "  Finished task 10.0 in stage 1.0 (TID 131) in 6111 ms on namenode (executor driver) (12/121)\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Times: total = 5631, boot = -29, init = 32, finish = 5628\n",
      "  Finished task 12.0 in stage 1.0 (TID 133). 2115 bytes result sent to driver\n",
      "  Starting task 16.0 in stage 1.0 (TID 137) (namenode, executor driver, partition 16, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 16.0 in stage 1.0 (TID 137)\n",
      "  Finished task 12.0 in stage 1.0 (TID 133) in 5672 ms on namenode (executor driver) (13/121)\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Times: total = 5618, boot = -23, init = 26, finish = 5615\n",
      "  Finished task 13.0 in stage 1.0 (TID 134). 2115 bytes result sent to driver\n",
      "  Starting task 17.0 in stage 1.0 (TID 138) (namenode, executor driver, partition 17, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 17.0 in stage 1.0 (TID 138)\n",
      "  Finished task 13.0 in stage 1.0 (TID 134) in 5654 ms on namenode (executor driver) (14/121)\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Times: total = 5639, boot = -53, init = 55, finish = 5637\n",
      "  Finished task 15.0 in stage 1.0 (TID 136). 2115 bytes result sent to driver\n",
      "  Starting task 18.0 in stage 1.0 (TID 139) (namenode, executor driver, partition 18, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 15.0 in stage 1.0 (TID 136) in 5676 ms on namenode (executor driver) (15/121)\n",
      "  Running task 18.0 in stage 1.0 (TID 139)\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Started 0 remote fetches in 2 ms\n",
      "  Times: total = 6148, boot = -35, init = 38, finish = 6145\n",
      "  Finished task 14.0 in stage 1.0 (TID 135). 2115 bytes result sent to driver\n",
      "  Starting task 19.0 in stage 1.0 (TID 140) (namenode, executor driver, partition 19, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 14.0 in stage 1.0 (TID 135) in 6204 ms on namenode (executor driver) (16/121)\n",
      "  Running task 19.0 in stage 1.0 (TID 140)\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Times: total = 5616, boot = -15, init = 17, finish = 5614\n",
      "  Finished task 17.0 in stage 1.0 (TID 138). 2072 bytes result sent to driver\n",
      "  Starting task 20.0 in stage 1.0 (TID 141) (namenode, executor driver, partition 20, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 17.0 in stage 1.0 (TID 138) in 5636 ms on namenode (executor driver) (17/121)\n",
      "  Running task 20.0 in stage 1.0 (TID 141)\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 9 ms\n",
      "  Times: total = 5902, boot = -15, init = 18, finish = 5899\n",
      "  Finished task 16.0 in stage 1.0 (TID 137). 2072 bytes result sent to driver\n",
      "  Starting task 21.0 in stage 1.0 (TID 142) (namenode, executor driver, partition 21, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 16.0 in stage 1.0 (TID 137) in 5931 ms on namenode (executor driver) (18/121)\n",
      "  Running task 21.0 in stage 1.0 (TID 142)\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Times: total = 5549, boot = 5, init = 10, finish = 5534\n",
      "  Finished task 18.0 in stage 1.0 (TID 139). 2072 bytes result sent to driver\n",
      "  Starting task 22.0 in stage 1.0 (TID 143) (namenode, executor driver, partition 22, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 22.0 in stage 1.0 (TID 143)\n",
      "  Finished task 18.0 in stage 1.0 (TID 139) in 5591 ms on namenode (executor driver) (19/121)\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Times: total = 5762, boot = -30, init = 38, finish = 5754\n",
      "  Finished task 19.0 in stage 1.0 (TID 140). 2072 bytes result sent to driver\n",
      "  Starting task 23.0 in stage 1.0 (TID 144) (namenode, executor driver, partition 23, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 19.0 in stage 1.0 (TID 140) in 5810 ms on namenode (executor driver) (20/121)\n",
      "  Running task 23.0 in stage 1.0 (TID 144)\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 2 ms\n",
      "  Times: total = 5559, boot = 4, init = 2, finish = 5553\n",
      "  Finished task 20.0 in stage 1.0 (TID 141). 2072 bytes result sent to driver\n",
      "  Starting task 24.0 in stage 1.0 (TID 145) (namenode, executor driver, partition 24, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 20.0 in stage 1.0 (TID 141) in 5608 ms on namenode (executor driver) (21/121)\n",
      "  Running task 24.0 in stage 1.0 (TID 145)\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Times: total = 5656, boot = -17, init = 36, finish = 5637\n",
      "  Finished task 21.0 in stage 1.0 (TID 142). 2072 bytes result sent to driver\n",
      "  Starting task 25.0 in stage 1.0 (TID 146) (namenode, executor driver, partition 25, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 25.0 in stage 1.0 (TID 146)\n",
      "  Finished task 21.0 in stage 1.0 (TID 142) in 5698 ms on namenode (executor driver) (22/121)\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Times: total = 5886, boot = -21, init = 24, finish = 5883\n",
      "  Finished task 22.0 in stage 1.0 (TID 143). 2072 bytes result sent to driver\n",
      "  Starting task 26.0 in stage 1.0 (TID 147) (namenode, executor driver, partition 26, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 26.0 in stage 1.0 (TID 147)\n",
      "  Finished task 22.0 in stage 1.0 (TID 143) in 5919 ms on namenode (executor driver) (23/121)\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Times: total = 5781, boot = -18, init = 21, finish = 5778\n",
      "  Finished task 23.0 in stage 1.0 (TID 144). 2072 bytes result sent to driver\n",
      "  Finished task 23.0 in stage 1.0 (TID 144) in 5816 ms on namenode (executor driver) (24/121)\n",
      "  Starting task 27.0 in stage 1.0 (TID 148) (namenode, executor driver, partition 27, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 27.0 in stage 1.0 (TID 148)\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 5695, boot = -21, init = 24, finish = 5692\n",
      "  Finished task 24.0 in stage 1.0 (TID 145). 2072 bytes result sent to driver\n",
      "  Starting task 28.0 in stage 1.0 (TID 149) (namenode, executor driver, partition 28, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 24.0 in stage 1.0 (TID 145) in 5721 ms on namenode (executor driver) (25/121)\n",
      "  Running task 28.0 in stage 1.0 (TID 149)\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Times: total = 5595, boot = -28, init = 30, finish = 5593\n",
      "  Finished task 25.0 in stage 1.0 (TID 146). 2115 bytes result sent to driver\n",
      "  Starting task 29.0 in stage 1.0 (TID 150) (namenode, executor driver, partition 29, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 25.0 in stage 1.0 (TID 146) in 5650 ms on namenode (executor driver) (26/121)\n",
      "  Running task 29.0 in stage 1.0 (TID 150)\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Times: total = 5672, boot = -18, init = 20, finish = 5670\n",
      "  Finished task 27.0 in stage 1.0 (TID 148). 2115 bytes result sent to driver\n",
      "  Starting task 30.0 in stage 1.0 (TID 151) (namenode, executor driver, partition 30, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 27.0 in stage 1.0 (TID 148) in 5706 ms on namenode (executor driver) (27/121)\n",
      "  Running task 30.0 in stage 1.0 (TID 151)\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Times: total = 6211, boot = -18, init = 21, finish = 6208\n",
      "  Finished task 26.0 in stage 1.0 (TID 147). 2115 bytes result sent to driver\n",
      "  Starting task 31.0 in stage 1.0 (TID 152) (namenode, executor driver, partition 31, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 26.0 in stage 1.0 (TID 147) in 6271 ms on namenode (executor driver) (28/121)\n",
      "  Running task 31.0 in stage 1.0 (TID 152)\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 5716, boot = -9, init = 12, finish = 5713\n",
      "  Finished task 28.0 in stage 1.0 (TID 149). 2115 bytes result sent to driver\n",
      "  Finished task 28.0 in stage 1.0 (TID 149) in 5746 ms on namenode (executor driver) (29/121)\n",
      "  Starting task 32.0 in stage 1.0 (TID 153) (namenode, executor driver, partition 32, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 32.0 in stage 1.0 (TID 153)\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Started 0 remote fetches in 9 ms\n",
      "  Times: total = 5706, boot = -41, init = 48, finish = 5699\n",
      "  Finished task 29.0 in stage 1.0 (TID 150). 2072 bytes result sent to driver\n",
      "  Starting task 33.0 in stage 1.0 (TID 154) (namenode, executor driver, partition 33, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 29.0 in stage 1.0 (TID 150) in 5758 ms on namenode (executor driver) (30/121)\n",
      "  Running task 33.0 in stage 1.0 (TID 154)\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 3 ms\n",
      "  Times: total = 5520, boot = -40, init = 43, finish = 5517\n",
      "  Finished task 31.0 in stage 1.0 (TID 152). 2072 bytes result sent to driver\n",
      "  Starting task 34.0 in stage 1.0 (TID 155) (namenode, executor driver, partition 34, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 31.0 in stage 1.0 (TID 152) in 5560 ms on namenode (executor driver) (31/121)\n",
      "  Running task 34.0 in stage 1.0 (TID 155)\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 5 ms\n",
      "  Times: total = 5738, boot = -10, init = 39, finish = 5709\n",
      "  Finished task 30.0 in stage 1.0 (TID 151). 2072 bytes result sent to driver\n",
      "  Starting task 35.0 in stage 1.0 (TID 156) (namenode, executor driver, partition 35, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 30.0 in stage 1.0 (TID 151) in 5784 ms on namenode (executor driver) (32/121)\n",
      "  Running task 35.0 in stage 1.0 (TID 156)\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Times: total = 5534, boot = -4, init = 7, finish = 5531\n",
      "  Finished task 32.0 in stage 1.0 (TID 153). 2072 bytes result sent to driver\n",
      "  Starting task 36.0 in stage 1.0 (TID 157) (namenode, executor driver, partition 36, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 32.0 in stage 1.0 (TID 153) in 5565 ms on namenode (executor driver) (33/121)\n",
      "  Running task 36.0 in stage 1.0 (TID 157)\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 5 ms\n",
      "  Times: total = 5612, boot = -27, init = 30, finish = 5609\n",
      "  Finished task 33.0 in stage 1.0 (TID 154). 2072 bytes result sent to driver\n",
      "  Starting task 37.0 in stage 1.0 (TID 158) (namenode, executor driver, partition 37, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 33.0 in stage 1.0 (TID 154) in 5644 ms on namenode (executor driver) (34/121)\n",
      "  Running task 37.0 in stage 1.0 (TID 158)\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 7 ms\n",
      "  Times: total = 5618, boot = -31, init = 33, finish = 5616\n",
      "  Finished task 34.0 in stage 1.0 (TID 155). 2072 bytes result sent to driver\n",
      "  Starting task 38.0 in stage 1.0 (TID 159) (namenode, executor driver, partition 38, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 38.0 in stage 1.0 (TID 159)\n",
      "  Finished task 34.0 in stage 1.0 (TID 155) in 5654 ms on namenode (executor driver) (35/121)\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 5559, boot = -33, init = 39, finish = 5553\n",
      "  Finished task 35.0 in stage 1.0 (TID 156). 2072 bytes result sent to driver\n",
      "  Starting task 39.0 in stage 1.0 (TID 160) (namenode, executor driver, partition 39, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 35.0 in stage 1.0 (TID 156) in 5591 ms on namenode (executor driver) (36/121)\n",
      "  Running task 39.0 in stage 1.0 (TID 160)\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Times: total = 5456, boot = -13, init = 26, finish = 5443\n",
      "  Finished task 36.0 in stage 1.0 (TID 157). 2072 bytes result sent to driver\n",
      "  Starting task 40.0 in stage 1.0 (TID 161) (namenode, executor driver, partition 40, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 40.0 in stage 1.0 (TID 161)\n",
      "  Finished task 36.0 in stage 1.0 (TID 157) in 5498 ms on namenode (executor driver) (37/121)\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 7 ms\n",
      "  Times: total = 5731, boot = -20, init = 23, finish = 5728\n",
      "  Finished task 37.0 in stage 1.0 (TID 158). 2072 bytes result sent to driver\n",
      "  Starting task 41.0 in stage 1.0 (TID 162) (namenode, executor driver, partition 41, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 37.0 in stage 1.0 (TID 158) in 5763 ms on namenode (executor driver) (38/121)\n",
      "  Running task 41.0 in stage 1.0 (TID 162)\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 5539, boot = -14, init = 17, finish = 5536\n",
      "  Finished task 39.0 in stage 1.0 (TID 160). 2072 bytes result sent to driver\n",
      "  Starting task 42.0 in stage 1.0 (TID 163) (namenode, executor driver, partition 42, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 39.0 in stage 1.0 (TID 160) in 5565 ms on namenode (executor driver) (39/121)\n",
      "  Running task 42.0 in stage 1.0 (TID 163)\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 15 ms\n",
      "  Times: total = 5868, boot = -16, init = 19, finish = 5865\n",
      "  Finished task 38.0 in stage 1.0 (TID 159). 2072 bytes result sent to driver\n",
      "  Starting task 43.0 in stage 1.0 (TID 164) (namenode, executor driver, partition 43, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 38.0 in stage 1.0 (TID 159) in 5898 ms on namenode (executor driver) (40/121)\n",
      "  Running task 43.0 in stage 1.0 (TID 164)\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Times: total = 5969, boot = 2, init = 14, finish = 5953\n",
      "  Finished task 40.0 in stage 1.0 (TID 161). 2115 bytes result sent to driver\n",
      "  Starting task 44.0 in stage 1.0 (TID 165) (namenode, executor driver, partition 44, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 44.0 in stage 1.0 (TID 165)\n",
      "  Finished task 40.0 in stage 1.0 (TID 161) in 6010 ms on namenode (executor driver) (41/121)\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 5505, boot = -12, init = 14, finish = 5503\n",
      "  Finished task 41.0 in stage 1.0 (TID 162). 2115 bytes result sent to driver\n",
      "  Starting task 45.0 in stage 1.0 (TID 166) (namenode, executor driver, partition 45, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 41.0 in stage 1.0 (TID 162) in 5560 ms on namenode (executor driver) (42/121)\n",
      "  Running task 45.0 in stage 1.0 (TID 166)\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 5563, boot = -29, init = 46, finish = 5546\n",
      "  Finished task 42.0 in stage 1.0 (TID 163). 2115 bytes result sent to driver\n",
      "  Starting task 46.0 in stage 1.0 (TID 167) (namenode, executor driver, partition 46, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 46.0 in stage 1.0 (TID 167)\n",
      "  Finished task 42.0 in stage 1.0 (TID 163) in 5610 ms on namenode (executor driver) (43/121)\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Started 0 remote fetches in 7 ms\n",
      "  Times: total = 5541, boot = -16, init = 19, finish = 5538\n",
      "  Finished task 43.0 in stage 1.0 (TID 164). 2115 bytes result sent to driver\n",
      "  Starting task 47.0 in stage 1.0 (TID 168) (namenode, executor driver, partition 47, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 43.0 in stage 1.0 (TID 164) in 5568 ms on namenode (executor driver) (44/121)\n",
      "  Running task 47.0 in stage 1.0 (TID 168)\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 6 ms\n",
      "  Times: total = 5558, boot = -20, init = 22, finish = 5556\n",
      "  Finished task 44.0 in stage 1.0 (TID 165). 2072 bytes result sent to driver\n",
      "  Starting task 48.0 in stage 1.0 (TID 169) (namenode, executor driver, partition 48, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 48.0 in stage 1.0 (TID 169)\n",
      "  Finished task 44.0 in stage 1.0 (TID 165) in 5582 ms on namenode (executor driver) (45/121)\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 5561, boot = -39, init = 48, finish = 5552\n",
      "  Finished task 45.0 in stage 1.0 (TID 166). 2072 bytes result sent to driver\n",
      "  Starting task 49.0 in stage 1.0 (TID 170) (namenode, executor driver, partition 49, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 45.0 in stage 1.0 (TID 166) in 5586 ms on namenode (executor driver) (46/121)\n",
      "  Running task 49.0 in stage 1.0 (TID 170)\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 2 ms\n",
      "  Times: total = 5560, boot = -23, init = 26, finish = 5557\n",
      "  Finished task 46.0 in stage 1.0 (TID 167). 2072 bytes result sent to driver\n",
      "  Starting task 50.0 in stage 1.0 (TID 171) (namenode, executor driver, partition 50, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 50.0 in stage 1.0 (TID 171)\n",
      "  Finished task 46.0 in stage 1.0 (TID 167) in 5593 ms on namenode (executor driver) (47/121)\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 5530, boot = 8, init = 4, finish = 5518\n",
      "  Finished task 47.0 in stage 1.0 (TID 168). 2072 bytes result sent to driver\n",
      "  Starting task 51.0 in stage 1.0 (TID 172) (namenode, executor driver, partition 51, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 47.0 in stage 1.0 (TID 168) in 5576 ms on namenode (executor driver) (48/121)\n",
      "  Running task 51.0 in stage 1.0 (TID 172)\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Times: total = 5732, boot = -11, init = 13, finish = 5730\n",
      "  Finished task 48.0 in stage 1.0 (TID 169). 2072 bytes result sent to driver\n",
      "  Starting task 52.0 in stage 1.0 (TID 173) (namenode, executor driver, partition 52, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 52.0 in stage 1.0 (TID 173)\n",
      "  Times: total = 5599, boot = -14, init = 16, finish = 5597\n",
      "  Finished task 48.0 in stage 1.0 (TID 169) in 5757 ms on namenode (executor driver) (49/121)\n",
      "  Finished task 49.0 in stage 1.0 (TID 170). 2072 bytes result sent to driver\n",
      "  Starting task 53.0 in stage 1.0 (TID 174) (namenode, executor driver, partition 53, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Finished task 49.0 in stage 1.0 (TID 170) in 5630 ms on namenode (executor driver) (50/121)\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Running task 53.0 in stage 1.0 (TID 174)\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 5537, boot = -12, init = 14, finish = 5535\n",
      "  Finished task 50.0 in stage 1.0 (TID 171). 2072 bytes result sent to driver\n",
      "  Starting task 54.0 in stage 1.0 (TID 175) (namenode, executor driver, partition 54, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 54.0 in stage 1.0 (TID 175)\n",
      "  Finished task 50.0 in stage 1.0 (TID 171) in 5569 ms on namenode (executor driver) (51/121)\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Times: total = 5615, boot = -24, init = 41, finish = 5598\n",
      "  Finished task 51.0 in stage 1.0 (TID 172). 2072 bytes result sent to driver\n",
      "  Starting task 55.0 in stage 1.0 (TID 176) (namenode, executor driver, partition 55, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 51.0 in stage 1.0 (TID 172) in 5636 ms on namenode (executor driver) (52/121)\n",
      "  Running task 55.0 in stage 1.0 (TID 176)\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 8 ms\n",
      "  Times: total = 5441, boot = 8, init = 1, finish = 5432\n",
      "  Finished task 52.0 in stage 1.0 (TID 173). 2072 bytes result sent to driver\n",
      "  Starting task 56.0 in stage 1.0 (TID 177) (namenode, executor driver, partition 56, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 52.0 in stage 1.0 (TID 173) in 5484 ms on namenode (executor driver) (53/121)\n",
      "  Running task 56.0 in stage 1.0 (TID 177)\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 5540, boot = -9, init = 37, finish = 5512\n",
      "  Finished task 53.0 in stage 1.0 (TID 174). 2072 bytes result sent to driver\n",
      "  Starting task 57.0 in stage 1.0 (TID 178) (namenode, executor driver, partition 57, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 53.0 in stage 1.0 (TID 174) in 5571 ms on namenode (executor driver) (54/121)\n",
      "  Running task 57.0 in stage 1.0 (TID 178)\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 5665, boot = -30, init = 33, finish = 5662\n",
      "  Finished task 54.0 in stage 1.0 (TID 175). 2072 bytes result sent to driver\n",
      "  Starting task 58.0 in stage 1.0 (TID 179) (namenode, executor driver, partition 58, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 58.0 in stage 1.0 (TID 179)\n",
      "  Finished task 54.0 in stage 1.0 (TID 175) in 5706 ms on namenode (executor driver) (55/121)\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 5926, boot = -4, init = 6, finish = 5924\n",
      "  Finished task 55.0 in stage 1.0 (TID 176). 2115 bytes result sent to driver\n",
      "  Starting task 59.0 in stage 1.0 (TID 180) (namenode, executor driver, partition 59, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 59.0 in stage 1.0 (TID 180)\n",
      "  Finished task 55.0 in stage 1.0 (TID 176) in 5962 ms on namenode (executor driver) (56/121)\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 5 ms\n",
      "  Times: total = 5559, boot = -14, init = 17, finish = 5556\n",
      "  Finished task 56.0 in stage 1.0 (TID 177). 2115 bytes result sent to driver\n",
      "  Starting task 60.0 in stage 1.0 (TID 181) (namenode, executor driver, partition 60, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 56.0 in stage 1.0 (TID 177) in 5613 ms on namenode (executor driver) (57/121)\n",
      "  Running task 60.0 in stage 1.0 (TID 181)\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 5827, boot = -16, init = 18, finish = 5825\n",
      "  Finished task 57.0 in stage 1.0 (TID 178). 2115 bytes result sent to driver\n",
      "  Starting task 61.0 in stage 1.0 (TID 182) (namenode, executor driver, partition 61, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 57.0 in stage 1.0 (TID 178) in 5848 ms on namenode (executor driver) (58/121)\n",
      "  Running task 61.0 in stage 1.0 (TID 182)\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 5800, boot = -14, init = 19, finish = 5795\n",
      "  Finished task 58.0 in stage 1.0 (TID 179). 2115 bytes result sent to driver\n",
      "  Starting task 62.0 in stage 1.0 (TID 183) (namenode, executor driver, partition 62, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 58.0 in stage 1.0 (TID 179) in 5856 ms on namenode (executor driver) (59/121)\n",
      "  Running task 62.0 in stage 1.0 (TID 183)\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 5785, boot = -3, init = 6, finish = 5782\n",
      "  Finished task 59.0 in stage 1.0 (TID 180). 2072 bytes result sent to driver\n",
      "  Starting task 63.0 in stage 1.0 (TID 184) (namenode, executor driver, partition 63, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 59.0 in stage 1.0 (TID 180) in 5814 ms on namenode (executor driver) (60/121)\n",
      "  Running task 63.0 in stage 1.0 (TID 184)\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Times: total = 5449, boot = -39, init = 44, finish = 5444\n",
      "  Finished task 60.0 in stage 1.0 (TID 181). 2072 bytes result sent to driver\n",
      "  Starting task 64.0 in stage 1.0 (TID 185) (namenode, executor driver, partition 64, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 64.0 in stage 1.0 (TID 185)\n",
      "  Finished task 60.0 in stage 1.0 (TID 181) in 5468 ms on namenode (executor driver) (61/121)\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 6 ms\n",
      "  Times: total = 6058, boot = 8, init = 6, finish = 6044\n",
      "  Finished task 61.0 in stage 1.0 (TID 182). 2072 bytes result sent to driver\n",
      "  Starting task 65.0 in stage 1.0 (TID 186) (namenode, executor driver, partition 65, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 61.0 in stage 1.0 (TID 182) in 6108 ms on namenode (executor driver) (62/121)\n",
      "  Running task 65.0 in stage 1.0 (TID 186)\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 3 ms\n",
      "  Times: total = 5680, boot = -44, init = 47, finish = 5677\n",
      "  Finished task 62.0 in stage 1.0 (TID 183). 2072 bytes result sent to driver\n",
      "  Starting task 66.0 in stage 1.0 (TID 187) (namenode, executor driver, partition 66, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 66.0 in stage 1.0 (TID 187)\n",
      "  Finished task 62.0 in stage 1.0 (TID 183) in 5711 ms on namenode (executor driver) (63/121)\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 5450, boot = 7, init = 5, finish = 5438\n",
      "  Finished task 63.0 in stage 1.0 (TID 184). 2072 bytes result sent to driver\n",
      "  Starting task 67.0 in stage 1.0 (TID 188) (namenode, executor driver, partition 67, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 63.0 in stage 1.0 (TID 184) in 5477 ms on namenode (executor driver) (64/121)\n",
      "  Running task 67.0 in stage 1.0 (TID 188)\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 6 ms\n",
      "  Times: total = 5611, boot = 4, init = 2, finish = 5605\n",
      "  Finished task 64.0 in stage 1.0 (TID 185). 2072 bytes result sent to driver\n",
      "  Starting task 68.0 in stage 1.0 (TID 189) (namenode, executor driver, partition 68, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 68.0 in stage 1.0 (TID 189)\n",
      "  Finished task 64.0 in stage 1.0 (TID 185) in 5638 ms on namenode (executor driver) (65/121)\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 6 ms\n",
      "  Times: total = 5722, boot = -23, init = 39, finish = 5706\n",
      "  Finished task 65.0 in stage 1.0 (TID 186). 2115 bytes result sent to driver\n",
      "  Starting task 69.0 in stage 1.0 (TID 190) (namenode, executor driver, partition 69, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 65.0 in stage 1.0 (TID 186) in 5753 ms on namenode (executor driver) (66/121)\n",
      "  Running task 69.0 in stage 1.0 (TID 190)\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 14 ms\n",
      "  Times: total = 5493, boot = -14, init = 16, finish = 5491\n",
      "  Finished task 66.0 in stage 1.0 (TID 187). 2072 bytes result sent to driver\n",
      "  Starting task 70.0 in stage 1.0 (TID 191) (namenode, executor driver, partition 70, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 66.0 in stage 1.0 (TID 187) in 5514 ms on namenode (executor driver) (67/121)\n",
      "  Running task 70.0 in stage 1.0 (TID 191)\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 5629, boot = -18, init = 22, finish = 5625\n",
      "  Finished task 67.0 in stage 1.0 (TID 188). 2072 bytes result sent to driver\n",
      "  Starting task 71.0 in stage 1.0 (TID 192) (namenode, executor driver, partition 71, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 67.0 in stage 1.0 (TID 188) in 5696 ms on namenode (executor driver) (68/121)\n",
      "  Running task 71.0 in stage 1.0 (TID 192)\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Times: total = 5752, boot = 1, init = 2, finish = 5749\n",
      "  Finished task 68.0 in stage 1.0 (TID 189). 2072 bytes result sent to driver\n",
      "  Starting task 72.0 in stage 1.0 (TID 193) (namenode, executor driver, partition 72, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 72.0 in stage 1.0 (TID 193)\n",
      "  Finished task 68.0 in stage 1.0 (TID 189) in 5782 ms on namenode (executor driver) (69/121)\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 5656, boot = -2, init = 6, finish = 5652\n",
      "  Finished task 69.0 in stage 1.0 (TID 190). 2072 bytes result sent to driver\n",
      "  Starting task 73.0 in stage 1.0 (TID 194) (namenode, executor driver, partition 73, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 69.0 in stage 1.0 (TID 190) in 5705 ms on namenode (executor driver) (70/121)\n",
      "  Running task 73.0 in stage 1.0 (TID 194)\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 5815, boot = -1, init = 16, finish = 5800\n",
      "  Finished task 70.0 in stage 1.0 (TID 191). 2072 bytes result sent to driver\n",
      "  Starting task 74.0 in stage 1.0 (TID 195) (namenode, executor driver, partition 74, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 70.0 in stage 1.0 (TID 191) in 5858 ms on namenode (executor driver) (71/121)\n",
      "  Running task 74.0 in stage 1.0 (TID 195)\n",
      "  Times: total = 5403, boot = -68, init = 90, finish = 5381\n",
      "  Finished task 71.0 in stage 1.0 (TID 192). 2072 bytes result sent to driver\n",
      "  Starting task 75.0 in stage 1.0 (TID 196) (namenode, executor driver, partition 75, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 75.0 in stage 1.0 (TID 196)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Finished task 71.0 in stage 1.0 (TID 192) in 5455 ms on namenode (executor driver) (72/121)\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 5627, boot = 7, init = 14, finish = 5606\n",
      "  Finished task 72.0 in stage 1.0 (TID 193). 2115 bytes result sent to driver\n",
      "  Starting task 76.0 in stage 1.0 (TID 197) (namenode, executor driver, partition 76, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 72.0 in stage 1.0 (TID 193) in 5668 ms on namenode (executor driver) (73/121)\n",
      "  Running task 76.0 in stage 1.0 (TID 197)\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Times: total = 5542, boot = -13, init = 17, finish = 5538\n",
      "  Finished task 73.0 in stage 1.0 (TID 194). 2115 bytes result sent to driver\n",
      "  Starting task 77.0 in stage 1.0 (TID 198) (namenode, executor driver, partition 77, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 73.0 in stage 1.0 (TID 194) in 5561 ms on namenode (executor driver) (74/121)\n",
      "  Running task 77.0 in stage 1.0 (TID 198)\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 5375, boot = -12, init = 50, finish = 5337\n",
      "  Finished task 74.0 in stage 1.0 (TID 195). 2115 bytes result sent to driver\n",
      "  Starting task 78.0 in stage 1.0 (TID 199) (namenode, executor driver, partition 78, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 74.0 in stage 1.0 (TID 195) in 5416 ms on namenode (executor driver) (75/121)\n",
      "  Running task 78.0 in stage 1.0 (TID 199)\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 5652, boot = -43, init = 46, finish = 5649\n",
      "  Finished task 75.0 in stage 1.0 (TID 196). 2115 bytes result sent to driver\n",
      "  Starting task 79.0 in stage 1.0 (TID 200) (namenode, executor driver, partition 79, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 79.0 in stage 1.0 (TID 200)\n",
      "  Finished task 75.0 in stage 1.0 (TID 196) in 5677 ms on namenode (executor driver) (76/121)\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 5693, boot = -28, init = 35, finish = 5686\n",
      "  Finished task 76.0 in stage 1.0 (TID 197). 2072 bytes result sent to driver\n",
      "  Starting task 80.0 in stage 1.0 (TID 201) (namenode, executor driver, partition 80, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 76.0 in stage 1.0 (TID 197) in 5726 ms on namenode (executor driver) (77/121)\n",
      "  Running task 80.0 in stage 1.0 (TID 201)\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 5609, boot = 7, init = 6, finish = 5596\n",
      "  Finished task 77.0 in stage 1.0 (TID 198). 2072 bytes result sent to driver\n",
      "  Starting task 81.0 in stage 1.0 (TID 202) (namenode, executor driver, partition 81, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 77.0 in stage 1.0 (TID 198) in 5629 ms on namenode (executor driver) (78/121)\n",
      "  Running task 81.0 in stage 1.0 (TID 202)\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 3 ms\n",
      "  Times: total = 5485, boot = -5, init = 13, finish = 5477\n",
      "  Finished task 78.0 in stage 1.0 (TID 199). 2072 bytes result sent to driver\n",
      "  Starting task 82.0 in stage 1.0 (TID 203) (namenode, executor driver, partition 82, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 78.0 in stage 1.0 (TID 199) in 5527 ms on namenode (executor driver) (79/121)\n",
      "  Running task 82.0 in stage 1.0 (TID 203)\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 5565, boot = -7, init = 9, finish = 5563\n",
      "  Finished task 79.0 in stage 1.0 (TID 200). 2072 bytes result sent to driver\n",
      "  Starting task 83.0 in stage 1.0 (TID 204) (namenode, executor driver, partition 83, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 83.0 in stage 1.0 (TID 204)\n",
      "  Finished task 79.0 in stage 1.0 (TID 200) in 5589 ms on namenode (executor driver) (80/121)\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 5704, boot = -20, init = 22, finish = 5702\n",
      "  Finished task 80.0 in stage 1.0 (TID 201). 2072 bytes result sent to driver\n",
      "  Starting task 84.0 in stage 1.0 (TID 205) (namenode, executor driver, partition 84, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 80.0 in stage 1.0 (TID 201) in 5732 ms on namenode (executor driver) (81/121)\n",
      "  Running task 84.0 in stage 1.0 (TID 205)\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 11 ms\n",
      "  Times: total = 5719, boot = 5, init = 10, finish = 5704\n",
      "  Finished task 81.0 in stage 1.0 (TID 202). 2072 bytes result sent to driver\n",
      "  Starting task 85.0 in stage 1.0 (TID 206) (namenode, executor driver, partition 85, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 81.0 in stage 1.0 (TID 202) in 5772 ms on namenode (executor driver) (82/121)\n",
      "  Running task 85.0 in stage 1.0 (TID 206)\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 5646, boot = -19, init = 21, finish = 5644\n",
      "  Finished task 82.0 in stage 1.0 (TID 203). 2072 bytes result sent to driver\n",
      "  Starting task 86.0 in stage 1.0 (TID 207) (namenode, executor driver, partition 86, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 86.0 in stage 1.0 (TID 207)\n",
      "  Finished task 82.0 in stage 1.0 (TID 203) in 5688 ms on namenode (executor driver) (83/121)\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 5521, boot = -10, init = 12, finish = 5519\n",
      "  Finished task 83.0 in stage 1.0 (TID 204). 2072 bytes result sent to driver\n",
      "  Starting task 87.0 in stage 1.0 (TID 208) (namenode, executor driver, partition 87, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 83.0 in stage 1.0 (TID 204) in 5551 ms on namenode (executor driver) (84/121)\n",
      "  Running task 87.0 in stage 1.0 (TID 208)\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Times: total = 5596, boot = -27, init = 48, finish = 5575\n",
      "  Finished task 84.0 in stage 1.0 (TID 205). 2072 bytes result sent to driver\n",
      "  Starting task 88.0 in stage 1.0 (TID 209) (namenode, executor driver, partition 88, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 88.0 in stage 1.0 (TID 209)\n",
      "  Finished task 84.0 in stage 1.0 (TID 205) in 5637 ms on namenode (executor driver) (85/121)\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Started 0 remote fetches in 4 ms\n",
      "  Times: total = 5734, boot = -37, init = 39, finish = 5732\n",
      "  Finished task 85.0 in stage 1.0 (TID 206). 2029 bytes result sent to driver\n",
      "  Starting task 89.0 in stage 1.0 (TID 210) (namenode, executor driver, partition 89, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 85.0 in stage 1.0 (TID 206) in 5761 ms on namenode (executor driver) (86/121)\n",
      "  Running task 89.0 in stage 1.0 (TID 210)\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 7 ms\n",
      "  Times: total = 5558, boot = -28, init = 43, finish = 5543\n",
      "  Finished task 86.0 in stage 1.0 (TID 207). 2115 bytes result sent to driver\n",
      "  Starting task 90.0 in stage 1.0 (TID 211) (namenode, executor driver, partition 90, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 86.0 in stage 1.0 (TID 207) in 5585 ms on namenode (executor driver) (87/121)\n",
      "  Running task 90.0 in stage 1.0 (TID 211)\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 5576, boot = -19, init = 22, finish = 5573\n",
      "  Finished task 87.0 in stage 1.0 (TID 208). 2115 bytes result sent to driver\n",
      "  Starting task 91.0 in stage 1.0 (TID 212) (namenode, executor driver, partition 91, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 87.0 in stage 1.0 (TID 208) in 5601 ms on namenode (executor driver) (88/121)\n",
      "  Running task 91.0 in stage 1.0 (TID 212)\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Times: total = 5400, boot = -14, init = 16, finish = 5398\n",
      "  Finished task 88.0 in stage 1.0 (TID 209). 2115 bytes result sent to driver\n",
      "  Starting task 92.0 in stage 1.0 (TID 213) (namenode, executor driver, partition 92, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 88.0 in stage 1.0 (TID 209) in 5416 ms on namenode (executor driver) (89/121)\n",
      "  Running task 92.0 in stage 1.0 (TID 213)\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 5398, boot = -11, init = 25, finish = 5384\n",
      "  Times: total = 5532, boot = -21, init = 24, finish = 5529\n",
      "  Finished task 89.0 in stage 1.0 (TID 210). 2115 bytes result sent to driver\n",
      "  Starting task 93.0 in stage 1.0 (TID 214) (namenode, executor driver, partition 93, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 89.0 in stage 1.0 (TID 210) in 5577 ms on namenode (executor driver) (90/121)\n",
      "  Running task 93.0 in stage 1.0 (TID 214)\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Finished task 90.0 in stage 1.0 (TID 211). 2072 bytes result sent to driver\n",
      "  Starting task 94.0 in stage 1.0 (TID 215) (namenode, executor driver, partition 94, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 90.0 in stage 1.0 (TID 211) in 5432 ms on namenode (executor driver) (91/121)\n",
      "  Running task 94.0 in stage 1.0 (TID 215)\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 5592, boot = 5, init = 6, finish = 5581\n",
      "  Finished task 91.0 in stage 1.0 (TID 212). 2072 bytes result sent to driver\n",
      "  Starting task 95.0 in stage 1.0 (TID 216) (namenode, executor driver, partition 95, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 91.0 in stage 1.0 (TID 212) in 5617 ms on namenode (executor driver) (92/121)\n",
      "  Running task 95.0 in stage 1.0 (TID 216)\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Times: total = 5781, boot = 8, init = 7, finish = 5766\n",
      "  Finished task 92.0 in stage 1.0 (TID 213). 2072 bytes result sent to driver\n",
      "  Starting task 96.0 in stage 1.0 (TID 217) (namenode, executor driver, partition 96, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 92.0 in stage 1.0 (TID 213) in 5810 ms on namenode (executor driver) (93/121)\n",
      "  Running task 96.0 in stage 1.0 (TID 217)\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 5590, boot = -19, init = 33, finish = 5576\n",
      "  Finished task 94.0 in stage 1.0 (TID 215). 2072 bytes result sent to driver\n",
      "  Starting task 97.0 in stage 1.0 (TID 218) (namenode, executor driver, partition 97, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 94.0 in stage 1.0 (TID 215) in 5621 ms on namenode (executor driver) (94/121)\n",
      "  Running task 97.0 in stage 1.0 (TID 218)\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 5706, boot = 2, init = 2, finish = 5702\n",
      "  Finished task 93.0 in stage 1.0 (TID 214). 2072 bytes result sent to driver\n",
      "  Starting task 98.0 in stage 1.0 (TID 219) (namenode, executor driver, partition 98, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 98.0 in stage 1.0 (TID 219)\n",
      "  Finished task 93.0 in stage 1.0 (TID 214) in 5721 ms on namenode (executor driver) (95/121)\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 5652, boot = -12, init = 15, finish = 5649\n",
      "  Finished task 95.0 in stage 1.0 (TID 216). 2072 bytes result sent to driver\n",
      "  Starting task 99.0 in stage 1.0 (TID 220) (namenode, executor driver, partition 99, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 95.0 in stage 1.0 (TID 216) in 5677 ms on namenode (executor driver) (96/121)\n",
      "  Running task 99.0 in stage 1.0 (TID 220)\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Times: total = 5937, boot = -11, init = 14, finish = 5934\n",
      "  Finished task 96.0 in stage 1.0 (TID 217). 2029 bytes result sent to driver\n",
      "  Starting task 100.0 in stage 1.0 (TID 221) (namenode, executor driver, partition 100, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 100.0 in stage 1.0 (TID 221)\n",
      "  Finished task 96.0 in stage 1.0 (TID 217) in 5961 ms on namenode (executor driver) (97/121)\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Times: total = 5567, boot = 8, init = 5, finish = 5554\n",
      "  Finished task 98.0 in stage 1.0 (TID 219). 2072 bytes result sent to driver\n",
      "  Starting task 101.0 in stage 1.0 (TID 222) (namenode, executor driver, partition 101, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 98.0 in stage 1.0 (TID 219) in 5593 ms on namenode (executor driver) (98/121)\n",
      "  Running task 101.0 in stage 1.0 (TID 222)\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 5816, boot = -16, init = 23, finish = 5809\n",
      "  Finished task 97.0 in stage 1.0 (TID 218). 2072 bytes result sent to driver\n",
      "  Starting task 102.0 in stage 1.0 (TID 223) (namenode, executor driver, partition 102, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 102.0 in stage 1.0 (TID 223)\n",
      "  Finished task 97.0 in stage 1.0 (TID 218) in 5843 ms on namenode (executor driver) (99/121)\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Started 0 remote fetches in 3 ms\n",
      "  Times: total = 5713, boot = -3, init = 5, finish = 5711\n",
      "  Finished task 99.0 in stage 1.0 (TID 220). 2072 bytes result sent to driver\n",
      "  Starting task 103.0 in stage 1.0 (TID 224) (namenode, executor driver, partition 103, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 99.0 in stage 1.0 (TID 220) in 5741 ms on namenode (executor driver) (100/121)\n",
      "  Running task 103.0 in stage 1.0 (TID 224)\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 6046, boot = -14, init = 17, finish = 6043\n",
      "  Finished task 100.0 in stage 1.0 (TID 221). 2072 bytes result sent to driver\n",
      "  Starting task 104.0 in stage 1.0 (TID 225) (namenode, executor driver, partition 104, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 100.0 in stage 1.0 (TID 221) in 6069 ms on namenode (executor driver) (101/121)\n",
      "  Running task 104.0 in stage 1.0 (TID 225)\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 5988, boot = -13, init = 15, finish = 5986\n",
      "  Finished task 101.0 in stage 1.0 (TID 222). 2072 bytes result sent to driver\n",
      "  Starting task 105.0 in stage 1.0 (TID 226) (namenode, executor driver, partition 105, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 105.0 in stage 1.0 (TID 226)\n",
      "  Finished task 101.0 in stage 1.0 (TID 222) in 6017 ms on namenode (executor driver) (102/121)\n",
      "  Times: total = 5842, boot = -14, init = 25, finish = 5831\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 9 ms\n",
      "  Finished task 102.0 in stage 1.0 (TID 223). 2072 bytes result sent to driver\n",
      "  Starting task 106.0 in stage 1.0 (TID 227) (namenode, executor driver, partition 106, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 106.0 in stage 1.0 (TID 227)\n",
      "  Finished task 102.0 in stage 1.0 (TID 223) in 5874 ms on namenode (executor driver) (103/121)\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 5916, boot = -15, init = 20, finish = 5911\n",
      "  Finished task 103.0 in stage 1.0 (TID 224). 2115 bytes result sent to driver\n",
      "  Starting task 107.0 in stage 1.0 (TID 228) (namenode, executor driver, partition 107, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 103.0 in stage 1.0 (TID 224) in 5968 ms on namenode (executor driver) (104/121)\n",
      "  Running task 107.0 in stage 1.0 (TID 228)\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 6296, boot = 5, init = 7, finish = 6284\n",
      "  Finished task 104.0 in stage 1.0 (TID 225). 2115 bytes result sent to driver\n",
      "  Starting task 108.0 in stage 1.0 (TID 229) (namenode, executor driver, partition 108, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 104.0 in stage 1.0 (TID 225) in 6334 ms on namenode (executor driver) (105/121)\n",
      "  Running task 108.0 in stage 1.0 (TID 229)\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 8 ms\n",
      "  Times: total = 7117, boot = -22, init = 27, finish = 7112\n",
      "  Finished task 105.0 in stage 1.0 (TID 226). 2115 bytes result sent to driver\n",
      "  Starting task 109.0 in stage 1.0 (TID 230) (namenode, executor driver, partition 109, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 105.0 in stage 1.0 (TID 226) in 7164 ms on namenode (executor driver) (106/121)\n",
      "  Running task 109.0 in stage 1.0 (TID 230)\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 8005, boot = -11, init = 29, finish = 7987\n",
      "  Finished task 106.0 in stage 1.0 (TID 227). 2115 bytes result sent to driver\n",
      "  Starting task 110.0 in stage 1.0 (TID 231) (namenode, executor driver, partition 110, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 110.0 in stage 1.0 (TID 231)\n",
      "  Finished task 106.0 in stage 1.0 (TID 227) in 8032 ms on namenode (executor driver) (107/121)\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Times: total = 8655, boot = -24, init = 35, finish = 8644\n",
      "  Finished task 107.0 in stage 1.0 (TID 228). 2072 bytes result sent to driver\n",
      "  Starting task 111.0 in stage 1.0 (TID 232) (namenode, executor driver, partition 111, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 107.0 in stage 1.0 (TID 228) in 8677 ms on namenode (executor driver) (108/121)\n",
      "  Running task 111.0 in stage 1.0 (TID 232)\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 8282, boot = -55, init = 73, finish = 8264\n",
      "  Finished task 108.0 in stage 1.0 (TID 229). 2072 bytes result sent to driver\n",
      "  Starting task 112.0 in stage 1.0 (TID 233) (namenode, executor driver, partition 112, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 112.0 in stage 1.0 (TID 233)\n",
      "  Finished task 108.0 in stage 1.0 (TID 229) in 8341 ms on namenode (executor driver) (109/121)\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 2 ms\n",
      "  Times: total = 7850, boot = -15, init = 23, finish = 7842\n",
      "  Finished task 109.0 in stage 1.0 (TID 230). 2072 bytes result sent to driver\n",
      "  Starting task 113.0 in stage 1.0 (TID 234) (namenode, executor driver, partition 113, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 109.0 in stage 1.0 (TID 230) in 7896 ms on namenode (executor driver) (110/121)\n",
      "  Running task 113.0 in stage 1.0 (TID 234)\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 5 ms\n",
      "  Times: total = 7876, boot = 1, init = 22, finish = 7853\n",
      "  Finished task 110.0 in stage 1.0 (TID 231). 2072 bytes result sent to driver\n",
      "  Starting task 114.0 in stage 1.0 (TID 235) (namenode, executor driver, partition 114, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 110.0 in stage 1.0 (TID 231) in 7906 ms on namenode (executor driver) (111/121)\n",
      "  Running task 114.0 in stage 1.0 (TID 235)\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 7544, boot = 5, init = 7, finish = 7532\n",
      "  Finished task 111.0 in stage 1.0 (TID 232). 2072 bytes result sent to driver\n",
      "  Starting task 115.0 in stage 1.0 (TID 236) (namenode, executor driver, partition 115, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 115.0 in stage 1.0 (TID 236)\n",
      "  Finished task 111.0 in stage 1.0 (TID 232) in 7574 ms on namenode (executor driver) (112/121)\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 7229, boot = 46, init = 4, finish = 7179\n",
      "  Finished task 112.0 in stage 1.0 (TID 233). 2072 bytes result sent to driver\n",
      "  Starting task 116.0 in stage 1.0 (TID 237) (namenode, executor driver, partition 116, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 112.0 in stage 1.0 (TID 233) in 7266 ms on namenode (executor driver) (113/121)\n",
      "  Running task 116.0 in stage 1.0 (TID 237)\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 6561, boot = -35, init = 54, finish = 6542\n",
      "  Finished task 113.0 in stage 1.0 (TID 234). 2072 bytes result sent to driver\n",
      "  Starting task 117.0 in stage 1.0 (TID 238) (namenode, executor driver, partition 117, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 113.0 in stage 1.0 (TID 234) in 6610 ms on namenode (executor driver) (114/121)\n",
      "  Running task 117.0 in stage 1.0 (TID 238)\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 5 ms\n",
      "  Times: total = 6861, boot = -16, init = 19, finish = 6858\n",
      "  Finished task 114.0 in stage 1.0 (TID 235). 2072 bytes result sent to driver\n",
      "  Starting task 118.0 in stage 1.0 (TID 239) (namenode, executor driver, partition 118, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 114.0 in stage 1.0 (TID 235) in 6896 ms on namenode (executor driver) (115/121)\n",
      "  Running task 118.0 in stage 1.0 (TID 239)\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 7255, boot = -15, init = 17, finish = 7253\n",
      "  Finished task 115.0 in stage 1.0 (TID 236). 2072 bytes result sent to driver\n",
      "  Starting task 119.0 in stage 1.0 (TID 240) (namenode, executor driver, partition 119, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 115.0 in stage 1.0 (TID 236) in 7295 ms on namenode (executor driver) (116/121)\n",
      "  Running task 119.0 in stage 1.0 (TID 240)\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Times: total = 6805, boot = 27, init = 1, finish = 6777\n",
      "  Finished task 116.0 in stage 1.0 (TID 237). 2072 bytes result sent to driver\n",
      "  Starting task 120.0 in stage 1.0 (TID 241) (namenode, executor driver, partition 120, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 116.0 in stage 1.0 (TID 237) in 6838 ms on namenode (executor driver) (117/121)\n",
      "  Running task 120.0 in stage 1.0 (TID 241)\n",
      "  Getting 121 (2.6 MiB) non-empty blocks including 121 (2.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 6620, boot = -36, init = 39, finish = 6617\n",
      "  Finished task 117.0 in stage 1.0 (TID 238). 2072 bytes result sent to driver\n",
      "  Finished task 117.0 in stage 1.0 (TID 238) in 6663 ms on namenode (executor driver) (118/121)\n",
      "  Times: total = 6275, boot = -19, init = 41, finish = 6253\n",
      "  Finished task 118.0 in stage 1.0 (TID 239). 2072 bytes result sent to driver\n",
      "  Finished task 118.0 in stage 1.0 (TID 239) in 6296 ms on namenode (executor driver) (119/121)\n",
      "  Times: total = 6355, boot = -24, init = 26, finish = 6353\n",
      "  Finished task 119.0 in stage 1.0 (TID 240). 2072 bytes result sent to driver\n",
      "  Finished task 119.0 in stage 1.0 (TID 240) in 6384 ms on namenode (executor driver) (120/121)\n",
      "  Times: total = 5628, boot = -19, init = 21, finish = 5626\n",
      "  Finished task 120.0 in stage 1.0 (TID 241). 2115 bytes result sent to driver\n",
      "  Finished task 120.0 in stage 1.0 (TID 241) in 5679 ms on namenode (executor driver) (121/121)\n",
      "  Removed TaskSet 1.0, whose tasks have all completed, from pool \n",
      "  ShuffleMapStage 1 (groupBy at /home/ubuntu/.local/lib/python3.8/site-packages/mrjob/spark/harness.py:539) finished in 182.658 s\n",
      "  looking for newly runnable stages\n",
      "  running: Set()\n",
      "  waiting: Set(ResultStage 2)\n",
      "  failed: Set()\n",
      "  Submitting ResultStage 2 (MapPartitionsRDD[12] at saveAsTextFile at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "  Block broadcast_3 stored as values in memory (estimated size 134.8 KiB, free 365.7 MiB)\n",
      "  Block broadcast_3_piece0 stored as bytes in memory (estimated size 52.9 KiB, free 365.6 MiB)\n",
      "  Added broadcast_3_piece0 in memory on namenode:43301 (size: 52.9 KiB, free: 366.2 MiB)\n",
      "  Created broadcast 3 from broadcast at DAGScheduler.scala:1427\n",
      "  Submitting 121 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at saveAsTextFile at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))\n",
      "  Adding task set 2.0 with 121 tasks resource profile 0\n",
      "  Starting task 69.0 in stage 2.0 (TID 242) (namenode, executor driver, partition 69, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Starting task 0.0 in stage 2.0 (TID 243) (namenode, executor driver, partition 0, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Starting task 1.0 in stage 2.0 (TID 244) (namenode, executor driver, partition 1, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Starting task 2.0 in stage 2.0 (TID 245) (namenode, executor driver, partition 2, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 69.0 in stage 2.0 (TID 242)\n",
      "  Running task 0.0 in stage 2.0 (TID 243)\n",
      "  Running task 1.0 in stage 2.0 (TID 244)\n",
      "  Running task 2.0 in stage 2.0 (TID 245)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Getting 121 (154.3 MiB) non-empty blocks including 121 (154.3 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  File Output Committer Algorithm version is 1\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 14, boot = -5617, init = 5625, finish = 6\n",
      "  Times: total = 15, boot = -4807, init = 4816, finish = 6\n",
      "  Times: total = 33, boot = -3549, init = 3574, finish = 8\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000002_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000002\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000001_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000001\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000000_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000000\n",
      "  attempt_202204241347101051138738791519994_0012_m_000001_0: Committed\n",
      "  attempt_202204241347101051138738791519994_0012_m_000002_0: Committed\n",
      "  attempt_202204241347101051138738791519994_0012_m_000000_0: Committed\n",
      "  Finished task 2.0 in stage 2.0 (TID 245). 2039 bytes result sent to driver\n",
      "  Finished task 1.0 in stage 2.0 (TID 244). 2039 bytes result sent to driver\n",
      "  Starting task 3.0 in stage 2.0 (TID 246) (namenode, executor driver, partition 3, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 3.0 in stage 2.0 (TID 246)\n",
      "  Starting task 4.0 in stage 2.0 (TID 247) (namenode, executor driver, partition 4, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Finished task 0.0 in stage 2.0 (TID 243). 2039 bytes result sent to driver\n",
      "  Starting task 5.0 in stage 2.0 (TID 248) (namenode, executor driver, partition 5, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 5.0 in stage 2.0 (TID 248)\n",
      "  Running task 4.0 in stage 2.0 (TID 247)\n",
      "  Finished task 0.0 in stage 2.0 (TID 243) in 225 ms on namenode (executor driver) (1/121)\n",
      "  Finished task 2.0 in stage 2.0 (TID 245) in 225 ms on namenode (executor driver) (2/121)\n",
      "  Finished task 1.0 in stage 2.0 (TID 244) in 226 ms on namenode (executor driver) (3/121)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 55, boot = -145, init = 194, finish = 6\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000003_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000003\n",
      "  attempt_202204241347101051138738791519994_0012_m_000003_0: Committed\n",
      "  Finished task 3.0 in stage 2.0 (TID 246). 1996 bytes result sent to driver\n",
      "  Starting task 6.0 in stage 2.0 (TID 249) (namenode, executor driver, partition 6, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 3.0 in stage 2.0 (TID 246) in 133 ms on namenode (executor driver) (4/121)\n",
      "  Running task 6.0 in stage 2.0 (TID 249)\n",
      "  Times: total = 39, boot = -146, init = 179, finish = 6\n",
      "  Times: total = 31, boot = -112, init = 137, finish = 6\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000005_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000005\n",
      "  attempt_202204241347101051138738791519994_0012_m_000005_0: Committed\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000004_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000004\n",
      "  attempt_202204241347101051138738791519994_0012_m_000004_0: Committed\n",
      "  Finished task 4.0 in stage 2.0 (TID 247). 1996 bytes result sent to driver\n",
      "  Finished task 5.0 in stage 2.0 (TID 248). 1996 bytes result sent to driver\n",
      "  Starting task 7.0 in stage 2.0 (TID 250) (namenode, executor driver, partition 7, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Starting task 8.0 in stage 2.0 (TID 251) (namenode, executor driver, partition 8, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 7.0 in stage 2.0 (TID 250)\n",
      "  Running task 8.0 in stage 2.0 (TID 251)\n",
      "  Finished task 4.0 in stage 2.0 (TID 247) in 152 ms on namenode (executor driver) (5/121)\n",
      "  Finished task 5.0 in stage 2.0 (TID 248) in 152 ms on namenode (executor driver) (6/121)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 31, boot = -75, init = 99, finish = 7\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000008_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000008\n",
      "  attempt_202204241347101051138738791519994_0012_m_000008_0: Committed\n",
      "  Finished task 8.0 in stage 2.0 (TID 251). 1996 bytes result sent to driver\n",
      "  Starting task 9.0 in stage 2.0 (TID 252) (namenode, executor driver, partition 9, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 8.0 in stage 2.0 (TID 251) in 115 ms on namenode (executor driver) (7/121)\n",
      "  Running task 9.0 in stage 2.0 (TID 252)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 26, boot = -50, init = 70, finish = 6\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000006_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000006\n",
      "  attempt_202204241347101051138738791519994_0012_m_000006_0: Committed\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Finished task 6.0 in stage 2.0 (TID 249). 1996 bytes result sent to driver\n",
      "  Starting task 10.0 in stage 2.0 (TID 253) (namenode, executor driver, partition 10, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 6.0 in stage 2.0 (TID 249) in 168 ms on namenode (executor driver) (8/121)\n",
      "  Running task 10.0 in stage 2.0 (TID 253)\n",
      "  Times: total = 46, boot = -69, init = 109, finish = 6\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000007_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000007\n",
      "  attempt_202204241347101051138738791519994_0012_m_000007_0: Committed\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Finished task 7.0 in stage 2.0 (TID 250). 1996 bytes result sent to driver\n",
      "  Starting task 11.0 in stage 2.0 (TID 254) (namenode, executor driver, partition 11, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 7.0 in stage 2.0 (TID 250) in 173 ms on namenode (executor driver) (9/121)\n",
      "  Running task 11.0 in stage 2.0 (TID 254)\n",
      "  Started 0 remote fetches in 3 ms\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 89, boot = -61, init = 139, finish = 11\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000009_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000009\n",
      "  attempt_202204241347101051138738791519994_0012_m_000009_0: Committed\n",
      "  Finished task 9.0 in stage 2.0 (TID 252). 1996 bytes result sent to driver\n",
      "  Starting task 12.0 in stage 2.0 (TID 255) (namenode, executor driver, partition 12, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 9.0 in stage 2.0 (TID 252) in 122 ms on namenode (executor driver) (10/121)\n",
      "  Running task 12.0 in stage 2.0 (TID 255)\n",
      "  Times: total = 60, boot = -98, init = 152, finish = 6\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000011_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000011\n",
      "  attempt_202204241347101051138738791519994_0012_m_000011_0: Committed\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Finished task 11.0 in stage 2.0 (TID 254). 1996 bytes result sent to driver\n",
      "  Starting task 13.0 in stage 2.0 (TID 256) (namenode, executor driver, partition 13, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 13.0 in stage 2.0 (TID 256)\n",
      "  Finished task 11.0 in stage 2.0 (TID 254) in 78 ms on namenode (executor driver) (11/121)\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 79, boot = -113, init = 171, finish = 21\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000010_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000010\n",
      "  attempt_202204241347101051138738791519994_0012_m_000010_0: Committed\n",
      "  Finished task 10.0 in stage 2.0 (TID 253). 1996 bytes result sent to driver\n",
      "  Starting task 14.0 in stage 2.0 (TID 257) (namenode, executor driver, partition 14, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 14.0 in stage 2.0 (TID 257)\n",
      "  Finished task 10.0 in stage 2.0 (TID 253) in 132 ms on namenode (executor driver) (12/121)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 13, boot = -14, init = 20, finish = 7\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000012_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000012\n",
      "  attempt_202204241347101051138738791519994_0012_m_000012_0: Committed\n",
      "  Finished task 12.0 in stage 2.0 (TID 255). 1996 bytes result sent to driver\n",
      "  Starting task 15.0 in stage 2.0 (TID 258) (namenode, executor driver, partition 15, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 12.0 in stage 2.0 (TID 255) in 91 ms on namenode (executor driver) (13/121)\n",
      "  Running task 15.0 in stage 2.0 (TID 258)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 31, boot = 12, init = 10, finish = 9\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000013_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000013\n",
      "  attempt_202204241347101051138738791519994_0012_m_000013_0: Committed\n",
      "  Finished task 13.0 in stage 2.0 (TID 256). 1996 bytes result sent to driver\n",
      "  Starting task 16.0 in stage 2.0 (TID 259) (namenode, executor driver, partition 16, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 16.0 in stage 2.0 (TID 259)\n",
      "  Finished task 13.0 in stage 2.0 (TID 256) in 104 ms on namenode (executor driver) (14/121)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 17, boot = -27, init = 37, finish = 7\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000014_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000014\n",
      "  attempt_202204241347101051138738791519994_0012_m_000014_0: Committed\n",
      "  Finished task 14.0 in stage 2.0 (TID 257). 1996 bytes result sent to driver\n",
      "  Starting task 17.0 in stage 2.0 (TID 260) (namenode, executor driver, partition 17, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 17.0 in stage 2.0 (TID 260)\n",
      "  Finished task 14.0 in stage 2.0 (TID 257) in 95 ms on namenode (executor driver) (15/121)\n",
      "  Times: total = 12, boot = -44, init = 50, finish = 6\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000015_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000015\n",
      "  attempt_202204241347101051138738791519994_0012_m_000015_0: Committed\n",
      "  Finished task 15.0 in stage 2.0 (TID 258). 1996 bytes result sent to driver\n",
      "  Starting task 18.0 in stage 2.0 (TID 261) (namenode, executor driver, partition 18, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 15.0 in stage 2.0 (TID 258) in 58 ms on namenode (executor driver) (16/121)\n",
      "  Running task 18.0 in stage 2.0 (TID 261)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 13, boot = -31, init = 38, finish = 6\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000016_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000016\n",
      "  attempt_202204241347101051138738791519994_0012_m_000016_0: Committed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Finished task 16.0 in stage 2.0 (TID 259). 1996 bytes result sent to driver\n",
      "  Starting task 19.0 in stage 2.0 (TID 262) (namenode, executor driver, partition 19, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 16.0 in stage 2.0 (TID 259) in 73 ms on namenode (executor driver) (17/121)\n",
      "  Running task 19.0 in stage 2.0 (TID 262)\n",
      "  Times: total = 12, boot = -50, init = 56, finish = 6\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000017_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000017\n",
      "  attempt_202204241347101051138738791519994_0012_m_000017_0: Committed\n",
      "  Finished task 17.0 in stage 2.0 (TID 260). 1996 bytes result sent to driver\n",
      "  Starting task 20.0 in stage 2.0 (TID 263) (namenode, executor driver, partition 20, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 17.0 in stage 2.0 (TID 260) in 57 ms on namenode (executor driver) (18/121)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Running task 20.0 in stage 2.0 (TID 263)\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 10 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 65, boot = -43, init = 100, finish = 8\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000018_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000018\n",
      "  attempt_202204241347101051138738791519994_0012_m_000018_0: Committed\n",
      "  Finished task 18.0 in stage 2.0 (TID 261). 1996 bytes result sent to driver\n",
      "  Starting task 21.0 in stage 2.0 (TID 264) (namenode, executor driver, partition 21, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 18.0 in stage 2.0 (TID 261) in 122 ms on namenode (executor driver) (19/121)\n",
      "  Running task 21.0 in stage 2.0 (TID 264)\n",
      "  Times: total = 57, boot = -41, init = 92, finish = 6\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000019_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000019\n",
      "  attempt_202204241347101051138738791519994_0012_m_000019_0: Committed\n",
      "  Finished task 19.0 in stage 2.0 (TID 262). 1996 bytes result sent to driver\n",
      "  Starting task 22.0 in stage 2.0 (TID 265) (namenode, executor driver, partition 22, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 19.0 in stage 2.0 (TID 262) in 93 ms on namenode (executor driver) (20/121)\n",
      "  Running task 22.0 in stage 2.0 (TID 265)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  Started 0 remote fetches in 11 ms\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 53, boot = -46, init = 92, finish = 7\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000020_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000020\n",
      "  attempt_202204241347101051138738791519994_0012_m_000020_0: Committed\n",
      "  Finished task 20.0 in stage 2.0 (TID 263). 1996 bytes result sent to driver\n",
      "  Starting task 23.0 in stage 2.0 (TID 266) (namenode, executor driver, partition 23, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 20.0 in stage 2.0 (TID 263) in 140 ms on namenode (executor driver) (21/121)\n",
      "  Running task 23.0 in stage 2.0 (TID 266)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 39, boot = -3, init = 27, finish = 15\n",
      "  Times: total = 25, boot = -31, init = 49, finish = 7\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000021_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000021\n",
      "  attempt_202204241347101051138738791519994_0012_m_000021_0: Committed\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000022_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000022\n",
      "  Finished task 21.0 in stage 2.0 (TID 264). 1996 bytes result sent to driver\n",
      "  Starting task 24.0 in stage 2.0 (TID 267) (namenode, executor driver, partition 24, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  attempt_202204241347101051138738791519994_0012_m_000022_0: Committed\n",
      "  Finished task 21.0 in stage 2.0 (TID 264) in 107 ms on namenode (executor driver) (22/121)\n",
      "  Running task 24.0 in stage 2.0 (TID 267)\n",
      "  Finished task 22.0 in stage 2.0 (TID 265). 1996 bytes result sent to driver\n",
      "  Starting task 25.0 in stage 2.0 (TID 268) (namenode, executor driver, partition 25, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 22.0 in stage 2.0 (TID 265) in 103 ms on namenode (executor driver) (23/121)\n",
      "  Running task 25.0 in stage 2.0 (TID 268)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 9, boot = -50, init = 53, finish = 6\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000023_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000023\n",
      "  attempt_202204241347101051138738791519994_0012_m_000023_0: Committed\n",
      "  Finished task 23.0 in stage 2.0 (TID 266). 1996 bytes result sent to driver\n",
      "  Starting task 26.0 in stage 2.0 (TID 269) (namenode, executor driver, partition 26, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 23.0 in stage 2.0 (TID 266) in 69 ms on namenode (executor driver) (24/121)\n",
      "  Running task 26.0 in stage 2.0 (TID 269)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 14, boot = -26, init = 34, finish = 6\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000024_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000024\n",
      "  attempt_202204241347101051138738791519994_0012_m_000024_0: Committed\n",
      "  Finished task 24.0 in stage 2.0 (TID 267). 1996 bytes result sent to driver\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Starting task 27.0 in stage 2.0 (TID 270) (namenode, executor driver, partition 27, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 24.0 in stage 2.0 (TID 267) in 53 ms on namenode (executor driver) (25/121)\n",
      "  Running task 27.0 in stage 2.0 (TID 270)\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 13, boot = -83, init = 89, finish = 7\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000025_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000025\n",
      "  attempt_202204241347101051138738791519994_0012_m_000025_0: Committed\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Finished task 25.0 in stage 2.0 (TID 268). 1996 bytes result sent to driver\n",
      "  Starting task 28.0 in stage 2.0 (TID 271) (namenode, executor driver, partition 28, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 28.0 in stage 2.0 (TID 271)\n",
      "  Finished task 25.0 in stage 2.0 (TID 268) in 74 ms on namenode (executor driver) (26/121)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 22, boot = -33, init = 49, finish = 6\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000026_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000026\n",
      "  attempt_202204241347101051138738791519994_0012_m_000026_0: Committed\n",
      "  Finished task 26.0 in stage 2.0 (TID 269). 1996 bytes result sent to driver\n",
      "  Starting task 29.0 in stage 2.0 (TID 272) (namenode, executor driver, partition 29, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 26.0 in stage 2.0 (TID 269) in 78 ms on namenode (executor driver) (27/121)\n",
      "  Running task 29.0 in stage 2.0 (TID 272)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 61, boot = -20, init = 73, finish = 8\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000027_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000027\n",
      "  attempt_202204241347101051138738791519994_0012_m_000027_0: Committed\n",
      "  Finished task 27.0 in stage 2.0 (TID 270). 1996 bytes result sent to driver\n",
      "  Starting task 30.0 in stage 2.0 (TID 273) (namenode, executor driver, partition 30, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 27.0 in stage 2.0 (TID 270) in 84 ms on namenode (executor driver) (28/121)\n",
      "  Running task 30.0 in stage 2.0 (TID 273)\n",
      "  Times: total = 52, boot = -25, init = 71, finish = 6\n",
      "  Times: total = 54, boot = -35, init = 81, finish = 8\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000029_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000029\n",
      "  attempt_202204241347101051138738791519994_0012_m_000029_0: Committed\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000028_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000028\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  attempt_202204241347101051138738791519994_0012_m_000028_0: Committed\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Finished task 28.0 in stage 2.0 (TID 271). 2039 bytes result sent to driver\n",
      "  Finished task 29.0 in stage 2.0 (TID 272). 2039 bytes result sent to driver\n",
      "  Starting task 31.0 in stage 2.0 (TID 274) (namenode, executor driver, partition 31, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Starting task 32.0 in stage 2.0 (TID 275) (namenode, executor driver, partition 32, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 31.0 in stage 2.0 (TID 274)\n",
      "  Finished task 28.0 in stage 2.0 (TID 271) in 125 ms on namenode (executor driver) (29/121)\n",
      "  Finished task 29.0 in stage 2.0 (TID 272) in 104 ms on namenode (executor driver) (30/121)\n",
      "  Running task 32.0 in stage 2.0 (TID 275)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 25, boot = -29, init = 48, finish = 6\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000030_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000030\n",
      "  attempt_202204241347101051138738791519994_0012_m_000030_0: Committed\n",
      "  Finished task 30.0 in stage 2.0 (TID 273). 2039 bytes result sent to driver\n",
      "  Starting task 33.0 in stage 2.0 (TID 276) (namenode, executor driver, partition 33, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 33.0 in stage 2.0 (TID 276)\n",
      "  Finished task 30.0 in stage 2.0 (TID 273) in 139 ms on namenode (executor driver) (31/121)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 19, boot = -59, init = 71, finish = 7\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000032_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000032\n",
      "  attempt_202204241347101051138738791519994_0012_m_000032_0: Committed\n",
      "  Finished task 32.0 in stage 2.0 (TID 275). 1996 bytes result sent to driver\n",
      "  Starting task 34.0 in stage 2.0 (TID 277) (namenode, executor driver, partition 34, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 32.0 in stage 2.0 (TID 275) in 96 ms on namenode (executor driver) (32/121)\n",
      "  Running task 34.0 in stage 2.0 (TID 277)\n",
      "  Times: total = 15, boot = -47, init = 55, finish = 7\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000031_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000031\n",
      "  attempt_202204241347101051138738791519994_0012_m_000031_0: Committed\n",
      "  Finished task 31.0 in stage 2.0 (TID 274). 1996 bytes result sent to driver\n",
      "  Starting task 35.0 in stage 2.0 (TID 278) (namenode, executor driver, partition 35, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 35.0 in stage 2.0 (TID 278)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Finished task 31.0 in stage 2.0 (TID 274) in 110 ms on namenode (executor driver) (33/121)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 10, boot = -38, init = 41, finish = 7\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000033_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000033\n",
      "  attempt_202204241347101051138738791519994_0012_m_000033_0: Committed\n",
      "  Finished task 33.0 in stage 2.0 (TID 276). 1996 bytes result sent to driver\n",
      "  Starting task 36.0 in stage 2.0 (TID 279) (namenode, executor driver, partition 36, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 33.0 in stage 2.0 (TID 276) in 92 ms on namenode (executor driver) (34/121)\n",
      "  Running task 36.0 in stage 2.0 (TID 279)\n",
      "  Times: total = 11, boot = -33, init = 35, finish = 9\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000034_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000034\n",
      "  attempt_202204241347101051138738791519994_0012_m_000034_0: Committed\n",
      "  Finished task 34.0 in stage 2.0 (TID 277). 1996 bytes result sent to driver\n",
      "  Starting task 37.0 in stage 2.0 (TID 280) (namenode, executor driver, partition 37, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 37.0 in stage 2.0 (TID 280)\n",
      "  Finished task 34.0 in stage 2.0 (TID 277) in 76 ms on namenode (executor driver) (35/121)\n",
      "  Times: total = 24, boot = -51, init = 69, finish = 6\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000035_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000035\n",
      "  attempt_202204241347101051138738791519994_0012_m_000035_0: Committed\n",
      "  Finished task 35.0 in stage 2.0 (TID 278). 1996 bytes result sent to driver\n",
      "  Starting task 38.0 in stage 2.0 (TID 281) (namenode, executor driver, partition 38, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 38.0 in stage 2.0 (TID 281)\n",
      "  Finished task 35.0 in stage 2.0 (TID 278) in 81 ms on namenode (executor driver) (36/121)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 53, boot = -62, init = 107, finish = 8\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000036_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000036\n",
      "  attempt_202204241347101051138738791519994_0012_m_000036_0: Committed\n",
      "  Finished task 36.0 in stage 2.0 (TID 279). 1996 bytes result sent to driver\n",
      "  Starting task 39.0 in stage 2.0 (TID 282) (namenode, executor driver, partition 39, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 36.0 in stage 2.0 (TID 279) in 79 ms on namenode (executor driver) (37/121)\n",
      "  Running task 39.0 in stage 2.0 (TID 282)\n",
      "  Times: total = 58, boot = -50, init = 97, finish = 11\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000037_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000037\n",
      "  attempt_202204241347101051138738791519994_0012_m_000037_0: Committed\n",
      "  Finished task 37.0 in stage 2.0 (TID 280). 1996 bytes result sent to driver\n",
      "  Starting task 40.0 in stage 2.0 (TID 283) (namenode, executor driver, partition 40, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 37.0 in stage 2.0 (TID 280) in 78 ms on namenode (executor driver) (38/121)\n",
      "  Running task 40.0 in stage 2.0 (TID 283)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 62, boot = -39, init = 84, finish = 17\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000038_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000038\n",
      "  attempt_202204241347101051138738791519994_0012_m_000038_0: Committed\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Finished task 38.0 in stage 2.0 (TID 281). 1996 bytes result sent to driver\n",
      "  Starting task 41.0 in stage 2.0 (TID 284) (namenode, executor driver, partition 41, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 41.0 in stage 2.0 (TID 284)\n",
      "  Finished task 38.0 in stage 2.0 (TID 281) in 97 ms on namenode (executor driver) (39/121)\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 3 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 33, boot = 6, init = 13, finish = 14\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000039_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000039\n",
      "  attempt_202204241347101051138738791519994_0012_m_000039_0: Committed\n",
      "  Finished task 39.0 in stage 2.0 (TID 282). 1996 bytes result sent to driver\n",
      "  Starting task 42.0 in stage 2.0 (TID 285) (namenode, executor driver, partition 42, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 39.0 in stage 2.0 (TID 282) in 98 ms on namenode (executor driver) (40/121)\n",
      "  Running task 42.0 in stage 2.0 (TID 285)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 37, boot = 3, init = 17, finish = 17\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000040_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000040\n",
      "  attempt_202204241347101051138738791519994_0012_m_000040_0: Committed\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 26, boot = -22, init = 40, finish = 8\n",
      "  Finished task 40.0 in stage 2.0 (TID 283). 1996 bytes result sent to driver\n",
      "  Starting task 43.0 in stage 2.0 (TID 286) (namenode, executor driver, partition 43, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 40.0 in stage 2.0 (TID 283) in 112 ms on namenode (executor driver) (41/121)\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000041_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000041\n",
      "  attempt_202204241347101051138738791519994_0012_m_000041_0: Committed\n",
      "  Finished task 41.0 in stage 2.0 (TID 284). 1996 bytes result sent to driver\n",
      "  Running task 43.0 in stage 2.0 (TID 286)\n",
      "  Starting task 44.0 in stage 2.0 (TID 287) (namenode, executor driver, partition 44, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 41.0 in stage 2.0 (TID 284) in 85 ms on namenode (executor driver) (42/121)\n",
      "  Running task 44.0 in stage 2.0 (TID 287)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Started 0 remote fetches in 11 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 15, boot = -46, init = 52, finish = 9\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000042_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000042\n",
      "  attempt_202204241347101051138738791519994_0012_m_000042_0: Committed\n",
      "  Finished task 42.0 in stage 2.0 (TID 285). 1996 bytes result sent to driver\n",
      "  Starting task 45.0 in stage 2.0 (TID 288) (namenode, executor driver, partition 45, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 42.0 in stage 2.0 (TID 285) in 66 ms on namenode (executor driver) (43/121)\n",
      "  Running task 45.0 in stage 2.0 (TID 288)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 11, boot = -51, init = 56, finish = 6\n",
      "  Times: total = 9, boot = -34, init = 36, finish = 7\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000043_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000043\n",
      "  attempt_202204241347101051138738791519994_0012_m_000043_0: Committed\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000044_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000044\n",
      "  attempt_202204241347101051138738791519994_0012_m_000044_0: Committed\n",
      "  Finished task 43.0 in stage 2.0 (TID 286). 1996 bytes result sent to driver\n",
      "  Finished task 44.0 in stage 2.0 (TID 287). 1996 bytes result sent to driver\n",
      "  Starting task 46.0 in stage 2.0 (TID 289) (namenode, executor driver, partition 46, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 43.0 in stage 2.0 (TID 286) in 68 ms on namenode (executor driver) (44/121)\n",
      "  Finished task 44.0 in stage 2.0 (TID 287) in 64 ms on namenode (executor driver) (45/121)\n",
      "  Running task 46.0 in stage 2.0 (TID 289)\n",
      "  Starting task 47.0 in stage 2.0 (TID 290) (namenode, executor driver, partition 47, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 47.0 in stage 2.0 (TID 290)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 54, boot = -32, init = 81, finish = 5\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000045_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000045\n",
      "  attempt_202204241347101051138738791519994_0012_m_000045_0: Committed\n",
      "  Finished task 45.0 in stage 2.0 (TID 288). 1996 bytes result sent to driver\n",
      "  Starting task 48.0 in stage 2.0 (TID 291) (namenode, executor driver, partition 48, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 45.0 in stage 2.0 (TID 288) in 76 ms on namenode (executor driver) (46/121)\n",
      "  Running task 48.0 in stage 2.0 (TID 291)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 54, boot = -19, init = 67, finish = 6\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000047_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000047\n",
      "  attempt_202204241347101051138738791519994_0012_m_000047_0: Committed\n",
      "  Times: total = 56, boot = -22, init = 69, finish = 9\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000046_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000046\n",
      "  attempt_202204241347101051138738791519994_0012_m_000046_0: Committed\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Finished task 46.0 in stage 2.0 (TID 289). 1996 bytes result sent to driver\n",
      "  Finished task 47.0 in stage 2.0 (TID 290). 1996 bytes result sent to driver\n",
      "  Starting task 49.0 in stage 2.0 (TID 292) (namenode, executor driver, partition 49, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 49.0 in stage 2.0 (TID 292)\n",
      "  Starting task 50.0 in stage 2.0 (TID 293) (namenode, executor driver, partition 50, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 46.0 in stage 2.0 (TID 289) in 89 ms on namenode (executor driver) (47/121)\n",
      "  Finished task 47.0 in stage 2.0 (TID 290) in 86 ms on namenode (executor driver) (48/121)\n",
      "  Running task 50.0 in stage 2.0 (TID 293)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 17, boot = 8, init = 1, finish = 8\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000048_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000048\n",
      "  attempt_202204241347101051138738791519994_0012_m_000048_0: Committed\n",
      "  Finished task 48.0 in stage 2.0 (TID 291). 1996 bytes result sent to driver\n",
      "  Times: total = 16, boot = -17, init = 27, finish = 6\n",
      "  Starting task 51.0 in stage 2.0 (TID 294) (namenode, executor driver, partition 51, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 51.0 in stage 2.0 (TID 294)\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000049_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000049\n",
      "  attempt_202204241347101051138738791519994_0012_m_000049_0: Committed\n",
      "  Finished task 49.0 in stage 2.0 (TID 292). 1996 bytes result sent to driver\n",
      "  Finished task 48.0 in stage 2.0 (TID 291) in 102 ms on namenode (executor driver) (49/121)\n",
      "  Times: total = 19, boot = -5, init = 16, finish = 8\n",
      "  Starting task 52.0 in stage 2.0 (TID 295) (namenode, executor driver, partition 52, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 49.0 in stage 2.0 (TID 292) in 68 ms on namenode (executor driver) (50/121)\n",
      "  Running task 52.0 in stage 2.0 (TID 295)\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000050_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000050\n",
      "  attempt_202204241347101051138738791519994_0012_m_000050_0: Committed\n",
      "  Finished task 50.0 in stage 2.0 (TID 293). 1996 bytes result sent to driver\n",
      "  Starting task 53.0 in stage 2.0 (TID 296) (namenode, executor driver, partition 53, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 53.0 in stage 2.0 (TID 296)\n",
      "  Finished task 50.0 in stage 2.0 (TID 293) in 71 ms on namenode (executor driver) (51/121)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 22, boot = -57, init = 60, finish = 19\n",
      "  Times: total = 9, boot = -28, init = 29, finish = 8\n",
      "  Times: total = 9, boot = -29, init = 32, finish = 6\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000051_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000051\n",
      "  attempt_202204241347101051138738791519994_0012_m_000051_0: Committed\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000053_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000053\n",
      "  attempt_202204241347101051138738791519994_0012_m_000053_0: Committed\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000052_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000052\n",
      "  attempt_202204241347101051138738791519994_0012_m_000052_0: Committed\n",
      "  Finished task 51.0 in stage 2.0 (TID 294). 1996 bytes result sent to driver\n",
      "  Finished task 52.0 in stage 2.0 (TID 295). 1996 bytes result sent to driver\n",
      "  Starting task 54.0 in stage 2.0 (TID 297) (namenode, executor driver, partition 54, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 53.0 in stage 2.0 (TID 296). 1996 bytes result sent to driver\n",
      "  Running task 54.0 in stage 2.0 (TID 297)\n",
      "  Starting task 55.0 in stage 2.0 (TID 298) (namenode, executor driver, partition 55, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Starting task 56.0 in stage 2.0 (TID 299) (namenode, executor driver, partition 56, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 55.0 in stage 2.0 (TID 298)\n",
      "  Finished task 51.0 in stage 2.0 (TID 294) in 72 ms on namenode (executor driver) (52/121)\n",
      "  Running task 56.0 in stage 2.0 (TID 299)\n",
      "  Finished task 52.0 in stage 2.0 (TID 295) in 64 ms on namenode (executor driver) (53/121)\n",
      "  Finished task 53.0 in stage 2.0 (TID 296) in 62 ms on namenode (executor driver) (54/121)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 50, boot = -37, init = 81, finish = 6\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000056_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000056\n",
      "  attempt_202204241347101051138738791519994_0012_m_000056_0: Committed\n",
      "  Finished task 56.0 in stage 2.0 (TID 299). 1996 bytes result sent to driver\n",
      "  Times: total = 51, boot = -24, init = 68, finish = 7\n",
      "  Starting task 57.0 in stage 2.0 (TID 300) (namenode, executor driver, partition 57, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 57.0 in stage 2.0 (TID 300)\n",
      "  Finished task 56.0 in stage 2.0 (TID 299) in 66 ms on namenode (executor driver) (55/121)\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000055_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000055\n",
      "  attempt_202204241347101051138738791519994_0012_m_000055_0: Committed\n",
      "  Finished task 55.0 in stage 2.0 (TID 298). 1996 bytes result sent to driver\n",
      "  Starting task 58.0 in stage 2.0 (TID 301) (namenode, executor driver, partition 58, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 55.0 in stage 2.0 (TID 298) in 69 ms on namenode (executor driver) (56/121)\n",
      "  Running task 58.0 in stage 2.0 (TID 301)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 67, boot = -39, init = 85, finish = 21\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000054_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000054\n",
      "  attempt_202204241347101051138738791519994_0012_m_000054_0: Committed\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 3 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Finished task 54.0 in stage 2.0 (TID 297). 1996 bytes result sent to driver\n",
      "  Starting task 59.0 in stage 2.0 (TID 302) (namenode, executor driver, partition 59, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 54.0 in stage 2.0 (TID 297) in 113 ms on namenode (executor driver) (57/121)\n",
      "  Running task 59.0 in stage 2.0 (TID 302)\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 17, boot = -26, init = 36, finish = 7\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000059_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000059\n",
      "  attempt_202204241347101051138738791519994_0012_m_000059_0: Committed\n",
      "  Finished task 59.0 in stage 2.0 (TID 302). 1996 bytes result sent to driver\n",
      "  Starting task 60.0 in stage 2.0 (TID 303) (namenode, executor driver, partition 60, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 59.0 in stage 2.0 (TID 302) in 58 ms on namenode (executor driver) (58/121)\n",
      "  Running task 60.0 in stage 2.0 (TID 303)\n",
      "  Times: total = 27, boot = 19, init = 1, finish = 7\n",
      "  Times: total = 41, boot = 19, init = 1, finish = 21\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000057_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000057\n",
      "  attempt_202204241347101051138738791519994_0012_m_000057_0: Committed\n",
      "  Finished task 57.0 in stage 2.0 (TID 300). 1996 bytes result sent to driver\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000058_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000058\n",
      "  attempt_202204241347101051138738791519994_0012_m_000058_0: Committed\n",
      "  Starting task 61.0 in stage 2.0 (TID 304) (namenode, executor driver, partition 61, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 57.0 in stage 2.0 (TID 300) in 116 ms on namenode (executor driver) (59/121)\n",
      "  Finished task 58.0 in stage 2.0 (TID 301). 1996 bytes result sent to driver\n",
      "  Running task 61.0 in stage 2.0 (TID 304)\n",
      "  Starting task 62.0 in stage 2.0 (TID 305) (namenode, executor driver, partition 62, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 62.0 in stage 2.0 (TID 305)\n",
      "  Finished task 58.0 in stage 2.0 (TID 301) in 115 ms on namenode (executor driver) (60/121)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 13, boot = -50, init = 55, finish = 8\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000060_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000060\n",
      "  attempt_202204241347101051138738791519994_0012_m_000060_0: Committed\n",
      "  Finished task 60.0 in stage 2.0 (TID 303). 1996 bytes result sent to driver\n",
      "  Starting task 63.0 in stage 2.0 (TID 306) (namenode, executor driver, partition 63, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 60.0 in stage 2.0 (TID 303) in 83 ms on namenode (executor driver) (61/121)\n",
      "  Running task 63.0 in stage 2.0 (TID 306)\n",
      "  Times: total = 8, boot = -22, init = 24, finish = 6\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000061_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000061\n",
      "  attempt_202204241347101051138738791519994_0012_m_000061_0: Committed\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Times: total = 38, boot = -48, init = 80, finish = 6\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Finished task 61.0 in stage 2.0 (TID 304). 1996 bytes result sent to driver\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000062_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000062\n",
      "  attempt_202204241347101051138738791519994_0012_m_000062_0: Committed\n",
      "  Finished task 62.0 in stage 2.0 (TID 305). 1996 bytes result sent to driver\n",
      "  Starting task 64.0 in stage 2.0 (TID 307) (namenode, executor driver, partition 64, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 62.0 in stage 2.0 (TID 305) in 85 ms on namenode (executor driver) (62/121)\n",
      "  Finished task 61.0 in stage 2.0 (TID 304) in 87 ms on namenode (executor driver) (63/121)\n",
      "  Starting task 65.0 in stage 2.0 (TID 308) (namenode, executor driver, partition 65, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 64.0 in stage 2.0 (TID 307)\n",
      "  Running task 65.0 in stage 2.0 (TID 308)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 50, boot = -30, init = 73, finish = 7\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000063_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000063\n",
      "  attempt_202204241347101051138738791519994_0012_m_000063_0: Committed\n",
      "  Finished task 63.0 in stage 2.0 (TID 306). 1996 bytes result sent to driver\n",
      "  Starting task 66.0 in stage 2.0 (TID 309) (namenode, executor driver, partition 66, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 66.0 in stage 2.0 (TID 309)\n",
      "  Finished task 63.0 in stage 2.0 (TID 306) in 67 ms on namenode (executor driver) (64/121)\n",
      "  Times: total = 53, boot = -39, init = 86, finish = 6\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000065_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000065\n",
      "  attempt_202204241347101051138738791519994_0012_m_000065_0: Committed\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 59, boot = -65, init = 110, finish = 14\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000064_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000064\n",
      "  attempt_202204241347101051138738791519994_0012_m_000064_0: Committed\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Finished task 64.0 in stage 2.0 (TID 307). 1996 bytes result sent to driver\n",
      "  Starting task 67.0 in stage 2.0 (TID 310) (namenode, executor driver, partition 67, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 64.0 in stage 2.0 (TID 307) in 111 ms on namenode (executor driver) (65/121)\n",
      "  Finished task 65.0 in stage 2.0 (TID 308). 1996 bytes result sent to driver\n",
      "  Starting task 68.0 in stage 2.0 (TID 311) (namenode, executor driver, partition 68, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 65.0 in stage 2.0 (TID 308) in 112 ms on namenode (executor driver) (66/121)\n",
      "  Running task 67.0 in stage 2.0 (TID 310)\n",
      "  Running task 68.0 in stage 2.0 (TID 311)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 36, boot = -5, init = 32, finish = 9\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000066_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000066\n",
      "  attempt_202204241347101051138738791519994_0012_m_000066_0: Committed\n",
      "  Finished task 66.0 in stage 2.0 (TID 309). 1996 bytes result sent to driver\n",
      "  Starting task 70.0 in stage 2.0 (TID 312) (namenode, executor driver, partition 70, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 66.0 in stage 2.0 (TID 309) in 199 ms on namenode (executor driver) (67/121)\n",
      "  Running task 70.0 in stage 2.0 (TID 312)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 11, boot = -17, init = 22, finish = 6\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000068_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000068\n",
      "  attempt_202204241347101051138738791519994_0012_m_000068_0: Committed\n",
      "  Times: total = 33, boot = -19, init = 46, finish = 6\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000067_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000067\n",
      "  attempt_202204241347101051138738791519994_0012_m_000067_0: Committed\n",
      "  Finished task 67.0 in stage 2.0 (TID 310). 2039 bytes result sent to driver\n",
      "  Starting task 71.0 in stage 2.0 (TID 313) (namenode, executor driver, partition 71, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 67.0 in stage 2.0 (TID 310) in 175 ms on namenode (executor driver) (68/121)\n",
      "  Running task 71.0 in stage 2.0 (TID 313)\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Finished task 68.0 in stage 2.0 (TID 311). 2039 bytes result sent to driver\n",
      "  Starting task 72.0 in stage 2.0 (TID 314) (namenode, executor driver, partition 72, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 68.0 in stage 2.0 (TID 311) in 185 ms on namenode (executor driver) (69/121)\n",
      "  Running task 72.0 in stage 2.0 (TID 314)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Started 0 remote fetches in 0 ms\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 62, boot = -135, init = 191, finish = 6\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000070_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000070\n",
      "  attempt_202204241347101051138738791519994_0012_m_000070_0: Committed\n",
      "  Finished task 70.0 in stage 2.0 (TID 312). 1996 bytes result sent to driver\n",
      "  Starting task 73.0 in stage 2.0 (TID 315) (namenode, executor driver, partition 73, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 73.0 in stage 2.0 (TID 315)\n",
      "  Finished task 70.0 in stage 2.0 (TID 312) in 130 ms on namenode (executor driver) (70/121)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 2 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 37, boot = -136, init = 165, finish = 8\n",
      "  Times: total = 37, boot = -167, init = 197, finish = 7\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000072_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000072\n",
      "  attempt_202204241347101051138738791519994_0012_m_000072_0: Committed\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000071_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000071\n",
      "  attempt_202204241347101051138738791519994_0012_m_000071_0: Committed\n",
      "  Finished task 71.0 in stage 2.0 (TID 313). 1996 bytes result sent to driver\n",
      "  Starting task 74.0 in stage 2.0 (TID 316) (namenode, executor driver, partition 74, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 72.0 in stage 2.0 (TID 314). 1996 bytes result sent to driver\n",
      "  Finished task 71.0 in stage 2.0 (TID 313) in 117 ms on namenode (executor driver) (71/121)\n",
      "  Running task 74.0 in stage 2.0 (TID 316)\n",
      "  Starting task 75.0 in stage 2.0 (TID 317) (namenode, executor driver, partition 75, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 75.0 in stage 2.0 (TID 317)\n",
      "  Finished task 72.0 in stage 2.0 (TID 314) in 107 ms on namenode (executor driver) (72/121)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 54, boot = -50, init = 95, finish = 9\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000073_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000073\n",
      "  attempt_202204241347101051138738791519994_0012_m_000073_0: Committed\n",
      "  Finished task 73.0 in stage 2.0 (TID 315). 1996 bytes result sent to driver\n",
      "  Starting task 76.0 in stage 2.0 (TID 318) (namenode, executor driver, partition 76, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 73.0 in stage 2.0 (TID 315) in 105 ms on namenode (executor driver) (73/121)\n",
      "  Running task 76.0 in stage 2.0 (TID 318)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 57, boot = -39, init = 89, finish = 7\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000074_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000074\n",
      "  attempt_202204241347101051138738791519994_0012_m_000074_0: Committed\n",
      "  Finished task 74.0 in stage 2.0 (TID 316). 1996 bytes result sent to driver\n",
      "  Starting task 77.0 in stage 2.0 (TID 319) (namenode, executor driver, partition 77, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 74.0 in stage 2.0 (TID 316) in 102 ms on namenode (executor driver) (74/121)\n",
      "  Times: total = 61, boot = -41, init = 91, finish = 11\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000075_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000075\n",
      "  attempt_202204241347101051138738791519994_0012_m_000075_0: Committed\n",
      "  Running task 77.0 in stage 2.0 (TID 319)\n",
      "  Finished task 75.0 in stage 2.0 (TID 317). 1996 bytes result sent to driver\n",
      "  Starting task 78.0 in stage 2.0 (TID 320) (namenode, executor driver, partition 78, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 78.0 in stage 2.0 (TID 320)\n",
      "  Finished task 75.0 in stage 2.0 (TID 317) in 123 ms on namenode (executor driver) (75/121)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 23 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 18, boot = -38, init = 50, finish = 6\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000078_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000078\n",
      "  attempt_202204241347101051138738791519994_0012_m_000078_0: Committed\n",
      "  Finished task 78.0 in stage 2.0 (TID 320). 1996 bytes result sent to driver\n",
      "  Starting task 79.0 in stage 2.0 (TID 321) (namenode, executor driver, partition 79, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 78.0 in stage 2.0 (TID 320) in 98 ms on namenode (executor driver) (76/121)\n",
      "  Running task 79.0 in stage 2.0 (TID 321)\n",
      "  Times: total = 37, boot = -33, init = 60, finish = 10\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000076_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000076\n",
      "  attempt_202204241347101051138738791519994_0012_m_000076_0: Committed\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Finished task 76.0 in stage 2.0 (TID 318). 1996 bytes result sent to driver\n",
      "  Starting task 80.0 in stage 2.0 (TID 322) (namenode, executor driver, partition 80, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 76.0 in stage 2.0 (TID 318) in 151 ms on namenode (executor driver) (77/121)\n",
      "  Running task 80.0 in stage 2.0 (TID 322)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 24, boot = -51, init = 67, finish = 8\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000077_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000077\n",
      "  attempt_202204241347101051138738791519994_0012_m_000077_0: Committed\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Finished task 77.0 in stage 2.0 (TID 319). 1996 bytes result sent to driver\n",
      "  Starting task 81.0 in stage 2.0 (TID 323) (namenode, executor driver, partition 81, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 77.0 in stage 2.0 (TID 319) in 170 ms on namenode (executor driver) (78/121)\n",
      "  Running task 81.0 in stage 2.0 (TID 323)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 34, boot = -99, init = 126, finish = 7\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000080_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000080\n",
      "  attempt_202204241347101051138738791519994_0012_m_000080_0: Committed\n",
      "  Finished task 80.0 in stage 2.0 (TID 322). 1996 bytes result sent to driver\n",
      "  Starting task 82.0 in stage 2.0 (TID 324) (namenode, executor driver, partition 82, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 80.0 in stage 2.0 (TID 322) in 106 ms on namenode (executor driver) (79/121)\n",
      "  Running task 82.0 in stage 2.0 (TID 324)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 14, boot = -103, init = 109, finish = 8\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000081_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000081\n",
      "  attempt_202204241347101051138738791519994_0012_m_000081_0: Committed\n",
      "  Finished task 81.0 in stage 2.0 (TID 323). 1996 bytes result sent to driver\n",
      "  Starting task 83.0 in stage 2.0 (TID 325) (namenode, executor driver, partition 83, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 81.0 in stage 2.0 (TID 323) in 92 ms on namenode (executor driver) (80/121)\n",
      "  Running task 83.0 in stage 2.0 (TID 325)\n",
      "  Times: total = 21, boot = -58, init = 72, finish = 7\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000079_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000079\n",
      "  attempt_202204241347101051138738791519994_0012_m_000079_0: Committed\n",
      "  Finished task 79.0 in stage 2.0 (TID 321). 1996 bytes result sent to driver\n",
      "  Starting task 84.0 in stage 2.0 (TID 326) (namenode, executor driver, partition 84, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 79.0 in stage 2.0 (TID 321) in 161 ms on namenode (executor driver) (81/121)\n",
      "  Running task 84.0 in stage 2.0 (TID 326)\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 51, boot = -53, init = 99, finish = 5\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000082_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000082\n",
      "  attempt_202204241347101051138738791519994_0012_m_000082_0: Committed\n",
      "  Finished task 82.0 in stage 2.0 (TID 324). 1996 bytes result sent to driver\n",
      "  Starting task 85.0 in stage 2.0 (TID 327) (namenode, executor driver, partition 85, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 82.0 in stage 2.0 (TID 324) in 73 ms on namenode (executor driver) (82/121)\n",
      "  Running task 85.0 in stage 2.0 (TID 327)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 55, boot = -49, init = 97, finish = 7\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000083_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000083\n",
      "  attempt_202204241347101051138738791519994_0012_m_000083_0: Committed\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Finished task 83.0 in stage 2.0 (TID 325). 1996 bytes result sent to driver\n",
      "  Starting task 86.0 in stage 2.0 (TID 328) (namenode, executor driver, partition 86, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 86.0 in stage 2.0 (TID 328)\n",
      "  Finished task 83.0 in stage 2.0 (TID 325) in 82 ms on namenode (executor driver) (83/121)\n",
      "  Times: total = 66, boot = -120, init = 169, finish = 17\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000084_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000084\n",
      "  attempt_202204241347101051138738791519994_0012_m_000084_0: Committed\n",
      "  Finished task 84.0 in stage 2.0 (TID 326). 1996 bytes result sent to driver\n",
      "  Starting task 87.0 in stage 2.0 (TID 329) (namenode, executor driver, partition 87, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 84.0 in stage 2.0 (TID 326) in 83 ms on namenode (executor driver) (84/121)\n",
      "  Running task 87.0 in stage 2.0 (TID 329)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 10, boot = -6, init = 10, finish = 6\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000085_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000085\n",
      "  attempt_202204241347101051138738791519994_0012_m_000085_0: Committed\n",
      "  Finished task 85.0 in stage 2.0 (TID 327). 1996 bytes result sent to driver\n",
      "  Starting task 88.0 in stage 2.0 (TID 330) (namenode, executor driver, partition 88, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 85.0 in stage 2.0 (TID 327) in 120 ms on namenode (executor driver) (85/121)\n",
      "  Running task 88.0 in stage 2.0 (TID 330)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 30, boot = 21, init = 1, finish = 8\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000087_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000087\n",
      "  attempt_202204241347101051138738791519994_0012_m_000087_0: Committed\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Finished task 87.0 in stage 2.0 (TID 329). 1996 bytes result sent to driver\n",
      "  Starting task 89.0 in stage 2.0 (TID 331) (namenode, executor driver, partition 89, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 87.0 in stage 2.0 (TID 329) in 113 ms on namenode (executor driver) (86/121)\n",
      "  Times: total = 35, boot = 9, init = 9, finish = 17\n",
      "  Running task 89.0 in stage 2.0 (TID 331)\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000086_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000086\n",
      "  attempt_202204241347101051138738791519994_0012_m_000086_0: Committed\n",
      "  Finished task 86.0 in stage 2.0 (TID 328). 1996 bytes result sent to driver\n",
      "  Starting task 90.0 in stage 2.0 (TID 332) (namenode, executor driver, partition 90, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 86.0 in stage 2.0 (TID 328) in 130 ms on namenode (executor driver) (87/121)\n",
      "  Running task 90.0 in stage 2.0 (TID 332)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 8, boot = -54, init = 56, finish = 6\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000089_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000089\n",
      "  attempt_202204241347101051138738791519994_0012_m_000089_0: Committed\n",
      "  Finished task 89.0 in stage 2.0 (TID 331). 1996 bytes result sent to driver\n",
      "  Starting task 91.0 in stage 2.0 (TID 333) (namenode, executor driver, partition 91, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 91.0 in stage 2.0 (TID 333)\n",
      "  Finished task 89.0 in stage 2.0 (TID 331) in 45 ms on namenode (executor driver) (88/121)\n",
      "  Times: total = 8, boot = -58, init = 61, finish = 5\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000090_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000090\n",
      "  attempt_202204241347101051138738791519994_0012_m_000090_0: Committed\n",
      "  Finished task 90.0 in stage 2.0 (TID 332). 1996 bytes result sent to driver\n",
      "  Starting task 92.0 in stage 2.0 (TID 334) (namenode, executor driver, partition 92, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 90.0 in stage 2.0 (TID 332) in 45 ms on namenode (executor driver) (89/121)\n",
      "  Running task 92.0 in stage 2.0 (TID 334)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 14, boot = -80, init = 87, finish = 7\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000088_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000088\n",
      "  attempt_202204241347101051138738791519994_0012_m_000088_0: Committed\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Finished task 88.0 in stage 2.0 (TID 330). 1996 bytes result sent to driver\n",
      "  Starting task 93.0 in stage 2.0 (TID 335) (namenode, executor driver, partition 93, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 88.0 in stage 2.0 (TID 330) in 101 ms on namenode (executor driver) (90/121)\n",
      "  Running task 93.0 in stage 2.0 (TID 335)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 61, boot = -13, init = 62, finish = 12\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000091_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000091\n",
      "  attempt_202204241347101051138738791519994_0012_m_000091_0: Committed\n",
      "  Times: total = 61, boot = -19, init = 69, finish = 11\n",
      "  Finished task 91.0 in stage 2.0 (TID 333). 1996 bytes result sent to driver\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000092_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000092\n",
      "  attempt_202204241347101051138738791519994_0012_m_000092_0: Committed\n",
      "  Finished task 92.0 in stage 2.0 (TID 334). 1996 bytes result sent to driver\n",
      "  Starting task 94.0 in stage 2.0 (TID 336) (namenode, executor driver, partition 94, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 94.0 in stage 2.0 (TID 336)\n",
      "  Starting task 95.0 in stage 2.0 (TID 337) (namenode, executor driver, partition 95, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 95.0 in stage 2.0 (TID 337)\n",
      "  Finished task 92.0 in stage 2.0 (TID 334) in 74 ms on namenode (executor driver) (91/121)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Finished task 91.0 in stage 2.0 (TID 333) in 78 ms on namenode (executor driver) (92/121)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 59, boot = -72, init = 115, finish = 16\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000093_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000093\n",
      "  attempt_202204241347101051138738791519994_0012_m_000093_0: Committed\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Finished task 93.0 in stage 2.0 (TID 335). 1996 bytes result sent to driver\n",
      "  Starting task 96.0 in stage 2.0 (TID 338) (namenode, executor driver, partition 96, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 93.0 in stage 2.0 (TID 335) in 79 ms on namenode (executor driver) (93/121)\n",
      "  Running task 96.0 in stage 2.0 (TID 338)\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 22, boot = 14, init = 1, finish = 7\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000095_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000095\n",
      "  attempt_202204241347101051138738791519994_0012_m_000095_0: Committed\n",
      "  Finished task 95.0 in stage 2.0 (TID 337). 1996 bytes result sent to driver\n",
      "  Starting task 97.0 in stage 2.0 (TID 339) (namenode, executor driver, partition 97, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 97.0 in stage 2.0 (TID 339)\n",
      "  Finished task 95.0 in stage 2.0 (TID 337) in 72 ms on namenode (executor driver) (94/121)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 20, boot = -6, init = 20, finish = 6\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000094_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000094\n",
      "  attempt_202204241347101051138738791519994_0012_m_000094_0: Committed\n",
      "  Times: total = 18, boot = 2, init = 10, finish = 6\n",
      "  Finished task 94.0 in stage 2.0 (TID 336). 1996 bytes result sent to driver\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000096_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000096\n",
      "  attempt_202204241347101051138738791519994_0012_m_000096_0: Committed\n",
      "  Starting task 98.0 in stage 2.0 (TID 340) (namenode, executor driver, partition 98, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 94.0 in stage 2.0 (TID 336) in 93 ms on namenode (executor driver) (95/121)\n",
      "  Running task 98.0 in stage 2.0 (TID 340)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Finished task 96.0 in stage 2.0 (TID 338). 1996 bytes result sent to driver\n",
      "  Starting task 99.0 in stage 2.0 (TID 341) (namenode, executor driver, partition 99, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 96.0 in stage 2.0 (TID 338) in 87 ms on namenode (executor driver) (96/121)\n",
      "  Running task 99.0 in stage 2.0 (TID 341)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 11, boot = -22, init = 26, finish = 7\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000097_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000097\n",
      "  attempt_202204241347101051138738791519994_0012_m_000097_0: Committed\n",
      "  Finished task 97.0 in stage 2.0 (TID 339). 1996 bytes result sent to driver\n",
      "  Starting task 100.0 in stage 2.0 (TID 342) (namenode, executor driver, partition 100, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 100.0 in stage 2.0 (TID 342)\n",
      "  Finished task 97.0 in stage 2.0 (TID 339) in 68 ms on namenode (executor driver) (97/121)\n",
      "  Times: total = 11, boot = -52, init = 56, finish = 7\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000099_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000099\n",
      "  attempt_202204241347101051138738791519994_0012_m_000099_0: Committed\n",
      "  Finished task 99.0 in stage 2.0 (TID 341). 1996 bytes result sent to driver\n",
      "  Starting task 101.0 in stage 2.0 (TID 343) (namenode, executor driver, partition 101, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Running task 101.0 in stage 2.0 (TID 343)\n",
      "  Finished task 99.0 in stage 2.0 (TID 341) in 43 ms on namenode (executor driver) (98/121)\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 10, boot = -49, init = 53, finish = 6\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000098_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000098\n",
      "  attempt_202204241347101051138738791519994_0012_m_000098_0: Committed\n",
      "  Finished task 98.0 in stage 2.0 (TID 340). 1996 bytes result sent to driver\n",
      "  Starting task 102.0 in stage 2.0 (TID 344) (namenode, executor driver, partition 102, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 102.0 in stage 2.0 (TID 344)\n",
      "  Finished task 98.0 in stage 2.0 (TID 340) in 68 ms on namenode (executor driver) (99/121)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 57, boot = -44, init = 94, finish = 7\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000100_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000100\n",
      "  attempt_202204241347101051138738791519994_0012_m_000100_0: Committed\n",
      "  Finished task 100.0 in stage 2.0 (TID 342). 1996 bytes result sent to driver\n",
      "  Starting task 103.0 in stage 2.0 (TID 345) (namenode, executor driver, partition 103, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 103.0 in stage 2.0 (TID 345)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Finished task 100.0 in stage 2.0 (TID 342) in 71 ms on namenode (executor driver) (100/121)\n",
      "  Times: total = 48, boot = 0, init = 43, finish = 5\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000101_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000101\n",
      "  attempt_202204241347101051138738791519994_0012_m_000101_0: Committed\n",
      "  Finished task 101.0 in stage 2.0 (TID 343). 1996 bytes result sent to driver\n",
      "  Starting task 104.0 in stage 2.0 (TID 346) (namenode, executor driver, partition 104, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 101.0 in stage 2.0 (TID 343) in 78 ms on namenode (executor driver) (101/121)\n",
      "  Running task 104.0 in stage 2.0 (TID 346)\n",
      "  Times: total = 59, boot = -29, init = 79, finish = 9\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000102_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000102\n",
      "  attempt_202204241347101051138738791519994_0012_m_000102_0: Committed\n",
      "  Finished task 102.0 in stage 2.0 (TID 344). 1996 bytes result sent to driver\n",
      "  Starting task 105.0 in stage 2.0 (TID 347) (namenode, executor driver, partition 105, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 105.0 in stage 2.0 (TID 347)\n",
      "  Finished task 102.0 in stage 2.0 (TID 344) in 80 ms on namenode (executor driver) (102/121)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 2 ms\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 8, boot = -24, init = 26, finish = 6\n",
      "  Times: total = 17, boot = 4, init = 7, finish = 6\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000104_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000104\n",
      "  attempt_202204241347101051138738791519994_0012_m_000104_0: Committed\n",
      "  Finished task 104.0 in stage 2.0 (TID 346). 1996 bytes result sent to driver\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000105_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000105\n",
      "  attempt_202204241347101051138738791519994_0012_m_000105_0: Committed\n",
      "  Starting task 106.0 in stage 2.0 (TID 348) (namenode, executor driver, partition 106, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 104.0 in stage 2.0 (TID 346) in 65 ms on namenode (executor driver) (103/121)\n",
      "  Running task 106.0 in stage 2.0 (TID 348)\n",
      "  Finished task 105.0 in stage 2.0 (TID 347). 1996 bytes result sent to driver\n",
      "  Starting task 107.0 in stage 2.0 (TID 349) (namenode, executor driver, partition 107, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 105.0 in stage 2.0 (TID 347) in 60 ms on namenode (executor driver) (104/121)\n",
      "  Running task 107.0 in stage 2.0 (TID 349)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 20, boot = 9, init = 1, finish = 10\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000103_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000103\n",
      "  attempt_202204241347101051138738791519994_0012_m_000103_0: Committed\n",
      "  Finished task 103.0 in stage 2.0 (TID 345). 1996 bytes result sent to driver\n",
      "  Starting task 108.0 in stage 2.0 (TID 350) (namenode, executor driver, partition 108, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Running task 108.0 in stage 2.0 (TID 350)\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Finished task 103.0 in stage 2.0 (TID 345) in 94 ms on namenode (executor driver) (105/121)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 12, boot = -18, init = 24, finish = 6\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000106_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000106\n",
      "  attempt_202204241347101051138738791519994_0012_m_000106_0: Committed\n",
      "  Times: total = 16, boot = -26, init = 36, finish = 6\n",
      "  Finished task 106.0 in stage 2.0 (TID 348). 1996 bytes result sent to driver\n",
      "  Starting task 109.0 in stage 2.0 (TID 351) (namenode, executor driver, partition 109, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 106.0 in stage 2.0 (TID 348) in 63 ms on namenode (executor driver) (106/121)\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000107_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000107\n",
      "  attempt_202204241347101051138738791519994_0012_m_000107_0: Committed\n",
      "  Finished task 107.0 in stage 2.0 (TID 349). 1996 bytes result sent to driver\n",
      "  Running task 109.0 in stage 2.0 (TID 351)\n",
      "  Starting task 110.0 in stage 2.0 (TID 352) (namenode, executor driver, partition 110, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 107.0 in stage 2.0 (TID 349) in 64 ms on namenode (executor driver) (107/121)\n",
      "  Running task 110.0 in stage 2.0 (TID 352)\n",
      "  Times: total = 15, boot = -28, init = 37, finish = 6\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000108_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000108\n",
      "  attempt_202204241347101051138738791519994_0012_m_000108_0: Committed\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Finished task 108.0 in stage 2.0 (TID 350). 1996 bytes result sent to driver\n",
      "  Starting task 111.0 in stage 2.0 (TID 353) (namenode, executor driver, partition 111, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 108.0 in stage 2.0 (TID 350) in 63 ms on namenode (executor driver) (108/121)\n",
      "  Running task 111.0 in stage 2.0 (TID 353)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 59, boot = -35, init = 84, finish = 10\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000110_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000110\n",
      "  attempt_202204241347101051138738791519994_0012_m_000110_0: Committed\n",
      "  Finished task 110.0 in stage 2.0 (TID 352). 1996 bytes result sent to driver\n",
      "  Starting task 112.0 in stage 2.0 (TID 354) (namenode, executor driver, partition 112, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 110.0 in stage 2.0 (TID 352) in 76 ms on namenode (executor driver) (109/121)\n",
      "  Running task 112.0 in stage 2.0 (TID 354)\n",
      "  Times: total = 66, boot = -34, init = 84, finish = 16\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000109_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000109\n",
      "  attempt_202204241347101051138738791519994_0012_m_000109_0: Committed\n",
      "  Finished task 109.0 in stage 2.0 (TID 351). 1996 bytes result sent to driver\n",
      "  Starting task 113.0 in stage 2.0 (TID 355) (namenode, executor driver, partition 113, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 109.0 in stage 2.0 (TID 351) in 85 ms on namenode (executor driver) (110/121)\n",
      "  Running task 113.0 in stage 2.0 (TID 355)\n",
      "  Times: total = 67, boot = -26, init = 75, finish = 18\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000111_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000111\n",
      "  attempt_202204241347101051138738791519994_0012_m_000111_0: Committed\n",
      "  Finished task 111.0 in stage 2.0 (TID 353). 1996 bytes result sent to driver\n",
      "  Starting task 114.0 in stage 2.0 (TID 356) (namenode, executor driver, partition 114, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 111.0 in stage 2.0 (TID 353) in 80 ms on namenode (executor driver) (111/121)\n",
      "  Running task 114.0 in stage 2.0 (TID 356)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 13, boot = -5, init = 9, finish = 9\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000113_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000113\n",
      "  attempt_202204241347101051138738791519994_0012_m_000113_0: Committed\n",
      "  Finished task 113.0 in stage 2.0 (TID 355). 1996 bytes result sent to driver\n",
      "  Starting task 115.0 in stage 2.0 (TID 357) (namenode, executor driver, partition 115, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 113.0 in stage 2.0 (TID 355) in 56 ms on namenode (executor driver) (112/121)\n",
      "  Running task 115.0 in stage 2.0 (TID 357)\n",
      "  Times: total = 21, boot = 11, init = 1, finish = 9\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000112_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000112\n",
      "  attempt_202204241347101051138738791519994_0012_m_000112_0: Committed\n",
      "  Finished task 112.0 in stage 2.0 (TID 354). 1996 bytes result sent to driver\n",
      "  Starting task 116.0 in stage 2.0 (TID 358) (namenode, executor driver, partition 116, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 116.0 in stage 2.0 (TID 358)\n",
      "  Finished task 112.0 in stage 2.0 (TID 354) in 70 ms on namenode (executor driver) (113/121)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 26, boot = 15, init = 3, finish = 8\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000114_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000114\n",
      "  attempt_202204241347101051138738791519994_0012_m_000114_0: Committed\n",
      "  Finished task 114.0 in stage 2.0 (TID 356). 1996 bytes result sent to driver\n",
      "  Starting task 117.0 in stage 2.0 (TID 359) (namenode, executor driver, partition 117, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 114.0 in stage 2.0 (TID 356) in 64 ms on namenode (executor driver) (114/121)\n",
      "  Running task 117.0 in stage 2.0 (TID 359)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 10, boot = -30, init = 34, finish = 6\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000115_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000115\n",
      "  attempt_202204241347101051138738791519994_0012_m_000115_0: Committed\n",
      "  Finished task 115.0 in stage 2.0 (TID 357). 1996 bytes result sent to driver\n",
      "  Starting task 118.0 in stage 2.0 (TID 360) (namenode, executor driver, partition 118, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 115.0 in stage 2.0 (TID 357) in 72 ms on namenode (executor driver) (115/121)\n",
      "  Running task 118.0 in stage 2.0 (TID 360)\n",
      "  Times: total = 11, boot = -15, init = 18, finish = 8\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000116_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000116\n",
      "  attempt_202204241347101051138738791519994_0012_m_000116_0: Committed\n",
      "  Finished task 116.0 in stage 2.0 (TID 358). 1996 bytes result sent to driver\n",
      "  Starting task 119.0 in stage 2.0 (TID 361) (namenode, executor driver, partition 119, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 116.0 in stage 2.0 (TID 358) in 71 ms on namenode (executor driver) (116/121)\n",
      "  Running task 119.0 in stage 2.0 (TID 361)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 2 ms\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 21, boot = -21, init = 36, finish = 6\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000117_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000117\n",
      "  attempt_202204241347101051138738791519994_0012_m_000117_0: Committed\n",
      "  Finished task 117.0 in stage 2.0 (TID 359). 1996 bytes result sent to driver\n",
      "  Starting task 120.0 in stage 2.0 (TID 362) (namenode, executor driver, partition 120, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 120.0 in stage 2.0 (TID 362)\n",
      "  Finished task 117.0 in stage 2.0 (TID 359) in 99 ms on namenode (executor driver) (117/121)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 50, boot = -46, init = 91, finish = 5\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000119_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000119\n",
      "  attempt_202204241347101051138738791519994_0012_m_000119_0: Committed\n",
      "  Finished task 119.0 in stage 2.0 (TID 361). 1996 bytes result sent to driver\n",
      "  Finished task 119.0 in stage 2.0 (TID 361) in 69 ms on namenode (executor driver) (118/121)\n",
      "  Times: total = 63, boot = -58, init = 115, finish = 6\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000118_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000118\n",
      "  attempt_202204241347101051138738791519994_0012_m_000118_0: Committed\n",
      "  Finished task 118.0 in stage 2.0 (TID 360). 1996 bytes result sent to driver\n",
      "  Finished task 118.0 in stage 2.0 (TID 360) in 93 ms on namenode (executor driver) (119/121)\n",
      "  Times: total = 55, boot = -61, init = 111, finish = 5\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000120_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000120\n",
      "  attempt_202204241347101051138738791519994_0012_m_000120_0: Committed\n",
      "  Finished task 120.0 in stage 2.0 (TID 362). 1996 bytes result sent to driver\n",
      "  Finished task 120.0 in stage 2.0 (TID 362) in 66 ms on namenode (executor driver) (120/121)\n",
      "  Times: total = 90802, boot = -167, init = 191, finish = 90778\n",
      "  Saved output of task 'attempt_202204241347101051138738791519994_0012_m_000069_0' to file:/tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output/_temporary/0/task_202204241347101051138738791519994_0012_m_000069\n",
      "  attempt_202204241347101051138738791519994_0012_m_000069_0: Committed\n",
      "  Finished task 69.0 in stage 2.0 (TID 242). 2125 bytes result sent to driver\n",
      "  Finished task 69.0 in stage 2.0 (TID 242) in 90893 ms on namenode (executor driver) (121/121)\n",
      "  Removed TaskSet 2.0, whose tasks have all completed, from pool \n",
      "  ResultStage 2 (runJob at SparkHadoopWriter.scala:83) finished in 90.945 s\n",
      "  Job 0 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "  Killing all running tasks in stage 2: Stage finished\n",
      "  Job 0 finished: runJob at SparkHadoopWriter.scala:83, took 487.781314 s\n",
      "  Start to commit write Job job_202204241347101051138738791519994_0012.\n",
      "  Write Job job_202204241347101051138738791519994_0012 committed. Elapsed time: 98 ms.\n",
      "  Invoking stop() from shutdown hook\n",
      "  Stopped Spark@2af70df9{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}\n",
      "  Stopped Spark web UI at http://namenode:4040\n",
      "  MapOutputTrackerMasterEndpoint stopped!\n",
      "  MemoryStore cleared\n",
      "  BlockManager stopped\n",
      "  BlockManagerMaster stopped\n",
      "  OutputCommitCoordinator stopped!\n",
      "  Successfully stopped SparkContext\n",
      "  Shutdown hook called\n",
      "  Deleting directory /tmp/spark-ca1e997a-5ee3-4d39-8154-af65d38bd92e\n",
      "  Deleting directory /tmp/spark-65315124-3a0f-47ce-b161-66531872181f\n",
      "  Deleting directory /tmp/spark-ca1e997a-5ee3-4d39-8154-af65d38bd92e/pyspark-c27032da-633d-4300-bc81-64275ebceed7\n",
      "job output is in /tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output\n",
      "Streaming final output from /tmp/popular_comment.ubuntu.20220424.134700.657971-spark/output...\n",
      "Removing temp directory /tmp/popular_comment.ubuntu.20220424.134700.657971...\n"
     ]
    }
   ],
   "source": [
    "!python3 popular_comment.py -r spark hdfs://namenode:9000/dis_materials/data_reddit.csv >outco.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a194e481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "No configs specified for spark runner\n",
      "Looking for hadoop binary in /usr/local/hadoop/bin...\n",
      "Found hadoop binary: /usr/local/hadoop/bin/hadoop\n",
      "Looking for spark-submit binary in /usr/local/spark/bin...\n",
      "Found spark-submit binary: /usr/local/spark/bin/spark-submit\n",
      "Running steps 1-2 of 2\n",
      "Creating temp directory /tmp/popular_comment.ubuntu.20220424.192746.474191\n",
      "  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "  Running Spark version 3.2.0\n",
      "  ==============================================================\n",
      "  No custom resources configured for spark.driver.\n",
      "  ==============================================================\n",
      "  Submitted application: harness.py\n",
      "  Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)\n",
      "  Limiting resource is cpu\n",
      "  Added ResourceProfile id: 0\n",
      "  Changing view acls to: ubuntu\n",
      "  Changing modify acls to: ubuntu\n",
      "  Changing view acls groups to: \n",
      "  Changing modify acls groups to: \n",
      "  SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ubuntu); groups with view permissions: Set(); users  with modify permissions: Set(ubuntu); groups with modify permissions: Set()\n",
      "  Successfully started service 'sparkDriver' on port 37807.\n",
      "  Registering MapOutputTracker\n",
      "  Registering BlockManagerMaster\n",
      "  Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information\n",
      "  BlockManagerMasterEndpoint up\n",
      "  Registering BlockManagerMasterHeartbeat\n",
      "  Created local directory at /tmp/blockmgr-aef8fccd-2a91-427c-bfba-defbc9791b43\n",
      "  MemoryStore started with capacity 366.3 MiB\n",
      "  Registering OutputCommitCoordinator\n",
      "  Logging initialized @3449ms to org.sparkproject.jetty.util.log.Slf4jLog\n",
      "  jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_312-8u312-b07-0ubuntu1~20.04-b07\n",
      "  Started @3597ms\n",
      "  Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "  Started ServerConnector@2b261552{HTTP/1.1, (http/1.1)}{0.0.0.0:4041}\n",
      "  Successfully started service 'SparkUI' on port 4041.\n",
      "  Started o.s.j.s.ServletContextHandler@856e1c{/jobs,null,AVAILABLE,@Spark}\n",
      "  Started o.s.j.s.ServletContextHandler@2082e0aa{/jobs/json,null,AVAILABLE,@Spark}\n",
      "  Started o.s.j.s.ServletContextHandler@7c8bdd8e{/jobs/job,null,AVAILABLE,@Spark}\n",
      "  Started o.s.j.s.ServletContextHandler@5213f96d{/jobs/job/json,null,AVAILABLE,@Spark}\n",
      "  Started o.s.j.s.ServletContextHandler@64df04e1{/stages,null,AVAILABLE,@Spark}\n",
      "  Started o.s.j.s.ServletContextHandler@68b7f4eb{/stages/json,null,AVAILABLE,@Spark}\n",
      "  Started o.s.j.s.ServletContextHandler@226b9132{/stages/stage,null,AVAILABLE,@Spark}\n",
      "  Started o.s.j.s.ServletContextHandler@7eb503f8{/stages/stage/json,null,AVAILABLE,@Spark}\n",
      "  Started o.s.j.s.ServletContextHandler@14689444{/stages/pool,null,AVAILABLE,@Spark}\n",
      "  Started o.s.j.s.ServletContextHandler@d744b4d{/stages/pool/json,null,AVAILABLE,@Spark}\n",
      "  Started o.s.j.s.ServletContextHandler@453b3f13{/storage,null,AVAILABLE,@Spark}\n",
      "  Started o.s.j.s.ServletContextHandler@70e06020{/storage/json,null,AVAILABLE,@Spark}\n",
      "  Started o.s.j.s.ServletContextHandler@739bc75c{/storage/rdd,null,AVAILABLE,@Spark}\n",
      "  Started o.s.j.s.ServletContextHandler@5409eed8{/storage/rdd/json,null,AVAILABLE,@Spark}\n",
      "  Started o.s.j.s.ServletContextHandler@337bfbc2{/environment,null,AVAILABLE,@Spark}\n",
      "  Started o.s.j.s.ServletContextHandler@5423466b{/environment/json,null,AVAILABLE,@Spark}\n",
      "  Started o.s.j.s.ServletContextHandler@1d4bdec7{/executors,null,AVAILABLE,@Spark}\n",
      "  Started o.s.j.s.ServletContextHandler@24d6dc09{/executors/json,null,AVAILABLE,@Spark}\n",
      "  Started o.s.j.s.ServletContextHandler@2b9112a{/executors/threadDump,null,AVAILABLE,@Spark}\n",
      "  Started o.s.j.s.ServletContextHandler@3cc0f036{/executors/threadDump/json,null,AVAILABLE,@Spark}\n",
      "  Started o.s.j.s.ServletContextHandler@d9702d1{/static,null,AVAILABLE,@Spark}\n",
      "  Started o.s.j.s.ServletContextHandler@6020314d{/,null,AVAILABLE,@Spark}\n",
      "  Started o.s.j.s.ServletContextHandler@77504f64{/api,null,AVAILABLE,@Spark}\n",
      "  Started o.s.j.s.ServletContextHandler@35485598{/jobs/job/kill,null,AVAILABLE,@Spark}\n",
      "  Started o.s.j.s.ServletContextHandler@5481576c{/stages/stage/kill,null,AVAILABLE,@Spark}\n",
      "  Bound SparkUI to 0.0.0.0, and started at http://namenode:4041\n",
      "  Added file file:///tmp/popular_comment.ubuntu.20220424.192746.474191/mrjob.zip at file:///tmp/popular_comment.ubuntu.20220424.192746.474191/mrjob.zip with timestamp 1650828471497\n",
      "  Copying /tmp/popular_comment.ubuntu.20220424.192746.474191/mrjob.zip to /tmp/spark-ca87ba9b-ddbe-43ab-bfc3-ed19c0bd6d4a/userFiles-764b985d-332b-4d3a-85f2-2fef596b0044/mrjob.zip\n",
      "  Added file file:///tmp/popular_comment.ubuntu.20220424.192746.474191/script.zip at file:///tmp/popular_comment.ubuntu.20220424.192746.474191/script.zip with timestamp 1650828471497\n",
      "  Copying /tmp/popular_comment.ubuntu.20220424.192746.474191/script.zip to /tmp/spark-ca87ba9b-ddbe-43ab-bfc3-ed19c0bd6d4a/userFiles-764b985d-332b-4d3a-85f2-2fef596b0044/script.zip\n",
      "  Starting executor ID driver on host namenode\n",
      "  Fetching file:///tmp/popular_comment.ubuntu.20220424.192746.474191/script.zip with timestamp 1650828471497\n",
      "  /tmp/popular_comment.ubuntu.20220424.192746.474191/script.zip has been previously copied to /tmp/spark-ca87ba9b-ddbe-43ab-bfc3-ed19c0bd6d4a/userFiles-764b985d-332b-4d3a-85f2-2fef596b0044/script.zip\n",
      "  Fetching file:///tmp/popular_comment.ubuntu.20220424.192746.474191/mrjob.zip with timestamp 1650828471497\n",
      "  /tmp/popular_comment.ubuntu.20220424.192746.474191/mrjob.zip has been previously copied to /tmp/spark-ca87ba9b-ddbe-43ab-bfc3-ed19c0bd6d4a/userFiles-764b985d-332b-4d3a-85f2-2fef596b0044/mrjob.zip\n",
      "  Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 32797.\n",
      "  Server created on namenode:32797\n",
      "  Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy\n",
      "  Registering BlockManager BlockManagerId(driver, namenode, 32797, None)\n",
      "  Registering block manager namenode:32797 with 366.3 MiB RAM, BlockManagerId(driver, namenode, 32797, None)\n",
      "  Registered BlockManager BlockManagerId(driver, namenode, 32797, None)\n",
      "  Initialized BlockManager: BlockManagerId(driver, namenode, 32797, None)\n",
      "  Started o.s.j.s.ServletContextHandler@af93741{/metrics/json,null,AVAILABLE,@Spark}\n",
      "  Block broadcast_0 stored as values in memory (estimated size 410.9 KiB, free 365.9 MiB)\n",
      "  Block broadcast_0_piece0 stored as bytes in memory (estimated size 42.1 KiB, free 365.9 MiB)\n",
      "  Added broadcast_0_piece0 in memory on namenode:32797 (size: 42.1 KiB, free: 366.3 MiB)\n",
      "  Created broadcast 0 from textFile at NativeMethodAccessorImpl.java:0\n",
      "  Total input files to process : 1\n",
      "  mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Starting job: runJob at SparkHadoopWriter.scala:83\n",
      "  Registering RDD 3 (groupBy at /home/ubuntu/.local/lib/python3.8/site-packages/mrjob/spark/harness.py:539) as input to shuffle 1\n",
      "  Registering RDD 7 (groupBy at /home/ubuntu/.local/lib/python3.8/site-packages/mrjob/spark/harness.py:539) as input to shuffle 0\n",
      "  Got job 0 (runJob at SparkHadoopWriter.scala:83) with 121 output partitions\n",
      "  Final stage: ResultStage 2 (runJob at SparkHadoopWriter.scala:83)\n",
      "  Parents of final stage: List(ShuffleMapStage 1)\n",
      "  Missing parents: List(ShuffleMapStage 1)\n",
      "  Submitting ShuffleMapStage 0 (PairwiseRDD[3] at groupBy at /home/ubuntu/.local/lib/python3.8/site-packages/mrjob/spark/harness.py:539), which has no missing parents\n",
      "  Block broadcast_1 stored as values in memory (estimated size 15.8 KiB, free 365.8 MiB)\n",
      "  Block broadcast_1_piece0 stored as bytes in memory (estimated size 9.5 KiB, free 365.8 MiB)\n",
      "  Added broadcast_1_piece0 in memory on namenode:32797 (size: 9.5 KiB, free: 366.2 MiB)\n",
      "  Created broadcast 1 from broadcast at DAGScheduler.scala:1427\n",
      "  Submitting 121 missing tasks from ShuffleMapStage 0 (PairwiseRDD[3] at groupBy at /home/ubuntu/.local/lib/python3.8/site-packages/mrjob/spark/harness.py:539) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Adding task set 0.0 with 121 tasks resource profile 0\n",
      "  Starting task 0.0 in stage 0.0 (TID 0) (namenode, executor driver, partition 0, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Starting task 1.0 in stage 0.0 (TID 1) (namenode, executor driver, partition 1, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Starting task 2.0 in stage 0.0 (TID 2) (namenode, executor driver, partition 2, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Starting task 3.0 in stage 0.0 (TID 3) (namenode, executor driver, partition 3, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 3.0 in stage 0.0 (TID 3)\n",
      "  Running task 0.0 in stage 0.0 (TID 0)\n",
      "  Running task 1.0 in stage 0.0 (TID 1)\n",
      "  Running task 2.0 in stage 0.0 (TID 2)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:268435456+134217728\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:134217728+134217728\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:402653184+134217728\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:0+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 9539, boot = 388, init = 356, finish = 8795\n",
      "  Times: total = 9419, boot = 402, init = 316, finish = 8701\n",
      "  Times: total = 9646, boot = 377, init = 417, finish = 8852\n",
      "  Finished task 3.0 in stage 0.0 (TID 3). 1900 bytes result sent to driver\n",
      "  Finished task 2.0 in stage 0.0 (TID 2). 1943 bytes result sent to driver\n",
      "  Finished task 1.0 in stage 0.0 (TID 1). 1900 bytes result sent to driver\n",
      "  Starting task 4.0 in stage 0.0 (TID 4) (namenode, executor driver, partition 4, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 4.0 in stage 0.0 (TID 4)\n",
      "  Starting task 5.0 in stage 0.0 (TID 5) (namenode, executor driver, partition 5, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 5.0 in stage 0.0 (TID 5)\n",
      "  Starting task 6.0 in stage 0.0 (TID 6) (namenode, executor driver, partition 6, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 3.0 in stage 0.0 (TID 3) in 10470 ms on namenode (executor driver) (1/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:536870912+134217728\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:671088640+134217728\n",
      "  Finished task 2.0 in stage 0.0 (TID 2) in 10494 ms on namenode (executor driver) (2/121)\n",
      "  Running task 6.0 in stage 0.0 (TID 6)\n",
      "  Finished task 1.0 in stage 0.0 (TID 1) in 10501 ms on namenode (executor driver) (3/121)\n",
      "  Connected to AccumulatorServer at host: 127.0.0.1 port: 52783\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:805306368+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 10546, boot = 529, init = 410, finish = 9607\n",
      "  Finished task 0.0 in stage 0.0 (TID 0). 1900 bytes result sent to driver\n",
      "  Starting task 7.0 in stage 0.0 (TID 7) (namenode, executor driver, partition 7, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 7.0 in stage 0.0 (TID 7)\n",
      "  Finished task 0.0 in stage 0.0 (TID 0) in 11081 ms on namenode (executor driver) (4/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:939524096+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 8180, boot = -383, init = 397, finish = 8166\n",
      "  Finished task 5.0 in stage 0.0 (TID 5). 1900 bytes result sent to driver\n",
      "  Starting task 8.0 in stage 0.0 (TID 8) (namenode, executor driver, partition 8, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 8.0 in stage 0.0 (TID 8)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:1073741824+134217728\n",
      "  Finished task 5.0 in stage 0.0 (TID 5) in 8297 ms on namenode (executor driver) (5/121)\n",
      "  Times: total = 8396, boot = -491, init = 518, finish = 8369\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Finished task 4.0 in stage 0.0 (TID 4). 1900 bytes result sent to driver\n",
      "  Starting task 9.0 in stage 0.0 (TID 9) (namenode, executor driver, partition 9, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 9.0 in stage 0.0 (TID 9)\n",
      "  Finished task 4.0 in stage 0.0 (TID 4) in 8612 ms on namenode (executor driver) (6/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:1207959552+134217728\n",
      "  Times: total = 8583, boot = -291, init = 327, finish = 8547\n",
      "  Finished task 6.0 in stage 0.0 (TID 6). 1900 bytes result sent to driver\n",
      "  Starting task 10.0 in stage 0.0 (TID 10) (namenode, executor driver, partition 10, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 10.0 in stage 0.0 (TID 10)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:1342177280+134217728\n",
      "  Finished task 6.0 in stage 0.0 (TID 6) in 8687 ms on namenode (executor driver) (7/121)\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 9257, boot = -132, init = 166, finish = 9223\n",
      "  Finished task 7.0 in stage 0.0 (TID 7). 1900 bytes result sent to driver\n",
      "  Starting task 11.0 in stage 0.0 (TID 11) (namenode, executor driver, partition 11, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 7.0 in stage 0.0 (TID 7) in 9391 ms on namenode (executor driver) (8/121)\n",
      "  Running task 11.0 in stage 0.0 (TID 11)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:1476395008+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 8125, boot = -112, init = 115, finish = 8122\n",
      "  Finished task 8.0 in stage 0.0 (TID 8). 1900 bytes result sent to driver\n",
      "  Starting task 12.0 in stage 0.0 (TID 12) (namenode, executor driver, partition 12, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 8.0 in stage 0.0 (TID 8) in 8241 ms on namenode (executor driver) (9/121)\n",
      "  Running task 12.0 in stage 0.0 (TID 12)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:1610612736+134217728\n",
      "  Times: total = 7992, boot = -41, init = 57, finish = 7976\n",
      "  Finished task 10.0 in stage 0.0 (TID 10). 1900 bytes result sent to driver\n",
      "  Starting task 13.0 in stage 0.0 (TID 13) (namenode, executor driver, partition 13, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 10.0 in stage 0.0 (TID 10) in 8064 ms on namenode (executor driver) (10/121)\n",
      "  Running task 13.0 in stage 0.0 (TID 13)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:1744830464+134217728\n",
      "  Times: total = 8199, boot = -212, init = 215, finish = 8196\n",
      "  Finished task 9.0 in stage 0.0 (TID 9). 1900 bytes result sent to driver\n",
      "  Starting task 14.0 in stage 0.0 (TID 14) (namenode, executor driver, partition 14, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 9.0 in stage 0.0 (TID 9) in 8332 ms on namenode (executor driver) (11/121)\n",
      "  Running task 14.0 in stage 0.0 (TID 14)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:1879048192+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 8404, boot = -63, init = 71, finish = 8396\n",
      "  Finished task 11.0 in stage 0.0 (TID 11). 1900 bytes result sent to driver\n",
      "  Starting task 15.0 in stage 0.0 (TID 15) (namenode, executor driver, partition 15, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 11.0 in stage 0.0 (TID 11) in 8458 ms on namenode (executor driver) (12/121)\n",
      "  Running task 15.0 in stage 0.0 (TID 15)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:2013265920+134217728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 7439, boot = -51, init = 64, finish = 7426\n",
      "  Finished task 13.0 in stage 0.0 (TID 13). 1900 bytes result sent to driver\n",
      "  Starting task 16.0 in stage 0.0 (TID 16) (namenode, executor driver, partition 16, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 13.0 in stage 0.0 (TID 13) in 7513 ms on namenode (executor driver) (13/121)\n",
      "  Running task 16.0 in stage 0.0 (TID 16)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:2147483648+134217728\n",
      "  Times: total = 7810, boot = -61, init = 63, finish = 7808\n",
      "  Finished task 12.0 in stage 0.0 (TID 12). 1900 bytes result sent to driver\n",
      "  Starting task 17.0 in stage 0.0 (TID 17) (namenode, executor driver, partition 17, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 12.0 in stage 0.0 (TID 12) in 7922 ms on namenode (executor driver) (14/121)\n",
      "  Running task 17.0 in stage 0.0 (TID 17)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:2281701376+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 7530, boot = -56, init = 66, finish = 7520\n",
      "  Finished task 14.0 in stage 0.0 (TID 14). 1900 bytes result sent to driver\n",
      "  Starting task 18.0 in stage 0.0 (TID 18) (namenode, executor driver, partition 18, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 18.0 in stage 0.0 (TID 18)\n",
      "  Finished task 14.0 in stage 0.0 (TID 14) in 7691 ms on namenode (executor driver) (15/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:2415919104+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 8264, boot = -58, init = 65, finish = 8257\n",
      "  Finished task 15.0 in stage 0.0 (TID 15). 1900 bytes result sent to driver\n",
      "  Starting task 19.0 in stage 0.0 (TID 19) (namenode, executor driver, partition 19, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 19.0 in stage 0.0 (TID 19)\n",
      "  Finished task 15.0 in stage 0.0 (TID 15) in 8355 ms on namenode (executor driver) (16/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:2550136832+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 7368, boot = -122, init = 136, finish = 7354\n",
      "  Finished task 18.0 in stage 0.0 (TID 18). 1900 bytes result sent to driver\n",
      "  Starting task 20.0 in stage 0.0 (TID 20) (namenode, executor driver, partition 20, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 18.0 in stage 0.0 (TID 18) in 7477 ms on namenode (executor driver) (17/121)\n",
      "  Running task 20.0 in stage 0.0 (TID 20)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:2684354560+134217728\n",
      "  Times: total = 7933, boot = -112, init = 115, finish = 7930\n",
      "  Finished task 16.0 in stage 0.0 (TID 16). 1900 bytes result sent to driver\n",
      "  Starting task 21.0 in stage 0.0 (TID 21) (namenode, executor driver, partition 21, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 16.0 in stage 0.0 (TID 16) in 8090 ms on namenode (executor driver) (18/121)\n",
      "  Running task 21.0 in stage 0.0 (TID 21)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:2818572288+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 8098, boot = -102, init = 127, finish = 8073\n",
      "  Finished task 17.0 in stage 0.0 (TID 17). 1900 bytes result sent to driver\n",
      "  Starting task 22.0 in stage 0.0 (TID 22) (namenode, executor driver, partition 22, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 17.0 in stage 0.0 (TID 17) in 8207 ms on namenode (executor driver) (19/121)\n",
      "  Running task 22.0 in stage 0.0 (TID 22)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:2952790016+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 8167, boot = -72, init = 121, finish = 8118\n",
      "  Finished task 19.0 in stage 0.0 (TID 19). 1900 bytes result sent to driver\n",
      "  Starting task 23.0 in stage 0.0 (TID 23) (namenode, executor driver, partition 23, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 23.0 in stage 0.0 (TID 23)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:3087007744+134217728\n",
      "  Finished task 19.0 in stage 0.0 (TID 19) in 8278 ms on namenode (executor driver) (20/121)\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 7065, boot = -145, init = 149, finish = 7061\n",
      "  Finished task 20.0 in stage 0.0 (TID 20). 1900 bytes result sent to driver\n",
      "  Starting task 24.0 in stage 0.0 (TID 24) (namenode, executor driver, partition 24, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 20.0 in stage 0.0 (TID 20) in 7177 ms on namenode (executor driver) (21/121)\n",
      "  Running task 24.0 in stage 0.0 (TID 24)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:3221225472+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 7956, boot = -71, init = 77, finish = 7950\n",
      "  Finished task 21.0 in stage 0.0 (TID 21). 1900 bytes result sent to driver\n",
      "  Starting task 25.0 in stage 0.0 (TID 25) (namenode, executor driver, partition 25, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 21.0 in stage 0.0 (TID 21) in 8050 ms on namenode (executor driver) (22/121)\n",
      "  Running task 25.0 in stage 0.0 (TID 25)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:3355443200+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 7995, boot = -90, init = 111, finish = 7974\n",
      "  Finished task 22.0 in stage 0.0 (TID 22). 1900 bytes result sent to driver\n",
      "  Starting task 26.0 in stage 0.0 (TID 26) (namenode, executor driver, partition 26, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 26.0 in stage 0.0 (TID 26)\n",
      "  Finished task 22.0 in stage 0.0 (TID 22) in 8096 ms on namenode (executor driver) (23/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:3489660928+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 8362, boot = -69, init = 76, finish = 8355\n",
      "  Finished task 23.0 in stage 0.0 (TID 23). 1900 bytes result sent to driver\n",
      "  Starting task 27.0 in stage 0.0 (TID 27) (namenode, executor driver, partition 27, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 23.0 in stage 0.0 (TID 23) in 8451 ms on namenode (executor driver) (24/121)\n",
      "  Running task 27.0 in stage 0.0 (TID 27)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:3623878656+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 7852, boot = -30, init = 32, finish = 7850\n",
      "  Finished task 24.0 in stage 0.0 (TID 24). 1900 bytes result sent to driver\n",
      "  Starting task 28.0 in stage 0.0 (TID 28) (namenode, executor driver, partition 28, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 24.0 in stage 0.0 (TID 24) in 7909 ms on namenode (executor driver) (25/121)\n",
      "  Running task 28.0 in stage 0.0 (TID 28)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:3758096384+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 7892, boot = -85, init = 93, finish = 7884\n",
      "  Finished task 25.0 in stage 0.0 (TID 25). 1900 bytes result sent to driver\n",
      "  Starting task 29.0 in stage 0.0 (TID 29) (namenode, executor driver, partition 29, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 29.0 in stage 0.0 (TID 29)\n",
      "  Finished task 25.0 in stage 0.0 (TID 25) in 7960 ms on namenode (executor driver) (26/121)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:3892314112+134217728\n",
      "  Times: total = 7773, boot = -102, init = 117, finish = 7758\n",
      "  Finished task 26.0 in stage 0.0 (TID 26). 1900 bytes result sent to driver\n",
      "  Starting task 30.0 in stage 0.0 (TID 30) (namenode, executor driver, partition 30, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 30.0 in stage 0.0 (TID 30)\n",
      "  Finished task 26.0 in stage 0.0 (TID 26) in 7886 ms on namenode (executor driver) (27/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:4026531840+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 7781, boot = -49, init = 86, finish = 7744\n",
      "  Finished task 27.0 in stage 0.0 (TID 27). 1900 bytes result sent to driver\n",
      "  Starting task 31.0 in stage 0.0 (TID 31) (namenode, executor driver, partition 31, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 31.0 in stage 0.0 (TID 31)\n",
      "  Finished task 27.0 in stage 0.0 (TID 27) in 7837 ms on namenode (executor driver) (28/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:4160749568+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 8077, boot = -108, init = 119, finish = 8066\n",
      "  Finished task 28.0 in stage 0.0 (TID 28). 1900 bytes result sent to driver\n",
      "  Starting task 32.0 in stage 0.0 (TID 32) (namenode, executor driver, partition 32, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 28.0 in stage 0.0 (TID 28) in 8240 ms on namenode (executor driver) (29/121)\n",
      "  Running task 32.0 in stage 0.0 (TID 32)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:4294967296+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 7247, boot = -44, init = 59, finish = 7232\n",
      "  Finished task 30.0 in stage 0.0 (TID 30). 1900 bytes result sent to driver\n",
      "  Starting task 33.0 in stage 0.0 (TID 33) (namenode, executor driver, partition 33, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 33.0 in stage 0.0 (TID 33)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:4429185024+134217728\n",
      "  Finished task 30.0 in stage 0.0 (TID 30) in 7307 ms on namenode (executor driver) (30/121)\n",
      "  Times: total = 7621, boot = -123, init = 127, finish = 7617\n",
      "  Finished task 29.0 in stage 0.0 (TID 29). 1900 bytes result sent to driver\n",
      "  Starting task 34.0 in stage 0.0 (TID 34) (namenode, executor driver, partition 34, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 34.0 in stage 0.0 (TID 34)\n",
      "  Finished task 29.0 in stage 0.0 (TID 29) in 7820 ms on namenode (executor driver) (31/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:4563402752+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 7863, boot = -65, init = 75, finish = 7853\n",
      "  Finished task 31.0 in stage 0.0 (TID 31). 1900 bytes result sent to driver\n",
      "  Starting task 35.0 in stage 0.0 (TID 35) (namenode, executor driver, partition 35, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 31.0 in stage 0.0 (TID 31) in 7937 ms on namenode (executor driver) (32/121)\n",
      "  Running task 35.0 in stage 0.0 (TID 35)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:4697620480+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 8001, boot = -36, init = 42, finish = 7995\n",
      "  Finished task 32.0 in stage 0.0 (TID 32). 1900 bytes result sent to driver\n",
      "  Starting task 36.0 in stage 0.0 (TID 36) (namenode, executor driver, partition 36, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 36.0 in stage 0.0 (TID 36)\n",
      "  Finished task 32.0 in stage 0.0 (TID 32) in 8052 ms on namenode (executor driver) (33/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:4831838208+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 8350, boot = -66, init = 77, finish = 8339\n",
      "  Finished task 33.0 in stage 0.0 (TID 33). 1900 bytes result sent to driver\n",
      "  Starting task 37.0 in stage 0.0 (TID 37) (namenode, executor driver, partition 37, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 33.0 in stage 0.0 (TID 33) in 8473 ms on namenode (executor driver) (34/121)\n",
      "  Running task 37.0 in stage 0.0 (TID 37)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:4966055936+134217728\n",
      "  Times: total = 8565, boot = -66, init = 78, finish = 8553\n",
      "  Finished task 34.0 in stage 0.0 (TID 34). 1900 bytes result sent to driver\n",
      "  Starting task 38.0 in stage 0.0 (TID 38) (namenode, executor driver, partition 38, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 34.0 in stage 0.0 (TID 34) in 8666 ms on namenode (executor driver) (35/121)\n",
      "  Running task 38.0 in stage 0.0 (TID 38)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:5100273664+134217728\n",
      "  Times: total = 7601, boot = -85, init = 105, finish = 7581\n",
      "  Finished task 35.0 in stage 0.0 (TID 35). 1900 bytes result sent to driver\n",
      "  Starting task 39.0 in stage 0.0 (TID 39) (namenode, executor driver, partition 39, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 35.0 in stage 0.0 (TID 35) in 7703 ms on namenode (executor driver) (36/121)\n",
      "  Running task 39.0 in stage 0.0 (TID 39)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:5234491392+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 7657, boot = -52, init = 54, finish = 7655\n",
      "  Finished task 36.0 in stage 0.0 (TID 36). 1900 bytes result sent to driver\n",
      "  Starting task 40.0 in stage 0.0 (TID 40) (namenode, executor driver, partition 40, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 40.0 in stage 0.0 (TID 40)\n",
      "  Finished task 36.0 in stage 0.0 (TID 36) in 7743 ms on namenode (executor driver) (37/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:5368709120+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 7401, boot = -97, init = 104, finish = 7394\n",
      "  Finished task 37.0 in stage 0.0 (TID 37). 1900 bytes result sent to driver\n",
      "  Starting task 41.0 in stage 0.0 (TID 41) (namenode, executor driver, partition 41, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 37.0 in stage 0.0 (TID 37) in 7458 ms on namenode (executor driver) (38/121)\n",
      "  Running task 41.0 in stage 0.0 (TID 41)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:5502926848+134217728\n",
      "  Times: total = 8303, boot = -116, init = 120, finish = 8299\n",
      "  Finished task 38.0 in stage 0.0 (TID 38). 1900 bytes result sent to driver\n",
      "  Starting task 42.0 in stage 0.0 (TID 42) (namenode, executor driver, partition 42, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 38.0 in stage 0.0 (TID 38) in 8420 ms on namenode (executor driver) (39/121)\n",
      "  Running task 42.0 in stage 0.0 (TID 42)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:5637144576+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 7776, boot = -40, init = 48, finish = 7768\n",
      "  Finished task 39.0 in stage 0.0 (TID 39). 1900 bytes result sent to driver\n",
      "  Starting task 43.0 in stage 0.0 (TID 43) (namenode, executor driver, partition 43, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 43.0 in stage 0.0 (TID 43)\n",
      "  Finished task 39.0 in stage 0.0 (TID 39) in 7826 ms on namenode (executor driver) (40/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:5771362304+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 7501, boot = -124, init = 129, finish = 7496\n",
      "  Finished task 40.0 in stage 0.0 (TID 40). 1900 bytes result sent to driver\n",
      "  Starting task 44.0 in stage 0.0 (TID 44) (namenode, executor driver, partition 44, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 40.0 in stage 0.0 (TID 40) in 7637 ms on namenode (executor driver) (41/121)\n",
      "  Running task 44.0 in stage 0.0 (TID 44)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:5905580032+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 7754, boot = -72, init = 84, finish = 7742\n",
      "  Finished task 41.0 in stage 0.0 (TID 41). 1900 bytes result sent to driver\n",
      "  Starting task 45.0 in stage 0.0 (TID 45) (namenode, executor driver, partition 45, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 41.0 in stage 0.0 (TID 41) in 7853 ms on namenode (executor driver) (42/121)\n",
      "  Running task 45.0 in stage 0.0 (TID 45)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:6039797760+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 7938, boot = -65, init = 69, finish = 7934\n",
      "  Finished task 42.0 in stage 0.0 (TID 42). 1900 bytes result sent to driver\n",
      "  Starting task 46.0 in stage 0.0 (TID 46) (namenode, executor driver, partition 46, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 42.0 in stage 0.0 (TID 42) in 7998 ms on namenode (executor driver) (43/121)\n",
      "  Running task 46.0 in stage 0.0 (TID 46)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:6174015488+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 7742, boot = -89, init = 119, finish = 7712\n",
      "  Finished task 43.0 in stage 0.0 (TID 43). 1900 bytes result sent to driver\n",
      "  Starting task 47.0 in stage 0.0 (TID 47) (namenode, executor driver, partition 47, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 43.0 in stage 0.0 (TID 43) in 7845 ms on namenode (executor driver) (44/121)\n",
      "  Running task 47.0 in stage 0.0 (TID 47)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:6308233216+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 7469, boot = -46, init = 48, finish = 7467\n",
      "  Finished task 44.0 in stage 0.0 (TID 44). 1900 bytes result sent to driver\n",
      "  Starting task 48.0 in stage 0.0 (TID 48) (namenode, executor driver, partition 48, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 48.0 in stage 0.0 (TID 48)\n",
      "  Finished task 44.0 in stage 0.0 (TID 44) in 7531 ms on namenode (executor driver) (45/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:6442450944+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 7535, boot = -22, init = 37, finish = 7520\n",
      "  Finished task 45.0 in stage 0.0 (TID 45). 1900 bytes result sent to driver\n",
      "  Starting task 49.0 in stage 0.0 (TID 49) (namenode, executor driver, partition 49, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 49.0 in stage 0.0 (TID 49)\n",
      "  Finished task 45.0 in stage 0.0 (TID 45) in 7586 ms on namenode (executor driver) (46/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:6576668672+134217728\n",
      "  Times: total = 7633, boot = -48, init = 52, finish = 7629\n",
      "  Finished task 46.0 in stage 0.0 (TID 46). 1900 bytes result sent to driver\n",
      "  Starting task 50.0 in stage 0.0 (TID 50) (namenode, executor driver, partition 50, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 46.0 in stage 0.0 (TID 46) in 7687 ms on namenode (executor driver) (47/121)\n",
      "  Running task 50.0 in stage 0.0 (TID 50)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:6710886400+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 8773, boot = -86, init = 88, finish = 8771\n",
      "  Finished task 47.0 in stage 0.0 (TID 47). 1900 bytes result sent to driver\n",
      "  Starting task 51.0 in stage 0.0 (TID 51) (namenode, executor driver, partition 51, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 47.0 in stage 0.0 (TID 47) in 8875 ms on namenode (executor driver) (48/121)\n",
      "  Running task 51.0 in stage 0.0 (TID 51)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:6845104128+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 7671, boot = -51, init = 67, finish = 7655\n",
      "  Finished task 48.0 in stage 0.0 (TID 48). 1900 bytes result sent to driver\n",
      "  Starting task 52.0 in stage 0.0 (TID 52) (namenode, executor driver, partition 52, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 52.0 in stage 0.0 (TID 52)\n",
      "  Finished task 48.0 in stage 0.0 (TID 48) in 7766 ms on namenode (executor driver) (49/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:6979321856+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 8243, boot = -56, init = 67, finish = 8232\n",
      "  Finished task 49.0 in stage 0.0 (TID 49). 1900 bytes result sent to driver\n",
      "  Starting task 53.0 in stage 0.0 (TID 53) (namenode, executor driver, partition 53, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 53.0 in stage 0.0 (TID 53)\n",
      "  Finished task 49.0 in stage 0.0 (TID 49) in 8320 ms on namenode (executor driver) (50/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:7113539584+134217728\n",
      "  Times: total = 8853, boot = -25, init = 37, finish = 8841\n",
      "  Finished task 50.0 in stage 0.0 (TID 50). 1900 bytes result sent to driver\n",
      "  Starting task 54.0 in stage 0.0 (TID 54) (namenode, executor driver, partition 54, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 54.0 in stage 0.0 (TID 54)\n",
      "  Finished task 50.0 in stage 0.0 (TID 50) in 8892 ms on namenode (executor driver) (51/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:7247757312+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 8445, boot = -64, init = 67, finish = 8442\n",
      "  Finished task 51.0 in stage 0.0 (TID 51). 1900 bytes result sent to driver\n",
      "  Starting task 55.0 in stage 0.0 (TID 55) (namenode, executor driver, partition 55, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 55.0 in stage 0.0 (TID 55)\n",
      "  Finished task 51.0 in stage 0.0 (TID 51) in 8536 ms on namenode (executor driver) (52/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:7381975040+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 7692, boot = -104, init = 129, finish = 7667\n",
      "  Finished task 52.0 in stage 0.0 (TID 52). 1900 bytes result sent to driver\n",
      "  Starting task 56.0 in stage 0.0 (TID 56) (namenode, executor driver, partition 56, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 56.0 in stage 0.0 (TID 56)\n",
      "  Finished task 52.0 in stage 0.0 (TID 52) in 7780 ms on namenode (executor driver) (53/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:7516192768+134217728\n",
      "  Times: total = 7366, boot = -21, init = 24, finish = 7363\n",
      "  Finished task 53.0 in stage 0.0 (TID 53). 1900 bytes result sent to driver\n",
      "  Starting task 57.0 in stage 0.0 (TID 57) (namenode, executor driver, partition 57, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 53.0 in stage 0.0 (TID 53) in 7423 ms on namenode (executor driver) (54/121)\n",
      "  Running task 57.0 in stage 0.0 (TID 57)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:7650410496+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 7948, boot = -35, init = 43, finish = 7940\n",
      "  Finished task 54.0 in stage 0.0 (TID 54). 1900 bytes result sent to driver\n",
      "  Starting task 58.0 in stage 0.0 (TID 58) (namenode, executor driver, partition 58, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 58.0 in stage 0.0 (TID 58)\n",
      "  Finished task 54.0 in stage 0.0 (TID 54) in 7999 ms on namenode (executor driver) (55/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:7784628224+134217728\n",
      "  Times: total = 8004, boot = -30, init = 39, finish = 7995\n",
      "  Finished task 55.0 in stage 0.0 (TID 55). 1900 bytes result sent to driver\n",
      "  Starting task 59.0 in stage 0.0 (TID 59) (namenode, executor driver, partition 59, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 55.0 in stage 0.0 (TID 55) in 8117 ms on namenode (executor driver) (56/121)\n",
      "  Running task 59.0 in stage 0.0 (TID 59)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:7918845952+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 7872, boot = -33, init = 36, finish = 7869\n",
      "  Finished task 56.0 in stage 0.0 (TID 56). 1900 bytes result sent to driver\n",
      "  Starting task 60.0 in stage 0.0 (TID 60) (namenode, executor driver, partition 60, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 60.0 in stage 0.0 (TID 60)\n",
      "  Finished task 56.0 in stage 0.0 (TID 56) in 7951 ms on namenode (executor driver) (57/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:8053063680+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 7366, boot = -31, init = 48, finish = 7349\n",
      "  Finished task 57.0 in stage 0.0 (TID 57). 1900 bytes result sent to driver\n",
      "  Starting task 61.0 in stage 0.0 (TID 61) (namenode, executor driver, partition 61, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 61.0 in stage 0.0 (TID 61)\n",
      "  Finished task 57.0 in stage 0.0 (TID 57) in 7431 ms on namenode (executor driver) (58/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:8187281408+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 7642, boot = -30, init = 43, finish = 7629\n",
      "  Finished task 58.0 in stage 0.0 (TID 58). 1900 bytes result sent to driver\n",
      "  Starting task 62.0 in stage 0.0 (TID 62) (namenode, executor driver, partition 62, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 58.0 in stage 0.0 (TID 58) in 7714 ms on namenode (executor driver) (59/121)\n",
      "  Running task 62.0 in stage 0.0 (TID 62)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:8321499136+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 7972, boot = -116, init = 119, finish = 7969\n",
      "  Finished task 59.0 in stage 0.0 (TID 59). 1900 bytes result sent to driver\n",
      "  Starting task 63.0 in stage 0.0 (TID 63) (namenode, executor driver, partition 63, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 59.0 in stage 0.0 (TID 59) in 8060 ms on namenode (executor driver) (60/121)\n",
      "  Running task 63.0 in stage 0.0 (TID 63)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:8455716864+134217728\n",
      "  Times: total = 8230, boot = -84, init = 101, finish = 8213\n",
      "  Finished task 60.0 in stage 0.0 (TID 60). 1900 bytes result sent to driver\n",
      "  Starting task 64.0 in stage 0.0 (TID 64) (namenode, executor driver, partition 64, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 64.0 in stage 0.0 (TID 64)\n",
      "  Finished task 60.0 in stage 0.0 (TID 60) in 8297 ms on namenode (executor driver) (61/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:8589934592+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 8227, boot = -104, init = 107, finish = 8224\n",
      "  Finished task 61.0 in stage 0.0 (TID 61). 1900 bytes result sent to driver\n",
      "  Starting task 65.0 in stage 0.0 (TID 65) (namenode, executor driver, partition 65, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 61.0 in stage 0.0 (TID 61) in 8351 ms on namenode (executor driver) (62/121)\n",
      "  Running task 65.0 in stage 0.0 (TID 65)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:8724152320+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 8035, boot = -23, init = 25, finish = 8033\n",
      "  Finished task 62.0 in stage 0.0 (TID 62). 1900 bytes result sent to driver\n",
      "  Starting task 66.0 in stage 0.0 (TID 66) (namenode, executor driver, partition 66, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 62.0 in stage 0.0 (TID 62) in 8080 ms on namenode (executor driver) (63/121)\n",
      "  Running task 66.0 in stage 0.0 (TID 66)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:8858370048+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 7472, boot = -89, init = 98, finish = 7463\n",
      "  Finished task 63.0 in stage 0.0 (TID 63). 1900 bytes result sent to driver\n",
      "  Starting task 67.0 in stage 0.0 (TID 67) (namenode, executor driver, partition 67, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 63.0 in stage 0.0 (TID 63) in 7546 ms on namenode (executor driver) (64/121)\n",
      "  Running task 67.0 in stage 0.0 (TID 67)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:8992587776+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 7607, boot = -27, init = 34, finish = 7600\n",
      "  Finished task 65.0 in stage 0.0 (TID 65). 1900 bytes result sent to driver\n",
      "  Starting task 68.0 in stage 0.0 (TID 68) (namenode, executor driver, partition 68, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 68.0 in stage 0.0 (TID 68)\n",
      "  Finished task 65.0 in stage 0.0 (TID 65) in 7659 ms on namenode (executor driver) (65/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:9126805504+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 8339, boot = -45, init = 49, finish = 8335\n",
      "  Finished task 64.0 in stage 0.0 (TID 64). 1900 bytes result sent to driver\n",
      "  Starting task 69.0 in stage 0.0 (TID 69) (namenode, executor driver, partition 69, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 69.0 in stage 0.0 (TID 69)\n",
      "  Finished task 64.0 in stage 0.0 (TID 64) in 8406 ms on namenode (executor driver) (66/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:9261023232+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 7647, boot = -73, init = 86, finish = 7634\n",
      "  Finished task 66.0 in stage 0.0 (TID 66). 1900 bytes result sent to driver\n",
      "  Starting task 70.0 in stage 0.0 (TID 70) (namenode, executor driver, partition 70, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 66.0 in stage 0.0 (TID 66) in 7725 ms on namenode (executor driver) (67/121)\n",
      "  Running task 70.0 in stage 0.0 (TID 70)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:9395240960+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 7589, boot = -63, init = 65, finish = 7587\n",
      "  Finished task 67.0 in stage 0.0 (TID 67). 1900 bytes result sent to driver\n",
      "  Starting task 71.0 in stage 0.0 (TID 71) (namenode, executor driver, partition 71, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 67.0 in stage 0.0 (TID 67) in 7702 ms on namenode (executor driver) (68/121)\n",
      "  Running task 71.0 in stage 0.0 (TID 71)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:9529458688+134217728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 7438, boot = -47, init = 53, finish = 7432\n",
      "  Finished task 68.0 in stage 0.0 (TID 68). 1900 bytes result sent to driver\n",
      "  Starting task 72.0 in stage 0.0 (TID 72) (namenode, executor driver, partition 72, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 72.0 in stage 0.0 (TID 72)\n",
      "  Finished task 68.0 in stage 0.0 (TID 68) in 7535 ms on namenode (executor driver) (69/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:9663676416+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 8038, boot = -66, init = 82, finish = 8022\n",
      "  Finished task 69.0 in stage 0.0 (TID 69). 1900 bytes result sent to driver\n",
      "  Starting task 73.0 in stage 0.0 (TID 73) (namenode, executor driver, partition 73, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 73.0 in stage 0.0 (TID 73)\n",
      "  Finished task 69.0 in stage 0.0 (TID 69) in 8093 ms on namenode (executor driver) (70/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:9797894144+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 7966, boot = -32, init = 43, finish = 7955\n",
      "  Finished task 70.0 in stage 0.0 (TID 70). 1900 bytes result sent to driver\n",
      "  Starting task 74.0 in stage 0.0 (TID 74) (namenode, executor driver, partition 74, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 74.0 in stage 0.0 (TID 74)\n",
      "  Finished task 70.0 in stage 0.0 (TID 70) in 8013 ms on namenode (executor driver) (71/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:9932111872+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6978, boot = -106, init = 128, finish = 6956\n",
      "  Finished task 71.0 in stage 0.0 (TID 71). 1900 bytes result sent to driver\n",
      "  Starting task 75.0 in stage 0.0 (TID 75) (namenode, executor driver, partition 75, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 71.0 in stage 0.0 (TID 71) in 7076 ms on namenode (executor driver) (72/121)\n",
      "  Running task 75.0 in stage 0.0 (TID 75)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:10066329600+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6763, boot = -54, init = 60, finish = 6757\n",
      "  Finished task 73.0 in stage 0.0 (TID 73). 1900 bytes result sent to driver\n",
      "  Starting task 76.0 in stage 0.0 (TID 76) (namenode, executor driver, partition 76, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 73.0 in stage 0.0 (TID 73) in 6830 ms on namenode (executor driver) (73/121)\n",
      "  Running task 76.0 in stage 0.0 (TID 76)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:10200547328+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 8107, boot = -70, init = 74, finish = 8103\n",
      "  Finished task 72.0 in stage 0.0 (TID 72). 1900 bytes result sent to driver\n",
      "  Starting task 77.0 in stage 0.0 (TID 77) (namenode, executor driver, partition 77, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 72.0 in stage 0.0 (TID 72) in 8153 ms on namenode (executor driver) (74/121)\n",
      "  Running task 77.0 in stage 0.0 (TID 77)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:10334765056+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 8541, boot = -21, init = 49, finish = 8513\n",
      "  Finished task 74.0 in stage 0.0 (TID 74). 1900 bytes result sent to driver\n",
      "  Starting task 78.0 in stage 0.0 (TID 78) (namenode, executor driver, partition 78, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 74.0 in stage 0.0 (TID 74) in 8602 ms on namenode (executor driver) (75/121)\n",
      "  Running task 78.0 in stage 0.0 (TID 78)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:10468982784+134217728\n",
      "  Times: total = 7415, boot = -93, init = 104, finish = 7404\n",
      "  Finished task 75.0 in stage 0.0 (TID 75). 1900 bytes result sent to driver\n",
      "  Starting task 79.0 in stage 0.0 (TID 79) (namenode, executor driver, partition 79, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 79.0 in stage 0.0 (TID 79)\n",
      "  Finished task 75.0 in stage 0.0 (TID 75) in 7560 ms on namenode (executor driver) (76/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:10603200512+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 7856, boot = -40, init = 58, finish = 7838\n",
      "  Finished task 76.0 in stage 0.0 (TID 76). 1900 bytes result sent to driver\n",
      "  Starting task 80.0 in stage 0.0 (TID 80) (namenode, executor driver, partition 80, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 80.0 in stage 0.0 (TID 80)\n",
      "  Finished task 76.0 in stage 0.0 (TID 76) in 7910 ms on namenode (executor driver) (77/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:10737418240+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 7471, boot = -86, init = 96, finish = 7461\n",
      "  Finished task 77.0 in stage 0.0 (TID 77). 1900 bytes result sent to driver\n",
      "  Starting task 81.0 in stage 0.0 (TID 81) (namenode, executor driver, partition 81, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 81.0 in stage 0.0 (TID 81)\n",
      "  Finished task 77.0 in stage 0.0 (TID 77) in 7576 ms on namenode (executor driver) (78/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:10871635968+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 8021, boot = -90, init = 100, finish = 8011\n",
      "  Finished task 79.0 in stage 0.0 (TID 79). 1900 bytes result sent to driver\n",
      "  Starting task 82.0 in stage 0.0 (TID 82) (namenode, executor driver, partition 82, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 79.0 in stage 0.0 (TID 79) in 8056 ms on namenode (executor driver) (79/121)\n",
      "  Running task 82.0 in stage 0.0 (TID 82)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:11005853696+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 8438, boot = -64, init = 79, finish = 8423\n",
      "  Finished task 78.0 in stage 0.0 (TID 78). 1900 bytes result sent to driver\n",
      "  Starting task 83.0 in stage 0.0 (TID 83) (namenode, executor driver, partition 83, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 83.0 in stage 0.0 (TID 83)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:11140071424+134217728\n",
      "  Finished task 78.0 in stage 0.0 (TID 78) in 8661 ms on namenode (executor driver) (80/121)\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 7402, boot = -21, init = 31, finish = 7392\n",
      "  Finished task 81.0 in stage 0.0 (TID 81). 1900 bytes result sent to driver\n",
      "  Starting task 84.0 in stage 0.0 (TID 84) (namenode, executor driver, partition 84, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 84.0 in stage 0.0 (TID 84)\n",
      "  Finished task 81.0 in stage 0.0 (TID 81) in 7467 ms on namenode (executor driver) (81/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:11274289152+134217728\n",
      "  Times: total = 8109, boot = -38, init = 74, finish = 8073\n",
      "  Finished task 80.0 in stage 0.0 (TID 80). 1900 bytes result sent to driver\n",
      "  Starting task 85.0 in stage 0.0 (TID 85) (namenode, executor driver, partition 85, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 80.0 in stage 0.0 (TID 80) in 8173 ms on namenode (executor driver) (82/121)\n",
      "  Running task 85.0 in stage 0.0 (TID 85)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:11408506880+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 8102, boot = -143, init = 157, finish = 8088\n",
      "  Finished task 83.0 in stage 0.0 (TID 83). 1900 bytes result sent to driver\n",
      "  Starting task 86.0 in stage 0.0 (TID 86) (namenode, executor driver, partition 86, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 86.0 in stage 0.0 (TID 86)\n",
      "  Finished task 83.0 in stage 0.0 (TID 83) in 8167 ms on namenode (executor driver) (83/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:11542724608+134217728\n",
      "  Times: total = 8789, boot = -59, init = 61, finish = 8787\n",
      "  Finished task 82.0 in stage 0.0 (TID 82). 1900 bytes result sent to driver\n",
      "  Starting task 87.0 in stage 0.0 (TID 87) (namenode, executor driver, partition 87, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 82.0 in stage 0.0 (TID 82) in 8881 ms on namenode (executor driver) (84/121)\n",
      "  Running task 87.0 in stage 0.0 (TID 87)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:11676942336+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 7636, boot = -46, init = 60, finish = 7622\n",
      "  Finished task 85.0 in stage 0.0 (TID 85). 1900 bytes result sent to driver\n",
      "  Starting task 88.0 in stage 0.0 (TID 88) (namenode, executor driver, partition 88, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 85.0 in stage 0.0 (TID 85) in 7677 ms on namenode (executor driver) (85/121)\n",
      "  Running task 88.0 in stage 0.0 (TID 88)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:11811160064+134217728\n",
      "  Times: total = 8113, boot = -26, init = 44, finish = 8095\n",
      "  Finished task 84.0 in stage 0.0 (TID 84). 1900 bytes result sent to driver\n",
      "  Starting task 89.0 in stage 0.0 (TID 89) (namenode, executor driver, partition 89, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 89.0 in stage 0.0 (TID 89)\n",
      "  Finished task 84.0 in stage 0.0 (TID 84) in 8247 ms on namenode (executor driver) (86/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:11945377792+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 7642, boot = -51, init = 54, finish = 7639\n",
      "  Finished task 86.0 in stage 0.0 (TID 86). 1900 bytes result sent to driver\n",
      "  Starting task 90.0 in stage 0.0 (TID 90) (namenode, executor driver, partition 90, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 86.0 in stage 0.0 (TID 86) in 7722 ms on namenode (executor driver) (87/121)\n",
      "  Running task 90.0 in stage 0.0 (TID 90)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:12079595520+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 8592, boot = -56, init = 58, finish = 8590\n",
      "  Finished task 87.0 in stage 0.0 (TID 87). 1900 bytes result sent to driver\n",
      "  Starting task 91.0 in stage 0.0 (TID 91) (namenode, executor driver, partition 91, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 87.0 in stage 0.0 (TID 87) in 8677 ms on namenode (executor driver) (88/121)\n",
      "  Running task 91.0 in stage 0.0 (TID 91)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:12213813248+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 8129, boot = -43, init = 53, finish = 8119\n",
      "  Finished task 88.0 in stage 0.0 (TID 88). 1900 bytes result sent to driver\n",
      "  Starting task 92.0 in stage 0.0 (TID 92) (namenode, executor driver, partition 92, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 88.0 in stage 0.0 (TID 88) in 8198 ms on namenode (executor driver) (89/121)\n",
      "  Running task 92.0 in stage 0.0 (TID 92)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:12348030976+134217728\n",
      "  Times: total = 7996, boot = -88, init = 101, finish = 7983\n",
      "  Finished task 89.0 in stage 0.0 (TID 89). 1900 bytes result sent to driver\n",
      "  Starting task 93.0 in stage 0.0 (TID 93) (namenode, executor driver, partition 93, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 89.0 in stage 0.0 (TID 89) in 8097 ms on namenode (executor driver) (90/121)\n",
      "  Running task 93.0 in stage 0.0 (TID 93)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:12482248704+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 8112, boot = -52, init = 54, finish = 8110\n",
      "  Finished task 90.0 in stage 0.0 (TID 90). 1900 bytes result sent to driver\n",
      "  Starting task 94.0 in stage 0.0 (TID 94) (namenode, executor driver, partition 94, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 94.0 in stage 0.0 (TID 94)\n",
      "  Finished task 90.0 in stage 0.0 (TID 90) in 8163 ms on namenode (executor driver) (91/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:12616466432+134217728\n",
      "  Times: total = 7839, boot = -43, init = 45, finish = 7837\n",
      "  Finished task 91.0 in stage 0.0 (TID 91). 1900 bytes result sent to driver\n",
      "  Starting task 95.0 in stage 0.0 (TID 95) (namenode, executor driver, partition 95, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 91.0 in stage 0.0 (TID 91) in 7897 ms on namenode (executor driver) (92/121)\n",
      "  Running task 95.0 in stage 0.0 (TID 95)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:12750684160+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 7489, boot = -20, init = 27, finish = 7482\n",
      "  Finished task 92.0 in stage 0.0 (TID 92). 1900 bytes result sent to driver\n",
      "  Starting task 96.0 in stage 0.0 (TID 96) (namenode, executor driver, partition 96, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 92.0 in stage 0.0 (TID 92) in 7589 ms on namenode (executor driver) (93/121)\n",
      "  Running task 96.0 in stage 0.0 (TID 96)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:12884901888+134217728\n",
      "  Times: total = 7957, boot = -101, init = 115, finish = 7943\n",
      "  Finished task 93.0 in stage 0.0 (TID 93). 1900 bytes result sent to driver\n",
      "  Starting task 97.0 in stage 0.0 (TID 97) (namenode, executor driver, partition 97, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 97.0 in stage 0.0 (TID 97)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:13019119616+134217728\n",
      "  Finished task 93.0 in stage 0.0 (TID 93) in 8045 ms on namenode (executor driver) (94/121)\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 8012, boot = -33, init = 38, finish = 8007\n",
      "  Finished task 94.0 in stage 0.0 (TID 94). 1900 bytes result sent to driver\n",
      "  Starting task 98.0 in stage 0.0 (TID 98) (namenode, executor driver, partition 98, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 98.0 in stage 0.0 (TID 98)\n",
      "  Finished task 94.0 in stage 0.0 (TID 94) in 8320 ms on namenode (executor driver) (95/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:13153337344+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 7578, boot = -27, init = 30, finish = 7575\n",
      "  Finished task 95.0 in stage 0.0 (TID 95). 1900 bytes result sent to driver\n",
      "  Starting task 99.0 in stage 0.0 (TID 99) (namenode, executor driver, partition 99, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 95.0 in stage 0.0 (TID 95) in 7650 ms on namenode (executor driver) (96/121)\n",
      "  Running task 99.0 in stage 0.0 (TID 99)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:13287555072+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 8215, boot = -79, init = 88, finish = 8206\n",
      "  Finished task 96.0 in stage 0.0 (TID 96). 1900 bytes result sent to driver\n",
      "  Starting task 100.0 in stage 0.0 (TID 100) (namenode, executor driver, partition 100, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 100.0 in stage 0.0 (TID 100)\n",
      "  Finished task 96.0 in stage 0.0 (TID 96) in 8292 ms on namenode (executor driver) (97/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:13421772800+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 8040, boot = -74, init = 76, finish = 8038\n",
      "  Finished task 97.0 in stage 0.0 (TID 97). 1900 bytes result sent to driver\n",
      "  Starting task 101.0 in stage 0.0 (TID 101) (namenode, executor driver, partition 101, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 101.0 in stage 0.0 (TID 101)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:13555990528+134217728\n",
      "  Finished task 97.0 in stage 0.0 (TID 97) in 8179 ms on namenode (executor driver) (98/121)\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 7188, boot = -296, init = 312, finish = 7172\n",
      "  Finished task 98.0 in stage 0.0 (TID 98). 1900 bytes result sent to driver\n",
      "  Starting task 102.0 in stage 0.0 (TID 102) (namenode, executor driver, partition 102, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 102.0 in stage 0.0 (TID 102)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:13690208256+134217728\n",
      "  Finished task 98.0 in stage 0.0 (TID 98) in 7243 ms on namenode (executor driver) (99/121)\n",
      "  Times: total = 7631, boot = -63, init = 66, finish = 7628\n",
      "  Finished task 99.0 in stage 0.0 (TID 99). 1900 bytes result sent to driver\n",
      "  Starting task 103.0 in stage 0.0 (TID 103) (namenode, executor driver, partition 103, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 103.0 in stage 0.0 (TID 103)\n",
      "  Finished task 99.0 in stage 0.0 (TID 99) in 7703 ms on namenode (executor driver) (100/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:13824425984+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 7514, boot = -61, init = 80, finish = 7495\n",
      "  Finished task 100.0 in stage 0.0 (TID 100). 1900 bytes result sent to driver\n",
      "  Starting task 104.0 in stage 0.0 (TID 104) (namenode, executor driver, partition 104, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 100.0 in stage 0.0 (TID 100) in 7563 ms on namenode (executor driver) (101/121)\n",
      "  Running task 104.0 in stage 0.0 (TID 104)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:13958643712+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 8942, boot = -104, init = 125, finish = 8921\n",
      "  Finished task 101.0 in stage 0.0 (TID 101). 1900 bytes result sent to driver\n",
      "  Starting task 105.0 in stage 0.0 (TID 105) (namenode, executor driver, partition 105, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 101.0 in stage 0.0 (TID 101) in 9016 ms on namenode (executor driver) (102/121)\n",
      "  Running task 105.0 in stage 0.0 (TID 105)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:14092861440+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6967, boot = -56, init = 58, finish = 6965\n",
      "  Finished task 103.0 in stage 0.0 (TID 103). 1900 bytes result sent to driver\n",
      "  Starting task 106.0 in stage 0.0 (TID 106) (namenode, executor driver, partition 106, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 103.0 in stage 0.0 (TID 103) in 7005 ms on namenode (executor driver) (103/121)\n",
      "  Running task 106.0 in stage 0.0 (TID 106)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:14227079168+134217728\n",
      "  Times: total = 8171, boot = -22, init = 24, finish = 8169\n",
      "  Finished task 102.0 in stage 0.0 (TID 102). 1900 bytes result sent to driver\n",
      "  Starting task 107.0 in stage 0.0 (TID 107) (namenode, executor driver, partition 107, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 102.0 in stage 0.0 (TID 102) in 8232 ms on namenode (executor driver) (104/121)\n",
      "  Running task 107.0 in stage 0.0 (TID 107)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:14361296896+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 7747, boot = -31, init = 34, finish = 7744\n",
      "  Finished task 104.0 in stage 0.0 (TID 104). 1900 bytes result sent to driver\n",
      "  Starting task 108.0 in stage 0.0 (TID 108) (namenode, executor driver, partition 108, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 104.0 in stage 0.0 (TID 104) in 7818 ms on namenode (executor driver) (105/121)\n",
      "  Running task 108.0 in stage 0.0 (TID 108)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:14495514624+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 7866, boot = -49, init = 54, finish = 7861\n",
      "  Finished task 105.0 in stage 0.0 (TID 105). 1900 bytes result sent to driver\n",
      "  Starting task 109.0 in stage 0.0 (TID 109) (namenode, executor driver, partition 109, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 105.0 in stage 0.0 (TID 105) in 7923 ms on namenode (executor driver) (106/121)\n",
      "  Running task 109.0 in stage 0.0 (TID 109)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:14629732352+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 7508, boot = -30, init = 72, finish = 7466\n",
      "  Finished task 106.0 in stage 0.0 (TID 106). 1900 bytes result sent to driver\n",
      "  Starting task 110.0 in stage 0.0 (TID 110) (namenode, executor driver, partition 110, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 106.0 in stage 0.0 (TID 106) in 7557 ms on namenode (executor driver) (107/121)\n",
      "  Running task 110.0 in stage 0.0 (TID 110)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:14763950080+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 7325, boot = -42, init = 44, finish = 7323\n",
      "  Finished task 107.0 in stage 0.0 (TID 107). 1900 bytes result sent to driver\n",
      "  Starting task 111.0 in stage 0.0 (TID 111) (namenode, executor driver, partition 111, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 111.0 in stage 0.0 (TID 111)\n",
      "  Finished task 107.0 in stage 0.0 (TID 107) in 7375 ms on namenode (executor driver) (108/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:14898167808+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 7488, boot = -30, init = 33, finish = 7485\n",
      "  Finished task 108.0 in stage 0.0 (TID 108). 1900 bytes result sent to driver\n",
      "  Starting task 112.0 in stage 0.0 (TID 112) (namenode, executor driver, partition 112, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 112.0 in stage 0.0 (TID 112)\n",
      "  Finished task 108.0 in stage 0.0 (TID 108) in 7538 ms on namenode (executor driver) (109/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:15032385536+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 8695, boot = -33, init = 35, finish = 8693\n",
      "  Finished task 109.0 in stage 0.0 (TID 109). 1900 bytes result sent to driver\n",
      "  Starting task 113.0 in stage 0.0 (TID 113) (namenode, executor driver, partition 113, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 113.0 in stage 0.0 (TID 113)\n",
      "  Finished task 109.0 in stage 0.0 (TID 109) in 8755 ms on namenode (executor driver) (110/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:15166603264+134217728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 7897, boot = -42, init = 46, finish = 7893\n",
      "  Times: total = 7712, boot = -25, init = 27, finish = 7710\n",
      "  Finished task 110.0 in stage 0.0 (TID 110). 1900 bytes result sent to driver\n",
      "  Starting task 114.0 in stage 0.0 (TID 114) (namenode, executor driver, partition 114, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 110.0 in stage 0.0 (TID 110) in 8153 ms on namenode (executor driver) (111/121)\n",
      "  Running task 114.0 in stage 0.0 (TID 114)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:15300820992+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Finished task 111.0 in stage 0.0 (TID 111). 1900 bytes result sent to driver\n",
      "  Starting task 115.0 in stage 0.0 (TID 115) (namenode, executor driver, partition 115, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 115.0 in stage 0.0 (TID 115)\n",
      "  Finished task 111.0 in stage 0.0 (TID 111) in 7909 ms on namenode (executor driver) (112/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:15435038720+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 7784, boot = -20, init = 22, finish = 7782\n",
      "  Finished task 112.0 in stage 0.0 (TID 112). 1900 bytes result sent to driver\n",
      "  Starting task 116.0 in stage 0.0 (TID 116) (namenode, executor driver, partition 116, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 112.0 in stage 0.0 (TID 112) in 7830 ms on namenode (executor driver) (113/121)\n",
      "  Running task 116.0 in stage 0.0 (TID 116)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:15569256448+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 7612, boot = -55, init = 57, finish = 7610\n",
      "  Finished task 113.0 in stage 0.0 (TID 113). 1900 bytes result sent to driver\n",
      "  Starting task 117.0 in stage 0.0 (TID 117) (namenode, executor driver, partition 117, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 113.0 in stage 0.0 (TID 113) in 7685 ms on namenode (executor driver) (114/121)\n",
      "  Running task 117.0 in stage 0.0 (TID 117)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:15703474176+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 7335, boot = -277, init = 281, finish = 7331\n",
      "  Finished task 114.0 in stage 0.0 (TID 114). 1900 bytes result sent to driver\n",
      "  Starting task 118.0 in stage 0.0 (TID 118) (namenode, executor driver, partition 118, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 118.0 in stage 0.0 (TID 118)\n",
      "  Finished task 114.0 in stage 0.0 (TID 114) in 7451 ms on namenode (executor driver) (115/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:15837691904+134217728\n",
      "  Times: total = 8620, boot = -205, init = 210, finish = 8615\n",
      "  Finished task 115.0 in stage 0.0 (TID 115). 1900 bytes result sent to driver\n",
      "  Starting task 119.0 in stage 0.0 (TID 119) (namenode, executor driver, partition 119, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 119.0 in stage 0.0 (TID 119)\n",
      "  Finished task 115.0 in stage 0.0 (TID 115) in 8678 ms on namenode (executor driver) (116/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:15971909632+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 7833, boot = -70, init = 77, finish = 7826\n",
      "  Finished task 116.0 in stage 0.0 (TID 116). 1900 bytes result sent to driver\n",
      "  Starting task 120.0 in stage 0.0 (TID 120) (namenode, executor driver, partition 120, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 116.0 in stage 0.0 (TID 116) in 7921 ms on namenode (executor driver) (117/121)\n",
      "  Running task 120.0 in stage 0.0 (TID 120)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:16106127360+79598254\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 8439, boot = -49, init = 54, finish = 8434\n",
      "  Finished task 117.0 in stage 0.0 (TID 117). 1900 bytes result sent to driver\n",
      "  Finished task 117.0 in stage 0.0 (TID 117) in 8507 ms on namenode (executor driver) (118/121)\n",
      "  Times: total = 4592, boot = -23, init = 37, finish = 4578\n",
      "  Finished task 120.0 in stage 0.0 (TID 120). 1900 bytes result sent to driver\n",
      "  Finished task 120.0 in stage 0.0 (TID 120) in 4629 ms on namenode (executor driver) (119/121)\n",
      "  Times: total = 7584, boot = -43, init = 54, finish = 7573\n",
      "  Finished task 118.0 in stage 0.0 (TID 118). 1900 bytes result sent to driver\n",
      "  Finished task 118.0 in stage 0.0 (TID 118) in 7632 ms on namenode (executor driver) (120/121)\n",
      "  Times: total = 7661, boot = -27, init = 30, finish = 7658\n",
      "  Finished task 119.0 in stage 0.0 (TID 119). 1900 bytes result sent to driver\n",
      "  Finished task 119.0 in stage 0.0 (TID 119) in 7705 ms on namenode (executor driver) (121/121)\n",
      "  Removed TaskSet 0.0, whose tasks have all completed, from pool \n",
      "  ShuffleMapStage 0 (groupBy at /home/ubuntu/.local/lib/python3.8/site-packages/mrjob/spark/harness.py:539) finished in 244.780 s\n",
      "  looking for newly runnable stages\n",
      "  running: Set()\n",
      "  waiting: Set(ShuffleMapStage 1, ResultStage 2)\n",
      "  failed: Set()\n",
      "  Submitting ShuffleMapStage 1 (PairwiseRDD[7] at groupBy at /home/ubuntu/.local/lib/python3.8/site-packages/mrjob/spark/harness.py:539), which has no missing parents\n",
      "  Block broadcast_2 stored as values in memory (estimated size 17.5 KiB, free 365.8 MiB)\n",
      "  Block broadcast_2_piece0 stored as bytes in memory (estimated size 10.0 KiB, free 365.8 MiB)\n",
      "  Added broadcast_2_piece0 in memory on namenode:32797 (size: 10.0 KiB, free: 366.2 MiB)\n",
      "  Created broadcast 2 from broadcast at DAGScheduler.scala:1427\n",
      "  Submitting 121 missing tasks from ShuffleMapStage 1 (PairwiseRDD[7] at groupBy at /home/ubuntu/.local/lib/python3.8/site-packages/mrjob/spark/harness.py:539) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))\n",
      "  Adding task set 1.0 with 121 tasks resource profile 0\n",
      "  Starting task 0.0 in stage 1.0 (TID 121) (namenode, executor driver, partition 0, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Starting task 1.0 in stage 1.0 (TID 122) (namenode, executor driver, partition 1, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Starting task 2.0 in stage 1.0 (TID 123) (namenode, executor driver, partition 2, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Starting task 3.0 in stage 1.0 (TID 124) (namenode, executor driver, partition 3, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 0.0 in stage 1.0 (TID 121)\n",
      "  Running task 1.0 in stage 1.0 (TID 122)\n",
      "  Running task 2.0 in stage 1.0 (TID 123)\n",
      "  Running task 3.0 in stage 1.0 (TID 124)\n",
      "  Getting 121 (4.7 MiB) non-empty blocks including 121 (4.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Getting 121 (4.7 MiB) non-empty blocks including 121 (4.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Getting 121 (4.6 MiB) non-empty blocks including 121 (4.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 24 ms\n",
      "  Getting 121 (4.7 MiB) non-empty blocks including 121 (4.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 25 ms\n",
      "  Started 0 remote fetches in 21 ms\n",
      "  Started 0 remote fetches in 26 ms\n",
      "  Times: total = 5897, boot = -2667, init = 2691, finish = 5873\n",
      "  Finished task 0.0 in stage 1.0 (TID 121). 2115 bytes result sent to driver\n",
      "  Starting task 4.0 in stage 1.0 (TID 125) (namenode, executor driver, partition 4, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 0.0 in stage 1.0 (TID 121) in 6024 ms on namenode (executor driver) (1/121)\n",
      "  Running task 4.0 in stage 1.0 (TID 125)\n",
      "  Getting 121 (4.7 MiB) non-empty blocks including 121 (4.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Started 0 remote fetches in 4 ms\n",
      "  Times: total = 6038, boot = -193, init = 212, finish = 6019\n",
      "  Finished task 3.0 in stage 1.0 (TID 124). 2115 bytes result sent to driver\n",
      "  Starting task 5.0 in stage 1.0 (TID 126) (namenode, executor driver, partition 5, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 3.0 in stage 1.0 (TID 124) in 6171 ms on namenode (executor driver) (2/121)\n",
      "  Running task 5.0 in stage 1.0 (TID 126)\n",
      "  Getting 121 (4.6 MiB) non-empty blocks including 121 (4.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 12 ms\n",
      "  Times: total = 6094, boot = -1546, init = 1578, finish = 6062\n",
      "  Finished task 1.0 in stage 1.0 (TID 122). 2115 bytes result sent to driver\n",
      "  Starting task 6.0 in stage 1.0 (TID 127) (namenode, executor driver, partition 6, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 6.0 in stage 1.0 (TID 127)\n",
      "  Finished task 1.0 in stage 1.0 (TID 122) in 6244 ms on namenode (executor driver) (3/121)\n",
      "  Getting 121 (4.7 MiB) non-empty blocks including 121 (4.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 6 ms\n",
      "  Times: total = 6169, boot = -1676, init = 1714, finish = 6131\n",
      "  Finished task 2.0 in stage 1.0 (TID 123). 2115 bytes result sent to driver\n",
      "  Starting task 7.0 in stage 1.0 (TID 128) (namenode, executor driver, partition 7, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 2.0 in stage 1.0 (TID 123) in 6318 ms on namenode (executor driver) (4/121)\n",
      "  Running task 7.0 in stage 1.0 (TID 128)\n",
      "  Getting 121 (4.7 MiB) non-empty blocks including 121 (4.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 3 ms\n",
      "  Times: total = 5978, boot = -37, init = 39, finish = 5976\n",
      "  Finished task 4.0 in stage 1.0 (TID 125). 2072 bytes result sent to driver\n",
      "  Starting task 8.0 in stage 1.0 (TID 129) (namenode, executor driver, partition 8, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 4.0 in stage 1.0 (TID 125) in 6033 ms on namenode (executor driver) (5/121)\n",
      "  Running task 8.0 in stage 1.0 (TID 129)\n",
      "  Getting 121 (4.7 MiB) non-empty blocks including 121 (4.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Times: total = 5817, boot = -71, init = 74, finish = 5814\n",
      "  Finished task 5.0 in stage 1.0 (TID 126). 2072 bytes result sent to driver\n",
      "  Starting task 9.0 in stage 1.0 (TID 130) (namenode, executor driver, partition 9, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 9.0 in stage 1.0 (TID 130)\n",
      "  Finished task 5.0 in stage 1.0 (TID 126) in 5947 ms on namenode (executor driver) (6/121)\n",
      "  Getting 121 (4.6 MiB) non-empty blocks including 121 (4.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Times: total = 6005, boot = -66, init = 81, finish = 5990\n",
      "  Finished task 6.0 in stage 1.0 (TID 127). 2072 bytes result sent to driver\n",
      "  Starting task 10.0 in stage 1.0 (TID 131) (namenode, executor driver, partition 10, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 6.0 in stage 1.0 (TID 127) in 6061 ms on namenode (executor driver) (7/121)\n",
      "  Running task 10.0 in stage 1.0 (TID 131)\n",
      "  Getting 121 (4.7 MiB) non-empty blocks including 121 (4.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Times: total = 6107, boot = -37, init = 64, finish = 6080\n",
      "  Finished task 7.0 in stage 1.0 (TID 128). 2072 bytes result sent to driver\n",
      "  Starting task 11.0 in stage 1.0 (TID 132) (namenode, executor driver, partition 11, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 7.0 in stage 1.0 (TID 128) in 6156 ms on namenode (executor driver) (8/121)\n",
      "  Running task 11.0 in stage 1.0 (TID 132)\n",
      "  Getting 121 (4.7 MiB) non-empty blocks including 121 (4.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Times: total = 5746, boot = -32, init = 34, finish = 5744\n",
      "  Finished task 8.0 in stage 1.0 (TID 129). 2115 bytes result sent to driver\n",
      "  Starting task 12.0 in stage 1.0 (TID 133) (namenode, executor driver, partition 12, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 8.0 in stage 1.0 (TID 129) in 5792 ms on namenode (executor driver) (9/121)\n",
      "  Running task 12.0 in stage 1.0 (TID 133)\n",
      "  Getting 121 (4.7 MiB) non-empty blocks including 121 (4.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Times: total = 5970, boot = -66, init = 72, finish = 5964\n",
      "  Finished task 9.0 in stage 1.0 (TID 130). 2115 bytes result sent to driver\n",
      "  Starting task 13.0 in stage 1.0 (TID 134) (namenode, executor driver, partition 13, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 13.0 in stage 1.0 (TID 134)\n",
      "  Finished task 9.0 in stage 1.0 (TID 130) in 6007 ms on namenode (executor driver) (10/121)\n",
      "  Getting 121 (4.7 MiB) non-empty blocks including 121 (4.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Times: total = 5955, boot = -35, init = 37, finish = 5953\n",
      "  Finished task 10.0 in stage 1.0 (TID 131). 2115 bytes result sent to driver\n",
      "  Starting task 14.0 in stage 1.0 (TID 135) (namenode, executor driver, partition 14, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 10.0 in stage 1.0 (TID 131) in 6015 ms on namenode (executor driver) (11/121)\n",
      "  Running task 14.0 in stage 1.0 (TID 135)\n",
      "  Getting 121 (4.7 MiB) non-empty blocks including 121 (4.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Times: total = 6033, boot = -34, init = 41, finish = 6026\n",
      "  Finished task 11.0 in stage 1.0 (TID 132). 2115 bytes result sent to driver\n",
      "  Starting task 15.0 in stage 1.0 (TID 136) (namenode, executor driver, partition 15, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 11.0 in stage 1.0 (TID 132) in 6075 ms on namenode (executor driver) (12/121)\n",
      "  Running task 15.0 in stage 1.0 (TID 136)\n",
      "  Getting 121 (4.7 MiB) non-empty blocks including 121 (4.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Times: total = 5731, boot = -38, init = 47, finish = 5722\n",
      "  Finished task 12.0 in stage 1.0 (TID 133). 2072 bytes result sent to driver\n",
      "  Starting task 16.0 in stage 1.0 (TID 137) (namenode, executor driver, partition 16, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 12.0 in stage 1.0 (TID 133) in 5766 ms on namenode (executor driver) (13/121)\n",
      "  Running task 16.0 in stage 1.0 (TID 137)\n",
      "  Getting 121 (4.7 MiB) non-empty blocks including 121 (4.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Times: total = 5936, boot = -15, init = 17, finish = 5934\n",
      "  Finished task 13.0 in stage 1.0 (TID 134). 2072 bytes result sent to driver\n",
      "  Starting task 17.0 in stage 1.0 (TID 138) (namenode, executor driver, partition 17, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 17.0 in stage 1.0 (TID 138)\n",
      "  Finished task 13.0 in stage 1.0 (TID 134) in 5961 ms on namenode (executor driver) (14/121)\n",
      "  Getting 121 (4.6 MiB) non-empty blocks including 121 (4.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 6036, boot = -31, init = 33, finish = 6034\n",
      "  Finished task 14.0 in stage 1.0 (TID 135). 2072 bytes result sent to driver\n",
      "  Starting task 18.0 in stage 1.0 (TID 139) (namenode, executor driver, partition 18, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 14.0 in stage 1.0 (TID 135) in 6073 ms on namenode (executor driver) (15/121)\n",
      "  Running task 18.0 in stage 1.0 (TID 139)\n",
      "  Getting 121 (4.7 MiB) non-empty blocks including 121 (4.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Started 0 remote fetches in 5 ms\n",
      "  Times: total = 5970, boot = -28, init = 37, finish = 5961\n",
      "  Finished task 15.0 in stage 1.0 (TID 136). 2072 bytes result sent to driver\n",
      "  Starting task 19.0 in stage 1.0 (TID 140) (namenode, executor driver, partition 19, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 15.0 in stage 1.0 (TID 136) in 6017 ms on namenode (executor driver) (16/121)\n",
      "  Running task 19.0 in stage 1.0 (TID 140)\n",
      "  Getting 121 (4.6 MiB) non-empty blocks including 121 (4.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 5850, boot = -24, init = 34, finish = 5840\n",
      "  Finished task 16.0 in stage 1.0 (TID 137). 2072 bytes result sent to driver\n",
      "  Starting task 20.0 in stage 1.0 (TID 141) (namenode, executor driver, partition 20, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 16.0 in stage 1.0 (TID 137) in 5895 ms on namenode (executor driver) (17/121)\n",
      "  Running task 20.0 in stage 1.0 (TID 141)\n",
      "  Getting 121 (4.7 MiB) non-empty blocks including 121 (4.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Times: total = 5825, boot = -17, init = 19, finish = 5823\n",
      "  Finished task 17.0 in stage 1.0 (TID 138). 2072 bytes result sent to driver\n",
      "  Starting task 21.0 in stage 1.0 (TID 142) (namenode, executor driver, partition 21, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 21.0 in stage 1.0 (TID 142)\n",
      "  Finished task 17.0 in stage 1.0 (TID 138) in 5860 ms on namenode (executor driver) (18/121)\n",
      "  Getting 121 (4.7 MiB) non-empty blocks including 121 (4.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Times: total = 5865, boot = -30, init = 32, finish = 5863\n",
      "  Finished task 19.0 in stage 1.0 (TID 140). 2115 bytes result sent to driver\n",
      "  Starting task 22.0 in stage 1.0 (TID 143) (namenode, executor driver, partition 22, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 19.0 in stage 1.0 (TID 140) in 5906 ms on namenode (executor driver) (19/121)\n",
      "  Running task 22.0 in stage 1.0 (TID 143)\n",
      "  Getting 121 (4.7 MiB) non-empty blocks including 121 (4.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 6526, boot = -32, init = 34, finish = 6524\n",
      "  Finished task 18.0 in stage 1.0 (TID 139). 2115 bytes result sent to driver\n",
      "  Starting task 23.0 in stage 1.0 (TID 144) (namenode, executor driver, partition 23, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 18.0 in stage 1.0 (TID 139) in 6569 ms on namenode (executor driver) (20/121)\n",
      "  Running task 23.0 in stage 1.0 (TID 144)\n",
      "  Getting 121 (4.7 MiB) non-empty blocks including 121 (4.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 6 ms\n",
      "  Times: total = 5836, boot = -16, init = 18, finish = 5834\n",
      "  Finished task 20.0 in stage 1.0 (TID 141). 2115 bytes result sent to driver\n",
      "  Starting task 24.0 in stage 1.0 (TID 145) (namenode, executor driver, partition 24, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 20.0 in stage 1.0 (TID 141) in 5880 ms on namenode (executor driver) (21/121)\n",
      "  Running task 24.0 in stage 1.0 (TID 145)\n",
      "  Getting 121 (4.7 MiB) non-empty blocks including 121 (4.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 6174, boot = -26, init = 28, finish = 6172\n",
      "  Finished task 21.0 in stage 1.0 (TID 142). 2115 bytes result sent to driver\n",
      "  Starting task 25.0 in stage 1.0 (TID 146) (namenode, executor driver, partition 25, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 21.0 in stage 1.0 (TID 142) in 6215 ms on namenode (executor driver) (22/121)\n",
      "  Running task 25.0 in stage 1.0 (TID 146)\n",
      "  Getting 121 (4.7 MiB) non-empty blocks including 121 (4.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Times: total = 6013, boot = -16, init = 25, finish = 6004\n",
      "  Finished task 22.0 in stage 1.0 (TID 143). 2072 bytes result sent to driver\n",
      "  Starting task 26.0 in stage 1.0 (TID 147) (namenode, executor driver, partition 26, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 22.0 in stage 1.0 (TID 143) in 6050 ms on namenode (executor driver) (23/121)\n",
      "  Running task 26.0 in stage 1.0 (TID 147)\n",
      "  Getting 121 (4.7 MiB) non-empty blocks including 121 (4.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 6079, boot = -44, init = 57, finish = 6066\n",
      "  Finished task 23.0 in stage 1.0 (TID 144). 2072 bytes result sent to driver\n",
      "  Starting task 27.0 in stage 1.0 (TID 148) (namenode, executor driver, partition 27, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 23.0 in stage 1.0 (TID 144) in 6124 ms on namenode (executor driver) (24/121)\n",
      "  Running task 27.0 in stage 1.0 (TID 148)\n",
      "  Getting 121 (4.7 MiB) non-empty blocks including 121 (4.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 6137, boot = -17, init = 19, finish = 6135\n",
      "  Finished task 24.0 in stage 1.0 (TID 145). 2072 bytes result sent to driver\n",
      "  Starting task 28.0 in stage 1.0 (TID 149) (namenode, executor driver, partition 28, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 24.0 in stage 1.0 (TID 145) in 6184 ms on namenode (executor driver) (25/121)\n",
      "  Running task 28.0 in stage 1.0 (TID 149)\n",
      "  Getting 121 (4.6 MiB) non-empty blocks including 121 (4.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 6162, boot = -34, init = 36, finish = 6160\n",
      "  Finished task 25.0 in stage 1.0 (TID 146). 2072 bytes result sent to driver\n",
      "  Starting task 29.0 in stage 1.0 (TID 150) (namenode, executor driver, partition 29, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 25.0 in stage 1.0 (TID 146) in 6200 ms on namenode (executor driver) (26/121)\n",
      "  Running task 29.0 in stage 1.0 (TID 150)\n",
      "  Getting 121 (4.7 MiB) non-empty blocks including 121 (4.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Times: total = 5947, boot = -27, init = 29, finish = 5945\n",
      "  Finished task 26.0 in stage 1.0 (TID 147). 2072 bytes result sent to driver\n",
      "  Starting task 30.0 in stage 1.0 (TID 151) (namenode, executor driver, partition 30, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 26.0 in stage 1.0 (TID 147) in 5982 ms on namenode (executor driver) (27/121)\n",
      "  Running task 30.0 in stage 1.0 (TID 151)\n",
      "  Getting 121 (4.6 MiB) non-empty blocks including 121 (4.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 6110, boot = -14, init = 19, finish = 6105\n",
      "  Finished task 27.0 in stage 1.0 (TID 148). 2072 bytes result sent to driver\n",
      "  Starting task 31.0 in stage 1.0 (TID 152) (namenode, executor driver, partition 31, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 27.0 in stage 1.0 (TID 148) in 6145 ms on namenode (executor driver) (28/121)\n",
      "  Running task 31.0 in stage 1.0 (TID 152)\n",
      "  Getting 121 (4.7 MiB) non-empty blocks including 121 (4.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 5956, boot = -35, init = 37, finish = 5954\n",
      "  Finished task 28.0 in stage 1.0 (TID 149). 2115 bytes result sent to driver\n",
      "  Starting task 32.0 in stage 1.0 (TID 153) (namenode, executor driver, partition 32, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 28.0 in stage 1.0 (TID 149) in 5996 ms on namenode (executor driver) (29/121)\n",
      "  Running task 32.0 in stage 1.0 (TID 153)\n",
      "  Getting 121 (4.7 MiB) non-empty blocks including 121 (4.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Started 0 remote fetches in 7 ms\n",
      "  Times: total = 5919, boot = -34, init = 46, finish = 5907\n",
      "  Finished task 29.0 in stage 1.0 (TID 150). 2115 bytes result sent to driver\n",
      "  Starting task 33.0 in stage 1.0 (TID 154) (namenode, executor driver, partition 33, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 33.0 in stage 1.0 (TID 154)\n",
      "  Finished task 29.0 in stage 1.0 (TID 150) in 5978 ms on namenode (executor driver) (30/121)\n",
      "  Getting 121 (4.7 MiB) non-empty blocks including 121 (4.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 6051, boot = -12, init = 14, finish = 6049\n",
      "  Finished task 30.0 in stage 1.0 (TID 151). 2115 bytes result sent to driver\n",
      "  Starting task 34.0 in stage 1.0 (TID 155) (namenode, executor driver, partition 34, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 34.0 in stage 1.0 (TID 155)\n",
      "  Finished task 30.0 in stage 1.0 (TID 151) in 6084 ms on namenode (executor driver) (31/121)\n",
      "  Getting 121 (4.7 MiB) non-empty blocks including 121 (4.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 5997, boot = -12, init = 14, finish = 5995\n",
      "  Finished task 31.0 in stage 1.0 (TID 152). 2115 bytes result sent to driver\n",
      "  Starting task 35.0 in stage 1.0 (TID 156) (namenode, executor driver, partition 35, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 31.0 in stage 1.0 (TID 152) in 6034 ms on namenode (executor driver) (32/121)\n",
      "  Running task 35.0 in stage 1.0 (TID 156)\n",
      "  Getting 121 (4.7 MiB) non-empty blocks including 121 (4.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Times: total = 6072, boot = -36, init = 38, finish = 6070\n",
      "  Finished task 32.0 in stage 1.0 (TID 153). 2072 bytes result sent to driver\n",
      "  Starting task 36.0 in stage 1.0 (TID 157) (namenode, executor driver, partition 36, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 32.0 in stage 1.0 (TID 153) in 6144 ms on namenode (executor driver) (33/121)\n",
      "  Running task 36.0 in stage 1.0 (TID 157)\n",
      "  Getting 121 (4.6 MiB) non-empty blocks including 121 (4.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 10 ms\n",
      "  Times: total = 6068, boot = -24, init = 28, finish = 6064\n",
      "  Finished task 34.0 in stage 1.0 (TID 155). 2072 bytes result sent to driver\n",
      "  Starting task 37.0 in stage 1.0 (TID 158) (namenode, executor driver, partition 37, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 37.0 in stage 1.0 (TID 158)\n",
      "  Finished task 34.0 in stage 1.0 (TID 155) in 6123 ms on namenode (executor driver) (34/121)\n",
      "  Getting 121 (4.7 MiB) non-empty blocks including 121 (4.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 6530, boot = -39, init = 41, finish = 6528\n",
      "  Finished task 33.0 in stage 1.0 (TID 154). 2072 bytes result sent to driver\n",
      "  Starting task 38.0 in stage 1.0 (TID 159) (namenode, executor driver, partition 38, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 33.0 in stage 1.0 (TID 154) in 6601 ms on namenode (executor driver) (35/121)\n",
      "  Running task 38.0 in stage 1.0 (TID 159)\n",
      "  Getting 121 (4.7 MiB) non-empty blocks including 121 (4.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Times: total = 6888, boot = -30, init = 32, finish = 6886\n",
      "  Finished task 35.0 in stage 1.0 (TID 156). 2072 bytes result sent to driver\n",
      "  Starting task 39.0 in stage 1.0 (TID 160) (namenode, executor driver, partition 39, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 39.0 in stage 1.0 (TID 160)\n",
      "  Finished task 35.0 in stage 1.0 (TID 156) in 6961 ms on namenode (executor driver) (36/121)\n",
      "  Getting 121 (4.6 MiB) non-empty blocks including 121 (4.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 7665, boot = -67, init = 86, finish = 7646\n",
      "  Finished task 36.0 in stage 1.0 (TID 157). 2072 bytes result sent to driver\n",
      "  Starting task 40.0 in stage 1.0 (TID 161) (namenode, executor driver, partition 40, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 36.0 in stage 1.0 (TID 157) in 7710 ms on namenode (executor driver) (37/121)\n",
      "  Running task 40.0 in stage 1.0 (TID 161)\n",
      "  Getting 121 (4.7 MiB) non-empty blocks including 121 (4.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 3 ms\n",
      "  Times: total = 7301, boot = -46, init = 58, finish = 7289\n",
      "  Finished task 37.0 in stage 1.0 (TID 158). 2072 bytes result sent to driver\n",
      "  Starting task 41.0 in stage 1.0 (TID 162) (namenode, executor driver, partition 41, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 41.0 in stage 1.0 (TID 162)\n",
      "  Finished task 37.0 in stage 1.0 (TID 158) in 7342 ms on namenode (executor driver) (38/121)\n",
      "  Getting 121 (4.7 MiB) non-empty blocks including 121 (4.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Times: total = 7143, boot = -63, init = 76, finish = 7130\n",
      "  Finished task 38.0 in stage 1.0 (TID 159). 2072 bytes result sent to driver\n",
      "  Starting task 42.0 in stage 1.0 (TID 163) (namenode, executor driver, partition 42, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 38.0 in stage 1.0 (TID 159) in 7188 ms on namenode (executor driver) (39/121)\n",
      "  Running task 42.0 in stage 1.0 (TID 163)\n",
      "  Getting 121 (4.7 MiB) non-empty blocks including 121 (4.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 7681, boot = -67, init = 84, finish = 7664\n",
      "  Finished task 39.0 in stage 1.0 (TID 160). 2115 bytes result sent to driver\n",
      "  Starting task 43.0 in stage 1.0 (TID 164) (namenode, executor driver, partition 43, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 39.0 in stage 1.0 (TID 160) in 7729 ms on namenode (executor driver) (40/121)\n",
      "  Running task 43.0 in stage 1.0 (TID 164)\n",
      "  Getting 121 (4.7 MiB) non-empty blocks including 121 (4.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 9531, boot = -27, init = 57, finish = 9501\n",
      "  Finished task 40.0 in stage 1.0 (TID 161). 2115 bytes result sent to driver\n",
      "  Starting task 44.0 in stage 1.0 (TID 165) (namenode, executor driver, partition 44, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 40.0 in stage 1.0 (TID 161) in 9578 ms on namenode (executor driver) (41/121)\n",
      "  Running task 44.0 in stage 1.0 (TID 165)\n",
      "  Getting 121 (4.7 MiB) non-empty blocks including 121 (4.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Times: total = 8902, boot = -28, init = 42, finish = 8888\n",
      "  Finished task 42.0 in stage 1.0 (TID 163). 2115 bytes result sent to driver\n",
      "  Starting task 45.0 in stage 1.0 (TID 166) (namenode, executor driver, partition 45, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 42.0 in stage 1.0 (TID 163) in 8957 ms on namenode (executor driver) (42/121)\n",
      "  Running task 45.0 in stage 1.0 (TID 166)\n",
      "  Getting 121 (4.7 MiB) non-empty blocks including 121 (4.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 7311, boot = -37, init = 41, finish = 7307\n",
      "  Times: total = 9225, boot = -18, init = 20, finish = 9223\n",
      "  Finished task 43.0 in stage 1.0 (TID 164). 2072 bytes result sent to driver\n",
      "  Starting task 46.0 in stage 1.0 (TID 167) (namenode, executor driver, partition 46, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 46.0 in stage 1.0 (TID 167)\n",
      "  Finished task 41.0 in stage 1.0 (TID 162). 2115 bytes result sent to driver\n",
      "  Finished task 43.0 in stage 1.0 (TID 164) in 7355 ms on namenode (executor driver) (43/121)\n",
      "  Starting task 47.0 in stage 1.0 (TID 168) (namenode, executor driver, partition 47, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 41.0 in stage 1.0 (TID 162) in 9261 ms on namenode (executor driver) (44/121)\n",
      "  Running task 47.0 in stage 1.0 (TID 168)\n",
      "  Getting 121 (4.7 MiB) non-empty blocks including 121 (4.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Getting 121 (4.7 MiB) non-empty blocks including 121 (4.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Started 0 remote fetches in 1 ms\n",
      "  Process of event SparkListenerExecutorMetricsUpdate(driver,WrappedArray(),Map((-1,-1) -> org.apache.spark.executor.ExecutorMetrics@2dd360d0)) by listener AppStatusListener took 1.651903097s.\n",
      "  Times: total = 10008, boot = -18, init = 24, finish = 10002\n",
      "  Times: total = 9622, boot = -44, init = 47, finish = 9619\n",
      "  Finished task 44.0 in stage 1.0 (TID 165). 2072 bytes result sent to driver\n",
      "  Starting task 48.0 in stage 1.0 (TID 169) (namenode, executor driver, partition 48, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 44.0 in stage 1.0 (TID 165) in 10122 ms on namenode (executor driver) (45/121)\n",
      "  Running task 48.0 in stage 1.0 (TID 169)\n",
      "  Getting 121 (4.7 MiB) non-empty blocks including 121 (4.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Finished task 45.0 in stage 1.0 (TID 166). 2072 bytes result sent to driver\n",
      "  Starting task 49.0 in stage 1.0 (TID 170) (namenode, executor driver, partition 49, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 45.0 in stage 1.0 (TID 166) in 10042 ms on namenode (executor driver) (46/121)\n",
      "  Running task 49.0 in stage 1.0 (TID 170)\n",
      "  Getting 121 (4.7 MiB) non-empty blocks including 121 (4.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 8 ms\n",
      "  Times: total = 9838, boot = -23, init = 39, finish = 9822\n",
      "  Finished task 46.0 in stage 1.0 (TID 167). 2072 bytes result sent to driver\n",
      "  Starting task 50.0 in stage 1.0 (TID 171) (namenode, executor driver, partition 50, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 50.0 in stage 1.0 (TID 171)\n",
      "  Finished task 46.0 in stage 1.0 (TID 167) in 9901 ms on namenode (executor driver) (47/121)\n",
      "  Getting 121 (4.7 MiB) non-empty blocks including 121 (4.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Times: total = 10080, boot = -16, init = 20, finish = 10076\n",
      "  Finished task 47.0 in stage 1.0 (TID 168). 2072 bytes result sent to driver\n",
      "  Starting task 51.0 in stage 1.0 (TID 172) (namenode, executor driver, partition 51, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 47.0 in stage 1.0 (TID 168) in 10121 ms on namenode (executor driver) (48/121)\n",
      "  Running task 51.0 in stage 1.0 (TID 172)\n",
      "  Getting 121 (4.7 MiB) non-empty blocks including 121 (4.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Times: total = 6340, boot = -530, init = 537, finish = 6333\n",
      "  Finished task 50.0 in stage 1.0 (TID 171). 2115 bytes result sent to driver\n",
      "  Starting task 52.0 in stage 1.0 (TID 173) (namenode, executor driver, partition 52, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 52.0 in stage 1.0 (TID 173)\n",
      "  Finished task 50.0 in stage 1.0 (TID 171) in 6724 ms on namenode (executor driver) (49/121)\n",
      "  Getting 121 (4.7 MiB) non-empty blocks including 121 (4.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 6383, boot = -145, init = 152, finish = 6376\n",
      "  Finished task 51.0 in stage 1.0 (TID 172). 2115 bytes result sent to driver\n",
      "  Starting task 53.0 in stage 1.0 (TID 174) (namenode, executor driver, partition 53, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 51.0 in stage 1.0 (TID 172) in 6540 ms on namenode (executor driver) (50/121)\n",
      "  Running task 53.0 in stage 1.0 (TID 174)\n",
      "  Getting 121 (4.7 MiB) non-empty blocks including 121 (4.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 6392, boot = -787, init = 796, finish = 6383\n",
      "  Finished task 49.0 in stage 1.0 (TID 170). 2115 bytes result sent to driver\n",
      "  Starting task 54.0 in stage 1.0 (TID 175) (namenode, executor driver, partition 54, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 49.0 in stage 1.0 (TID 170) in 6872 ms on namenode (executor driver) (51/121)\n",
      "  Running task 54.0 in stage 1.0 (TID 175)\n",
      "  Getting 121 (4.7 MiB) non-empty blocks including 121 (4.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 7166, boot = -375, init = 382, finish = 7159\n",
      "  Finished task 48.0 in stage 1.0 (TID 169). 2115 bytes result sent to driver\n",
      "  Starting task 55.0 in stage 1.0 (TID 176) (namenode, executor driver, partition 55, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 55.0 in stage 1.0 (TID 176)\n",
      "  Finished task 48.0 in stage 1.0 (TID 169) in 7632 ms on namenode (executor driver) (52/121)\n",
      "  Getting 121 (4.7 MiB) non-empty blocks including 121 (4.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 5852, boot = -39, init = 49, finish = 5842\n",
      "  Finished task 54.0 in stage 1.0 (TID 175). 2072 bytes result sent to driver\n",
      "  Starting task 56.0 in stage 1.0 (TID 177) (namenode, executor driver, partition 56, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 54.0 in stage 1.0 (TID 175) in 5890 ms on namenode (executor driver) (53/121)\n",
      "  Running task 56.0 in stage 1.0 (TID 177)\n",
      "  Getting 121 (4.7 MiB) non-empty blocks including 121 (4.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 6049, boot = -16, init = 32, finish = 6033\n",
      "  Finished task 52.0 in stage 1.0 (TID 173). 2072 bytes result sent to driver\n",
      "  Starting task 57.0 in stage 1.0 (TID 178) (namenode, executor driver, partition 57, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 52.0 in stage 1.0 (TID 173) in 6082 ms on namenode (executor driver) (54/121)\n",
      "  Running task 57.0 in stage 1.0 (TID 178)\n",
      "  Getting 121 (4.7 MiB) non-empty blocks including 121 (4.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 2 ms\n",
      "  Times: total = 6329, boot = -22, init = 24, finish = 6327\n",
      "  Finished task 53.0 in stage 1.0 (TID 174). 2072 bytes result sent to driver\n",
      "  Starting task 58.0 in stage 1.0 (TID 179) (namenode, executor driver, partition 58, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 53.0 in stage 1.0 (TID 174) in 6369 ms on namenode (executor driver) (55/121)\n",
      "  Running task 58.0 in stage 1.0 (TID 179)\n",
      "  Getting 121 (4.7 MiB) non-empty blocks including 121 (4.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 6051, boot = -30, init = 42, finish = 6039\n",
      "  Finished task 55.0 in stage 1.0 (TID 176). 2072 bytes result sent to driver\n",
      "  Starting task 59.0 in stage 1.0 (TID 180) (namenode, executor driver, partition 59, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 59.0 in stage 1.0 (TID 180)\n",
      "  Finished task 55.0 in stage 1.0 (TID 176) in 6087 ms on namenode (executor driver) (56/121)\n",
      "  Getting 121 (4.7 MiB) non-empty blocks including 121 (4.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 5683, boot = -29, init = 52, finish = 5660\n",
      "  Finished task 56.0 in stage 1.0 (TID 177). 2029 bytes result sent to driver\n",
      "  Starting task 60.0 in stage 1.0 (TID 181) (namenode, executor driver, partition 60, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 56.0 in stage 1.0 (TID 177) in 5719 ms on namenode (executor driver) (57/121)\n",
      "  Running task 60.0 in stage 1.0 (TID 181)\n",
      "  Getting 121 (4.7 MiB) non-empty blocks including 121 (4.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 5808, boot = -25, init = 27, finish = 5806\n",
      "  Finished task 57.0 in stage 1.0 (TID 178). 2072 bytes result sent to driver\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Starting task 61.0 in stage 1.0 (TID 182) (namenode, executor driver, partition 61, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 57.0 in stage 1.0 (TID 178) in 5845 ms on namenode (executor driver) (58/121)\n",
      "  Running task 61.0 in stage 1.0 (TID 182)\n",
      "  Getting 121 (4.7 MiB) non-empty blocks including 121 (4.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 5968, boot = -29, init = 34, finish = 5963\n",
      "  Finished task 58.0 in stage 1.0 (TID 179). 2072 bytes result sent to driver\n",
      "  Starting task 62.0 in stage 1.0 (TID 183) (namenode, executor driver, partition 62, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 62.0 in stage 1.0 (TID 183)\n",
      "  Finished task 58.0 in stage 1.0 (TID 179) in 6013 ms on namenode (executor driver) (59/121)\n",
      "  Getting 121 (4.7 MiB) non-empty blocks including 121 (4.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 6157, boot = -14, init = 16, finish = 6155\n",
      "  Finished task 59.0 in stage 1.0 (TID 180). 2115 bytes result sent to driver\n",
      "  Starting task 63.0 in stage 1.0 (TID 184) (namenode, executor driver, partition 63, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 59.0 in stage 1.0 (TID 180) in 6185 ms on namenode (executor driver) (60/121)\n",
      "  Running task 63.0 in stage 1.0 (TID 184)\n",
      "  Getting 121 (4.7 MiB) non-empty blocks including 121 (4.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 26 ms\n",
      "  Times: total = 5762, boot = -26, init = 28, finish = 5760\n",
      "  Finished task 60.0 in stage 1.0 (TID 181). 2115 bytes result sent to driver\n",
      "  Starting task 64.0 in stage 1.0 (TID 185) (namenode, executor driver, partition 64, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 60.0 in stage 1.0 (TID 181) in 5797 ms on namenode (executor driver) (61/121)\n",
      "  Running task 64.0 in stage 1.0 (TID 185)\n",
      "  Getting 121 (4.6 MiB) non-empty blocks including 121 (4.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 5918, boot = -25, init = 27, finish = 5916\n",
      "  Finished task 61.0 in stage 1.0 (TID 182). 2115 bytes result sent to driver\n",
      "  Starting task 65.0 in stage 1.0 (TID 186) (namenode, executor driver, partition 65, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 61.0 in stage 1.0 (TID 182) in 5971 ms on namenode (executor driver) (62/121)\n",
      "  Running task 65.0 in stage 1.0 (TID 186)\n",
      "  Getting 121 (4.7 MiB) non-empty blocks including 121 (4.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Times: total = 6126, boot = -25, init = 26, finish = 6125\n",
      "  Finished task 62.0 in stage 1.0 (TID 183). 2115 bytes result sent to driver\n",
      "  Starting task 66.0 in stage 1.0 (TID 187) (namenode, executor driver, partition 66, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 62.0 in stage 1.0 (TID 183) in 6167 ms on namenode (executor driver) (63/121)\n",
      "  Running task 66.0 in stage 1.0 (TID 187)\n",
      "  Getting 121 (4.6 MiB) non-empty blocks including 121 (4.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 5858, boot = -35, init = 45, finish = 5848\n",
      "  Finished task 63.0 in stage 1.0 (TID 184). 2072 bytes result sent to driver\n",
      "  Starting task 67.0 in stage 1.0 (TID 188) (namenode, executor driver, partition 67, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 63.0 in stage 1.0 (TID 184) in 5921 ms on namenode (executor driver) (64/121)\n",
      "  Running task 67.0 in stage 1.0 (TID 188)\n",
      "  Getting 121 (4.7 MiB) non-empty blocks including 121 (4.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 5713, boot = -26, init = 28, finish = 5711\n",
      "  Finished task 64.0 in stage 1.0 (TID 185). 2029 bytes result sent to driver\n",
      "  Starting task 68.0 in stage 1.0 (TID 189) (namenode, executor driver, partition 68, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 64.0 in stage 1.0 (TID 185) in 5746 ms on namenode (executor driver) (65/121)\n",
      "  Running task 68.0 in stage 1.0 (TID 189)\n",
      "  Getting 121 (4.7 MiB) non-empty blocks including 121 (4.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 6053, boot = -48, init = 50, finish = 6051\n",
      "  Finished task 65.0 in stage 1.0 (TID 186). 2072 bytes result sent to driver\n",
      "  Starting task 69.0 in stage 1.0 (TID 190) (namenode, executor driver, partition 69, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 69.0 in stage 1.0 (TID 190)\n",
      "  Finished task 65.0 in stage 1.0 (TID 186) in 6090 ms on namenode (executor driver) (66/121)\n",
      "  Getting 121 (4.7 MiB) non-empty blocks including 121 (4.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 5896, boot = -24, init = 26, finish = 5894\n",
      "  Finished task 66.0 in stage 1.0 (TID 187). 2072 bytes result sent to driver\n",
      "  Starting task 70.0 in stage 1.0 (TID 191) (namenode, executor driver, partition 70, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 66.0 in stage 1.0 (TID 187) in 5927 ms on namenode (executor driver) (67/121)\n",
      "  Running task 70.0 in stage 1.0 (TID 191)\n",
      "  Getting 121 (4.7 MiB) non-empty blocks including 121 (4.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Times: total = 5848, boot = -26, init = 28, finish = 5846\n",
      "  Finished task 67.0 in stage 1.0 (TID 188). 2072 bytes result sent to driver\n",
      "  Starting task 71.0 in stage 1.0 (TID 192) (namenode, executor driver, partition 71, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 71.0 in stage 1.0 (TID 192)\n",
      "  Finished task 67.0 in stage 1.0 (TID 188) in 5890 ms on namenode (executor driver) (68/121)\n",
      "  Getting 121 (4.7 MiB) non-empty blocks including 121 (4.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 5975, boot = -24, init = 26, finish = 5973\n",
      "  Finished task 68.0 in stage 1.0 (TID 189). 2072 bytes result sent to driver\n",
      "  Starting task 72.0 in stage 1.0 (TID 193) (namenode, executor driver, partition 72, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 68.0 in stage 1.0 (TID 189) in 6020 ms on namenode (executor driver) (69/121)\n",
      "  Running task 72.0 in stage 1.0 (TID 193)\n",
      "  Getting 121 (4.7 MiB) non-empty blocks including 121 (4.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 5 ms\n",
      "  Times: total = 5827, boot = -11, init = 13, finish = 5825\n",
      "  Finished task 69.0 in stage 1.0 (TID 190). 2115 bytes result sent to driver\n",
      "  Starting task 73.0 in stage 1.0 (TID 194) (namenode, executor driver, partition 73, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 69.0 in stage 1.0 (TID 190) in 5862 ms on namenode (executor driver) (70/121)\n",
      "  Running task 73.0 in stage 1.0 (TID 194)\n",
      "  Getting 121 (4.6 MiB) non-empty blocks including 121 (4.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 5824, boot = -24, init = 34, finish = 5814\n",
      "  Finished task 70.0 in stage 1.0 (TID 191). 2115 bytes result sent to driver\n",
      "  Starting task 74.0 in stage 1.0 (TID 195) (namenode, executor driver, partition 74, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 74.0 in stage 1.0 (TID 195)\n",
      "  Finished task 70.0 in stage 1.0 (TID 191) in 5866 ms on namenode (executor driver) (71/121)\n",
      "  Getting 121 (4.7 MiB) non-empty blocks including 121 (4.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 6084, boot = -29, init = 43, finish = 6070\n",
      "  Finished task 71.0 in stage 1.0 (TID 192). 2115 bytes result sent to driver\n",
      "  Starting task 75.0 in stage 1.0 (TID 196) (namenode, executor driver, partition 75, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 75.0 in stage 1.0 (TID 196)\n",
      "  Finished task 71.0 in stage 1.0 (TID 192) in 6127 ms on namenode (executor driver) (72/121)\n",
      "  Getting 121 (4.7 MiB) non-empty blocks including 121 (4.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 3 ms\n",
      "  Times: total = 5942, boot = -25, init = 28, finish = 5939\n",
      "  Finished task 72.0 in stage 1.0 (TID 193). 2115 bytes result sent to driver\n",
      "  Starting task 76.0 in stage 1.0 (TID 197) (namenode, executor driver, partition 76, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 72.0 in stage 1.0 (TID 193) in 5986 ms on namenode (executor driver) (73/121)\n",
      "  Running task 76.0 in stage 1.0 (TID 197)\n",
      "  Getting 121 (4.6 MiB) non-empty blocks including 121 (4.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 5799, boot = -28, init = 30, finish = 5797\n",
      "  Finished task 73.0 in stage 1.0 (TID 194). 2029 bytes result sent to driver\n",
      "  Starting task 77.0 in stage 1.0 (TID 198) (namenode, executor driver, partition 77, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 73.0 in stage 1.0 (TID 194) in 5825 ms on namenode (executor driver) (74/121)\n",
      "  Running task 77.0 in stage 1.0 (TID 198)\n",
      "  Getting 121 (4.7 MiB) non-empty blocks including 121 (4.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 5801, boot = -27, init = 30, finish = 5798\n",
      "  Finished task 74.0 in stage 1.0 (TID 195). 2072 bytes result sent to driver\n",
      "  Starting task 78.0 in stage 1.0 (TID 199) (namenode, executor driver, partition 78, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 78.0 in stage 1.0 (TID 199)\n",
      "  Finished task 74.0 in stage 1.0 (TID 195) in 5841 ms on namenode (executor driver) (75/121)\n",
      "  Getting 121 (4.7 MiB) non-empty blocks including 121 (4.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 6080, boot = -18, init = 20, finish = 6078\n",
      "  Finished task 75.0 in stage 1.0 (TID 196). 2072 bytes result sent to driver\n",
      "  Starting task 79.0 in stage 1.0 (TID 200) (namenode, executor driver, partition 79, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 75.0 in stage 1.0 (TID 196) in 6125 ms on namenode (executor driver) (76/121)\n",
      "  Running task 79.0 in stage 1.0 (TID 200)\n",
      "  Getting 121 (4.6 MiB) non-empty blocks including 121 (4.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 5923, boot = -29, init = 31, finish = 5921\n",
      "  Finished task 76.0 in stage 1.0 (TID 197). 2072 bytes result sent to driver\n",
      "  Starting task 80.0 in stage 1.0 (TID 201) (namenode, executor driver, partition 80, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 76.0 in stage 1.0 (TID 197) in 5962 ms on namenode (executor driver) (77/121)\n",
      "  Running task 80.0 in stage 1.0 (TID 201)\n",
      "  Getting 121 (4.7 MiB) non-empty blocks including 121 (4.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 5873, boot = -19, init = 20, finish = 5872\n",
      "  Finished task 77.0 in stage 1.0 (TID 198). 2072 bytes result sent to driver\n",
      "  Starting task 81.0 in stage 1.0 (TID 202) (namenode, executor driver, partition 81, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 77.0 in stage 1.0 (TID 198) in 5911 ms on namenode (executor driver) (78/121)\n",
      "  Running task 81.0 in stage 1.0 (TID 202)\n",
      "  Getting 121 (4.7 MiB) non-empty blocks including 121 (4.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 5989, boot = -19, init = 22, finish = 5986\n",
      "  Finished task 78.0 in stage 1.0 (TID 199). 2072 bytes result sent to driver\n",
      "  Starting task 82.0 in stage 1.0 (TID 203) (namenode, executor driver, partition 82, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 78.0 in stage 1.0 (TID 199) in 6021 ms on namenode (executor driver) (79/121)\n",
      "  Running task 82.0 in stage 1.0 (TID 203)\n",
      "  Getting 121 (4.7 MiB) non-empty blocks including 121 (4.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 6103, boot = -32, init = 34, finish = 6101\n",
      "  Finished task 79.0 in stage 1.0 (TID 200). 2072 bytes result sent to driver\n",
      "  Starting task 83.0 in stage 1.0 (TID 204) (namenode, executor driver, partition 83, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 79.0 in stage 1.0 (TID 200) in 6135 ms on namenode (executor driver) (80/121)\n",
      "  Running task 83.0 in stage 1.0 (TID 204)\n",
      "  Getting 121 (4.7 MiB) non-empty blocks including 121 (4.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 5947, boot = -27, init = 33, finish = 5941\n",
      "  Finished task 80.0 in stage 1.0 (TID 201). 2072 bytes result sent to driver\n",
      "  Starting task 84.0 in stage 1.0 (TID 205) (namenode, executor driver, partition 84, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 80.0 in stage 1.0 (TID 201) in 5981 ms on namenode (executor driver) (81/121)\n",
      "  Running task 84.0 in stage 1.0 (TID 205)\n",
      "  Getting 121 (4.6 MiB) non-empty blocks including 121 (4.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Times: total = 5910, boot = -24, init = 26, finish = 5908\n",
      "  Finished task 81.0 in stage 1.0 (TID 202). 2072 bytes result sent to driver\n",
      "  Starting task 85.0 in stage 1.0 (TID 206) (namenode, executor driver, partition 85, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 85.0 in stage 1.0 (TID 206)\n",
      "  Finished task 81.0 in stage 1.0 (TID 202) in 5944 ms on namenode (executor driver) (82/121)\n",
      "  Getting 121 (4.7 MiB) non-empty blocks including 121 (4.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 5914, boot = -23, init = 25, finish = 5912\n",
      "  Finished task 82.0 in stage 1.0 (TID 203). 2115 bytes result sent to driver\n",
      "  Starting task 86.0 in stage 1.0 (TID 207) (namenode, executor driver, partition 86, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 86.0 in stage 1.0 (TID 207)\n",
      "  Finished task 82.0 in stage 1.0 (TID 203) in 5951 ms on namenode (executor driver) (83/121)\n",
      "  Getting 121 (4.7 MiB) non-empty blocks including 121 (4.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 6070, boot = -22, init = 36, finish = 6056\n",
      "  Finished task 83.0 in stage 1.0 (TID 204). 2115 bytes result sent to driver\n",
      "  Starting task 87.0 in stage 1.0 (TID 208) (namenode, executor driver, partition 87, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 87.0 in stage 1.0 (TID 208)\n",
      "  Finished task 83.0 in stage 1.0 (TID 204) in 6107 ms on namenode (executor driver) (84/121)\n",
      "  Getting 121 (4.7 MiB) non-empty blocks including 121 (4.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 5787, boot = -25, init = 27, finish = 5785\n",
      "  Finished task 84.0 in stage 1.0 (TID 205). 2072 bytes result sent to driver\n",
      "  Starting task 88.0 in stage 1.0 (TID 209) (namenode, executor driver, partition 88, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 88.0 in stage 1.0 (TID 209)\n",
      "  Finished task 84.0 in stage 1.0 (TID 205) in 5825 ms on namenode (executor driver) (85/121)\n",
      "  Getting 121 (4.7 MiB) non-empty blocks including 121 (4.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 5917, boot = -25, init = 27, finish = 5915\n",
      "  Finished task 85.0 in stage 1.0 (TID 206). 2072 bytes result sent to driver\n",
      "  Starting task 89.0 in stage 1.0 (TID 210) (namenode, executor driver, partition 89, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 85.0 in stage 1.0 (TID 206) in 5966 ms on namenode (executor driver) (86/121)\n",
      "  Running task 89.0 in stage 1.0 (TID 210)\n",
      "  Getting 121 (4.7 MiB) non-empty blocks including 121 (4.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 4 ms\n",
      "  Times: total = 6003, boot = -29, init = 31, finish = 6001\n",
      "  Finished task 86.0 in stage 1.0 (TID 207). 2072 bytes result sent to driver\n",
      "  Starting task 90.0 in stage 1.0 (TID 211) (namenode, executor driver, partition 90, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 86.0 in stage 1.0 (TID 207) in 6048 ms on namenode (executor driver) (87/121)\n",
      "  Running task 90.0 in stage 1.0 (TID 211)\n",
      "  Getting 121 (4.7 MiB) non-empty blocks including 121 (4.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 5876, boot = -26, init = 28, finish = 5874\n",
      "  Finished task 87.0 in stage 1.0 (TID 208). 2029 bytes result sent to driver\n",
      "  Starting task 91.0 in stage 1.0 (TID 212) (namenode, executor driver, partition 91, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 87.0 in stage 1.0 (TID 208) in 5920 ms on namenode (executor driver) (88/121)\n",
      "  Running task 91.0 in stage 1.0 (TID 212)\n",
      "  Getting 121 (4.7 MiB) non-empty blocks including 121 (4.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 5769, boot = -26, init = 28, finish = 5767\n",
      "  Finished task 88.0 in stage 1.0 (TID 209). 2072 bytes result sent to driver\n",
      "  Starting task 92.0 in stage 1.0 (TID 213) (namenode, executor driver, partition 92, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 88.0 in stage 1.0 (TID 209) in 5822 ms on namenode (executor driver) (89/121)\n",
      "  Running task 92.0 in stage 1.0 (TID 213)\n",
      "  Getting 121 (4.7 MiB) non-empty blocks including 121 (4.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 5781, boot = -40, init = 46, finish = 5775\n",
      "  Finished task 89.0 in stage 1.0 (TID 210). 2072 bytes result sent to driver\n",
      "  Starting task 93.0 in stage 1.0 (TID 214) (namenode, executor driver, partition 93, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 93.0 in stage 1.0 (TID 214)\n",
      "  Finished task 89.0 in stage 1.0 (TID 210) in 5829 ms on namenode (executor driver) (90/121)\n",
      "  Getting 121 (4.6 MiB) non-empty blocks including 121 (4.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 6261, boot = -36, init = 39, finish = 6258\n",
      "  Finished task 90.0 in stage 1.0 (TID 211). 2115 bytes result sent to driver\n",
      "  Starting task 94.0 in stage 1.0 (TID 215) (namenode, executor driver, partition 94, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 94.0 in stage 1.0 (TID 215)\n",
      "  Finished task 90.0 in stage 1.0 (TID 211) in 6299 ms on namenode (executor driver) (91/121)\n",
      "  Getting 121 (4.7 MiB) non-empty blocks including 121 (4.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 2 ms\n",
      "  Times: total = 5982, boot = -25, init = 27, finish = 5980\n",
      "  Finished task 91.0 in stage 1.0 (TID 212). 2115 bytes result sent to driver\n",
      "  Starting task 95.0 in stage 1.0 (TID 216) (namenode, executor driver, partition 95, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 91.0 in stage 1.0 (TID 212) in 6021 ms on namenode (executor driver) (92/121)\n",
      "  Running task 95.0 in stage 1.0 (TID 216)\n",
      "  Getting 121 (4.7 MiB) non-empty blocks including 121 (4.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 5751, boot = -44, init = 46, finish = 5749\n",
      "  Finished task 92.0 in stage 1.0 (TID 213). 2115 bytes result sent to driver\n",
      "  Starting task 96.0 in stage 1.0 (TID 217) (namenode, executor driver, partition 96, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 96.0 in stage 1.0 (TID 217)\n",
      "  Finished task 92.0 in stage 1.0 (TID 213) in 5781 ms on namenode (executor driver) (93/121)\n",
      "  Getting 121 (4.7 MiB) non-empty blocks including 121 (4.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 5914, boot = -18, init = 20, finish = 5912\n",
      "  Finished task 93.0 in stage 1.0 (TID 214). 2115 bytes result sent to driver\n",
      "  Starting task 97.0 in stage 1.0 (TID 218) (namenode, executor driver, partition 97, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 97.0 in stage 1.0 (TID 218)\n",
      "  Finished task 93.0 in stage 1.0 (TID 214) in 5947 ms on namenode (executor driver) (94/121)\n",
      "  Getting 121 (4.7 MiB) non-empty blocks including 121 (4.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 5983, boot = -30, init = 32, finish = 5981\n",
      "  Finished task 94.0 in stage 1.0 (TID 215). 2072 bytes result sent to driver\n",
      "  Starting task 98.0 in stage 1.0 (TID 219) (namenode, executor driver, partition 98, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 98.0 in stage 1.0 (TID 219)\n",
      "  Finished task 94.0 in stage 1.0 (TID 215) in 6020 ms on namenode (executor driver) (95/121)\n",
      "  Getting 121 (4.7 MiB) non-empty blocks including 121 (4.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 2 ms\n",
      "  Times: total = 5968, boot = -29, init = 31, finish = 5966\n",
      "  Finished task 95.0 in stage 1.0 (TID 216). 2072 bytes result sent to driver\n",
      "  Starting task 99.0 in stage 1.0 (TID 220) (namenode, executor driver, partition 99, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 99.0 in stage 1.0 (TID 220)\n",
      "  Finished task 95.0 in stage 1.0 (TID 216) in 6006 ms on namenode (executor driver) (96/121)\n",
      "  Getting 121 (4.7 MiB) non-empty blocks including 121 (4.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 5871, boot = -5, init = 7, finish = 5869\n",
      "  Finished task 96.0 in stage 1.0 (TID 217). 2029 bytes result sent to driver\n",
      "  Starting task 100.0 in stage 1.0 (TID 221) (namenode, executor driver, partition 100, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 96.0 in stage 1.0 (TID 217) in 5907 ms on namenode (executor driver) (97/121)\n",
      "  Running task 100.0 in stage 1.0 (TID 221)\n",
      "  Getting 121 (4.7 MiB) non-empty blocks including 121 (4.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 5922, boot = -19, init = 21, finish = 5920\n",
      "  Finished task 97.0 in stage 1.0 (TID 218). 2072 bytes result sent to driver\n",
      "  Starting task 101.0 in stage 1.0 (TID 222) (namenode, executor driver, partition 101, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 101.0 in stage 1.0 (TID 222)\n",
      "  Finished task 97.0 in stage 1.0 (TID 218) in 5971 ms on namenode (executor driver) (98/121)\n",
      "  Getting 121 (4.7 MiB) non-empty blocks including 121 (4.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 6239, boot = -16, init = 18, finish = 6237\n",
      "  Finished task 98.0 in stage 1.0 (TID 219). 2029 bytes result sent to driver\n",
      "  Starting task 102.0 in stage 1.0 (TID 223) (namenode, executor driver, partition 102, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 98.0 in stage 1.0 (TID 219) in 6270 ms on namenode (executor driver) (99/121)\n",
      "  Running task 102.0 in stage 1.0 (TID 223)\n",
      "  Getting 121 (4.6 MiB) non-empty blocks including 121 (4.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 6067, boot = -27, init = 29, finish = 6065\n",
      "  Finished task 99.0 in stage 1.0 (TID 220). 2029 bytes result sent to driver\n",
      "  Starting task 103.0 in stage 1.0 (TID 224) (namenode, executor driver, partition 103, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 103.0 in stage 1.0 (TID 224)\n",
      "  Finished task 99.0 in stage 1.0 (TID 220) in 6105 ms on namenode (executor driver) (100/121)\n",
      "  Getting 121 (4.7 MiB) non-empty blocks including 121 (4.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 5886, boot = -29, init = 30, finish = 5885\n",
      "  Finished task 100.0 in stage 1.0 (TID 221). 2072 bytes result sent to driver\n",
      "  Starting task 104.0 in stage 1.0 (TID 225) (namenode, executor driver, partition 104, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 100.0 in stage 1.0 (TID 221) in 5923 ms on namenode (executor driver) (101/121)\n",
      "  Running task 104.0 in stage 1.0 (TID 225)\n",
      "  Getting 121 (4.7 MiB) non-empty blocks including 121 (4.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 6013, boot = -41, init = 43, finish = 6011\n",
      "  Finished task 101.0 in stage 1.0 (TID 222). 2072 bytes result sent to driver\n",
      "  Starting task 105.0 in stage 1.0 (TID 226) (namenode, executor driver, partition 105, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 105.0 in stage 1.0 (TID 226)\n",
      "  Finished task 101.0 in stage 1.0 (TID 222) in 6051 ms on namenode (executor driver) (102/121)\n",
      "  Getting 121 (4.7 MiB) non-empty blocks including 121 (4.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 5993, boot = -4, init = 6, finish = 5991\n",
      "  Finished task 102.0 in stage 1.0 (TID 223). 2072 bytes result sent to driver\n",
      "  Starting task 106.0 in stage 1.0 (TID 227) (namenode, executor driver, partition 106, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 102.0 in stage 1.0 (TID 223) in 6025 ms on namenode (executor driver) (103/121)\n",
      "  Running task 106.0 in stage 1.0 (TID 227)\n",
      "  Getting 121 (4.7 MiB) non-empty blocks including 121 (4.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 6169, boot = -28, init = 30, finish = 6167\n",
      "  Finished task 103.0 in stage 1.0 (TID 224). 2115 bytes result sent to driver\n",
      "  Starting task 107.0 in stage 1.0 (TID 228) (namenode, executor driver, partition 107, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 107.0 in stage 1.0 (TID 228)\n",
      "  Finished task 103.0 in stage 1.0 (TID 224) in 6202 ms on namenode (executor driver) (104/121)\n",
      "  Getting 121 (4.7 MiB) non-empty blocks including 121 (4.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 5757, boot = -28, init = 30, finish = 5755\n",
      "  Finished task 104.0 in stage 1.0 (TID 225). 2115 bytes result sent to driver\n",
      "  Starting task 108.0 in stage 1.0 (TID 229) (namenode, executor driver, partition 108, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 108.0 in stage 1.0 (TID 229)\n",
      "  Finished task 104.0 in stage 1.0 (TID 225) in 5792 ms on namenode (executor driver) (105/121)\n",
      "  Getting 121 (4.7 MiB) non-empty blocks including 121 (4.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Times: total = 6028, boot = -21, init = 24, finish = 6025\n",
      "  Finished task 105.0 in stage 1.0 (TID 226). 2072 bytes result sent to driver\n",
      "  Starting task 109.0 in stage 1.0 (TID 230) (namenode, executor driver, partition 109, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 105.0 in stage 1.0 (TID 226) in 6066 ms on namenode (executor driver) (106/121)\n",
      "  Running task 109.0 in stage 1.0 (TID 230)\n",
      "  Getting 121 (4.7 MiB) non-empty blocks including 121 (4.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 6286, boot = -23, init = 25, finish = 6284\n",
      "  Finished task 106.0 in stage 1.0 (TID 227). 2072 bytes result sent to driver\n",
      "  Starting task 110.0 in stage 1.0 (TID 231) (namenode, executor driver, partition 110, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 106.0 in stage 1.0 (TID 227) in 6325 ms on namenode (executor driver) (107/121)\n",
      "  Running task 110.0 in stage 1.0 (TID 231)\n",
      "  Getting 121 (4.7 MiB) non-empty blocks including 121 (4.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 6125, boot = -24, init = 25, finish = 6124\n",
      "  Finished task 107.0 in stage 1.0 (TID 228). 2029 bytes result sent to driver\n",
      "  Starting task 111.0 in stage 1.0 (TID 232) (namenode, executor driver, partition 111, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 107.0 in stage 1.0 (TID 228) in 6161 ms on namenode (executor driver) (108/121)\n",
      "  Running task 111.0 in stage 1.0 (TID 232)\n",
      "  Getting 121 (4.7 MiB) non-empty blocks including 121 (4.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 5829, boot = -26, init = 28, finish = 5827\n",
      "  Finished task 108.0 in stage 1.0 (TID 229). 2072 bytes result sent to driver\n",
      "  Starting task 112.0 in stage 1.0 (TID 233) (namenode, executor driver, partition 112, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 112.0 in stage 1.0 (TID 233)\n",
      "  Finished task 108.0 in stage 1.0 (TID 229) in 5861 ms on namenode (executor driver) (109/121)\n",
      "  Getting 121 (4.7 MiB) non-empty blocks including 121 (4.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 6042, boot = -30, init = 33, finish = 6039\n",
      "  Finished task 109.0 in stage 1.0 (TID 230). 2072 bytes result sent to driver\n",
      "  Starting task 113.0 in stage 1.0 (TID 234) (namenode, executor driver, partition 113, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 109.0 in stage 1.0 (TID 230) in 6076 ms on namenode (executor driver) (110/121)\n",
      "  Running task 113.0 in stage 1.0 (TID 234)\n",
      "  Getting 121 (4.7 MiB) non-empty blocks including 121 (4.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 3 ms\n",
      "  Times: total = 6242, boot = -37, init = 41, finish = 6238\n",
      "  Finished task 110.0 in stage 1.0 (TID 231). 2072 bytes result sent to driver\n",
      "  Starting task 114.0 in stage 1.0 (TID 235) (namenode, executor driver, partition 114, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 110.0 in stage 1.0 (TID 231) in 6282 ms on namenode (executor driver) (111/121)\n",
      "  Running task 114.0 in stage 1.0 (TID 235)\n",
      "  Getting 121 (4.7 MiB) non-empty blocks including 121 (4.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 5982, boot = -28, init = 29, finish = 5981\n",
      "  Finished task 111.0 in stage 1.0 (TID 232). 2072 bytes result sent to driver\n",
      "  Starting task 115.0 in stage 1.0 (TID 236) (namenode, executor driver, partition 115, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Finished task 111.0 in stage 1.0 (TID 232) in 6025 ms on namenode (executor driver) (112/121)\n",
      "  Running task 115.0 in stage 1.0 (TID 236)\n",
      "  Getting 121 (4.7 MiB) non-empty blocks including 121 (4.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 5913, boot = -21, init = 26, finish = 5908\n",
      "  Finished task 112.0 in stage 1.0 (TID 233). 2115 bytes result sent to driver\n",
      "  Starting task 116.0 in stage 1.0 (TID 237) (namenode, executor driver, partition 116, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 116.0 in stage 1.0 (TID 237)\n",
      "  Finished task 112.0 in stage 1.0 (TID 233) in 5939 ms on namenode (executor driver) (113/121)\n",
      "  Getting 121 (4.7 MiB) non-empty blocks including 121 (4.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 6172, boot = -14, init = 16, finish = 6170\n",
      "  Finished task 113.0 in stage 1.0 (TID 234). 2072 bytes result sent to driver\n",
      "  Starting task 117.0 in stage 1.0 (TID 238) (namenode, executor driver, partition 117, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 117.0 in stage 1.0 (TID 238)\n",
      "  Getting 121 (4.7 MiB) non-empty blocks including 121 (4.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Finished task 113.0 in stage 1.0 (TID 234) in 6218 ms on namenode (executor driver) (114/121)\n",
      "  Times: total = 6130, boot = -11, init = 13, finish = 6128\n",
      "  Finished task 114.0 in stage 1.0 (TID 235). 2072 bytes result sent to driver\n",
      "  Starting task 118.0 in stage 1.0 (TID 239) (namenode, executor driver, partition 118, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 118.0 in stage 1.0 (TID 239)\n",
      "  Finished task 114.0 in stage 1.0 (TID 235) in 6166 ms on namenode (executor driver) (115/121)\n",
      "  Getting 121 (4.7 MiB) non-empty blocks including 121 (4.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 6096, boot = -20, init = 32, finish = 6084\n",
      "  Finished task 115.0 in stage 1.0 (TID 236). 2115 bytes result sent to driver\n",
      "  Starting task 119.0 in stage 1.0 (TID 240) (namenode, executor driver, partition 119, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 119.0 in stage 1.0 (TID 240)\n",
      "  Finished task 115.0 in stage 1.0 (TID 236) in 6132 ms on namenode (executor driver) (116/121)\n",
      "  Getting 121 (4.7 MiB) non-empty blocks including 121 (4.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 6066, boot = -18, init = 20, finish = 6064\n",
      "  Finished task 116.0 in stage 1.0 (TID 237). 2072 bytes result sent to driver\n",
      "  Starting task 120.0 in stage 1.0 (TID 241) (namenode, executor driver, partition 120, NODE_LOCAL, 4260 bytes) taskResourceAssignments Map()\n",
      "  Running task 120.0 in stage 1.0 (TID 241)\n",
      "  Finished task 116.0 in stage 1.0 (TID 237) in 6103 ms on namenode (executor driver) (117/121)\n",
      "  Getting 121 (4.7 MiB) non-empty blocks including 121 (4.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 6023, boot = -13, init = 24, finish = 6012\n",
      "  Finished task 117.0 in stage 1.0 (TID 238). 2029 bytes result sent to driver\n",
      "  Finished task 117.0 in stage 1.0 (TID 238) in 6059 ms on namenode (executor driver) (118/121)\n",
      "  Times: total = 5855, boot = -27, init = 28, finish = 5854\n",
      "  Finished task 118.0 in stage 1.0 (TID 239). 2072 bytes result sent to driver\n",
      "  Finished task 118.0 in stage 1.0 (TID 239) in 5889 ms on namenode (executor driver) (119/121)\n",
      "  Times: total = 6095, boot = -11, init = 13, finish = 6093\n",
      "  Finished task 119.0 in stage 1.0 (TID 240). 2072 bytes result sent to driver\n",
      "  Finished task 119.0 in stage 1.0 (TID 240) in 6144 ms on namenode (executor driver) (120/121)\n",
      "  Times: total = 6339, boot = -29, init = 31, finish = 6337\n",
      "  Finished task 120.0 in stage 1.0 (TID 241). 2072 bytes result sent to driver\n",
      "  Finished task 120.0 in stage 1.0 (TID 241) in 6371 ms on namenode (executor driver) (121/121)\n",
      "  Removed TaskSet 1.0, whose tasks have all completed, from pool \n",
      "  ShuffleMapStage 1 (groupBy at /home/ubuntu/.local/lib/python3.8/site-packages/mrjob/spark/harness.py:539) finished in 194.437 s\n",
      "  looking for newly runnable stages\n",
      "  running: Set()\n",
      "  waiting: Set(ResultStage 2)\n",
      "  failed: Set()\n",
      "  Submitting ResultStage 2 (MapPartitionsRDD[12] at saveAsTextFile at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "  Block broadcast_3 stored as values in memory (estimated size 134.8 KiB, free 365.7 MiB)\n",
      "  Block broadcast_3_piece0 stored as bytes in memory (estimated size 52.9 KiB, free 365.6 MiB)\n",
      "  Added broadcast_3_piece0 in memory on namenode:32797 (size: 52.9 KiB, free: 366.2 MiB)\n",
      "  Created broadcast 3 from broadcast at DAGScheduler.scala:1427\n",
      "  Submitting 121 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at saveAsTextFile at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))\n",
      "  Adding task set 2.0 with 121 tasks resource profile 0\n",
      "  Starting task 69.0 in stage 2.0 (TID 242) (namenode, executor driver, partition 69, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Starting task 0.0 in stage 2.0 (TID 243) (namenode, executor driver, partition 0, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Starting task 1.0 in stage 2.0 (TID 244) (namenode, executor driver, partition 1, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Starting task 2.0 in stage 2.0 (TID 245) (namenode, executor driver, partition 2, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 69.0 in stage 2.0 (TID 242)\n",
      "  Running task 1.0 in stage 2.0 (TID 244)\n",
      "  Running task 0.0 in stage 2.0 (TID 243)\n",
      "  Running task 2.0 in stage 2.0 (TID 245)\n",
      "  Getting 121 (300.6 MiB) non-empty blocks including 121 (300.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Started 0 remote fetches in 5 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 21, boot = -3226, init = 3240, finish = 7\n",
      "  Times: total = 19, boot = -2640, init = 2652, finish = 7\n",
      "  Times: total = 15, boot = -5048, init = 5056, finish = 7\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000000_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000000\n",
      "  attempt_20220424192755421905508218217709_0012_m_000000_0: Committed\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000001_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000001\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000002_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000002\n",
      "  Finished task 0.0 in stage 2.0 (TID 243). 2039 bytes result sent to driver\n",
      "  attempt_20220424192755421905508218217709_0012_m_000001_0: Committed\n",
      "  attempt_20220424192755421905508218217709_0012_m_000002_0: Committed\n",
      "  Starting task 3.0 in stage 2.0 (TID 246) (namenode, executor driver, partition 3, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 3.0 in stage 2.0 (TID 246)\n",
      "  Finished task 1.0 in stage 2.0 (TID 244). 1996 bytes result sent to driver\n",
      "  Finished task 2.0 in stage 2.0 (TID 245). 1996 bytes result sent to driver\n",
      "  Starting task 4.0 in stage 2.0 (TID 247) (namenode, executor driver, partition 4, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 4.0 in stage 2.0 (TID 247)\n",
      "  Finished task 2.0 in stage 2.0 (TID 245) in 373 ms on namenode (executor driver) (1/121)\n",
      "  Finished task 0.0 in stage 2.0 (TID 243) in 374 ms on namenode (executor driver) (2/121)\n",
      "  Starting task 5.0 in stage 2.0 (TID 248) (namenode, executor driver, partition 5, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 5.0 in stage 2.0 (TID 248)\n",
      "  Finished task 1.0 in stage 2.0 (TID 244) in 376 ms on namenode (executor driver) (3/121)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 2 ms\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 25, boot = -201, init = 220, finish = 6\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000005_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000005\n",
      "  attempt_20220424192755421905508218217709_0012_m_000005_0: Committed\n",
      "  Times: total = 27, boot = -173, init = 193, finish = 7\n",
      "  Finished task 5.0 in stage 2.0 (TID 248). 1996 bytes result sent to driver\n",
      "  Starting task 6.0 in stage 2.0 (TID 249) (namenode, executor driver, partition 6, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 5.0 in stage 2.0 (TID 248) in 94 ms on namenode (executor driver) (4/121)\n",
      "  Running task 6.0 in stage 2.0 (TID 249)\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000004_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000004\n",
      "  attempt_20220424192755421905508218217709_0012_m_000004_0: Committed\n",
      "  Finished task 4.0 in stage 2.0 (TID 247). 1996 bytes result sent to driver\n",
      "  Starting task 7.0 in stage 2.0 (TID 250) (namenode, executor driver, partition 7, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 4.0 in stage 2.0 (TID 247) in 109 ms on namenode (executor driver) (5/121)\n",
      "  Running task 7.0 in stage 2.0 (TID 250)\n",
      "  Times: total = 22, boot = -170, init = 180, finish = 12\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000003_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000003\n",
      "  attempt_20220424192755421905508218217709_0012_m_000003_0: Committed\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Finished task 3.0 in stage 2.0 (TID 246). 1996 bytes result sent to driver\n",
      "  Starting task 8.0 in stage 2.0 (TID 251) (namenode, executor driver, partition 8, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 3.0 in stage 2.0 (TID 246) in 136 ms on namenode (executor driver) (6/121)\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Running task 8.0 in stage 2.0 (TID 251)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 18, boot = -58, init = 67, finish = 9\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000007_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000007\n",
      "  attempt_20220424192755421905508218217709_0012_m_000007_0: Committed\n",
      "  Times: total = 22, boot = -67, init = 82, finish = 7\n",
      "  Finished task 7.0 in stage 2.0 (TID 250). 1996 bytes result sent to driver\n",
      "  Starting task 9.0 in stage 2.0 (TID 252) (namenode, executor driver, partition 9, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000006_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000006\n",
      "  attempt_20220424192755421905508218217709_0012_m_000006_0: Committed\n",
      "  Finished task 6.0 in stage 2.0 (TID 249). 1996 bytes result sent to driver\n",
      "  Running task 9.0 in stage 2.0 (TID 252)\n",
      "  Starting task 10.0 in stage 2.0 (TID 253) (namenode, executor driver, partition 10, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 10.0 in stage 2.0 (TID 253)\n",
      "  Finished task 7.0 in stage 2.0 (TID 250) in 98 ms on namenode (executor driver) (7/121)\n",
      "  Finished task 6.0 in stage 2.0 (TID 249) in 109 ms on namenode (executor driver) (8/121)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 23, boot = -117, init = 124, finish = 16\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000008_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000008\n",
      "  attempt_20220424192755421905508218217709_0012_m_000008_0: Committed\n",
      "  Finished task 8.0 in stage 2.0 (TID 251). 1996 bytes result sent to driver\n",
      "  Starting task 11.0 in stage 2.0 (TID 254) (namenode, executor driver, partition 11, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 8.0 in stage 2.0 (TID 251) in 108 ms on namenode (executor driver) (9/121)\n",
      "  Running task 11.0 in stage 2.0 (TID 254)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  Times: total = 55, boot = -57, init = 106, finish = 6\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 56, boot = -58, init = 108, finish = 6\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000009_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000009\n",
      "  attempt_20220424192755421905508218217709_0012_m_000009_0: Committed\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000010_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000010\n",
      "  attempt_20220424192755421905508218217709_0012_m_000010_0: Committed\n",
      "  Finished task 9.0 in stage 2.0 (TID 252). 2039 bytes result sent to driver\n",
      "  Starting task 12.0 in stage 2.0 (TID 255) (namenode, executor driver, partition 12, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 9.0 in stage 2.0 (TID 252) in 98 ms on namenode (executor driver) (10/121)\n",
      "  Running task 12.0 in stage 2.0 (TID 255)\n",
      "  Finished task 10.0 in stage 2.0 (TID 253). 2039 bytes result sent to driver\n",
      "  Starting task 13.0 in stage 2.0 (TID 256) (namenode, executor driver, partition 13, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 13.0 in stage 2.0 (TID 256)\n",
      "  Finished task 10.0 in stage 2.0 (TID 253) in 100 ms on namenode (executor driver) (11/121)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 5 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 57, boot = -71, init = 122, finish = 6\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000011_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000011\n",
      "  attempt_20220424192755421905508218217709_0012_m_000011_0: Committed\n",
      "  Finished task 11.0 in stage 2.0 (TID 254). 2039 bytes result sent to driver\n",
      "  Starting task 14.0 in stage 2.0 (TID 257) (namenode, executor driver, partition 14, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 14.0 in stage 2.0 (TID 257)\n",
      "  Finished task 11.0 in stage 2.0 (TID 254) in 126 ms on namenode (executor driver) (12/121)\n",
      "  Times: total = 13, boot = -29, init = 35, finish = 7\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000012_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000012\n",
      "  attempt_20220424192755421905508218217709_0012_m_000012_0: Committed\n",
      "  Finished task 12.0 in stage 2.0 (TID 255). 1996 bytes result sent to driver\n",
      "  Starting task 15.0 in stage 2.0 (TID 258) (namenode, executor driver, partition 15, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 15.0 in stage 2.0 (TID 258)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Finished task 12.0 in stage 2.0 (TID 255) in 82 ms on namenode (executor driver) (13/121)\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 10, boot = -26, init = 30, finish = 6\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000013_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000013\n",
      "  attempt_20220424192755421905508218217709_0012_m_000013_0: Committed\n",
      "  Finished task 13.0 in stage 2.0 (TID 256). 1996 bytes result sent to driver\n",
      "  Starting task 16.0 in stage 2.0 (TID 259) (namenode, executor driver, partition 16, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 16.0 in stage 2.0 (TID 259)\n",
      "  Finished task 13.0 in stage 2.0 (TID 256) in 117 ms on namenode (executor driver) (14/121)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 10, boot = -24, init = 29, finish = 5\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000015_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000015\n",
      "  attempt_20220424192755421905508218217709_0012_m_000015_0: Committed\n",
      "  Finished task 15.0 in stage 2.0 (TID 258). 1996 bytes result sent to driver\n",
      "  Times: total = 10, boot = -31, init = 34, finish = 7\n",
      "  Starting task 17.0 in stage 2.0 (TID 260) (namenode, executor driver, partition 17, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 17.0 in stage 2.0 (TID 260)\n",
      "  Finished task 15.0 in stage 2.0 (TID 258) in 83 ms on namenode (executor driver) (15/121)\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000014_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000014\n",
      "  attempt_20220424192755421905508218217709_0012_m_000014_0: Committed\n",
      "  Finished task 14.0 in stage 2.0 (TID 257). 1996 bytes result sent to driver\n",
      "  Starting task 18.0 in stage 2.0 (TID 261) (namenode, executor driver, partition 18, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 18.0 in stage 2.0 (TID 261)\n",
      "  Finished task 14.0 in stage 2.0 (TID 257) in 100 ms on namenode (executor driver) (16/121)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 15, boot = -93, init = 100, finish = 8\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000016_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000016\n",
      "  attempt_20220424192755421905508218217709_0012_m_000016_0: Committed\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Finished task 16.0 in stage 2.0 (TID 259). 1996 bytes result sent to driver\n",
      "  Starting task 19.0 in stage 2.0 (TID 262) (namenode, executor driver, partition 19, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 16.0 in stage 2.0 (TID 259) in 67 ms on namenode (executor driver) (17/121)\n",
      "  Running task 19.0 in stage 2.0 (TID 262)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 9, boot = -78, init = 80, finish = 7\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000018_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000018\n",
      "  attempt_20220424192755421905508218217709_0012_m_000018_0: Committed\n",
      "  Finished task 18.0 in stage 2.0 (TID 261). 1996 bytes result sent to driver\n",
      "  Starting task 20.0 in stage 2.0 (TID 263) (namenode, executor driver, partition 20, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 20.0 in stage 2.0 (TID 263)\n",
      "  Finished task 18.0 in stage 2.0 (TID 261) in 45 ms on namenode (executor driver) (18/121)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 3 ms\n",
      "  Times: total = 54, boot = -59, init = 107, finish = 6\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000017_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000017\n",
      "  attempt_20220424192755421905508218217709_0012_m_000017_0: Committed\n",
      "  Finished task 17.0 in stage 2.0 (TID 260). 1996 bytes result sent to driver\n",
      "  Starting task 21.0 in stage 2.0 (TID 264) (namenode, executor driver, partition 21, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 21.0 in stage 2.0 (TID 264)\n",
      "  Finished task 17.0 in stage 2.0 (TID 260) in 72 ms on namenode (executor driver) (19/121)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 52, boot = -41, init = 86, finish = 7\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000019_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000019\n",
      "  attempt_20220424192755421905508218217709_0012_m_000019_0: Committed\n",
      "  Finished task 19.0 in stage 2.0 (TID 262). 1996 bytes result sent to driver\n",
      "  Starting task 22.0 in stage 2.0 (TID 265) (namenode, executor driver, partition 22, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 19.0 in stage 2.0 (TID 262) in 68 ms on namenode (executor driver) (20/121)\n",
      "  Running task 22.0 in stage 2.0 (TID 265)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 50, boot = -26, init = 69, finish = 7\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000020_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000020\n",
      "  attempt_20220424192755421905508218217709_0012_m_000020_0: Committed\n",
      "  Finished task 20.0 in stage 2.0 (TID 263). 1996 bytes result sent to driver\n",
      "  Starting task 23.0 in stage 2.0 (TID 266) (namenode, executor driver, partition 23, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 23.0 in stage 2.0 (TID 266)\n",
      "  Finished task 20.0 in stage 2.0 (TID 263) in 74 ms on namenode (executor driver) (21/121)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 17, boot = 3, init = 3, finish = 11\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000021_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000021\n",
      "  attempt_20220424192755421905508218217709_0012_m_000021_0: Committed\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Finished task 21.0 in stage 2.0 (TID 264). 1996 bytes result sent to driver\n",
      "  Starting task 24.0 in stage 2.0 (TID 267) (namenode, executor driver, partition 24, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 24.0 in stage 2.0 (TID 267)\n",
      "  Finished task 21.0 in stage 2.0 (TID 264) in 75 ms on namenode (executor driver) (22/121)\n",
      "  Times: total = 26, boot = -2, init = 15, finish = 13\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000022_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000022\n",
      "  attempt_20220424192755421905508218217709_0012_m_000022_0: Committed\n",
      "  Finished task 22.0 in stage 2.0 (TID 265). 1996 bytes result sent to driver\n",
      "  Starting task 25.0 in stage 2.0 (TID 268) (namenode, executor driver, partition 25, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 25.0 in stage 2.0 (TID 268)\n",
      "  Finished task 22.0 in stage 2.0 (TID 265) in 59 ms on namenode (executor driver) (23/121)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 14, boot = 1, init = 5, finish = 8\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000023_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000023\n",
      "  attempt_20220424192755421905508218217709_0012_m_000023_0: Committed\n",
      "  Finished task 23.0 in stage 2.0 (TID 266). 1996 bytes result sent to driver\n",
      "  Starting task 26.0 in stage 2.0 (TID 269) (namenode, executor driver, partition 26, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 23.0 in stage 2.0 (TID 266) in 45 ms on namenode (executor driver) (24/121)\n",
      "  Running task 26.0 in stage 2.0 (TID 269)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 16, boot = -43, init = 44, finish = 15\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000024_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000024\n",
      "  attempt_20220424192755421905508218217709_0012_m_000024_0: Committed\n",
      "  Times: total = 16, boot = -12, init = 17, finish = 11\n",
      "  Finished task 24.0 in stage 2.0 (TID 267). 1996 bytes result sent to driver\n",
      "  Starting task 27.0 in stage 2.0 (TID 270) (namenode, executor driver, partition 27, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 24.0 in stage 2.0 (TID 267) in 61 ms on namenode (executor driver) (25/121)\n",
      "  Running task 27.0 in stage 2.0 (TID 270)\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000025_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000025\n",
      "  attempt_20220424192755421905508218217709_0012_m_000025_0: Committed\n",
      "  Finished task 25.0 in stage 2.0 (TID 268). 1996 bytes result sent to driver\n",
      "  Starting task 28.0 in stage 2.0 (TID 271) (namenode, executor driver, partition 28, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 28.0 in stage 2.0 (TID 271)\n",
      "  Finished task 25.0 in stage 2.0 (TID 268) in 56 ms on namenode (executor driver) (26/121)\n",
      "  Times: total = 13, boot = -15, init = 21, finish = 7\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000026_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000026\n",
      "  attempt_20220424192755421905508218217709_0012_m_000026_0: Committed\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Finished task 26.0 in stage 2.0 (TID 269). 1996 bytes result sent to driver\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Starting task 29.0 in stage 2.0 (TID 272) (namenode, executor driver, partition 29, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 26.0 in stage 2.0 (TID 269) in 46 ms on namenode (executor driver) (27/121)\n",
      "  Running task 29.0 in stage 2.0 (TID 272)\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 55, boot = -26, init = 73, finish = 8\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000027_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000027\n",
      "  attempt_20220424192755421905508218217709_0012_m_000027_0: Committed\n",
      "  Finished task 27.0 in stage 2.0 (TID 270). 1996 bytes result sent to driver\n",
      "  Starting task 30.0 in stage 2.0 (TID 273) (namenode, executor driver, partition 30, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 27.0 in stage 2.0 (TID 270) in 68 ms on namenode (executor driver) (28/121)\n",
      "  Running task 30.0 in stage 2.0 (TID 273)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 51, boot = -25, init = 70, finish = 6\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000029_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000029\n",
      "  attempt_20220424192755421905508218217709_0012_m_000029_0: Committed\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Finished task 29.0 in stage 2.0 (TID 272). 1996 bytes result sent to driver\n",
      "  Starting task 31.0 in stage 2.0 (TID 274) (namenode, executor driver, partition 31, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 29.0 in stage 2.0 (TID 272) in 80 ms on namenode (executor driver) (29/121)\n",
      "  Times: total = 60, boot = -39, init = 88, finish = 11\n",
      "  Running task 31.0 in stage 2.0 (TID 274)\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000028_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000028\n",
      "  attempt_20220424192755421905508218217709_0012_m_000028_0: Committed\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Finished task 28.0 in stage 2.0 (TID 271). 1996 bytes result sent to driver\n",
      "  Starting task 32.0 in stage 2.0 (TID 275) (namenode, executor driver, partition 32, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 32.0 in stage 2.0 (TID 275)\n",
      "  Finished task 28.0 in stage 2.0 (TID 271) in 102 ms on namenode (executor driver) (30/121)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 9, boot = 1, init = 1, finish = 7\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000030_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000030\n",
      "  attempt_20220424192755421905508218217709_0012_m_000030_0: Committed\n",
      "  Finished task 30.0 in stage 2.0 (TID 273). 1996 bytes result sent to driver\n",
      "  Starting task 33.0 in stage 2.0 (TID 276) (namenode, executor driver, partition 33, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 33.0 in stage 2.0 (TID 276)\n",
      "  Finished task 30.0 in stage 2.0 (TID 273) in 77 ms on namenode (executor driver) (31/121)\n",
      "  Times: total = 20, boot = 0, init = 11, finish = 9\n",
      "  Times: total = 27, boot = 17, init = 1, finish = 9\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000032_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000032\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000031_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000031\n",
      "  attempt_20220424192755421905508218217709_0012_m_000032_0: Committed\n",
      "  attempt_20220424192755421905508218217709_0012_m_000031_0: Committed\n",
      "  Finished task 31.0 in stage 2.0 (TID 274). 1996 bytes result sent to driver\n",
      "  Finished task 32.0 in stage 2.0 (TID 275). 1996 bytes result sent to driver\n",
      "  Starting task 34.0 in stage 2.0 (TID 277) (namenode, executor driver, partition 34, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 34.0 in stage 2.0 (TID 277)\n",
      "  Starting task 35.0 in stage 2.0 (TID 278) (namenode, executor driver, partition 35, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 31.0 in stage 2.0 (TID 274) in 61 ms on namenode (executor driver) (32/121)\n",
      "  Running task 35.0 in stage 2.0 (TID 278)\n",
      "  Finished task 32.0 in stage 2.0 (TID 275) in 48 ms on namenode (executor driver) (33/121)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 10, boot = -59, init = 61, finish = 8\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000033_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000033\n",
      "  attempt_20220424192755421905508218217709_0012_m_000033_0: Committed\n",
      "  Finished task 33.0 in stage 2.0 (TID 276). 1996 bytes result sent to driver\n",
      "  Starting task 36.0 in stage 2.0 (TID 279) (namenode, executor driver, partition 36, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Times: total = 21, boot = -26, init = 41, finish = 6\n",
      "  Running task 36.0 in stage 2.0 (TID 279)\n",
      "  Finished task 33.0 in stage 2.0 (TID 276) in 56 ms on namenode (executor driver) (34/121)\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000035_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000035\n",
      "  attempt_20220424192755421905508218217709_0012_m_000035_0: Committed\n",
      "  Finished task 35.0 in stage 2.0 (TID 278). 1996 bytes result sent to driver\n",
      "  Starting task 37.0 in stage 2.0 (TID 280) (namenode, executor driver, partition 37, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 35.0 in stage 2.0 (TID 278) in 50 ms on namenode (executor driver) (35/121)\n",
      "  Running task 37.0 in stage 2.0 (TID 280)\n",
      "  Times: total = 15, boot = -15, init = 24, finish = 6\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000034_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000034\n",
      "  attempt_20220424192755421905508218217709_0012_m_000034_0: Committed\n",
      "  Finished task 34.0 in stage 2.0 (TID 277). 1996 bytes result sent to driver\n",
      "  Starting task 38.0 in stage 2.0 (TID 281) (namenode, executor driver, partition 38, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 34.0 in stage 2.0 (TID 277) in 55 ms on namenode (executor driver) (36/121)\n",
      "  Running task 38.0 in stage 2.0 (TID 281)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 54, boot = -36, init = 85, finish = 5\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000036_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000036\n",
      "  attempt_20220424192755421905508218217709_0012_m_000036_0: Committed\n",
      "  Finished task 36.0 in stage 2.0 (TID 279). 1996 bytes result sent to driver\n",
      "  Starting task 39.0 in stage 2.0 (TID 282) (namenode, executor driver, partition 39, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 39.0 in stage 2.0 (TID 282)\n",
      "  Finished task 36.0 in stage 2.0 (TID 279) in 72 ms on namenode (executor driver) (37/121)\n",
      "  Times: total = 57, boot = -28, init = 77, finish = 8\n",
      "  Times: total = 52, boot = -13, init = 57, finish = 8\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000038_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000038\n",
      "  attempt_20220424192755421905508218217709_0012_m_000038_0: Committed\n",
      "  Finished task 38.0 in stage 2.0 (TID 281). 1996 bytes result sent to driver\n",
      "  Starting task 40.0 in stage 2.0 (TID 283) (namenode, executor driver, partition 40, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000037_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000037\n",
      "  attempt_20220424192755421905508218217709_0012_m_000037_0: Committed\n",
      "  Finished task 37.0 in stage 2.0 (TID 280). 1996 bytes result sent to driver\n",
      "  Running task 40.0 in stage 2.0 (TID 283)\n",
      "  Finished task 38.0 in stage 2.0 (TID 281) in 73 ms on namenode (executor driver) (38/121)\n",
      "  Starting task 41.0 in stage 2.0 (TID 284) (namenode, executor driver, partition 41, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 41.0 in stage 2.0 (TID 284)\n",
      "  Finished task 37.0 in stage 2.0 (TID 280) in 79 ms on namenode (executor driver) (39/121)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 2 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 12, boot = -5, init = 7, finish = 10\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000039_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  attempt_20220424192755421905508218217709_0012_m_000039_0: Committed\n",
      "  Finished task 39.0 in stage 2.0 (TID 282). 1996 bytes result sent to driver\n",
      "  Starting task 42.0 in stage 2.0 (TID 285) (namenode, executor driver, partition 42, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 39.0 in stage 2.0 (TID 282) in 55 ms on namenode (executor driver) (40/121)\n",
      "  Running task 42.0 in stage 2.0 (TID 285)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 19, boot = 12, init = 1, finish = 6\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000041_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000041\n",
      "  attempt_20220424192755421905508218217709_0012_m_000041_0: Committed\n",
      "  Finished task 41.0 in stage 2.0 (TID 284). 1996 bytes result sent to driver\n",
      "  Times: total = 23, boot = -2, init = 19, finish = 6\n",
      "  Starting task 43.0 in stage 2.0 (TID 286) (namenode, executor driver, partition 43, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 41.0 in stage 2.0 (TID 284) in 59 ms on namenode (executor driver) (41/121)\n",
      "  Running task 43.0 in stage 2.0 (TID 286)\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000040_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000040\n",
      "  attempt_20220424192755421905508218217709_0012_m_000040_0: Committed\n",
      "  Finished task 40.0 in stage 2.0 (TID 283). 1996 bytes result sent to driver\n",
      "  Starting task 44.0 in stage 2.0 (TID 287) (namenode, executor driver, partition 44, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 44.0 in stage 2.0 (TID 287)\n",
      "  Finished task 40.0 in stage 2.0 (TID 283) in 66 ms on namenode (executor driver) (42/121)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 10, boot = -30, init = 33, finish = 7\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000042_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000042\n",
      "  attempt_20220424192755421905508218217709_0012_m_000042_0: Committed\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Finished task 42.0 in stage 2.0 (TID 285). 1996 bytes result sent to driver\n",
      "  Starting task 45.0 in stage 2.0 (TID 288) (namenode, executor driver, partition 45, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 45.0 in stage 2.0 (TID 288)\n",
      "  Finished task 42.0 in stage 2.0 (TID 285) in 35 ms on namenode (executor driver) (43/121)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 10, boot = -20, init = 24, finish = 6\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000044_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000044\n",
      "  attempt_20220424192755421905508218217709_0012_m_000044_0: Committed\n",
      "  Finished task 44.0 in stage 2.0 (TID 287). 1996 bytes result sent to driver\n",
      "  Starting task 46.0 in stage 2.0 (TID 289) (namenode, executor driver, partition 46, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Times: total = 11, boot = -31, init = 33, finish = 9\n",
      "  Running task 46.0 in stage 2.0 (TID 289)\n",
      "  Finished task 44.0 in stage 2.0 (TID 287) in 43 ms on namenode (executor driver) (44/121)\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000043_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000043\n",
      "  attempt_20220424192755421905508218217709_0012_m_000043_0: Committed\n",
      "  Finished task 43.0 in stage 2.0 (TID 286). 1996 bytes result sent to driver\n",
      "  Starting task 47.0 in stage 2.0 (TID 290) (namenode, executor driver, partition 47, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 47.0 in stage 2.0 (TID 290)\n",
      "  Finished task 43.0 in stage 2.0 (TID 286) in 48 ms on namenode (executor driver) (45/121)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 49, boot = -8, init = 51, finish = 6\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000045_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000045\n",
      "  attempt_20220424192755421905508218217709_0012_m_000045_0: Committed\n",
      "  Finished task 45.0 in stage 2.0 (TID 288). 1996 bytes result sent to driver\n",
      "  Starting task 48.0 in stage 2.0 (TID 291) (namenode, executor driver, partition 48, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 45.0 in stage 2.0 (TID 288) in 64 ms on namenode (executor driver) (46/121)\n",
      "  Running task 48.0 in stage 2.0 (TID 291)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 49, boot = -15, init = 58, finish = 6\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000046_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000046\n",
      "  attempt_20220424192755421905508218217709_0012_m_000046_0: Committed\n",
      "  Finished task 46.0 in stage 2.0 (TID 289). 1996 bytes result sent to driver\n",
      "  Starting task 49.0 in stage 2.0 (TID 292) (namenode, executor driver, partition 49, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 46.0 in stage 2.0 (TID 289) in 63 ms on namenode (executor driver) (47/121)\n",
      "  Running task 49.0 in stage 2.0 (TID 292)\n",
      "  Times: total = 51, boot = -19, init = 63, finish = 7\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000047_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000047\n",
      "  attempt_20220424192755421905508218217709_0012_m_000047_0: Committed\n",
      "  Finished task 47.0 in stage 2.0 (TID 290). 1996 bytes result sent to driver\n",
      "  Starting task 50.0 in stage 2.0 (TID 293) (namenode, executor driver, partition 50, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 50.0 in stage 2.0 (TID 293)\n",
      "  Finished task 47.0 in stage 2.0 (TID 290) in 69 ms on namenode (executor driver) (48/121)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 32, boot = -1, init = 3, finish = 30\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000048_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000048\n",
      "  attempt_20220424192755421905508218217709_0012_m_000048_0: Committed\n",
      "  Finished task 48.0 in stage 2.0 (TID 291). 1996 bytes result sent to driver\n",
      "  Starting task 51.0 in stage 2.0 (TID 294) (namenode, executor driver, partition 51, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 48.0 in stage 2.0 (TID 291) in 68 ms on namenode (executor driver) (49/121)\n",
      "  Running task 51.0 in stage 2.0 (TID 294)\n",
      "  Times: total = 16, boot = 6, init = 2, finish = 8\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000050_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000050\n",
      "  attempt_20220424192755421905508218217709_0012_m_000050_0: Committed\n",
      "  Finished task 50.0 in stage 2.0 (TID 293). 1996 bytes result sent to driver\n",
      "  Starting task 52.0 in stage 2.0 (TID 295) (namenode, executor driver, partition 52, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 50.0 in stage 2.0 (TID 293) in 47 ms on namenode (executor driver) (50/121)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Running task 52.0 in stage 2.0 (TID 295)\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 16, boot = -4, init = 14, finish = 6\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000049_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000049\n",
      "  attempt_20220424192755421905508218217709_0012_m_000049_0: Committed\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Finished task 49.0 in stage 2.0 (TID 292). 1996 bytes result sent to driver\n",
      "  Starting task 53.0 in stage 2.0 (TID 296) (namenode, executor driver, partition 53, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 53.0 in stage 2.0 (TID 296)\n",
      "  Finished task 49.0 in stage 2.0 (TID 292) in 73 ms on namenode (executor driver) (51/121)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Times: total = 7, boot = -15, init = 16, finish = 6\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000051_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000051\n",
      "  attempt_20220424192755421905508218217709_0012_m_000051_0: Committed\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Finished task 51.0 in stage 2.0 (TID 294). 2039 bytes result sent to driver\n",
      "  Starting task 54.0 in stage 2.0 (TID 297) (namenode, executor driver, partition 54, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 54.0 in stage 2.0 (TID 297)\n",
      "  Finished task 51.0 in stage 2.0 (TID 294) in 84 ms on namenode (executor driver) (52/121)\n",
      "  Times: total = 9, boot = -29, init = 31, finish = 7\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000052_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000052\n",
      "  attempt_20220424192755421905508218217709_0012_m_000052_0: Committed\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Finished task 52.0 in stage 2.0 (TID 295). 2039 bytes result sent to driver\n",
      "  Starting task 55.0 in stage 2.0 (TID 298) (namenode, executor driver, partition 55, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 55.0 in stage 2.0 (TID 298)\n",
      "  Finished task 52.0 in stage 2.0 (TID 295) in 89 ms on namenode (executor driver) (53/121)\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 20, boot = -80, init = 82, finish = 18\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000053_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000053\n",
      "  attempt_20220424192755421905508218217709_0012_m_000053_0: Committed\n",
      "  Finished task 53.0 in stage 2.0 (TID 296). 2039 bytes result sent to driver\n",
      "  Starting task 56.0 in stage 2.0 (TID 299) (namenode, executor driver, partition 56, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 53.0 in stage 2.0 (TID 296) in 113 ms on namenode (executor driver) (54/121)\n",
      "  Running task 56.0 in stage 2.0 (TID 299)\n",
      "  Times: total = 56, boot = -71, init = 122, finish = 5\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000054_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000054\n",
      "  attempt_20220424192755421905508218217709_0012_m_000054_0: Committed\n",
      "  Finished task 54.0 in stage 2.0 (TID 297). 1996 bytes result sent to driver\n",
      "  Starting task 57.0 in stage 2.0 (TID 300) (namenode, executor driver, partition 57, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 57.0 in stage 2.0 (TID 300)\n",
      "  Finished task 54.0 in stage 2.0 (TID 297) in 72 ms on namenode (executor driver) (55/121)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 60, boot = -82, init = 131, finish = 11\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000055_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000055\n",
      "  attempt_20220424192755421905508218217709_0012_m_000055_0: Committed\n",
      "  Finished task 55.0 in stage 2.0 (TID 298). 1996 bytes result sent to driver\n",
      "  Starting task 58.0 in stage 2.0 (TID 301) (namenode, executor driver, partition 58, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 58.0 in stage 2.0 (TID 301)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Finished task 55.0 in stage 2.0 (TID 298) in 93 ms on namenode (executor driver) (56/121)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 60, boot = -47, init = 101, finish = 6\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000056_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000056\n",
      "  attempt_20220424192755421905508218217709_0012_m_000056_0: Committed\n",
      "  Finished task 56.0 in stage 2.0 (TID 299). 1996 bytes result sent to driver\n",
      "  Starting task 59.0 in stage 2.0 (TID 302) (namenode, executor driver, partition 59, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 59.0 in stage 2.0 (TID 302)\n",
      "  Finished task 56.0 in stage 2.0 (TID 299) in 94 ms on namenode (executor driver) (57/121)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 7, boot = -4, init = 5, finish = 6\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000057_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000057\n",
      "  attempt_20220424192755421905508218217709_0012_m_000057_0: Committed\n",
      "  Finished task 57.0 in stage 2.0 (TID 300). 1996 bytes result sent to driver\n",
      "  Starting task 60.0 in stage 2.0 (TID 303) (namenode, executor driver, partition 60, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 57.0 in stage 2.0 (TID 300) in 97 ms on namenode (executor driver) (58/121)\n",
      "  Running task 60.0 in stage 2.0 (TID 303)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 2 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 9, boot = 1, init = 1, finish = 7\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000058_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000058\n",
      "  attempt_20220424192755421905508218217709_0012_m_000058_0: Committed\n",
      "  Finished task 58.0 in stage 2.0 (TID 301). 1996 bytes result sent to driver\n",
      "  Starting task 61.0 in stage 2.0 (TID 304) (namenode, executor driver, partition 61, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 61.0 in stage 2.0 (TID 304)\n",
      "  Finished task 58.0 in stage 2.0 (TID 301) in 86 ms on namenode (executor driver) (59/121)\n",
      "  Times: total = 8, boot = -15, init = 17, finish = 6\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000059_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000059\n",
      "  attempt_20220424192755421905508218217709_0012_m_000059_0: Committed\n",
      "  Finished task 59.0 in stage 2.0 (TID 302). 1996 bytes result sent to driver\n",
      "  Starting task 62.0 in stage 2.0 (TID 305) (namenode, executor driver, partition 62, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 62.0 in stage 2.0 (TID 305)\n",
      "  Finished task 59.0 in stage 2.0 (TID 302) in 46 ms on namenode (executor driver) (60/121)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 8, boot = -81, init = 83, finish = 6\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000060_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000060\n",
      "  attempt_20220424192755421905508218217709_0012_m_000060_0: Committed\n",
      "  Finished task 60.0 in stage 2.0 (TID 303). 1996 bytes result sent to driver\n",
      "  Starting task 63.0 in stage 2.0 (TID 306) (namenode, executor driver, partition 63, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 60.0 in stage 2.0 (TID 303) in 89 ms on namenode (executor driver) (61/121)\n",
      "  Running task 63.0 in stage 2.0 (TID 306)\n",
      "  Times: total = 14, boot = -53, init = 60, finish = 7\n",
      "  Times: total = 33, boot = -33, init = 60, finish = 6\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000062_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000062\n",
      "  attempt_20220424192755421905508218217709_0012_m_000062_0: Committed\n",
      "  Finished task 62.0 in stage 2.0 (TID 305). 1996 bytes result sent to driver\n",
      "  Starting task 64.0 in stage 2.0 (TID 307) (namenode, executor driver, partition 64, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 62.0 in stage 2.0 (TID 305) in 70 ms on namenode (executor driver) (62/121)\n",
      "  Running task 64.0 in stage 2.0 (TID 307)\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000061_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000061\n",
      "  attempt_20220424192755421905508218217709_0012_m_000061_0: Committed\n",
      "  Finished task 61.0 in stage 2.0 (TID 304). 1996 bytes result sent to driver\n",
      "  Starting task 65.0 in stage 2.0 (TID 308) (namenode, executor driver, partition 65, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 61.0 in stage 2.0 (TID 304) in 77 ms on namenode (executor driver) (63/121)\n",
      "  Running task 65.0 in stage 2.0 (TID 308)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 52, boot = -44, init = 90, finish = 6\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000065_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000065\n",
      "  attempt_20220424192755421905508218217709_0012_m_000065_0: Committed\n",
      "  Finished task 65.0 in stage 2.0 (TID 308). 1996 bytes result sent to driver\n",
      "  Times: total = 61, boot = -25, init = 80, finish = 6\n",
      "  Starting task 66.0 in stage 2.0 (TID 309) (namenode, executor driver, partition 66, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 66.0 in stage 2.0 (TID 309)\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000064_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000064\n",
      "  attempt_20220424192755421905508218217709_0012_m_000064_0: Committed\n",
      "  Finished task 64.0 in stage 2.0 (TID 307). 1996 bytes result sent to driver\n",
      "  Finished task 65.0 in stage 2.0 (TID 308) in 74 ms on namenode (executor driver) (64/121)\n",
      "  Starting task 67.0 in stage 2.0 (TID 310) (namenode, executor driver, partition 67, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 64.0 in stage 2.0 (TID 307) in 78 ms on namenode (executor driver) (65/121)\n",
      "  Running task 67.0 in stage 2.0 (TID 310)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 87, boot = -67, init = 121, finish = 33\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000063_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000063\n",
      "  attempt_20220424192755421905508218217709_0012_m_000063_0: Committed\n",
      "  Finished task 63.0 in stage 2.0 (TID 306). 1996 bytes result sent to driver\n",
      "  Starting task 68.0 in stage 2.0 (TID 311) (namenode, executor driver, partition 68, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Running task 68.0 in stage 2.0 (TID 311)\n",
      "  Finished task 63.0 in stage 2.0 (TID 306) in 103 ms on namenode (executor driver) (66/121)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 18, boot = -12, init = 14, finish = 16\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000067_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000067\n",
      "  attempt_20220424192755421905508218217709_0012_m_000067_0: Committed\n",
      "  Finished task 67.0 in stage 2.0 (TID 310). 1996 bytes result sent to driver\n",
      "  Starting task 70.0 in stage 2.0 (TID 312) (namenode, executor driver, partition 70, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 70.0 in stage 2.0 (TID 312)\n",
      "  Finished task 67.0 in stage 2.0 (TID 310) in 49 ms on namenode (executor driver) (67/121)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 29, boot = 20, init = 1, finish = 8\n",
      "  Times: total = 14, boot = 6, init = 1, finish = 7\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000066_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000066\n",
      "  attempt_20220424192755421905508218217709_0012_m_000066_0: Committed\n",
      "  Finished task 66.0 in stage 2.0 (TID 309). 1996 bytes result sent to driver\n",
      "  Starting task 71.0 in stage 2.0 (TID 313) (namenode, executor driver, partition 71, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 71.0 in stage 2.0 (TID 313)\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000068_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000068\n",
      "  attempt_20220424192755421905508218217709_0012_m_000068_0: Committed\n",
      "  Finished task 68.0 in stage 2.0 (TID 311). 1996 bytes result sent to driver\n",
      "  Finished task 66.0 in stage 2.0 (TID 309) in 63 ms on namenode (executor driver) (68/121)\n",
      "  Starting task 72.0 in stage 2.0 (TID 314) (namenode, executor driver, partition 72, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 68.0 in stage 2.0 (TID 311) in 47 ms on namenode (executor driver) (69/121)\n",
      "  Running task 72.0 in stage 2.0 (TID 314)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 10, boot = -16, init = 19, finish = 7\n",
      "  Times: total = 18, boot = 9, init = 1, finish = 8\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000071_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000071\n",
      "  attempt_20220424192755421905508218217709_0012_m_000071_0: Committed\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000070_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000070\n",
      "  attempt_20220424192755421905508218217709_0012_m_000070_0: Committed\n",
      "  Finished task 71.0 in stage 2.0 (TID 313). 1996 bytes result sent to driver\n",
      "  Finished task 70.0 in stage 2.0 (TID 312). 1996 bytes result sent to driver\n",
      "  Starting task 73.0 in stage 2.0 (TID 315) (namenode, executor driver, partition 73, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 73.0 in stage 2.0 (TID 315)\n",
      "  Starting task 74.0 in stage 2.0 (TID 316) (namenode, executor driver, partition 74, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 71.0 in stage 2.0 (TID 313) in 46 ms on namenode (executor driver) (70/121)\n",
      "  Finished task 70.0 in stage 2.0 (TID 312) in 58 ms on namenode (executor driver) (71/121)\n",
      "  Running task 74.0 in stage 2.0 (TID 316)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 11, boot = -23, init = 26, finish = 8\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000072_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000072\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  attempt_20220424192755421905508218217709_0012_m_000072_0: Committed\n",
      "  Finished task 72.0 in stage 2.0 (TID 314). 1996 bytes result sent to driver\n",
      "  Starting task 75.0 in stage 2.0 (TID 317) (namenode, executor driver, partition 75, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 75.0 in stage 2.0 (TID 317)\n",
      "  Finished task 72.0 in stage 2.0 (TID 314) in 56 ms on namenode (executor driver) (72/121)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 53, boot = -20, init = 65, finish = 8\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000074_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000074\n",
      "  attempt_20220424192755421905508218217709_0012_m_000074_0: Committed\n",
      "  Times: total = 61, boot = -28, init = 77, finish = 12\n",
      "  Finished task 74.0 in stage 2.0 (TID 316). 1996 bytes result sent to driver\n",
      "  Starting task 76.0 in stage 2.0 (TID 318) (namenode, executor driver, partition 76, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 74.0 in stage 2.0 (TID 316) in 74 ms on namenode (executor driver) (73/121)\n",
      "  Running task 76.0 in stage 2.0 (TID 318)\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000073_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000073\n",
      "  attempt_20220424192755421905508218217709_0012_m_000073_0: Committed\n",
      "  Times: total = 50, boot = -31, init = 76, finish = 5\n",
      "  Finished task 73.0 in stage 2.0 (TID 315). 1996 bytes result sent to driver\n",
      "  Starting task 77.0 in stage 2.0 (TID 319) (namenode, executor driver, partition 77, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 77.0 in stage 2.0 (TID 319)\n",
      "  Finished task 73.0 in stage 2.0 (TID 315) in 77 ms on namenode (executor driver) (74/121)\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000075_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000075\n",
      "  attempt_20220424192755421905508218217709_0012_m_000075_0: Committed\n",
      "  Finished task 75.0 in stage 2.0 (TID 317). 1996 bytes result sent to driver\n",
      "  Starting task 78.0 in stage 2.0 (TID 320) (namenode, executor driver, partition 78, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 75.0 in stage 2.0 (TID 317) in 67 ms on namenode (executor driver) (75/121)\n",
      "  Running task 78.0 in stage 2.0 (TID 320)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 23, boot = 13, init = 4, finish = 6\n",
      "  Times: total = 11, boot = -26, init = 31, finish = 6\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000076_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000076\n",
      "  attempt_20220424192755421905508218217709_0012_m_000076_0: Committed\n",
      "  Finished task 76.0 in stage 2.0 (TID 318). 1996 bytes result sent to driver\n",
      "  Starting task 79.0 in stage 2.0 (TID 321) (namenode, executor driver, partition 79, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000078_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000078\n",
      "  Running task 79.0 in stage 2.0 (TID 321)\n",
      "  attempt_20220424192755421905508218217709_0012_m_000078_0: Committed\n",
      "  Finished task 78.0 in stage 2.0 (TID 320). 1996 bytes result sent to driver\n",
      "  Finished task 76.0 in stage 2.0 (TID 318) in 91 ms on namenode (executor driver) (76/121)\n",
      "  Starting task 80.0 in stage 2.0 (TID 322) (namenode, executor driver, partition 80, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 78.0 in stage 2.0 (TID 320) in 85 ms on namenode (executor driver) (77/121)\n",
      "  Running task 80.0 in stage 2.0 (TID 322)\n",
      "  Times: total = 31, boot = -14, init = 40, finish = 5\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000077_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000077\n",
      "  attempt_20220424192755421905508218217709_0012_m_000077_0: Committed\n",
      "  Finished task 77.0 in stage 2.0 (TID 319). 1996 bytes result sent to driver\n",
      "  Starting task 81.0 in stage 2.0 (TID 323) (namenode, executor driver, partition 81, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 77.0 in stage 2.0 (TID 319) in 99 ms on namenode (executor driver) (78/121)\n",
      "  Running task 81.0 in stage 2.0 (TID 323)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 20, boot = -31, init = 34, finish = 17\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000081_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000081\n",
      "  attempt_20220424192755421905508218217709_0012_m_000081_0: Committed\n",
      "  Times: total = 20, boot = -33, init = 39, finish = 14\n",
      "  Finished task 81.0 in stage 2.0 (TID 323). 1996 bytes result sent to driver\n",
      "  Times: total = 7, boot = -49, init = 50, finish = 6\n",
      "  Starting task 82.0 in stage 2.0 (TID 324) (namenode, executor driver, partition 82, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 81.0 in stage 2.0 (TID 323) in 60 ms on namenode (executor driver) (79/121)\n",
      "  Running task 82.0 in stage 2.0 (TID 324)\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000080_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000080\n",
      "  attempt_20220424192755421905508218217709_0012_m_000080_0: Committed\n",
      "  Finished task 80.0 in stage 2.0 (TID 322). 1996 bytes result sent to driver\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000079_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000079\n",
      "  attempt_20220424192755421905508218217709_0012_m_000079_0: Committed\n",
      "  Finished task 79.0 in stage 2.0 (TID 321). 1996 bytes result sent to driver\n",
      "  Starting task 83.0 in stage 2.0 (TID 325) (namenode, executor driver, partition 83, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 83.0 in stage 2.0 (TID 325)\n",
      "  Starting task 84.0 in stage 2.0 (TID 326) (namenode, executor driver, partition 84, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 80.0 in stage 2.0 (TID 322) in 73 ms on namenode (executor driver) (80/121)\n",
      "  Finished task 79.0 in stage 2.0 (TID 321) in 75 ms on namenode (executor driver) (81/121)\n",
      "  Running task 84.0 in stage 2.0 (TID 326)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 51, boot = -37, init = 80, finish = 8\n",
      "  Times: total = 53, boot = -20, init = 67, finish = 6\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000083_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000083\n",
      "  attempt_20220424192755421905508218217709_0012_m_000083_0: Committed\n",
      "  Finished task 83.0 in stage 2.0 (TID 325). 1996 bytes result sent to driver\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000082_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000082\n",
      "  attempt_20220424192755421905508218217709_0012_m_000082_0: Committed\n",
      "  Starting task 85.0 in stage 2.0 (TID 327) (namenode, executor driver, partition 85, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 82.0 in stage 2.0 (TID 324). 1996 bytes result sent to driver\n",
      "  Starting task 86.0 in stage 2.0 (TID 328) (namenode, executor driver, partition 86, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 83.0 in stage 2.0 (TID 325) in 66 ms on namenode (executor driver) (82/121)\n",
      "  Finished task 82.0 in stage 2.0 (TID 324) in 70 ms on namenode (executor driver) (83/121)\n",
      "  Running task 86.0 in stage 2.0 (TID 328)\n",
      "  Running task 85.0 in stage 2.0 (TID 327)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 70, boot = -24, init = 70, finish = 24\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000084_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000084\n",
      "  attempt_20220424192755421905508218217709_0012_m_000084_0: Committed\n",
      "  Finished task 84.0 in stage 2.0 (TID 326). 1996 bytes result sent to driver\n",
      "  Starting task 87.0 in stage 2.0 (TID 329) (namenode, executor driver, partition 87, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 87.0 in stage 2.0 (TID 329)\n",
      "  Finished task 84.0 in stage 2.0 (TID 326) in 84 ms on namenode (executor driver) (84/121)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 2 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 20, boot = 13, init = 1, finish = 6\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000086_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000086\n",
      "  attempt_20220424192755421905508218217709_0012_m_000086_0: Committed\n",
      "  Finished task 86.0 in stage 2.0 (TID 328). 1996 bytes result sent to driver\n",
      "  Starting task 88.0 in stage 2.0 (TID 330) (namenode, executor driver, partition 88, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 88.0 in stage 2.0 (TID 330)\n",
      "  Finished task 86.0 in stage 2.0 (TID 328) in 62 ms on namenode (executor driver) (85/121)\n",
      "  Times: total = 12, boot = -4, init = 10, finish = 6\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000087_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000087\n",
      "  attempt_20220424192755421905508218217709_0012_m_000087_0: Committed\n",
      "  Finished task 87.0 in stage 2.0 (TID 329). 1996 bytes result sent to driver\n",
      "  Starting task 89.0 in stage 2.0 (TID 331) (namenode, executor driver, partition 89, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 89.0 in stage 2.0 (TID 331)\n",
      "  Finished task 87.0 in stage 2.0 (TID 329) in 46 ms on namenode (executor driver) (86/121)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 23, boot = -4, init = 19, finish = 8\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000085_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000085\n",
      "  attempt_20220424192755421905508218217709_0012_m_000085_0: Committed\n",
      "  Finished task 85.0 in stage 2.0 (TID 327). 1996 bytes result sent to driver\n",
      "  Starting task 90.0 in stage 2.0 (TID 332) (namenode, executor driver, partition 90, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 90.0 in stage 2.0 (TID 332)\n",
      "  Finished task 85.0 in stage 2.0 (TID 327) in 96 ms on namenode (executor driver) (87/121)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 9, boot = -28, init = 30, finish = 7\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000088_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000088\n",
      "  attempt_20220424192755421905508218217709_0012_m_000088_0: Committed\n",
      "  Finished task 88.0 in stage 2.0 (TID 330). 1996 bytes result sent to driver\n",
      "  Starting task 91.0 in stage 2.0 (TID 333) (namenode, executor driver, partition 91, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 91.0 in stage 2.0 (TID 333)\n",
      "  Finished task 88.0 in stage 2.0 (TID 330) in 62 ms on namenode (executor driver) (88/121)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 19, boot = -29, init = 34, finish = 14\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000089_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000089\n",
      "  attempt_20220424192755421905508218217709_0012_m_000089_0: Committed\n",
      "  Finished task 89.0 in stage 2.0 (TID 331). 1996 bytes result sent to driver\n",
      "  Starting task 92.0 in stage 2.0 (TID 334) (namenode, executor driver, partition 92, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 92.0 in stage 2.0 (TID 334)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Finished task 89.0 in stage 2.0 (TID 331) in 80 ms on namenode (executor driver) (89/121)\n",
      "  Times: total = 8, boot = -57, init = 59, finish = 6\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000090_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000090\n",
      "  attempt_20220424192755421905508218217709_0012_m_000090_0: Committed\n",
      "  Finished task 90.0 in stage 2.0 (TID 332). 2039 bytes result sent to driver\n",
      "  Starting task 93.0 in stage 2.0 (TID 335) (namenode, executor driver, partition 93, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 93.0 in stage 2.0 (TID 335)\n",
      "  Finished task 90.0 in stage 2.0 (TID 332) in 96 ms on namenode (executor driver) (90/121)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 6 ms\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 63, boot = -42, init = 89, finish = 16\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000091_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000091\n",
      "  attempt_20220424192755421905508218217709_0012_m_000091_0: Committed\n",
      "  Finished task 91.0 in stage 2.0 (TID 333). 2039 bytes result sent to driver\n",
      "  Starting task 94.0 in stage 2.0 (TID 336) (namenode, executor driver, partition 94, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 91.0 in stage 2.0 (TID 333) in 95 ms on namenode (executor driver) (91/121)\n",
      "  Running task 94.0 in stage 2.0 (TID 336)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 53, boot = -91, init = 138, finish = 6\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000092_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000092\n",
      "  attempt_20220424192755421905508218217709_0012_m_000092_0: Committed\n",
      "  Finished task 92.0 in stage 2.0 (TID 334). 2039 bytes result sent to driver\n",
      "  Starting task 95.0 in stage 2.0 (TID 337) (namenode, executor driver, partition 95, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 92.0 in stage 2.0 (TID 334) in 116 ms on namenode (executor driver) (92/121)\n",
      "  Running task 95.0 in stage 2.0 (TID 337)\n",
      "  Times: total = 58, boot = -74, init = 120, finish = 12\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000093_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000093\n",
      "  attempt_20220424192755421905508218217709_0012_m_000093_0: Committed\n",
      "  Finished task 93.0 in stage 2.0 (TID 335). 1996 bytes result sent to driver\n",
      "  Starting task 96.0 in stage 2.0 (TID 338) (namenode, executor driver, partition 96, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 93.0 in stage 2.0 (TID 335) in 77 ms on namenode (executor driver) (93/121)\n",
      "  Running task 96.0 in stage 2.0 (TID 338)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 12, boot = -20, init = 22, finish = 10\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000094_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000094\n",
      "  attempt_20220424192755421905508218217709_0012_m_000094_0: Committed\n",
      "  Finished task 94.0 in stage 2.0 (TID 336). 1996 bytes result sent to driver\n",
      "  Starting task 97.0 in stage 2.0 (TID 339) (namenode, executor driver, partition 97, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 97.0 in stage 2.0 (TID 339)\n",
      "  Finished task 94.0 in stage 2.0 (TID 336) in 79 ms on namenode (executor driver) (94/121)\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 11, boot = 1, init = 3, finish = 7\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000096_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000096\n",
      "  attempt_20220424192755421905508218217709_0012_m_000096_0: Committed\n",
      "  Finished task 96.0 in stage 2.0 (TID 338). 1996 bytes result sent to driver\n",
      "  Starting task 98.0 in stage 2.0 (TID 340) (namenode, executor driver, partition 98, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 96.0 in stage 2.0 (TID 338) in 52 ms on namenode (executor driver) (95/121)\n",
      "  Running task 98.0 in stage 2.0 (TID 340)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Times: total = 21, boot = 4, init = 8, finish = 9\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000095_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000095\n",
      "  attempt_20220424192755421905508218217709_0012_m_000095_0: Committed\n",
      "  Started 0 remote fetches in 2 ms\n",
      "  Finished task 95.0 in stage 2.0 (TID 337). 1996 bytes result sent to driver\n",
      "  Starting task 99.0 in stage 2.0 (TID 341) (namenode, executor driver, partition 99, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 99.0 in stage 2.0 (TID 341)\n",
      "  Finished task 95.0 in stage 2.0 (TID 337) in 72 ms on namenode (executor driver) (96/121)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 13, boot = -56, init = 58, finish = 11\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000097_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000097\n",
      "  attempt_20220424192755421905508218217709_0012_m_000097_0: Committed\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Finished task 97.0 in stage 2.0 (TID 339). 1996 bytes result sent to driver\n",
      "  Starting task 100.0 in stage 2.0 (TID 342) (namenode, executor driver, partition 100, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 97.0 in stage 2.0 (TID 339) in 63 ms on namenode (executor driver) (97/121)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Running task 100.0 in stage 2.0 (TID 342)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 11, boot = -26, init = 30, finish = 7\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000099_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000099\n",
      "  attempt_20220424192755421905508218217709_0012_m_000099_0: Committed\n",
      "  Finished task 99.0 in stage 2.0 (TID 341). 1996 bytes result sent to driver\n",
      "  Starting task 101.0 in stage 2.0 (TID 343) (namenode, executor driver, partition 101, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 101.0 in stage 2.0 (TID 343)\n",
      "  Finished task 99.0 in stage 2.0 (TID 341) in 48 ms on namenode (executor driver) (98/121)\n",
      "  Times: total = 17, boot = -16, init = 27, finish = 6\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000098_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000098\n",
      "  attempt_20220424192755421905508218217709_0012_m_000098_0: Committed\n",
      "  Finished task 98.0 in stage 2.0 (TID 340). 1996 bytes result sent to driver\n",
      "  Starting task 102.0 in stage 2.0 (TID 344) (namenode, executor driver, partition 102, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 98.0 in stage 2.0 (TID 340) in 70 ms on namenode (executor driver) (99/121)\n",
      "  Running task 102.0 in stage 2.0 (TID 344)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 49, boot = -39, init = 82, finish = 6\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000100_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000100\n",
      "  attempt_20220424192755421905508218217709_0012_m_000100_0: Committed\n",
      "  Finished task 100.0 in stage 2.0 (TID 342). 1996 bytes result sent to driver\n",
      "  Starting task 103.0 in stage 2.0 (TID 345) (namenode, executor driver, partition 103, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 100.0 in stage 2.0 (TID 342) in 63 ms on namenode (executor driver) (100/121)\n",
      "  Running task 103.0 in stage 2.0 (TID 345)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 51, boot = -25, init = 70, finish = 6\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000101_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000101\n",
      "  attempt_20220424192755421905508218217709_0012_m_000101_0: Committed\n",
      "  Finished task 101.0 in stage 2.0 (TID 343). 1996 bytes result sent to driver\n",
      "  Starting task 104.0 in stage 2.0 (TID 346) (namenode, executor driver, partition 104, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 101.0 in stage 2.0 (TID 343) in 68 ms on namenode (executor driver) (101/121)\n",
      "  Running task 104.0 in stage 2.0 (TID 346)\n",
      "  Times: total = 51, boot = -38, init = 83, finish = 6\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000102_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000102\n",
      "  attempt_20220424192755421905508218217709_0012_m_000102_0: Committed\n",
      "  Finished task 102.0 in stage 2.0 (TID 344). 1996 bytes result sent to driver\n",
      "  Starting task 105.0 in stage 2.0 (TID 347) (namenode, executor driver, partition 105, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 102.0 in stage 2.0 (TID 344) in 68 ms on namenode (executor driver) (102/121)\n",
      "  Running task 105.0 in stage 2.0 (TID 347)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 25, boot = 1, init = 2, finish = 22\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000103_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000103\n",
      "  attempt_20220424192755421905508218217709_0012_m_000103_0: Committed\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Finished task 103.0 in stage 2.0 (TID 345). 1996 bytes result sent to driver\n",
      "  Starting task 106.0 in stage 2.0 (TID 348) (namenode, executor driver, partition 106, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 106.0 in stage 2.0 (TID 348)\n",
      "  Finished task 103.0 in stage 2.0 (TID 345) in 50 ms on namenode (executor driver) (103/121)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 31, boot = 6, init = 11, finish = 14\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000104_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000104\n",
      "  attempt_20220424192755421905508218217709_0012_m_000104_0: Committed\n",
      "  Finished task 104.0 in stage 2.0 (TID 346). 1996 bytes result sent to driver\n",
      "  Starting task 107.0 in stage 2.0 (TID 349) (namenode, executor driver, partition 107, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 104.0 in stage 2.0 (TID 346) in 48 ms on namenode (executor driver) (104/121)\n",
      "  Running task 107.0 in stage 2.0 (TID 349)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 25, boot = -11, init = 14, finish = 22\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000106_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000106\n",
      "  attempt_20220424192755421905508218217709_0012_m_000106_0: Committed\n",
      "  Finished task 106.0 in stage 2.0 (TID 348). 1996 bytes result sent to driver\n",
      "  Starting task 108.0 in stage 2.0 (TID 350) (namenode, executor driver, partition 108, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Times: total = 11, boot = -2, init = 6, finish = 7\n",
      "  Finished task 106.0 in stage 2.0 (TID 348) in 46 ms on namenode (executor driver) (105/121)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Running task 108.0 in stage 2.0 (TID 350)\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000105_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000105\n",
      "  attempt_20220424192755421905508218217709_0012_m_000105_0: Committed\n",
      "  Finished task 105.0 in stage 2.0 (TID 347). 1996 bytes result sent to driver\n",
      "  Starting task 109.0 in stage 2.0 (TID 351) (namenode, executor driver, partition 109, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 109.0 in stage 2.0 (TID 351)\n",
      "  Finished task 105.0 in stage 2.0 (TID 347) in 73 ms on namenode (executor driver) (106/121)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Times: total = 9, boot = -4, init = 7, finish = 6\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000107_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000107\n",
      "  attempt_20220424192755421905508218217709_0012_m_000107_0: Committed\n",
      "  Finished task 107.0 in stage 2.0 (TID 349). 1996 bytes result sent to driver\n",
      "  Starting task 110.0 in stage 2.0 (TID 352) (namenode, executor driver, partition 110, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 110.0 in stage 2.0 (TID 352)\n",
      "  Finished task 107.0 in stage 2.0 (TID 349) in 46 ms on namenode (executor driver) (107/121)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 9, boot = -50, init = 53, finish = 6\n",
      "  Times: total = 55, boot = -6, init = 56, finish = 5\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000109_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000109\n",
      "  attempt_20220424192755421905508218217709_0012_m_000109_0: Committed\n",
      "  Finished task 109.0 in stage 2.0 (TID 351). 1996 bytes result sent to driver\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000108_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000108\n",
      "  attempt_20220424192755421905508218217709_0012_m_000108_0: Committed\n",
      "  Starting task 111.0 in stage 2.0 (TID 353) (namenode, executor driver, partition 111, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 108.0 in stage 2.0 (TID 350). 1996 bytes result sent to driver\n",
      "  Finished task 109.0 in stage 2.0 (TID 351) in 63 ms on namenode (executor driver) (108/121)\n",
      "  Running task 111.0 in stage 2.0 (TID 353)\n",
      "  Starting task 112.0 in stage 2.0 (TID 354) (namenode, executor driver, partition 112, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 108.0 in stage 2.0 (TID 350) in 81 ms on namenode (executor driver) (109/121)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Running task 112.0 in stage 2.0 (TID 354)\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 69, boot = -22, init = 84, finish = 7\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000110_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000110\n",
      "  attempt_20220424192755421905508218217709_0012_m_000110_0: Committed\n",
      "  Finished task 110.0 in stage 2.0 (TID 352). 1996 bytes result sent to driver\n",
      "  Starting task 113.0 in stage 2.0 (TID 355) (namenode, executor driver, partition 113, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 113.0 in stage 2.0 (TID 355)\n",
      "  Finished task 110.0 in stage 2.0 (TID 352) in 86 ms on namenode (executor driver) (110/121)\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 10, boot = -9, init = 12, finish = 7\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000112_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000112\n",
      "  attempt_20220424192755421905508218217709_0012_m_000112_0: Committed\n",
      "  Finished task 112.0 in stage 2.0 (TID 354). 1996 bytes result sent to driver\n",
      "  Starting task 114.0 in stage 2.0 (TID 356) (namenode, executor driver, partition 114, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 112.0 in stage 2.0 (TID 354) in 57 ms on namenode (executor driver) (111/121)\n",
      "  Running task 114.0 in stage 2.0 (TID 356)\n",
      "  Times: total = 57, boot = -41, init = 91, finish = 7\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000111_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000111\n",
      "  attempt_20220424192755421905508218217709_0012_m_000111_0: Committed\n",
      "  Finished task 111.0 in stage 2.0 (TID 353). 1996 bytes result sent to driver\n",
      "  Times: total = 9, boot = -8, init = 10, finish = 7\n",
      "  Starting task 115.0 in stage 2.0 (TID 357) (namenode, executor driver, partition 115, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Finished task 111.0 in stage 2.0 (TID 353) in 72 ms on namenode (executor driver) (112/121)\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000113_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000113\n",
      "  attempt_20220424192755421905508218217709_0012_m_000113_0: Committed\n",
      "  Running task 115.0 in stage 2.0 (TID 357)\n",
      "  Finished task 113.0 in stage 2.0 (TID 355). 1996 bytes result sent to driver\n",
      "  Starting task 116.0 in stage 2.0 (TID 358) (namenode, executor driver, partition 116, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 113.0 in stage 2.0 (TID 355) in 41 ms on namenode (executor driver) (113/121)\n",
      "  Running task 116.0 in stage 2.0 (TID 358)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Started 0 remote fetches in 0 ms\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 16, boot = -41, init = 51, finish = 6\n",
      "  Times: total = 44, boot = 7, init = 30, finish = 7\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000116_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000116\n",
      "  attempt_20220424192755421905508218217709_0012_m_000116_0: Committed\n",
      "  Finished task 116.0 in stage 2.0 (TID 358). 1996 bytes result sent to driver\n",
      "  Starting task 117.0 in stage 2.0 (TID 359) (namenode, executor driver, partition 117, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 117.0 in stage 2.0 (TID 359)\n",
      "  Finished task 116.0 in stage 2.0 (TID 358) in 67 ms on namenode (executor driver) (114/121)\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000114_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000114\n",
      "  attempt_20220424192755421905508218217709_0012_m_000114_0: Committed\n",
      "  Finished task 114.0 in stage 2.0 (TID 356). 1996 bytes result sent to driver\n",
      "  Starting task 118.0 in stage 2.0 (TID 360) (namenode, executor driver, partition 118, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 114.0 in stage 2.0 (TID 356) in 87 ms on namenode (executor driver) (115/121)\n",
      "  Running task 118.0 in stage 2.0 (TID 360)\n",
      "  Times: total = 23, boot = -20, init = 37, finish = 6\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000115_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000115\n",
      "  attempt_20220424192755421905508218217709_0012_m_000115_0: Committed\n",
      "  Finished task 115.0 in stage 2.0 (TID 357). 1996 bytes result sent to driver\n",
      "  Starting task 119.0 in stage 2.0 (TID 361) (namenode, executor driver, partition 119, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 115.0 in stage 2.0 (TID 357) in 76 ms on namenode (executor driver) (116/121)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Running task 119.0 in stage 2.0 (TID 361)\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 9, boot = -31, init = 34, finish = 6\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000119_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000119\n",
      "  attempt_20220424192755421905508218217709_0012_m_000119_0: Committed\n",
      "  Finished task 119.0 in stage 2.0 (TID 361). 1996 bytes result sent to driver\n",
      "  Starting task 120.0 in stage 2.0 (TID 362) (namenode, executor driver, partition 120, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 120.0 in stage 2.0 (TID 362)\n",
      "  Finished task 119.0 in stage 2.0 (TID 361) in 39 ms on namenode (executor driver) (117/121)\n",
      "  Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 49, boot = -41, init = 83, finish = 7\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000117_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000117\n",
      "  attempt_20220424192755421905508218217709_0012_m_000117_0: Committed\n",
      "  Finished task 117.0 in stage 2.0 (TID 359). 1996 bytes result sent to driver\n",
      "  Finished task 117.0 in stage 2.0 (TID 359) in 62 ms on namenode (executor driver) (118/121)\n",
      "  Times: total = 54, boot = -37, init = 83, finish = 8\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000118_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000118\n",
      "  attempt_20220424192755421905508218217709_0012_m_000118_0: Committed\n",
      "  Finished task 118.0 in stage 2.0 (TID 360). 1996 bytes result sent to driver\n",
      "  Finished task 118.0 in stage 2.0 (TID 360) in 70 ms on namenode (executor driver) (119/121)\n",
      "  Times: total = 52, boot = -17, init = 62, finish = 7\n",
      "  Saved output of task 'attempt_20220424192755421905508218217709_0012_m_000120_0' to file:/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output/_temporary/0/task_20220424192755421905508218217709_0012_m_000120\n",
      "  attempt_20220424192755421905508218217709_0012_m_000120_0: Committed\n",
      "  Finished task 120.0 in stage 2.0 (TID 362). 1996 bytes result sent to driver\n",
      "  Finished task 120.0 in stage 2.0 (TID 362) in 64 ms on namenode (executor driver) (120/121)\n",
      "  Aborting task\n",
      "org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n",
      "  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 619, in main\n",
      "    process()\n",
      "  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 611, in process\n",
      "    serializer.dump_stream(out_iter, outfile)\n",
      "  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 132, in dump_stream\n",
      "    for obj in iterator:\n",
      "  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/rdd.py\", line 1816, in func\n",
      "  File \"/home/ubuntu/.local/lib/python3.8/site-packages/mrjob/spark/harness.py\", line 575, in reduce_lines\n",
      "    for k, v in job.reduce_pairs(pairs, step_num):\n",
      "  File \"/tmp/spark-ca87ba9b-ddbe-43ab-bfc3-ed19c0bd6d4a/userFiles-764b985d-332b-4d3a-85f2-2fef596b0044/mrjob.zip/mrjob/job.py\", line 866, in reduce_pairs\n",
      "    for k, v in self._combine_or_reduce_pairs(pairs, 'reducer', step_num):\n",
      "  File \"/tmp/spark-ca87ba9b-ddbe-43ab-bfc3-ed19c0bd6d4a/userFiles-764b985d-332b-4d3a-85f2-2fef596b0044/mrjob.zip/mrjob/job.py\", line 889, in _combine_or_reduce_pairs\n",
      "    for k, v in task(key, values) or ():\n",
      "  File \"/tmp/spark-ca87ba9b-ddbe-43ab-bfc3-ed19c0bd6d4a/userFiles-764b985d-332b-4d3a-85f2-2fef596b0044/script.zip/popular_comment_ubuntu_20220424_192746_474191.py\", line 28, in reducer_find_popular\n",
      "    p,s,v=values\n",
      "ValueError: too many values to unpack (expected 3)\n",
      "\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:545)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:703)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:685)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:498)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.internal.io.SparkHadoopWriter$.$anonfun$executeTask$1(SparkHadoopWriter.scala:136)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1496)\n",
      "\tat org.apache.spark.internal.io.SparkHadoopWriter$.executeTask(SparkHadoopWriter.scala:135)\n",
      "\tat org.apache.spark.internal.io.SparkHadoopWriter$.$anonfun$write$1(SparkHadoopWriter.scala:88)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Task attempt_20220424192755421905508218217709_0012_m_000069_0 aborted.\n",
      "  Exception in task 69.0 in stage 2.0 (TID 242)\n",
      "org.apache.spark.SparkException: Task failed while writing rows\n",
      "\tat org.apache.spark.internal.io.SparkHadoopWriter$.executeTask(SparkHadoopWriter.scala:163)\n",
      "\tat org.apache.spark.internal.io.SparkHadoopWriter$.$anonfun$write$1(SparkHadoopWriter.scala:88)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n",
      "  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 619, in main\n",
      "    process()\n",
      "  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 611, in process\n",
      "    serializer.dump_stream(out_iter, outfile)\n",
      "  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 132, in dump_stream\n",
      "    for obj in iterator:\n",
      "  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/rdd.py\", line 1816, in func\n",
      "  File \"/home/ubuntu/.local/lib/python3.8/site-packages/mrjob/spark/harness.py\", line 575, in reduce_lines\n",
      "    for k, v in job.reduce_pairs(pairs, step_num):\n",
      "  File \"/tmp/spark-ca87ba9b-ddbe-43ab-bfc3-ed19c0bd6d4a/userFiles-764b985d-332b-4d3a-85f2-2fef596b0044/mrjob.zip/mrjob/job.py\", line 866, in reduce_pairs\n",
      "    for k, v in self._combine_or_reduce_pairs(pairs, 'reducer', step_num):\n",
      "  File \"/tmp/spark-ca87ba9b-ddbe-43ab-bfc3-ed19c0bd6d4a/userFiles-764b985d-332b-4d3a-85f2-2fef596b0044/mrjob.zip/mrjob/job.py\", line 889, in _combine_or_reduce_pairs\n",
      "    for k, v in task(key, values) or ():\n",
      "  File \"/tmp/spark-ca87ba9b-ddbe-43ab-bfc3-ed19c0bd6d4a/userFiles-764b985d-332b-4d3a-85f2-2fef596b0044/script.zip/popular_comment_ubuntu_20220424_192746_474191.py\", line 28, in reducer_find_popular\n",
      "    p,s,v=values\n",
      "ValueError: too many values to unpack (expected 3)\n",
      "\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:545)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:703)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:685)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:498)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.internal.io.SparkHadoopWriter$.$anonfun$executeTask$1(SparkHadoopWriter.scala:136)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1496)\n",
      "\tat org.apache.spark.internal.io.SparkHadoopWriter$.executeTask(SparkHadoopWriter.scala:135)\n",
      "\t... 9 more\n",
      "  Lost task 69.0 in stage 2.0 (TID 242) (namenode executor driver): org.apache.spark.SparkException: Task failed while writing rows\n",
      "\tat org.apache.spark.internal.io.SparkHadoopWriter$.executeTask(SparkHadoopWriter.scala:163)\n",
      "\tat org.apache.spark.internal.io.SparkHadoopWriter$.$anonfun$write$1(SparkHadoopWriter.scala:88)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n",
      "  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 619, in main\n",
      "    process()\n",
      "  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 611, in process\n",
      "    serializer.dump_stream(out_iter, outfile)\n",
      "  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 132, in dump_stream\n",
      "    for obj in iterator:\n",
      "  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/rdd.py\", line 1816, in func\n",
      "  File \"/home/ubuntu/.local/lib/python3.8/site-packages/mrjob/spark/harness.py\", line 575, in reduce_lines\n",
      "    for k, v in job.reduce_pairs(pairs, step_num):\n",
      "  File \"/tmp/spark-ca87ba9b-ddbe-43ab-bfc3-ed19c0bd6d4a/userFiles-764b985d-332b-4d3a-85f2-2fef596b0044/mrjob.zip/mrjob/job.py\", line 866, in reduce_pairs\n",
      "    for k, v in self._combine_or_reduce_pairs(pairs, 'reducer', step_num):\n",
      "  File \"/tmp/spark-ca87ba9b-ddbe-43ab-bfc3-ed19c0bd6d4a/userFiles-764b985d-332b-4d3a-85f2-2fef596b0044/mrjob.zip/mrjob/job.py\", line 889, in _combine_or_reduce_pairs\n",
      "    for k, v in task(key, values) or ():\n",
      "  File \"/tmp/spark-ca87ba9b-ddbe-43ab-bfc3-ed19c0bd6d4a/userFiles-764b985d-332b-4d3a-85f2-2fef596b0044/script.zip/popular_comment_ubuntu_20220424_192746_474191.py\", line 28, in reducer_find_popular\n",
      "    p,s,v=values\n",
      "ValueError: too many values to unpack (expected 3)\n",
      "\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:545)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:703)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:685)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:498)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.internal.io.SparkHadoopWriter$.$anonfun$executeTask$1(SparkHadoopWriter.scala:136)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1496)\n",
      "\tat org.apache.spark.internal.io.SparkHadoopWriter$.executeTask(SparkHadoopWriter.scala:135)\n",
      "\t... 9 more\n",
      "\n",
      "  Task 69 in stage 2.0 failed 1 times; aborting job\n",
      "  Removed TaskSet 2.0, whose tasks have all completed, from pool \n",
      "  Cancelling stage 2\n",
      "  Killing all running tasks in stage 2: Stage cancelled\n",
      "  ResultStage 2 (runJob at SparkHadoopWriter.scala:83) failed in 40.209 s due to Job aborted due to stage failure: Task 69 in stage 2.0 failed 1 times, most recent failure: Lost task 69.0 in stage 2.0 (TID 242) (namenode executor driver): org.apache.spark.SparkException: Task failed while writing rows\n",
      "\tat org.apache.spark.internal.io.SparkHadoopWriter$.executeTask(SparkHadoopWriter.scala:163)\n",
      "\tat org.apache.spark.internal.io.SparkHadoopWriter$.$anonfun$write$1(SparkHadoopWriter.scala:88)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n",
      "  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 619, in main\n",
      "    process()\n",
      "  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 611, in process\n",
      "    serializer.dump_stream(out_iter, outfile)\n",
      "  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 132, in dump_stream\n",
      "    for obj in iterator:\n",
      "  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/rdd.py\", line 1816, in func\n",
      "  File \"/home/ubuntu/.local/lib/python3.8/site-packages/mrjob/spark/harness.py\", line 575, in reduce_lines\n",
      "    for k, v in job.reduce_pairs(pairs, step_num):\n",
      "  File \"/tmp/spark-ca87ba9b-ddbe-43ab-bfc3-ed19c0bd6d4a/userFiles-764b985d-332b-4d3a-85f2-2fef596b0044/mrjob.zip/mrjob/job.py\", line 866, in reduce_pairs\n",
      "    for k, v in self._combine_or_reduce_pairs(pairs, 'reducer', step_num):\n",
      "  File \"/tmp/spark-ca87ba9b-ddbe-43ab-bfc3-ed19c0bd6d4a/userFiles-764b985d-332b-4d3a-85f2-2fef596b0044/mrjob.zip/mrjob/job.py\", line 889, in _combine_or_reduce_pairs\n",
      "    for k, v in task(key, values) or ():\n",
      "  File \"/tmp/spark-ca87ba9b-ddbe-43ab-bfc3-ed19c0bd6d4a/userFiles-764b985d-332b-4d3a-85f2-2fef596b0044/script.zip/popular_comment_ubuntu_20220424_192746_474191.py\", line 28, in reducer_find_popular\n",
      "    p,s,v=values\n",
      "ValueError: too many values to unpack (expected 3)\n",
      "\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:545)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:703)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:685)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:498)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.internal.io.SparkHadoopWriter$.$anonfun$executeTask$1(SparkHadoopWriter.scala:136)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1496)\n",
      "\tat org.apache.spark.internal.io.SparkHadoopWriter$.executeTask(SparkHadoopWriter.scala:135)\n",
      "\t... 9 more\n",
      "\n",
      "Driver stacktrace:\n",
      "  Job 0 failed: runJob at SparkHadoopWriter.scala:83, took 479.696215 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Aborting job job_20220424192755421905508218217709_0012.\r\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 69 in stage 2.0 failed 1 times, most recent failure: Lost task 69.0 in stage 2.0 (TID 242) (namenode executor driver): org.apache.spark.SparkException: Task failed while writing rows\r\n",
      "\tat org.apache.spark.internal.io.SparkHadoopWriter$.executeTask(SparkHadoopWriter.scala:163)\r\n",
      "\tat org.apache.spark.internal.io.SparkHadoopWriter$.$anonfun$write$1(SparkHadoopWriter.scala:88)\r\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\r\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\r\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\r\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\r\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:748)\r\n",
      "Caused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\r\n",
      "  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 619, in main\r\n",
      "    process()\r\n",
      "  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 611, in process\r\n",
      "    serializer.dump_stream(out_iter, outfile)\r\n",
      "  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 132, in dump_stream\r\n",
      "    for obj in iterator:\r\n",
      "  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/rdd.py\", line 1816, in func\r\n",
      "  File \"/home/ubuntu/.local/lib/python3.8/site-packages/mrjob/spark/harness.py\", line 575, in reduce_lines\r\n",
      "    for k, v in job.reduce_pairs(pairs, step_num):\r\n",
      "  File \"/tmp/spark-ca87ba9b-ddbe-43ab-bfc3-ed19c0bd6d4a/userFiles-764b985d-332b-4d3a-85f2-2fef596b0044/mrjob.zip/mrjob/job.py\", line 866, in reduce_pairs\r\n",
      "    for k, v in self._combine_or_reduce_pairs(pairs, 'reducer', step_num):\r\n",
      "  File \"/tmp/spark-ca87ba9b-ddbe-43ab-bfc3-ed19c0bd6d4a/userFiles-764b985d-332b-4d3a-85f2-2fef596b0044/mrjob.zip/mrjob/job.py\", line 889, in _combine_or_reduce_pairs\r\n",
      "    for k, v in task(key, values) or ():\r\n",
      "  File \"/tmp/spark-ca87ba9b-ddbe-43ab-bfc3-ed19c0bd6d4a/userFiles-764b985d-332b-4d3a-85f2-2fef596b0044/script.zip/popular_comment_ubuntu_20220424_192746_474191.py\", line 28, in reducer_find_popular\r\n",
      "    p,s,v=values\r\n",
      "ValueError: too many values to unpack (expected 3)\r\n",
      "\r\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:545)\r\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:703)\r\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:685)\r\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:498)\r\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\r\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\r\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\r\n",
      "\tat org.apache.spark.internal.io.SparkHadoopWriter$.$anonfun$executeTask$1(SparkHadoopWriter.scala:136)\r\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1496)\r\n",
      "\tat org.apache.spark.internal.io.SparkHadoopWriter$.executeTask(SparkHadoopWriter.scala:135)\r\n",
      "\t... 9 more\r\n",
      "\r\n",
      "Driver stacktrace:\r\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2403)\r\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2352)\r\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2351)\r\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2351)\r\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1109)\r\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1109)\r\n",
      "\tat scala.Option.foreach(Option.scala:407)\r\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1109)\r\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2591)\r\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2533)\r\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2522)\r\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:898)\r\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2214)\r\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2235)\r\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2267)\r\n",
      "\tat org.apache.spark.internal.io.SparkHadoopWriter$.write(SparkHadoopWriter.scala:83)\r\n",
      "\tat org.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopDataset$1(PairRDDFunctions.scala:1090)\r\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\r\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n",
      "\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:414)\r\n",
      "\tat org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopDataset(PairRDDFunctions.scala:1088)\r\n",
      "\tat org.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$4(PairRDDFunctions.scala:1061)\r\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\r\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n",
      "\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:414)\r\n",
      "\tat org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1026)\r\n",
      "\tat org.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$3(PairRDDFunctions.scala:1008)\r\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\r\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n",
      "\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:414)\r\n",
      "\tat org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1007)\r\n",
      "\tat org.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$2(PairRDDFunctions.scala:964)\r\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\r\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n",
      "\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:414)\r\n",
      "\tat org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:962)\r\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$saveAsTextFile$2(RDD.scala:1578)\r\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\r\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n",
      "\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:414)\r\n",
      "\tat org.apache.spark.rdd.RDD.saveAsTextFile(RDD.scala:1578)\r\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$saveAsTextFile$1(RDD.scala:1564)\r\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\r\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n",
      "\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:414)\r\n",
      "\tat org.apache.spark.rdd.RDD.saveAsTextFile(RDD.scala:1564)\r\n",
      "\tat org.apache.spark.api.java.JavaRDDLike.saveAsTextFile(JavaRDDLike.scala:551)\r\n",
      "\tat org.apache.spark.api.java.JavaRDDLike.saveAsTextFile$(JavaRDDLike.scala:550)\r\n",
      "\tat org.apache.spark.api.java.AbstractJavaRDDLike.saveAsTextFile(JavaRDDLike.scala:45)\r\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\r\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n",
      "\tat java.lang.Thread.run(Thread.java:748)\r\n",
      "Caused by: org.apache.spark.SparkException: Task failed while writing rows\r\n",
      "\tat org.apache.spark.internal.io.SparkHadoopWriter$.executeTask(SparkHadoopWriter.scala:163)\r\n",
      "\tat org.apache.spark.internal.io.SparkHadoopWriter$.$anonfun$write$1(SparkHadoopWriter.scala:88)\r\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\r\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\r\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\r\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\r\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\t... 1 more\r\n",
      "Caused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\r\n",
      "  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 619, in main\r\n",
      "    process()\r\n",
      "  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 611, in process\r\n",
      "    serializer.dump_stream(out_iter, outfile)\r\n",
      "  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 132, in dump_stream\r\n",
      "    for obj in iterator:\r\n",
      "  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/rdd.py\", line 1816, in func\r\n",
      "  File \"/home/ubuntu/.local/lib/python3.8/site-packages/mrjob/spark/harness.py\", line 575, in reduce_lines\r\n",
      "    for k, v in job.reduce_pairs(pairs, step_num):\r\n",
      "  File \"/tmp/spark-ca87ba9b-ddbe-43ab-bfc3-ed19c0bd6d4a/userFiles-764b985d-332b-4d3a-85f2-2fef596b0044/mrjob.zip/mrjob/job.py\", line 866, in reduce_pairs\r\n",
      "    for k, v in self._combine_or_reduce_pairs(pairs, 'reducer', step_num):\r\n",
      "  File \"/tmp/spark-ca87ba9b-ddbe-43ab-bfc3-ed19c0bd6d4a/userFiles-764b985d-332b-4d3a-85f2-2fef596b0044/mrjob.zip/mrjob/job.py\", line 889, in _combine_or_reduce_pairs\r\n",
      "    for k, v in task(key, values) or ():\r\n",
      "  File \"/tmp/spark-ca87ba9b-ddbe-43ab-bfc3-ed19c0bd6d4a/userFiles-764b985d-332b-4d3a-85f2-2fef596b0044/script.zip/popular_comment_ubuntu_20220424_192746_474191.py\", line 28, in reducer_find_popular\r\n",
      "    p,s,v=values\r\n",
      "ValueError: too many values to unpack (expected 3)\r\n",
      "\r\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:545)\r\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:703)\r\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:685)\r\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:498)\r\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\r\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\r\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\r\n",
      "\tat org.apache.spark.internal.io.SparkHadoopWriter$.$anonfun$executeTask$1(SparkHadoopWriter.scala:136)\r\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1496)\r\n",
      "\tat org.apache.spark.internal.io.SparkHadoopWriter$.executeTask(SparkHadoopWriter.scala:135)\r\n",
      "\t... 9 more\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/home/ubuntu/.local/lib/python3.8/site-packages/mrjob/spark/harness.py\", line 694, in <module>\r\n",
      "    main()\r\n",
      "  File \"/home/ubuntu/.local/lib/python3.8/site-packages/mrjob/spark/harness.py\", line 281, in main\r\n",
      "    rdd.saveAsTextFile(\r\n",
      "  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/rdd.py\", line 1828, in saveAsTextFile\r\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.9.2-src.zip/py4j/java_gateway.py\", line 1309, in __call__\r\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.9.2-src.zip/py4j/protocol.py\", line 326, in get_return_value\r\n",
      "py4j.protocol.Py4JJavaError: An error occurred while calling o63.saveAsTextFile.\r\n",
      ": org.apache.spark.SparkException: Job aborted.\r\n",
      "\tat org.apache.spark.internal.io.SparkHadoopWriter$.write(SparkHadoopWriter.scala:106)\r\n",
      "\tat org.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopDataset$1(PairRDDFunctions.scala:1090)\r\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\r\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n",
      "\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:414)\r\n",
      "\tat org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopDataset(PairRDDFunctions.scala:1088)\r\n",
      "\tat org.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$4(PairRDDFunctions.scala:1061)\r\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\r\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n",
      "\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:414)\r\n",
      "\tat org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1026)\r\n",
      "\tat org.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$3(PairRDDFunctions.scala:1008)\r\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\r\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n",
      "\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:414)\r\n",
      "\tat org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1007)\r\n",
      "\tat org.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$2(PairRDDFunctions.scala:964)\r\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\r\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n",
      "\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:414)\r\n",
      "\tat org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:962)\r\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$saveAsTextFile$2(RDD.scala:1578)\r\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\r\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n",
      "\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:414)\r\n",
      "\tat org.apache.spark.rdd.RDD.saveAsTextFile(RDD.scala:1578)\r\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$saveAsTextFile$1(RDD.scala:1564)\r\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\r\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n",
      "\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:414)\r\n",
      "\tat org.apache.spark.rdd.RDD.saveAsTextFile(RDD.scala:1564)\r\n",
      "\tat org.apache.spark.api.java.JavaRDDLike.saveAsTextFile(JavaRDDLike.scala:551)\r\n",
      "\tat org.apache.spark.api.java.JavaRDDLike.saveAsTextFile$(JavaRDDLike.scala:550)\r\n",
      "\tat org.apache.spark.api.java.AbstractJavaRDDLike.saveAsTextFile(JavaRDDLike.scala:45)\r\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\r\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n",
      "\tat java.lang.Thread.run(Thread.java:748)\r\n",
      "Caused by: org.apache.spark.SparkException: Job aborted due to stage failure: Task 69 in stage 2.0 failed 1 times, most recent failure: Lost task 69.0 in stage 2.0 (TID 242) (namenode executor driver): org.apache.spark.SparkException: Task failed while writing rows\r\n",
      "\tat org.apache.spark.internal.io.SparkHadoopWriter$.executeTask(SparkHadoopWriter.scala:163)\r\n",
      "\tat org.apache.spark.internal.io.SparkHadoopWriter$.$anonfun$write$1(SparkHadoopWriter.scala:88)\r\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\r\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\r\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\r\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\r\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\tat java.lang.Thread.run(Thread.java:748)\r\n",
      "Caused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\r\n",
      "  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 619, in main\r\n",
      "    process()\r\n",
      "  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 611, in process\r\n",
      "    serializer.dump_stream(out_iter, outfile)\r\n",
      "  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 132, in dump_stream\r\n",
      "    for obj in iterator:\r\n",
      "  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/rdd.py\", line 1816, in func\r\n",
      "  File \"/home/ubuntu/.local/lib/python3.8/site-packages/mrjob/spark/harness.py\", line 575, in reduce_lines\r\n",
      "    for k, v in job.reduce_pairs(pairs, step_num):\r\n",
      "  File \"/tmp/spark-ca87ba9b-ddbe-43ab-bfc3-ed19c0bd6d4a/userFiles-764b985d-332b-4d3a-85f2-2fef596b0044/mrjob.zip/mrjob/job.py\", line 866, in reduce_pairs\r\n",
      "    for k, v in self._combine_or_reduce_pairs(pairs, 'reducer', step_num):\r\n",
      "  File \"/tmp/spark-ca87ba9b-ddbe-43ab-bfc3-ed19c0bd6d4a/userFiles-764b985d-332b-4d3a-85f2-2fef596b0044/mrjob.zip/mrjob/job.py\", line 889, in _combine_or_reduce_pairs\r\n",
      "    for k, v in task(key, values) or ():\r\n",
      "  File \"/tmp/spark-ca87ba9b-ddbe-43ab-bfc3-ed19c0bd6d4a/userFiles-764b985d-332b-4d3a-85f2-2fef596b0044/script.zip/popular_comment_ubuntu_20220424_192746_474191.py\", line 28, in reducer_find_popular\r\n",
      "    p,s,v=values\r\n",
      "ValueError: too many values to unpack (expected 3)\r\n",
      "\r\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:545)\r\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:703)\r\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:685)\r\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:498)\r\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\r\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\r\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\r\n",
      "\tat org.apache.spark.internal.io.SparkHadoopWriter$.$anonfun$executeTask$1(SparkHadoopWriter.scala:136)\r\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1496)\r\n",
      "\tat org.apache.spark.internal.io.SparkHadoopWriter$.executeTask(SparkHadoopWriter.scala:135)\r\n",
      "\t... 9 more\r\n",
      "\r\n",
      "Driver stacktrace:\r\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2403)\r\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2352)\r\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2351)\r\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2351)\r\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1109)\r\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1109)\r\n",
      "\tat scala.Option.foreach(Option.scala:407)\r\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1109)\r\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2591)\r\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2533)\r\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2522)\r\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:898)\r\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2214)\r\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2235)\r\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2267)\r\n",
      "\tat org.apache.spark.internal.io.SparkHadoopWriter$.write(SparkHadoopWriter.scala:83)\r\n",
      "\t... 51 more\r\n",
      "Caused by: org.apache.spark.SparkException: Task failed while writing rows\r\n",
      "\tat org.apache.spark.internal.io.SparkHadoopWriter$.executeTask(SparkHadoopWriter.scala:163)\r\n",
      "\tat org.apache.spark.internal.io.SparkHadoopWriter$.$anonfun$write$1(SparkHadoopWriter.scala:88)\r\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\r\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\r\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\r\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\r\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n",
      "\t... 1 more\r\n",
      "Caused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\r\n",
      "  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 619, in main\r\n",
      "    process()\r\n",
      "  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 611, in process\r\n",
      "    serializer.dump_stream(out_iter, outfile)\r\n",
      "  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 132, in dump_stream\r\n",
      "    for obj in iterator:\r\n",
      "  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/rdd.py\", line 1816, in func\r\n",
      "  File \"/home/ubuntu/.local/lib/python3.8/site-packages/mrjob/spark/harness.py\", line 575, in reduce_lines\r\n",
      "    for k, v in job.reduce_pairs(pairs, step_num):\r\n",
      "  File \"/tmp/spark-ca87ba9b-ddbe-43ab-bfc3-ed19c0bd6d4a/userFiles-764b985d-332b-4d3a-85f2-2fef596b0044/mrjob.zip/mrjob/job.py\", line 866, in reduce_pairs\r\n",
      "    for k, v in self._combine_or_reduce_pairs(pairs, 'reducer', step_num):\r\n",
      "  File \"/tmp/spark-ca87ba9b-ddbe-43ab-bfc3-ed19c0bd6d4a/userFiles-764b985d-332b-4d3a-85f2-2fef596b0044/mrjob.zip/mrjob/job.py\", line 889, in _combine_or_reduce_pairs\r\n",
      "    for k, v in task(key, values) or ():\r\n",
      "  File \"/tmp/spark-ca87ba9b-ddbe-43ab-bfc3-ed19c0bd6d4a/userFiles-764b985d-332b-4d3a-85f2-2fef596b0044/script.zip/popular_comment_ubuntu_20220424_192746_474191.py\", line 28, in reducer_find_popular\r\n",
      "    p,s,v=values\r\n",
      "ValueError: too many values to unpack (expected 3)\r\n",
      "\r\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:545)\r\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:703)\r\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:685)\r\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:498)\r\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\r\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\r\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\r\n",
      "\tat org.apache.spark.internal.io.SparkHadoopWriter$.$anonfun$executeTask$1(SparkHadoopWriter.scala:136)\r\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1496)\r\n",
      "\tat org.apache.spark.internal.io.SparkHadoopWriter$.executeTask(SparkHadoopWriter.scala:135)\r\n",
      "\t... 9 more\r\n",
      "\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Invoking stop() from shutdown hook\n",
      "  Stopped Spark@2b261552{HTTP/1.1, (http/1.1)}{0.0.0.0:4041}\n",
      "  Stopped Spark web UI at http://namenode:4041\n",
      "  MapOutputTrackerMasterEndpoint stopped!\n",
      "  MemoryStore cleared\n",
      "  BlockManager stopped\n",
      "  BlockManagerMaster stopped\n",
      "  OutputCommitCoordinator stopped!\n",
      "  Successfully stopped SparkContext\n",
      "  Shutdown hook called\n",
      "  Deleting directory /tmp/spark-ca87ba9b-ddbe-43ab-bfc3-ed19c0bd6d4a\n",
      "  Deleting directory /tmp/spark-318364e7-8a47-4813-9c2d-3aeeebfd22c8\n",
      "  Deleting directory /tmp/spark-ca87ba9b-ddbe-43ab-bfc3-ed19c0bd6d4a/pyspark-ee2612bc-dd00-4a1e-9c04-f128d72c196c\n",
      "\n",
      "Probable cause of failure:\n",
      "\n",
      "Aborting task\n",
      "org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n",
      "  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 619, in main\n",
      "    process()\n",
      "  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 611, in process\n",
      "    serializer.dump_stream(out_iter, outfile)\n",
      "  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 132, in dump_stream\n",
      "    for obj in iterator:\n",
      "  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/rdd.py\", line 1816, in func\n",
      "  File \"/home/ubuntu/.local/lib/python3.8/site-packages/mrjob/spark/harness.py\", line 575, in reduce_lines\n",
      "    for k, v in job.reduce_pairs(pairs, step_num):\n",
      "  File \"/tmp/spark-ca87ba9b-ddbe-43ab-bfc3-ed19c0bd6d4a/userFiles-764b985d-332b-4d3a-85f2-2fef596b0044/mrjob.zip/mrjob/job.py\", line 866, in reduce_pairs\n",
      "    for k, v in self._combine_or_reduce_pairs(pairs, 'reducer', step_num):\n",
      "  File \"/tmp/spark-ca87ba9b-ddbe-43ab-bfc3-ed19c0bd6d4a/userFiles-764b985d-332b-4d3a-85f2-2fef596b0044/mrjob.zip/mrjob/job.py\", line 889, in _combine_or_reduce_pairs\n",
      "    for k, v in task(key, values) or ():\n",
      "  File \"/tmp/spark-ca87ba9b-ddbe-43ab-bfc3-ed19c0bd6d4a/userFiles-764b985d-332b-4d3a-85f2-2fef596b0044/script.zip/popular_comment_ubuntu_20220424_192746_474191.py\", line 28, in reducer_find_popular\n",
      "    p,s,v=values\n",
      "ValueError: too many values to unpack (expected 3)\n",
      "\n",
      "\n",
      "Steps 1-2 of 2 failed: Command '['/usr/local/spark/bin/spark-submit', '--conf', 'spark.executorEnv.PYSPARK_PYTHON=python3', '--master', 'local[*]', '--deploy-mode', 'client', '--py-files', '/tmp/popular_comment.ubuntu.20220424.192746.474191/mrjob.zip,/tmp/popular_comment.ubuntu.20220424.192746.474191/script.zip', '/home/ubuntu/.local/lib/python3.8/site-packages/mrjob/spark/harness.py', 'popular_comment_ubuntu_20220424_192746_474191.MostPopular', 'hdfs://namenode:9000/dis_materials/data_reddit.csv', 'file:///tmp/popular_comment.ubuntu.20220424.192746.474191-spark/output', '--no-hadoop-input-format', '--no-hadoop-output-format', '--no-sort-values', '--steps-desc', '[{\"type\": \"streaming\", \"mapper\": {\"type\": \"script\"}, \"reducer\": {\"type\": \"script\"} }, {\"type\": \"streaming\", \"mapper\": {\"type\": \"script\"}, \"reducer\": {\"type\": \"script\"} }]', '--counter-output-dir', '/tmp/popular_comment.ubuntu.20220424.192746.474191-spark/counter-output-step-0', '--first-step-num', '0', '--last-step-num', '1']' returned non-zero exit status 256.\n"
     ]
    }
   ],
   "source": [
    "!python3 popular_comment.py -r spark hdfs://namenode:9000/dis_materials/data_reddit.csv >outco211.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f71c852c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "No configs specified for spark runner\n",
      "Looking for hadoop binary in /usr/local/hadoop/bin...\n",
      "Found hadoop binary: /usr/local/hadoop/bin/hadoop\n",
      "Looking for spark-submit binary in /usr/local/spark/bin...\n",
      "Found spark-submit binary: /usr/local/spark/bin/spark-submit\n",
      "Running step 1 of 1\n",
      "Creating temp directory /tmp/popular.ubuntu.20220426.080555.284224\n",
      "  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "  Running Spark version 3.2.0\n",
      "  ==============================================================\n",
      "  No custom resources configured for spark.driver.\n",
      "  ==============================================================\n",
      "  Submitted application: harness.py\n",
      "  Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)\n",
      "  Limiting resource is cpu\n",
      "  Added ResourceProfile id: 0\n",
      "  Changing view acls to: ubuntu\n",
      "  Changing modify acls to: ubuntu\n",
      "  Changing view acls groups to: \n",
      "  Changing modify acls groups to: \n",
      "  SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ubuntu); groups with view permissions: Set(); users  with modify permissions: Set(ubuntu); groups with modify permissions: Set()\n",
      "  Successfully started service 'sparkDriver' on port 37871.\n",
      "  Registering MapOutputTracker\n",
      "  Registering BlockManagerMaster\n",
      "  Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information\n",
      "  BlockManagerMasterEndpoint up\n",
      "  Registering BlockManagerMasterHeartbeat\n",
      "  Created local directory at /tmp/blockmgr-aaf85acc-a5ff-4094-941d-b069532d448f\n",
      "  MemoryStore started with capacity 366.3 MiB\n",
      "  Registering OutputCommitCoordinator\n",
      "  Logging initialized @3998ms to org.sparkproject.jetty.util.log.Slf4jLog\n",
      "  jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_312-8u312-b07-0ubuntu1~20.04-b07\n",
      "  Started @4149ms\n",
      "  Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "  Started ServerConnector@54b480aa{HTTP/1.1, (http/1.1)}{0.0.0.0:4041}\n",
      "  Successfully started service 'SparkUI' on port 4041.\n",
      "  Started o.s.j.s.ServletContextHandler@25e258a3{/jobs,null,AVAILABLE,@Spark}\n",
      "  Started o.s.j.s.ServletContextHandler@6077a3f9{/jobs/json,null,AVAILABLE,@Spark}\n",
      "  Started o.s.j.s.ServletContextHandler@191c2764{/jobs/job,null,AVAILABLE,@Spark}\n",
      "  Started o.s.j.s.ServletContextHandler@4666747d{/jobs/job/json,null,AVAILABLE,@Spark}\n",
      "  Started o.s.j.s.ServletContextHandler@334ade09{/stages,null,AVAILABLE,@Spark}\n",
      "  Started o.s.j.s.ServletContextHandler@32a9a5a0{/stages/json,null,AVAILABLE,@Spark}\n",
      "  Started o.s.j.s.ServletContextHandler@244243ac{/stages/stage,null,AVAILABLE,@Spark}\n",
      "  Started o.s.j.s.ServletContextHandler@4feb80c0{/stages/stage/json,null,AVAILABLE,@Spark}\n",
      "  Started o.s.j.s.ServletContextHandler@691230b5{/stages/pool,null,AVAILABLE,@Spark}\n",
      "  Started o.s.j.s.ServletContextHandler@141bc2df{/stages/pool/json,null,AVAILABLE,@Spark}\n",
      "  Started o.s.j.s.ServletContextHandler@6bf3d2cd{/storage,null,AVAILABLE,@Spark}\n",
      "  Started o.s.j.s.ServletContextHandler@b80c9aa{/storage/json,null,AVAILABLE,@Spark}\n",
      "  Started o.s.j.s.ServletContextHandler@b85af2b{/storage/rdd,null,AVAILABLE,@Spark}\n",
      "  Started o.s.j.s.ServletContextHandler@78cf4e70{/storage/rdd/json,null,AVAILABLE,@Spark}\n",
      "  Started o.s.j.s.ServletContextHandler@ba9399a{/environment,null,AVAILABLE,@Spark}\n",
      "  Started o.s.j.s.ServletContextHandler@4326666{/environment/json,null,AVAILABLE,@Spark}\n",
      "  Started o.s.j.s.ServletContextHandler@726d4705{/executors,null,AVAILABLE,@Spark}\n",
      "  Started o.s.j.s.ServletContextHandler@331ec39{/executors/json,null,AVAILABLE,@Spark}\n",
      "  Started o.s.j.s.ServletContextHandler@7dbb4ec1{/executors/threadDump,null,AVAILABLE,@Spark}\n",
      "  Started o.s.j.s.ServletContextHandler@58a50538{/executors/threadDump/json,null,AVAILABLE,@Spark}\n",
      "  Started o.s.j.s.ServletContextHandler@292f7226{/static,null,AVAILABLE,@Spark}\n",
      "  Started o.s.j.s.ServletContextHandler@42c6d56a{/,null,AVAILABLE,@Spark}\n",
      "  Started o.s.j.s.ServletContextHandler@26d1a3ae{/api,null,AVAILABLE,@Spark}\n",
      "  Started o.s.j.s.ServletContextHandler@a68f435{/jobs/job/kill,null,AVAILABLE,@Spark}\n",
      "  Started o.s.j.s.ServletContextHandler@193302db{/stages/stage/kill,null,AVAILABLE,@Spark}\n",
      "  Bound SparkUI to 0.0.0.0, and started at http://namenode:4041\n",
      "  Added file file:///tmp/popular.ubuntu.20220426.080555.284224/mrjob.zip at file:///tmp/popular.ubuntu.20220426.080555.284224/mrjob.zip with timestamp 1650960360867\n",
      "  Copying /tmp/popular.ubuntu.20220426.080555.284224/mrjob.zip to /tmp/spark-30229df0-a1d7-4e2b-b0e0-c1675d0a2e51/userFiles-3594e4bf-82af-4bf4-b192-02ad57f9d40c/mrjob.zip\n",
      "  Added file file:///tmp/popular.ubuntu.20220426.080555.284224/script.zip at file:///tmp/popular.ubuntu.20220426.080555.284224/script.zip with timestamp 1650960360867\n",
      "  Copying /tmp/popular.ubuntu.20220426.080555.284224/script.zip to /tmp/spark-30229df0-a1d7-4e2b-b0e0-c1675d0a2e51/userFiles-3594e4bf-82af-4bf4-b192-02ad57f9d40c/script.zip\n",
      "  Starting executor ID driver on host namenode\n",
      "  Fetching file:///tmp/popular.ubuntu.20220426.080555.284224/script.zip with timestamp 1650960360867\n",
      "  /tmp/popular.ubuntu.20220426.080555.284224/script.zip has been previously copied to /tmp/spark-30229df0-a1d7-4e2b-b0e0-c1675d0a2e51/userFiles-3594e4bf-82af-4bf4-b192-02ad57f9d40c/script.zip\n",
      "  Fetching file:///tmp/popular.ubuntu.20220426.080555.284224/mrjob.zip with timestamp 1650960360867\n",
      "  /tmp/popular.ubuntu.20220426.080555.284224/mrjob.zip has been previously copied to /tmp/spark-30229df0-a1d7-4e2b-b0e0-c1675d0a2e51/userFiles-3594e4bf-82af-4bf4-b192-02ad57f9d40c/mrjob.zip\n",
      "  Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38187.\n",
      "  Server created on namenode:38187\n",
      "  Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy\n",
      "  Registering BlockManager BlockManagerId(driver, namenode, 38187, None)\n",
      "  Registering block manager namenode:38187 with 366.3 MiB RAM, BlockManagerId(driver, namenode, 38187, None)\n",
      "  Registered BlockManager BlockManagerId(driver, namenode, 38187, None)\n",
      "  Initialized BlockManager: BlockManagerId(driver, namenode, 38187, None)\n",
      "  Started o.s.j.s.ServletContextHandler@647e6958{/metrics/json,null,AVAILABLE,@Spark}\n",
      "  Block broadcast_0 stored as values in memory (estimated size 410.9 KiB, free 365.9 MiB)\n",
      "  Block broadcast_0_piece0 stored as bytes in memory (estimated size 42.1 KiB, free 365.9 MiB)\n",
      "  Added broadcast_0_piece0 in memory on namenode:38187 (size: 42.1 KiB, free: 366.3 MiB)\n",
      "  Created broadcast 0 from textFile at NativeMethodAccessorImpl.java:0\n",
      "  Total input files to process : 1\n",
      "  mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Starting job: runJob at SparkHadoopWriter.scala:83\n",
      "  Registering RDD 3 (groupBy at /home/ubuntu/.local/lib/python3.8/site-packages/mrjob/spark/harness.py:539) as input to shuffle 0\n",
      "  Got job 0 (runJob at SparkHadoopWriter.scala:83) with 121 output partitions\n",
      "  Final stage: ResultStage 1 (runJob at SparkHadoopWriter.scala:83)\n",
      "  Parents of final stage: List(ShuffleMapStage 0)\n",
      "  Missing parents: List(ShuffleMapStage 0)\n",
      "  Submitting ShuffleMapStage 0 (PairwiseRDD[3] at groupBy at /home/ubuntu/.local/lib/python3.8/site-packages/mrjob/spark/harness.py:539), which has no missing parents\n",
      "  Block broadcast_1 stored as values in memory (estimated size 15.7 KiB, free 365.8 MiB)\n",
      "  Block broadcast_1_piece0 stored as bytes in memory (estimated size 9.5 KiB, free 365.8 MiB)\n",
      "  Added broadcast_1_piece0 in memory on namenode:38187 (size: 9.5 KiB, free: 366.2 MiB)\n",
      "  Created broadcast 1 from broadcast at DAGScheduler.scala:1427\n",
      "  Submitting 121 missing tasks from ShuffleMapStage 0 (PairwiseRDD[3] at groupBy at /home/ubuntu/.local/lib/python3.8/site-packages/mrjob/spark/harness.py:539) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Adding task set 0.0 with 121 tasks resource profile 0\n",
      "  Starting task 0.0 in stage 0.0 (TID 0) (namenode, executor driver, partition 0, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Starting task 1.0 in stage 0.0 (TID 1) (namenode, executor driver, partition 1, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Starting task 2.0 in stage 0.0 (TID 2) (namenode, executor driver, partition 2, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Starting task 3.0 in stage 0.0 (TID 3) (namenode, executor driver, partition 3, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 3.0 in stage 0.0 (TID 3)\n",
      "  Running task 0.0 in stage 0.0 (TID 0)\n",
      "  Running task 2.0 in stage 0.0 (TID 2)\n",
      "  Running task 1.0 in stage 0.0 (TID 1)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:0+134217728\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:402653184+134217728\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:134217728+134217728\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:268435456+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 7511, boot = 381, init = 745, finish = 6385\n",
      "  Times: total = 7447, boot = 406, init = 703, finish = 6338\n",
      "  Finished task 1.0 in stage 0.0 (TID 1). 1863 bytes result sent to driver\n",
      "  Starting task 4.0 in stage 0.0 (TID 4) (namenode, executor driver, partition 4, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 4.0 in stage 0.0 (TID 4)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:536870912+134217728\n",
      "  Finished task 1.0 in stage 0.0 (TID 1) in 8664 ms on namenode (executor driver) (1/121)\n",
      "  Times: total = 7499, boot = 392, init = 716, finish = 6391\n",
      "  Connected to AccumulatorServer at host: 127.0.0.1 port: 34341\n",
      "  Finished task 3.0 in stage 0.0 (TID 3). 1820 bytes result sent to driver\n",
      "  Starting task 5.0 in stage 0.0 (TID 5) (namenode, executor driver, partition 5, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 5.0 in stage 0.0 (TID 5)\n",
      "  Finished task 3.0 in stage 0.0 (TID 3) in 8733 ms on namenode (executor driver) (2/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:671088640+134217728\n",
      "  Finished task 2.0 in stage 0.0 (TID 2). 1820 bytes result sent to driver\n",
      "  Starting task 6.0 in stage 0.0 (TID 6) (namenode, executor driver, partition 6, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 2.0 in stage 0.0 (TID 2) in 8811 ms on namenode (executor driver) (3/121)\n",
      "  Running task 6.0 in stage 0.0 (TID 6)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:805306368+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 8098, boot = 530, init = 775, finish = 6793\n",
      "  Finished task 0.0 in stage 0.0 (TID 0). 1820 bytes result sent to driver\n",
      "  Starting task 7.0 in stage 0.0 (TID 7) (namenode, executor driver, partition 7, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 7.0 in stage 0.0 (TID 7)\n",
      "  Finished task 0.0 in stage 0.0 (TID 0) in 9277 ms on namenode (executor driver) (4/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:939524096+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6490, boot = -451, init = 508, finish = 6433\n",
      "  Finished task 4.0 in stage 0.0 (TID 4). 1820 bytes result sent to driver\n",
      "  Starting task 8.0 in stage 0.0 (TID 8) (namenode, executor driver, partition 8, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 4.0 in stage 0.0 (TID 4) in 6687 ms on namenode (executor driver) (5/121)\n",
      "  Running task 8.0 in stage 0.0 (TID 8)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:1073741824+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6374, boot = -690, init = 704, finish = 6360\n",
      "  Finished task 5.0 in stage 0.0 (TID 5). 1820 bytes result sent to driver\n",
      "  Starting task 9.0 in stage 0.0 (TID 9) (namenode, executor driver, partition 9, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 5.0 in stage 0.0 (TID 5) in 6676 ms on namenode (executor driver) (6/121)\n",
      "  Running task 9.0 in stage 0.0 (TID 9)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:1207959552+134217728\n",
      "  Times: total = 6609, boot = -731, init = 749, finish = 6591\n",
      "  Finished task 6.0 in stage 0.0 (TID 6). 1820 bytes result sent to driver\n",
      "  Starting task 10.0 in stage 0.0 (TID 10) (namenode, executor driver, partition 10, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 10.0 in stage 0.0 (TID 10)\n",
      "  Finished task 6.0 in stage 0.0 (TID 6) in 6986 ms on namenode (executor driver) (7/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:1342177280+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6756, boot = -740, init = 754, finish = 6742\n",
      "  Finished task 7.0 in stage 0.0 (TID 7). 1820 bytes result sent to driver\n",
      "  Starting task 11.0 in stage 0.0 (TID 11) (namenode, executor driver, partition 11, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 11.0 in stage 0.0 (TID 11)\n",
      "  Finished task 7.0 in stage 0.0 (TID 7) in 7120 ms on namenode (executor driver) (8/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:1476395008+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 5941, boot = -189, init = 198, finish = 5932\n",
      "  Finished task 8.0 in stage 0.0 (TID 8). 1820 bytes result sent to driver\n",
      "  Starting task 12.0 in stage 0.0 (TID 12) (namenode, executor driver, partition 12, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 8.0 in stage 0.0 (TID 8) in 6157 ms on namenode (executor driver) (9/121)\n",
      "  Running task 12.0 in stage 0.0 (TID 12)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:1610612736+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6264, boot = -304, init = 317, finish = 6251\n",
      "  Finished task 9.0 in stage 0.0 (TID 9). 1820 bytes result sent to driver\n",
      "  Starting task 13.0 in stage 0.0 (TID 13) (namenode, executor driver, partition 13, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 9.0 in stage 0.0 (TID 9) in 6335 ms on namenode (executor driver) (10/121)\n",
      "  Running task 13.0 in stage 0.0 (TID 13)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:1744830464+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6441, boot = -244, init = 248, finish = 6437\n",
      "  Finished task 10.0 in stage 0.0 (TID 10). 1820 bytes result sent to driver\n",
      "  Starting task 14.0 in stage 0.0 (TID 14) (namenode, executor driver, partition 14, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 14.0 in stage 0.0 (TID 14)\n",
      "  Finished task 10.0 in stage 0.0 (TID 10) in 6613 ms on namenode (executor driver) (11/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:1879048192+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6288, boot = -327, init = 331, finish = 6284\n",
      "  Finished task 11.0 in stage 0.0 (TID 11). 1820 bytes result sent to driver\n",
      "  Starting task 15.0 in stage 0.0 (TID 15) (namenode, executor driver, partition 15, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 11.0 in stage 0.0 (TID 11) in 6556 ms on namenode (executor driver) (12/121)\n",
      "  Running task 15.0 in stage 0.0 (TID 15)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:2013265920+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 5485, boot = 8, init = 1, finish = 5476\n",
      "  Finished task 13.0 in stage 0.0 (TID 13). 1820 bytes result sent to driver\n",
      "  Starting task 16.0 in stage 0.0 (TID 16) (namenode, executor driver, partition 16, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 13.0 in stage 0.0 (TID 13) in 5764 ms on namenode (executor driver) (13/121)\n",
      "  Running task 16.0 in stage 0.0 (TID 16)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:2147483648+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6515, boot = -140, init = 150, finish = 6505\n",
      "  Finished task 12.0 in stage 0.0 (TID 12). 1820 bytes result sent to driver\n",
      "  Starting task 17.0 in stage 0.0 (TID 17) (namenode, executor driver, partition 17, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 17.0 in stage 0.0 (TID 17)\n",
      "  Finished task 12.0 in stage 0.0 (TID 12) in 6643 ms on namenode (executor driver) (14/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:2281701376+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6106, boot = -125, init = 127, finish = 6104\n",
      "  Finished task 14.0 in stage 0.0 (TID 14). 1820 bytes result sent to driver\n",
      "  Starting task 18.0 in stage 0.0 (TID 18) (namenode, executor driver, partition 18, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 14.0 in stage 0.0 (TID 14) in 6346 ms on namenode (executor driver) (15/121)\n",
      "  Running task 18.0 in stage 0.0 (TID 18)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:2415919104+134217728\n",
      "  Times: total = 5871, boot = -182, init = 185, finish = 5868\n",
      "  Finished task 15.0 in stage 0.0 (TID 15). 1820 bytes result sent to driver\n",
      "  Starting task 19.0 in stage 0.0 (TID 19) (namenode, executor driver, partition 19, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 19.0 in stage 0.0 (TID 19)\n",
      "  Finished task 15.0 in stage 0.0 (TID 15) in 6087 ms on namenode (executor driver) (16/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:2550136832+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 5363, boot = -264, init = 278, finish = 5349\n",
      "  Finished task 16.0 in stage 0.0 (TID 16). 1820 bytes result sent to driver\n",
      "  Starting task 20.0 in stage 0.0 (TID 20) (namenode, executor driver, partition 20, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 16.0 in stage 0.0 (TID 16) in 5499 ms on namenode (executor driver) (17/121)\n",
      "  Running task 20.0 in stage 0.0 (TID 20)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:2684354560+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6009, boot = -67, init = 147, finish = 5929\n",
      "  Finished task 17.0 in stage 0.0 (TID 17). 1820 bytes result sent to driver\n",
      "  Starting task 21.0 in stage 0.0 (TID 21) (namenode, executor driver, partition 21, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 17.0 in stage 0.0 (TID 17) in 6186 ms on namenode (executor driver) (18/121)\n",
      "  Running task 21.0 in stage 0.0 (TID 21)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:2818572288+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 5858, boot = -208, init = 221, finish = 5845\n",
      "  Finished task 18.0 in stage 0.0 (TID 18). 1820 bytes result sent to driver\n",
      "  Starting task 22.0 in stage 0.0 (TID 22) (namenode, executor driver, partition 22, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 18.0 in stage 0.0 (TID 18) in 6061 ms on namenode (executor driver) (19/121)\n",
      "  Running task 22.0 in stage 0.0 (TID 22)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:2952790016+134217728\n",
      "  Times: total = 6354, boot = -176, init = 182, finish = 6348\n",
      "  Finished task 19.0 in stage 0.0 (TID 19). 1820 bytes result sent to driver\n",
      "  Starting task 23.0 in stage 0.0 (TID 23) (namenode, executor driver, partition 23, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 23.0 in stage 0.0 (TID 23)\n",
      "  Finished task 19.0 in stage 0.0 (TID 19) in 6618 ms on namenode (executor driver) (20/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:3087007744+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6377, boot = -105, init = 113, finish = 6369\n",
      "  Finished task 20.0 in stage 0.0 (TID 20). 1820 bytes result sent to driver\n",
      "  Starting task 24.0 in stage 0.0 (TID 24) (namenode, executor driver, partition 24, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 20.0 in stage 0.0 (TID 20) in 6495 ms on namenode (executor driver) (21/121)\n",
      "  Running task 24.0 in stage 0.0 (TID 24)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:3221225472+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 5753, boot = -148, init = 152, finish = 5749\n",
      "  Finished task 21.0 in stage 0.0 (TID 21). 1820 bytes result sent to driver\n",
      "  Starting task 25.0 in stage 0.0 (TID 25) (namenode, executor driver, partition 25, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 21.0 in stage 0.0 (TID 21) in 5890 ms on namenode (executor driver) (22/121)\n",
      "  Running task 25.0 in stage 0.0 (TID 25)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:3355443200+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 5841, boot = -174, init = 200, finish = 5815\n",
      "  Finished task 22.0 in stage 0.0 (TID 22). 1820 bytes result sent to driver\n",
      "  Starting task 26.0 in stage 0.0 (TID 26) (namenode, executor driver, partition 26, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 22.0 in stage 0.0 (TID 22) in 6027 ms on namenode (executor driver) (23/121)\n",
      "  Running task 26.0 in stage 0.0 (TID 26)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:3489660928+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6402, boot = -269, init = 272, finish = 6399\n",
      "  Finished task 23.0 in stage 0.0 (TID 23). 1820 bytes result sent to driver\n",
      "  Starting task 27.0 in stage 0.0 (TID 27) (namenode, executor driver, partition 27, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 27.0 in stage 0.0 (TID 27)\n",
      "  Finished task 23.0 in stage 0.0 (TID 23) in 6529 ms on namenode (executor driver) (24/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:3623878656+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6010, boot = -56, init = 67, finish = 5999\n",
      "  Finished task 24.0 in stage 0.0 (TID 24). 1820 bytes result sent to driver\n",
      "  Starting task 28.0 in stage 0.0 (TID 28) (namenode, executor driver, partition 28, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 24.0 in stage 0.0 (TID 24) in 6175 ms on namenode (executor driver) (25/121)\n",
      "  Running task 28.0 in stage 0.0 (TID 28)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:3758096384+134217728\n",
      "  Times: total = 5506, boot = -43, init = 54, finish = 5495\n",
      "  Finished task 25.0 in stage 0.0 (TID 25). 1820 bytes result sent to driver\n",
      "  Starting task 29.0 in stage 0.0 (TID 29) (namenode, executor driver, partition 29, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 25.0 in stage 0.0 (TID 25) in 5877 ms on namenode (executor driver) (26/121)\n",
      "  Running task 29.0 in stage 0.0 (TID 29)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:3892314112+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 5675, boot = -130, init = 141, finish = 5664\n",
      "  Finished task 26.0 in stage 0.0 (TID 26). 1820 bytes result sent to driver\n",
      "  Starting task 30.0 in stage 0.0 (TID 30) (namenode, executor driver, partition 30, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 26.0 in stage 0.0 (TID 26) in 5812 ms on namenode (executor driver) (27/121)\n",
      "  Running task 30.0 in stage 0.0 (TID 30)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:4026531840+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 5873, boot = -99, init = 106, finish = 5866\n",
      "  Finished task 27.0 in stage 0.0 (TID 27). 1820 bytes result sent to driver\n",
      "  Starting task 31.0 in stage 0.0 (TID 31) (namenode, executor driver, partition 31, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 31.0 in stage 0.0 (TID 31)\n",
      "  Finished task 27.0 in stage 0.0 (TID 27) in 6060 ms on namenode (executor driver) (28/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:4160749568+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 5301, boot = -140, init = 169, finish = 5272\n",
      "  Finished task 28.0 in stage 0.0 (TID 28). 1820 bytes result sent to driver\n",
      "  Starting task 32.0 in stage 0.0 (TID 32) (namenode, executor driver, partition 32, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 32.0 in stage 0.0 (TID 32)\n",
      "  Finished task 28.0 in stage 0.0 (TID 28) in 5445 ms on namenode (executor driver) (29/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:4294967296+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6006, boot = -387, init = 400, finish = 5993\n",
      "  Finished task 29.0 in stage 0.0 (TID 29). 1820 bytes result sent to driver\n",
      "  Starting task 33.0 in stage 0.0 (TID 33) (namenode, executor driver, partition 33, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 33.0 in stage 0.0 (TID 33)\n",
      "  Finished task 29.0 in stage 0.0 (TID 29) in 6177 ms on namenode (executor driver) (30/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:4429185024+134217728\n",
      "  Times: total = 5738, boot = -125, init = 136, finish = 5727\n",
      "  Finished task 30.0 in stage 0.0 (TID 30). 1820 bytes result sent to driver\n",
      "  Starting task 34.0 in stage 0.0 (TID 34) (namenode, executor driver, partition 34, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 30.0 in stage 0.0 (TID 30) in 5971 ms on namenode (executor driver) (31/121)\n",
      "  Running task 34.0 in stage 0.0 (TID 34)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:4563402752+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6315, boot = -131, init = 145, finish = 6301\n",
      "  Finished task 31.0 in stage 0.0 (TID 31). 1820 bytes result sent to driver\n",
      "  Starting task 35.0 in stage 0.0 (TID 35) (namenode, executor driver, partition 35, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 31.0 in stage 0.0 (TID 31) in 6398 ms on namenode (executor driver) (32/121)\n",
      "  Running task 35.0 in stage 0.0 (TID 35)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:4697620480+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 5941, boot = -152, init = 154, finish = 5939\n",
      "  Finished task 32.0 in stage 0.0 (TID 32). 1820 bytes result sent to driver\n",
      "  Starting task 36.0 in stage 0.0 (TID 36) (namenode, executor driver, partition 36, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 36.0 in stage 0.0 (TID 36)\n",
      "  Finished task 32.0 in stage 0.0 (TID 32) in 6135 ms on namenode (executor driver) (33/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:4831838208+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 5322, boot = -91, init = 93, finish = 5320\n",
      "  Finished task 33.0 in stage 0.0 (TID 33). 1820 bytes result sent to driver\n",
      "  Starting task 37.0 in stage 0.0 (TID 37) (namenode, executor driver, partition 37, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 37.0 in stage 0.0 (TID 37)\n",
      "  Finished task 33.0 in stage 0.0 (TID 33) in 5474 ms on namenode (executor driver) (34/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:4966055936+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6506, boot = -260, init = 272, finish = 6494\n",
      "  Finished task 34.0 in stage 0.0 (TID 34). 1820 bytes result sent to driver\n",
      "  Starting task 38.0 in stage 0.0 (TID 38) (namenode, executor driver, partition 38, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 34.0 in stage 0.0 (TID 34) in 6624 ms on namenode (executor driver) (35/121)\n",
      "  Running task 38.0 in stage 0.0 (TID 38)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:5100273664+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6266, boot = -95, init = 100, finish = 6261\n",
      "  Finished task 35.0 in stage 0.0 (TID 35). 1820 bytes result sent to driver\n",
      "  Starting task 39.0 in stage 0.0 (TID 39) (namenode, executor driver, partition 39, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 35.0 in stage 0.0 (TID 35) in 6396 ms on namenode (executor driver) (36/121)\n",
      "  Running task 39.0 in stage 0.0 (TID 39)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:5234491392+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 5582, boot = -109, init = 118, finish = 5573\n",
      "  Finished task 36.0 in stage 0.0 (TID 36). 1820 bytes result sent to driver\n",
      "  Starting task 40.0 in stage 0.0 (TID 40) (namenode, executor driver, partition 40, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 40.0 in stage 0.0 (TID 40)\n",
      "  Finished task 36.0 in stage 0.0 (TID 36) in 5644 ms on namenode (executor driver) (37/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:5368709120+134217728\n",
      "  Times: total = 5566, boot = -99, init = 112, finish = 5553\n",
      "  Finished task 37.0 in stage 0.0 (TID 37). 1820 bytes result sent to driver\n",
      "  Starting task 41.0 in stage 0.0 (TID 41) (namenode, executor driver, partition 41, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 37.0 in stage 0.0 (TID 37) in 5668 ms on namenode (executor driver) (38/121)\n",
      "  Running task 41.0 in stage 0.0 (TID 41)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:5502926848+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6050, boot = -33, init = 44, finish = 6039\n",
      "  Finished task 38.0 in stage 0.0 (TID 38). 1820 bytes result sent to driver\n",
      "  Starting task 42.0 in stage 0.0 (TID 42) (namenode, executor driver, partition 42, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 38.0 in stage 0.0 (TID 38) in 6284 ms on namenode (executor driver) (39/121)\n",
      "  Running task 42.0 in stage 0.0 (TID 42)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:5637144576+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 5977, boot = -43, init = 58, finish = 5962\n",
      "  Finished task 39.0 in stage 0.0 (TID 39). 1820 bytes result sent to driver\n",
      "  Starting task 43.0 in stage 0.0 (TID 43) (namenode, executor driver, partition 43, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 43.0 in stage 0.0 (TID 43)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Finished task 39.0 in stage 0.0 (TID 39) in 6114 ms on namenode (executor driver) (40/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:5771362304+134217728\n",
      "  Times: total = 5521, boot = -20, init = 25, finish = 5516\n",
      "  Finished task 40.0 in stage 0.0 (TID 40). 1820 bytes result sent to driver\n",
      "  Starting task 44.0 in stage 0.0 (TID 44) (namenode, executor driver, partition 44, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 44.0 in stage 0.0 (TID 44)\n",
      "  Finished task 40.0 in stage 0.0 (TID 40) in 5600 ms on namenode (executor driver) (41/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:5905580032+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 5983, boot = -122, init = 133, finish = 5972\n",
      "  Finished task 41.0 in stage 0.0 (TID 41). 1820 bytes result sent to driver\n",
      "  Starting task 45.0 in stage 0.0 (TID 45) (namenode, executor driver, partition 45, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 41.0 in stage 0.0 (TID 41) in 6180 ms on namenode (executor driver) (42/121)\n",
      "  Running task 45.0 in stage 0.0 (TID 45)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:6039797760+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 5597, boot = -190, init = 207, finish = 5580\n",
      "  Finished task 42.0 in stage 0.0 (TID 42). 1820 bytes result sent to driver\n",
      "  Starting task 46.0 in stage 0.0 (TID 46) (namenode, executor driver, partition 46, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 42.0 in stage 0.0 (TID 42) in 5725 ms on namenode (executor driver) (43/121)\n",
      "  Running task 46.0 in stage 0.0 (TID 46)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:6174015488+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 5817, boot = -114, init = 117, finish = 5814\n",
      "  Finished task 43.0 in stage 0.0 (TID 43). 1820 bytes result sent to driver\n",
      "  Starting task 47.0 in stage 0.0 (TID 47) (namenode, executor driver, partition 47, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 43.0 in stage 0.0 (TID 43) in 5922 ms on namenode (executor driver) (44/121)\n",
      "  Running task 47.0 in stage 0.0 (TID 47)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:6308233216+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6339, boot = -108, init = 121, finish = 6326\n",
      "  Finished task 44.0 in stage 0.0 (TID 44). 1820 bytes result sent to driver\n",
      "  Starting task 48.0 in stage 0.0 (TID 48) (namenode, executor driver, partition 48, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 48.0 in stage 0.0 (TID 48)\n",
      "  Finished task 44.0 in stage 0.0 (TID 44) in 6535 ms on namenode (executor driver) (45/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:6442450944+134217728\n",
      "  Times: total = 5811, boot = -172, init = 178, finish = 5805\n",
      "  Finished task 45.0 in stage 0.0 (TID 45). 1820 bytes result sent to driver\n",
      "  Starting task 49.0 in stage 0.0 (TID 49) (namenode, executor driver, partition 49, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 49.0 in stage 0.0 (TID 49)\n",
      "  Finished task 45.0 in stage 0.0 (TID 45) in 5972 ms on namenode (executor driver) (46/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:6576668672+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6072, boot = -63, init = 66, finish = 6069\n",
      "  Finished task 46.0 in stage 0.0 (TID 46). 1820 bytes result sent to driver\n",
      "  Starting task 50.0 in stage 0.0 (TID 50) (namenode, executor driver, partition 50, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 50.0 in stage 0.0 (TID 50)\n",
      "  Finished task 46.0 in stage 0.0 (TID 46) in 6190 ms on namenode (executor driver) (47/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:6710886400+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 5947, boot = -108, init = 132, finish = 5923\n",
      "  Finished task 47.0 in stage 0.0 (TID 47). 1820 bytes result sent to driver\n",
      "  Starting task 51.0 in stage 0.0 (TID 51) (namenode, executor driver, partition 51, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 47.0 in stage 0.0 (TID 47) in 6121 ms on namenode (executor driver) (48/121)\n",
      "  Running task 51.0 in stage 0.0 (TID 51)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:6845104128+134217728\n",
      "  Times: total = 5223, boot = -81, init = 100, finish = 5204\n",
      "  Finished task 48.0 in stage 0.0 (TID 48). 1820 bytes result sent to driver\n",
      "  Starting task 52.0 in stage 0.0 (TID 52) (namenode, executor driver, partition 52, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 48.0 in stage 0.0 (TID 48) in 5313 ms on namenode (executor driver) (49/121)\n",
      "  Running task 52.0 in stage 0.0 (TID 52)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:6979321856+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 5996, boot = -64, init = 77, finish = 5983\n",
      "  Finished task 49.0 in stage 0.0 (TID 49). 1820 bytes result sent to driver\n",
      "  Starting task 53.0 in stage 0.0 (TID 53) (namenode, executor driver, partition 53, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 49.0 in stage 0.0 (TID 49) in 6103 ms on namenode (executor driver) (50/121)\n",
      "  Running task 53.0 in stage 0.0 (TID 53)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:7113539584+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6038, boot = -71, init = 84, finish = 6025\n",
      "  Finished task 50.0 in stage 0.0 (TID 50). 1820 bytes result sent to driver\n",
      "  Starting task 54.0 in stage 0.0 (TID 54) (namenode, executor driver, partition 54, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 54.0 in stage 0.0 (TID 54)\n",
      "  Finished task 50.0 in stage 0.0 (TID 50) in 6151 ms on namenode (executor driver) (51/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:7247757312+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 5270, boot = -164, init = 179, finish = 5255\n",
      "  Finished task 51.0 in stage 0.0 (TID 51). 1820 bytes result sent to driver\n",
      "  Starting task 55.0 in stage 0.0 (TID 55) (namenode, executor driver, partition 55, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 55.0 in stage 0.0 (TID 55)\n",
      "  Finished task 51.0 in stage 0.0 (TID 51) in 5462 ms on namenode (executor driver) (52/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:7381975040+134217728\n",
      "  Times: total = 5992, boot = -32, init = 46, finish = 5978\n",
      "  Finished task 52.0 in stage 0.0 (TID 52). 1820 bytes result sent to driver\n",
      "  Starting task 56.0 in stage 0.0 (TID 56) (namenode, executor driver, partition 56, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 52.0 in stage 0.0 (TID 52) in 6117 ms on namenode (executor driver) (53/121)\n",
      "  Running task 56.0 in stage 0.0 (TID 56)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:7516192768+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 5530, boot = -88, init = 106, finish = 5512\n",
      "  Finished task 53.0 in stage 0.0 (TID 53). 1820 bytes result sent to driver\n",
      "  Starting task 57.0 in stage 0.0 (TID 57) (namenode, executor driver, partition 57, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 53.0 in stage 0.0 (TID 53) in 5679 ms on namenode (executor driver) (54/121)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Running task 57.0 in stage 0.0 (TID 57)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:7650410496+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6057, boot = -105, init = 126, finish = 6036\n",
      "  Finished task 54.0 in stage 0.0 (TID 54). 1820 bytes result sent to driver\n",
      "  Starting task 58.0 in stage 0.0 (TID 58) (namenode, executor driver, partition 58, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 54.0 in stage 0.0 (TID 54) in 6177 ms on namenode (executor driver) (55/121)\n",
      "  Running task 58.0 in stage 0.0 (TID 58)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:7784628224+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 5771, boot = -180, init = 191, finish = 5760\n",
      "  Finished task 55.0 in stage 0.0 (TID 55). 1820 bytes result sent to driver\n",
      "  Starting task 59.0 in stage 0.0 (TID 59) (namenode, executor driver, partition 59, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 55.0 in stage 0.0 (TID 55) in 6065 ms on namenode (executor driver) (56/121)\n",
      "  Running task 59.0 in stage 0.0 (TID 59)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:7918845952+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 5645, boot = -87, init = 90, finish = 5642\n",
      "  Finished task 56.0 in stage 0.0 (TID 56). 1820 bytes result sent to driver\n",
      "  Starting task 60.0 in stage 0.0 (TID 60) (namenode, executor driver, partition 60, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 56.0 in stage 0.0 (TID 56) in 5737 ms on namenode (executor driver) (57/121)\n",
      "  Running task 60.0 in stage 0.0 (TID 60)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:8053063680+134217728\n",
      "  Times: total = 5865, boot = -108, init = 110, finish = 5863\n",
      "  Finished task 57.0 in stage 0.0 (TID 57). 1820 bytes result sent to driver\n",
      "  Starting task 61.0 in stage 0.0 (TID 61) (namenode, executor driver, partition 61, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 61.0 in stage 0.0 (TID 61)\n",
      "  Finished task 57.0 in stage 0.0 (TID 57) in 5966 ms on namenode (executor driver) (58/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:8187281408+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 5562, boot = -119, init = 128, finish = 5553\n",
      "  Finished task 58.0 in stage 0.0 (TID 58). 1820 bytes result sent to driver\n",
      "  Starting task 62.0 in stage 0.0 (TID 62) (namenode, executor driver, partition 62, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 58.0 in stage 0.0 (TID 58) in 5686 ms on namenode (executor driver) (59/121)\n",
      "  Running task 62.0 in stage 0.0 (TID 62)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:8321499136+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6315, boot = -199, init = 210, finish = 6304\n",
      "  Finished task 59.0 in stage 0.0 (TID 59). 1863 bytes result sent to driver\n",
      "  Starting task 63.0 in stage 0.0 (TID 63) (namenode, executor driver, partition 63, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 59.0 in stage 0.0 (TID 59) in 6455 ms on namenode (executor driver) (60/121)\n",
      "  Running task 63.0 in stage 0.0 (TID 63)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:8455716864+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6326, boot = -112, init = 126, finish = 6312\n",
      "  Finished task 60.0 in stage 0.0 (TID 60). 1820 bytes result sent to driver\n",
      "  Starting task 64.0 in stage 0.0 (TID 64) (namenode, executor driver, partition 64, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 60.0 in stage 0.0 (TID 60) in 6476 ms on namenode (executor driver) (61/121)\n",
      "  Running task 64.0 in stage 0.0 (TID 64)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:8589934592+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 5619, boot = -79, init = 103, finish = 5595\n",
      "  Finished task 61.0 in stage 0.0 (TID 61). 1820 bytes result sent to driver\n",
      "  Starting task 65.0 in stage 0.0 (TID 65) (namenode, executor driver, partition 65, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 61.0 in stage 0.0 (TID 61) in 5742 ms on namenode (executor driver) (62/121)\n",
      "  Running task 65.0 in stage 0.0 (TID 65)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:8724152320+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6264, boot = -83, init = 90, finish = 6257\n",
      "  Finished task 62.0 in stage 0.0 (TID 62). 1820 bytes result sent to driver\n",
      "  Starting task 66.0 in stage 0.0 (TID 66) (namenode, executor driver, partition 66, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 66.0 in stage 0.0 (TID 66)\n",
      "  Finished task 62.0 in stage 0.0 (TID 62) in 6320 ms on namenode (executor driver) (63/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:8858370048+134217728\n",
      "  Times: total = 5941, boot = -109, init = 125, finish = 5925\n",
      "  Finished task 63.0 in stage 0.0 (TID 63). 1820 bytes result sent to driver\n",
      "  Starting task 67.0 in stage 0.0 (TID 67) (namenode, executor driver, partition 67, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 63.0 in stage 0.0 (TID 63) in 5986 ms on namenode (executor driver) (64/121)\n",
      "  Running task 67.0 in stage 0.0 (TID 67)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:8992587776+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 5648, boot = -129, init = 143, finish = 5634\n",
      "  Finished task 64.0 in stage 0.0 (TID 64). 1820 bytes result sent to driver\n",
      "  Starting task 68.0 in stage 0.0 (TID 68) (namenode, executor driver, partition 68, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 64.0 in stage 0.0 (TID 64) in 5848 ms on namenode (executor driver) (65/121)\n",
      "  Running task 68.0 in stage 0.0 (TID 68)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:9126805504+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 5961, boot = -94, init = 115, finish = 5940\n",
      "  Finished task 65.0 in stage 0.0 (TID 65). 1820 bytes result sent to driver\n",
      "  Starting task 69.0 in stage 0.0 (TID 69) (namenode, executor driver, partition 69, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 69.0 in stage 0.0 (TID 69)\n",
      "  Finished task 65.0 in stage 0.0 (TID 65) in 6072 ms on namenode (executor driver) (66/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:9261023232+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 5601, boot = -10, init = 31, finish = 5580\n",
      "  Finished task 66.0 in stage 0.0 (TID 66). 1820 bytes result sent to driver\n",
      "  Starting task 70.0 in stage 0.0 (TID 70) (namenode, executor driver, partition 70, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 66.0 in stage 0.0 (TID 66) in 5776 ms on namenode (executor driver) (67/121)\n",
      "  Running task 70.0 in stage 0.0 (TID 70)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:9395240960+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 5748, boot = 17, init = 1, finish = 5730\n",
      "  Finished task 67.0 in stage 0.0 (TID 67). 1820 bytes result sent to driver\n",
      "  Starting task 71.0 in stage 0.0 (TID 71) (namenode, executor driver, partition 71, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 67.0 in stage 0.0 (TID 67) in 5919 ms on namenode (executor driver) (68/121)\n",
      "  Running task 71.0 in stage 0.0 (TID 71)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:9529458688+134217728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 5382, boot = -150, init = 160, finish = 5372\n",
      "  Finished task 68.0 in stage 0.0 (TID 68). 1820 bytes result sent to driver\n",
      "  Starting task 72.0 in stage 0.0 (TID 72) (namenode, executor driver, partition 72, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 68.0 in stage 0.0 (TID 68) in 5524 ms on namenode (executor driver) (69/121)\n",
      "  Running task 72.0 in stage 0.0 (TID 72)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:9663676416+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 5488, boot = -33, init = 51, finish = 5470\n",
      "  Finished task 69.0 in stage 0.0 (TID 69). 1820 bytes result sent to driver\n",
      "  Starting task 73.0 in stage 0.0 (TID 73) (namenode, executor driver, partition 73, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 73.0 in stage 0.0 (TID 73)\n",
      "  Finished task 69.0 in stage 0.0 (TID 69) in 5594 ms on namenode (executor driver) (70/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:9797894144+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6128, boot = -130, init = 139, finish = 6119\n",
      "  Finished task 70.0 in stage 0.0 (TID 70). 1820 bytes result sent to driver\n",
      "  Starting task 74.0 in stage 0.0 (TID 74) (namenode, executor driver, partition 74, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 70.0 in stage 0.0 (TID 70) in 6190 ms on namenode (executor driver) (71/121)\n",
      "  Running task 74.0 in stage 0.0 (TID 74)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:9932111872+134217728\n",
      "  Times: total = 5890, boot = -127, init = 130, finish = 5887\n",
      "  Finished task 71.0 in stage 0.0 (TID 71). 1820 bytes result sent to driver\n",
      "  Starting task 75.0 in stage 0.0 (TID 75) (namenode, executor driver, partition 75, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 75.0 in stage 0.0 (TID 75)\n",
      "  Finished task 71.0 in stage 0.0 (TID 71) in 5981 ms on namenode (executor driver) (72/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:10066329600+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 5711, boot = -114, init = 122, finish = 5703\n",
      "  Finished task 72.0 in stage 0.0 (TID 72). 1820 bytes result sent to driver\n",
      "  Starting task 76.0 in stage 0.0 (TID 76) (namenode, executor driver, partition 76, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 72.0 in stage 0.0 (TID 72) in 5847 ms on namenode (executor driver) (73/121)\n",
      "  Running task 76.0 in stage 0.0 (TID 76)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:10200547328+134217728\n",
      "  Times: total = 5595, boot = -94, init = 99, finish = 5590\n",
      "  Finished task 73.0 in stage 0.0 (TID 73). 1820 bytes result sent to driver\n",
      "  Starting task 77.0 in stage 0.0 (TID 77) (namenode, executor driver, partition 77, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 77.0 in stage 0.0 (TID 77)\n",
      "  Finished task 73.0 in stage 0.0 (TID 73) in 5838 ms on namenode (executor driver) (74/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:10334765056+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6679, boot = -67, init = 76, finish = 6670\n",
      "  Finished task 74.0 in stage 0.0 (TID 74). 1820 bytes result sent to driver\n",
      "  Starting task 78.0 in stage 0.0 (TID 78) (namenode, executor driver, partition 78, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 74.0 in stage 0.0 (TID 74) in 6820 ms on namenode (executor driver) (75/121)\n",
      "  Running task 78.0 in stage 0.0 (TID 78)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:10468982784+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6044, boot = -141, init = 151, finish = 6034\n",
      "  Finished task 76.0 in stage 0.0 (TID 76). 1820 bytes result sent to driver\n",
      "  Starting task 79.0 in stage 0.0 (TID 79) (namenode, executor driver, partition 79, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 76.0 in stage 0.0 (TID 76) in 6179 ms on namenode (executor driver) (76/121)\n",
      "  Running task 79.0 in stage 0.0 (TID 79)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:10603200512+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 7094, boot = -62, init = 86, finish = 7070\n",
      "  Finished task 75.0 in stage 0.0 (TID 75). 1820 bytes result sent to driver\n",
      "  Starting task 80.0 in stage 0.0 (TID 80) (namenode, executor driver, partition 80, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 75.0 in stage 0.0 (TID 75) in 7364 ms on namenode (executor driver) (77/121)\n",
      "  Running task 80.0 in stage 0.0 (TID 80)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:10737418240+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6536, boot = -219, init = 235, finish = 6520\n",
      "  Finished task 77.0 in stage 0.0 (TID 77). 1820 bytes result sent to driver\n",
      "  Starting task 81.0 in stage 0.0 (TID 81) (namenode, executor driver, partition 81, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 77.0 in stage 0.0 (TID 77) in 6621 ms on namenode (executor driver) (78/121)\n",
      "  Running task 81.0 in stage 0.0 (TID 81)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:10871635968+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6693, boot = -90, init = 98, finish = 6685\n",
      "  Finished task 78.0 in stage 0.0 (TID 78). 1820 bytes result sent to driver\n",
      "  Starting task 82.0 in stage 0.0 (TID 82) (namenode, executor driver, partition 82, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 82.0 in stage 0.0 (TID 82)\n",
      "  Finished task 78.0 in stage 0.0 (TID 78) in 6790 ms on namenode (executor driver) (79/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:11005853696+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 5267, boot = -247, init = 260, finish = 5254\n",
      "  Finished task 80.0 in stage 0.0 (TID 80). 1820 bytes result sent to driver\n",
      "  Starting task 83.0 in stage 0.0 (TID 83) (namenode, executor driver, partition 83, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 80.0 in stage 0.0 (TID 80) in 5460 ms on namenode (executor driver) (80/121)\n",
      "  Running task 83.0 in stage 0.0 (TID 83)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:11140071424+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 5260, boot = -40, init = 70, finish = 5230\n",
      "  Finished task 81.0 in stage 0.0 (TID 81). 1820 bytes result sent to driver\n",
      "  Starting task 84.0 in stage 0.0 (TID 84) (namenode, executor driver, partition 84, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 81.0 in stage 0.0 (TID 81) in 5303 ms on namenode (executor driver) (81/121)\n",
      "  Running task 84.0 in stage 0.0 (TID 84)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:11274289152+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6378, boot = -134, init = 149, finish = 6363\n",
      "  Finished task 79.0 in stage 0.0 (TID 79). 1863 bytes result sent to driver\n",
      "  Starting task 85.0 in stage 0.0 (TID 85) (namenode, executor driver, partition 85, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 85.0 in stage 0.0 (TID 85)\n",
      "  Finished task 79.0 in stage 0.0 (TID 79) in 6560 ms on namenode (executor driver) (82/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:11408506880+134217728\n",
      "  Times: total = 5689, boot = -95, init = 97, finish = 5687\n",
      "  Finished task 82.0 in stage 0.0 (TID 82). 1820 bytes result sent to driver\n",
      "  Starting task 86.0 in stage 0.0 (TID 86) (namenode, executor driver, partition 86, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 82.0 in stage 0.0 (TID 82) in 5822 ms on namenode (executor driver) (83/121)\n",
      "  Running task 86.0 in stage 0.0 (TID 86)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:11542724608+134217728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 5209, boot = 0, init = 14, finish = 5195\n",
      "  Finished task 84.0 in stage 0.0 (TID 84). 1820 bytes result sent to driver\n",
      "  Starting task 87.0 in stage 0.0 (TID 87) (namenode, executor driver, partition 87, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 87.0 in stage 0.0 (TID 87)\n",
      "  Finished task 84.0 in stage 0.0 (TID 84) in 5338 ms on namenode (executor driver) (84/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:11676942336+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6350, boot = -141, init = 145, finish = 6346\n",
      "  Finished task 83.0 in stage 0.0 (TID 83). 1820 bytes result sent to driver\n",
      "  Starting task 88.0 in stage 0.0 (TID 88) (namenode, executor driver, partition 88, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 88.0 in stage 0.0 (TID 88)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:11811160064+134217728\n",
      "  Finished task 83.0 in stage 0.0 (TID 83) in 6418 ms on namenode (executor driver) (85/121)\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6184, boot = -130, init = 140, finish = 6174\n",
      "  Finished task 85.0 in stage 0.0 (TID 85). 1820 bytes result sent to driver\n",
      "  Starting task 89.0 in stage 0.0 (TID 89) (namenode, executor driver, partition 89, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 89.0 in stage 0.0 (TID 89)\n",
      "  Finished task 85.0 in stage 0.0 (TID 85) in 6310 ms on namenode (executor driver) (86/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:11945377792+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6367, boot = -107, init = 127, finish = 6347\n",
      "  Finished task 86.0 in stage 0.0 (TID 86). 1820 bytes result sent to driver\n",
      "  Starting task 90.0 in stage 0.0 (TID 90) (namenode, executor driver, partition 90, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 90.0 in stage 0.0 (TID 90)\n",
      "  Finished task 86.0 in stage 0.0 (TID 86) in 6439 ms on namenode (executor driver) (87/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:12079595520+134217728\n",
      "  Times: total = 5766, boot = -124, init = 188, finish = 5702\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Finished task 87.0 in stage 0.0 (TID 87). 1820 bytes result sent to driver\n",
      "  Starting task 91.0 in stage 0.0 (TID 91) (namenode, executor driver, partition 91, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 87.0 in stage 0.0 (TID 87) in 5879 ms on namenode (executor driver) (88/121)\n",
      "  Running task 91.0 in stage 0.0 (TID 91)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:12213813248+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 5631, boot = -85, init = 96, finish = 5620\n",
      "  Finished task 88.0 in stage 0.0 (TID 88). 1820 bytes result sent to driver\n",
      "  Starting task 92.0 in stage 0.0 (TID 92) (namenode, executor driver, partition 92, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 92.0 in stage 0.0 (TID 92)\n",
      "  Finished task 88.0 in stage 0.0 (TID 88) in 5745 ms on namenode (executor driver) (89/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:12348030976+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6349, boot = -92, init = 109, finish = 6332\n",
      "  Finished task 89.0 in stage 0.0 (TID 89). 1820 bytes result sent to driver\n",
      "  Starting task 93.0 in stage 0.0 (TID 93) (namenode, executor driver, partition 93, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 93.0 in stage 0.0 (TID 93)\n",
      "  Finished task 89.0 in stage 0.0 (TID 89) in 6479 ms on namenode (executor driver) (90/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:12482248704+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 5901, boot = -28, init = 31, finish = 5898\n",
      "  Finished task 90.0 in stage 0.0 (TID 90). 1820 bytes result sent to driver\n",
      "  Starting task 94.0 in stage 0.0 (TID 94) (namenode, executor driver, partition 94, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 94.0 in stage 0.0 (TID 94)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:12616466432+134217728\n",
      "  Finished task 90.0 in stage 0.0 (TID 90) in 6020 ms on namenode (executor driver) (91/121)\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6080, boot = -61, init = 63, finish = 6078\n",
      "  Finished task 91.0 in stage 0.0 (TID 91). 1820 bytes result sent to driver\n",
      "  Starting task 95.0 in stage 0.0 (TID 95) (namenode, executor driver, partition 95, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 91.0 in stage 0.0 (TID 91) in 6198 ms on namenode (executor driver) (92/121)\n",
      "  Running task 95.0 in stage 0.0 (TID 95)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:12750684160+134217728\n",
      "  Times: total = 5885, boot = -49, init = 56, finish = 5878\n",
      "  Finished task 92.0 in stage 0.0 (TID 92). 1820 bytes result sent to driver\n",
      "  Starting task 96.0 in stage 0.0 (TID 96) (namenode, executor driver, partition 96, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 96.0 in stage 0.0 (TID 96)\n",
      "  Finished task 92.0 in stage 0.0 (TID 92) in 6017 ms on namenode (executor driver) (93/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:12884901888+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 5623, boot = -76, init = 126, finish = 5573\n",
      "  Finished task 93.0 in stage 0.0 (TID 93). 1820 bytes result sent to driver\n",
      "  Starting task 97.0 in stage 0.0 (TID 97) (namenode, executor driver, partition 97, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 97.0 in stage 0.0 (TID 97)\n",
      "  Finished task 93.0 in stage 0.0 (TID 93) in 5752 ms on namenode (executor driver) (94/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:13019119616+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 5499, boot = -97, init = 115, finish = 5481\n",
      "  Finished task 95.0 in stage 0.0 (TID 95). 1820 bytes result sent to driver\n",
      "  Starting task 98.0 in stage 0.0 (TID 98) (namenode, executor driver, partition 98, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 98.0 in stage 0.0 (TID 98)\n",
      "  Finished task 95.0 in stage 0.0 (TID 95) in 5558 ms on namenode (executor driver) (95/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:13153337344+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 5750, boot = -102, init = 120, finish = 5732\n",
      "  Finished task 94.0 in stage 0.0 (TID 94). 1820 bytes result sent to driver\n",
      "  Starting task 99.0 in stage 0.0 (TID 99) (namenode, executor driver, partition 99, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 94.0 in stage 0.0 (TID 94) in 5844 ms on namenode (executor driver) (96/121)\n",
      "  Running task 99.0 in stage 0.0 (TID 99)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:13287555072+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6224, boot = -129, init = 139, finish = 6214\n",
      "  Finished task 96.0 in stage 0.0 (TID 96). 1820 bytes result sent to driver\n",
      "  Starting task 100.0 in stage 0.0 (TID 100) (namenode, executor driver, partition 100, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 96.0 in stage 0.0 (TID 96) in 6375 ms on namenode (executor driver) (97/121)\n",
      "  Running task 100.0 in stage 0.0 (TID 100)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:13421772800+134217728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 5954, boot = -92, init = 93, finish = 5953\n",
      "  Finished task 97.0 in stage 0.0 (TID 97). 1820 bytes result sent to driver\n",
      "  Starting task 101.0 in stage 0.0 (TID 101) (namenode, executor driver, partition 101, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 101.0 in stage 0.0 (TID 101)\n",
      "  Finished task 97.0 in stage 0.0 (TID 97) in 6039 ms on namenode (executor driver) (98/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:13555990528+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 5154, boot = -40, init = 42, finish = 5152\n",
      "  Finished task 98.0 in stage 0.0 (TID 98). 1820 bytes result sent to driver\n",
      "  Starting task 102.0 in stage 0.0 (TID 102) (namenode, executor driver, partition 102, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 102.0 in stage 0.0 (TID 102)\n",
      "  Finished task 98.0 in stage 0.0 (TID 98) in 5338 ms on namenode (executor driver) (99/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:13690208256+134217728\n",
      "  Times: total = 5430, boot = -80, init = 94, finish = 5416\n",
      "  Finished task 99.0 in stage 0.0 (TID 99). 1820 bytes result sent to driver\n",
      "  Starting task 103.0 in stage 0.0 (TID 103) (namenode, executor driver, partition 103, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 99.0 in stage 0.0 (TID 99) in 5589 ms on namenode (executor driver) (100/121)\n",
      "  Running task 103.0 in stage 0.0 (TID 103)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:13824425984+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 5915, boot = -128, init = 139, finish = 5904\n",
      "  Finished task 100.0 in stage 0.0 (TID 100). 1820 bytes result sent to driver\n",
      "  Starting task 104.0 in stage 0.0 (TID 104) (namenode, executor driver, partition 104, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 104.0 in stage 0.0 (TID 104)\n",
      "  Finished task 100.0 in stage 0.0 (TID 100) in 6026 ms on namenode (executor driver) (101/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:13958643712+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6174, boot = -61, init = 107, finish = 6128\n",
      "  Finished task 101.0 in stage 0.0 (TID 101). 1820 bytes result sent to driver\n",
      "  Starting task 105.0 in stage 0.0 (TID 105) (namenode, executor driver, partition 105, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 105.0 in stage 0.0 (TID 105)\n",
      "  Finished task 101.0 in stage 0.0 (TID 101) in 6207 ms on namenode (executor driver) (102/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:14092861440+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 4956, boot = -119, init = 131, finish = 4944\n",
      "  Finished task 103.0 in stage 0.0 (TID 103). 1820 bytes result sent to driver\n",
      "  Starting task 106.0 in stage 0.0 (TID 106) (namenode, executor driver, partition 106, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 103.0 in stage 0.0 (TID 103) in 4997 ms on namenode (executor driver) (103/121)\n",
      "  Running task 106.0 in stage 0.0 (TID 106)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:14227079168+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6009, boot = -77, init = 78, finish = 6008\n",
      "  Finished task 102.0 in stage 0.0 (TID 102). 1820 bytes result sent to driver\n",
      "  Starting task 107.0 in stage 0.0 (TID 107) (namenode, executor driver, partition 107, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 102.0 in stage 0.0 (TID 102) in 6075 ms on namenode (executor driver) (104/121)\n",
      "  Running task 107.0 in stage 0.0 (TID 107)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:14361296896+134217728\n",
      "  Times: total = 5748, boot = -78, init = 81, finish = 5745\n",
      "  Finished task 104.0 in stage 0.0 (TID 104). 1820 bytes result sent to driver\n",
      "  Starting task 108.0 in stage 0.0 (TID 108) (namenode, executor driver, partition 108, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 108.0 in stage 0.0 (TID 108)\n",
      "  Finished task 104.0 in stage 0.0 (TID 104) in 5817 ms on namenode (executor driver) (105/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:14495514624+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6302, boot = -11, init = 13, finish = 6300\n",
      "  Finished task 105.0 in stage 0.0 (TID 105). 1820 bytes result sent to driver\n",
      "  Starting task 109.0 in stage 0.0 (TID 109) (namenode, executor driver, partition 109, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 105.0 in stage 0.0 (TID 105) in 6402 ms on namenode (executor driver) (106/121)\n",
      "  Running task 109.0 in stage 0.0 (TID 109)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:14629732352+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 5707, boot = -44, init = 49, finish = 5702\n",
      "  Finished task 106.0 in stage 0.0 (TID 106). 1820 bytes result sent to driver\n",
      "  Starting task 110.0 in stage 0.0 (TID 110) (namenode, executor driver, partition 110, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 110.0 in stage 0.0 (TID 110)\n",
      "  Finished task 106.0 in stage 0.0 (TID 106) in 5828 ms on namenode (executor driver) (107/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:14763950080+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 5383, boot = -63, init = 70, finish = 5376\n",
      "  Finished task 107.0 in stage 0.0 (TID 107). 1820 bytes result sent to driver\n",
      "  Starting task 111.0 in stage 0.0 (TID 111) (namenode, executor driver, partition 111, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 111.0 in stage 0.0 (TID 111)\n",
      "  Finished task 107.0 in stage 0.0 (TID 107) in 5456 ms on namenode (executor driver) (108/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:14898167808+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 5328, boot = -24, init = 31, finish = 5321\n",
      "  Finished task 108.0 in stage 0.0 (TID 108). 1820 bytes result sent to driver\n",
      "  Starting task 112.0 in stage 0.0 (TID 112) (namenode, executor driver, partition 112, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 108.0 in stage 0.0 (TID 108) in 5421 ms on namenode (executor driver) (109/121)\n",
      "  Running task 112.0 in stage 0.0 (TID 112)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:15032385536+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6295, boot = -78, init = 84, finish = 6289\n",
      "  Finished task 109.0 in stage 0.0 (TID 109). 1820 bytes result sent to driver\n",
      "  Starting task 113.0 in stage 0.0 (TID 113) (namenode, executor driver, partition 113, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 109.0 in stage 0.0 (TID 109) in 6367 ms on namenode (executor driver) (110/121)\n",
      "  Running task 113.0 in stage 0.0 (TID 113)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:15166603264+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 5710, boot = -71, init = 76, finish = 5705\n",
      "  Finished task 110.0 in stage 0.0 (TID 110). 1820 bytes result sent to driver\n",
      "  Starting task 114.0 in stage 0.0 (TID 114) (namenode, executor driver, partition 114, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 110.0 in stage 0.0 (TID 110) in 5812 ms on namenode (executor driver) (111/121)\n",
      "  Running task 114.0 in stage 0.0 (TID 114)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:15300820992+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 5873, boot = 1, init = 3, finish = 5869\n",
      "  Finished task 111.0 in stage 0.0 (TID 111). 1820 bytes result sent to driver\n",
      "  Starting task 115.0 in stage 0.0 (TID 115) (namenode, executor driver, partition 115, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 115.0 in stage 0.0 (TID 115)\n",
      "  Finished task 111.0 in stage 0.0 (TID 111) in 5993 ms on namenode (executor driver) (112/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:15435038720+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 5663, boot = -83, init = 85, finish = 5661\n",
      "  Finished task 112.0 in stage 0.0 (TID 112). 1820 bytes result sent to driver\n",
      "  Starting task 116.0 in stage 0.0 (TID 116) (namenode, executor driver, partition 116, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 112.0 in stage 0.0 (TID 112) in 5820 ms on namenode (executor driver) (113/121)\n",
      "  Running task 116.0 in stage 0.0 (TID 116)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:15569256448+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 5649, boot = -25, init = 34, finish = 5640\n",
      "  Finished task 113.0 in stage 0.0 (TID 113). 1820 bytes result sent to driver\n",
      "  Starting task 117.0 in stage 0.0 (TID 117) (namenode, executor driver, partition 117, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 117.0 in stage 0.0 (TID 117)\n",
      "  Finished task 113.0 in stage 0.0 (TID 113) in 5771 ms on namenode (executor driver) (114/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:15703474176+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 5815, boot = -101, init = 104, finish = 5812\n",
      "  Finished task 114.0 in stage 0.0 (TID 114). 1820 bytes result sent to driver\n",
      "  Starting task 118.0 in stage 0.0 (TID 118) (namenode, executor driver, partition 118, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 118.0 in stage 0.0 (TID 118)\n",
      "  Finished task 114.0 in stage 0.0 (TID 114) in 5994 ms on namenode (executor driver) (115/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:15837691904+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6118, boot = -136, init = 138, finish = 6116\n",
      "  Finished task 115.0 in stage 0.0 (TID 115). 1820 bytes result sent to driver\n",
      "  Starting task 119.0 in stage 0.0 (TID 119) (namenode, executor driver, partition 119, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Running task 119.0 in stage 0.0 (TID 119)\n",
      "  Finished task 115.0 in stage 0.0 (TID 115) in 6228 ms on namenode (executor driver) (116/121)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:15971909632+134217728\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6264, boot = -128, init = 132, finish = 6260\n",
      "  Finished task 116.0 in stage 0.0 (TID 116). 1820 bytes result sent to driver\n",
      "  Starting task 120.0 in stage 0.0 (TID 120) (namenode, executor driver, partition 120, ANY, 4508 bytes) taskResourceAssignments Map()\n",
      "  Finished task 116.0 in stage 0.0 (TID 116) in 6330 ms on namenode (executor driver) (117/121)\n",
      "  Running task 120.0 in stage 0.0 (TID 120)\n",
      "  Input split: hdfs://namenode:9000/dis_materials/data_reddit.csv:16106127360+79598254\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 6164, boot = -137, init = 149, finish = 6152\n",
      "  Finished task 117.0 in stage 0.0 (TID 117). 1820 bytes result sent to driver\n",
      "  Finished task 117.0 in stage 0.0 (TID 117) in 6333 ms on namenode (executor driver) (118/121)\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Times: total = 3368, boot = -4, init = 17, finish = 3355\n",
      "  Finished task 120.0 in stage 0.0 (TID 120). 1820 bytes result sent to driver\n",
      "  Finished task 120.0 in stage 0.0 (TID 120) in 3434 ms on namenode (executor driver) (119/121)\n",
      "  Times: total = 4833, boot = -25, init = 38, finish = 4820\n",
      "  Finished task 119.0 in stage 0.0 (TID 119). 1820 bytes result sent to driver\n",
      "  Finished task 119.0 in stage 0.0 (TID 119) in 4882 ms on namenode (executor driver) (120/121)\n",
      "  Times: total = 5775, boot = -106, init = 117, finish = 5764\n",
      "  Finished task 118.0 in stage 0.0 (TID 118). 1820 bytes result sent to driver\n",
      "  Finished task 118.0 in stage 0.0 (TID 118) in 5823 ms on namenode (executor driver) (121/121)\n",
      "  ShuffleMapStage 0 (groupBy at /home/ubuntu/.local/lib/python3.8/site-packages/mrjob/spark/harness.py:539) finished in 185.675 s\n",
      "  Removed TaskSet 0.0, whose tasks have all completed, from pool \n",
      "  looking for newly runnable stages\n",
      "  running: Set()\n",
      "  waiting: Set(ResultStage 1)\n",
      "  failed: Set()\n",
      "  Submitting ResultStage 1 (MapPartitionsRDD[8] at saveAsTextFile at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "  Block broadcast_2 stored as values in memory (estimated size 134.6 KiB, free 365.7 MiB)\n",
      "  Block broadcast_2_piece0 stored as bytes in memory (estimated size 52.8 KiB, free 365.7 MiB)\n",
      "  Added broadcast_2_piece0 in memory on namenode:38187 (size: 52.8 KiB, free: 366.2 MiB)\n",
      "  Created broadcast 2 from broadcast at DAGScheduler.scala:1427\n",
      "  Submitting 121 missing tasks from ResultStage 1 (MapPartitionsRDD[8] at saveAsTextFile at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))\n",
      "  Adding task set 1.0 with 121 tasks resource profile 0\n",
      "  Starting task 0.0 in stage 1.0 (TID 121) (namenode, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Starting task 1.0 in stage 1.0 (TID 122) (namenode, executor driver, partition 1, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Starting task 2.0 in stage 1.0 (TID 123) (namenode, executor driver, partition 2, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Starting task 3.0 in stage 1.0 (TID 124) (namenode, executor driver, partition 3, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 0.0 in stage 1.0 (TID 121)\n",
      "  Running task 1.0 in stage 1.0 (TID 122)\n",
      "  Running task 3.0 in stage 1.0 (TID 124)\n",
      "  Running task 2.0 in stage 1.0 (TID 123)\n",
      "  Getting 121 (241.6 KiB) non-empty blocks including 121 (241.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Getting 121 (279.1 KiB) non-empty blocks including 121 (279.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Getting 121 (216.8 KiB) non-empty blocks including 121 (216.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 47 ms\n",
      "  Getting 121 (224.8 KiB) non-empty blocks including 121 (224.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 49 ms\n",
      "  Started 0 remote fetches in 46 ms\n",
      "  Started 0 remote fetches in 50 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  File Output Committer Algorithm version is 1\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 411, boot = -490, init = 519, finish = 382\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000002_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000002\n",
      "  attempt_202204260806042090827804316438547_0008_m_000002_0: Committed\n",
      "  Finished task 2.0 in stage 1.0 (TID 123). 2002 bytes result sent to driver\n",
      "  Starting task 4.0 in stage 1.0 (TID 125) (namenode, executor driver, partition 4, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 2.0 in stage 1.0 (TID 123) in 648 ms on namenode (executor driver) (1/121)\n",
      "  Running task 4.0 in stage 1.0 (TID 125)\n",
      "  Getting 121 (251.5 KiB) non-empty blocks including 121 (251.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 5 ms\n",
      "  Times: total = 473, boot = -596, init = 628, finish = 441\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000000_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000000\n",
      "  attempt_202204260806042090827804316438547_0008_m_000000_0: Committed\n",
      "  Finished task 0.0 in stage 1.0 (TID 121). 1959 bytes result sent to driver\n",
      "  Starting task 5.0 in stage 1.0 (TID 126) (namenode, executor driver, partition 5, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 5.0 in stage 1.0 (TID 126)\n",
      "  Finished task 0.0 in stage 1.0 (TID 121) in 694 ms on namenode (executor driver) (2/121)\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Getting 121 (234.1 KiB) non-empty blocks including 121 (234.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 19 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 457, boot = 2, init = 4, finish = 451\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000005_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000005\n",
      "  attempt_202204260806042090827804316438547_0008_m_000005_0: Committed\n",
      "  Finished task 5.0 in stage 1.0 (TID 126). 1916 bytes result sent to driver\n",
      "  Starting task 6.0 in stage 1.0 (TID 127) (namenode, executor driver, partition 6, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 6.0 in stage 1.0 (TID 127)\n",
      "  Finished task 5.0 in stage 1.0 (TID 126) in 495 ms on namenode (executor driver) (3/121)\n",
      "  Getting 121 (301.5 KiB) non-empty blocks including 121 (301.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Times: total = 975, boot = -1635, init = 1651, finish = 959\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000001_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000001\n",
      "  attempt_202204260806042090827804316438547_0008_m_000001_0: Committed\n",
      "  Finished task 1.0 in stage 1.0 (TID 122). 2045 bytes result sent to driver\n",
      "  Starting task 7.0 in stage 1.0 (TID 128) (namenode, executor driver, partition 7, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 7.0 in stage 1.0 (TID 128)\n",
      "  Finished task 1.0 in stage 1.0 (TID 122) in 1202 ms on namenode (executor driver) (4/121)\n",
      "  Getting 121 (227.3 KiB) non-empty blocks including 121 (227.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 4 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 1215, boot = -343, init = 373, finish = 1185\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000003_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000003\n",
      "  attempt_202204260806042090827804316438547_0008_m_000003_0: Committed\n",
      "  Finished task 3.0 in stage 1.0 (TID 124). 2045 bytes result sent to driver\n",
      "  Starting task 8.0 in stage 1.0 (TID 129) (namenode, executor driver, partition 8, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 3.0 in stage 1.0 (TID 124) in 1435 ms on namenode (executor driver) (5/121)\n",
      "  Running task 8.0 in stage 1.0 (TID 129)\n",
      "  Getting 121 (244.9 KiB) non-empty blocks including 121 (244.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 835, boot = -35, init = 49, finish = 821\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000004_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000004\n",
      "  attempt_202204260806042090827804316438547_0008_m_000004_0: Committed\n",
      "  Finished task 4.0 in stage 1.0 (TID 125). 2002 bytes result sent to driver\n",
      "  Starting task 9.0 in stage 1.0 (TID 130) (namenode, executor driver, partition 9, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 4.0 in stage 1.0 (TID 125) in 879 ms on namenode (executor driver) (6/121)\n",
      "  Running task 9.0 in stage 1.0 (TID 130)\n",
      "  Getting 121 (229.5 KiB) non-empty blocks including 121 (229.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 570, boot = 3, init = 47, finish = 520\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000007_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000007\n",
      "  attempt_202204260806042090827804316438547_0008_m_000007_0: Committed\n",
      "  Finished task 7.0 in stage 1.0 (TID 128). 1916 bytes result sent to driver\n",
      "  Starting task 10.0 in stage 1.0 (TID 131) (namenode, executor driver, partition 10, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 10.0 in stage 1.0 (TID 131)\n",
      "  Finished task 7.0 in stage 1.0 (TID 128) in 602 ms on namenode (executor driver) (7/121)\n",
      "  Getting 121 (263.4 KiB) non-empty blocks including 121 (263.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 386, boot = -2, init = 15, finish = 373\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000008_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000008\n",
      "  attempt_202204260806042090827804316438547_0008_m_000008_0: Committed\n",
      "  Finished task 8.0 in stage 1.0 (TID 129). 1916 bytes result sent to driver\n",
      "  Starting task 11.0 in stage 1.0 (TID 132) (namenode, executor driver, partition 11, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 8.0 in stage 1.0 (TID 129) in 421 ms on namenode (executor driver) (8/121)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Running task 11.0 in stage 1.0 (TID 132)\n",
      "  Getting 121 (254.0 KiB) non-empty blocks including 121 (254.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 670, boot = -9, init = 10, finish = 669\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000009_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000009\n",
      "  attempt_202204260806042090827804316438547_0008_m_000009_0: Committed\n",
      "  Finished task 9.0 in stage 1.0 (TID 130). 1916 bytes result sent to driver\n",
      "  Starting task 12.0 in stage 1.0 (TID 133) (namenode, executor driver, partition 12, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 12.0 in stage 1.0 (TID 133)\n",
      "  Finished task 9.0 in stage 1.0 (TID 130) in 693 ms on namenode (executor driver) (9/121)\n",
      "  Getting 121 (257.4 KiB) non-empty blocks including 121 (257.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 5 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 499, boot = 6, init = 14, finish = 479\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000011_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000011\n",
      "  attempt_202204260806042090827804316438547_0008_m_000011_0: Committed\n",
      "  Finished task 11.0 in stage 1.0 (TID 132). 1916 bytes result sent to driver\n",
      "  Starting task 13.0 in stage 1.0 (TID 134) (namenode, executor driver, partition 13, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 13.0 in stage 1.0 (TID 134)\n",
      "  Finished task 11.0 in stage 1.0 (TID 132) in 538 ms on namenode (executor driver) (10/121)\n",
      "  Getting 121 (221.5 KiB) non-empty blocks including 121 (221.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 608, boot = -2, init = 9, finish = 601\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000012_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000012\n",
      "  attempt_202204260806042090827804316438547_0008_m_000012_0: Committed\n",
      "  Finished task 12.0 in stage 1.0 (TID 133). 1916 bytes result sent to driver\n",
      "  Starting task 14.0 in stage 1.0 (TID 135) (namenode, executor driver, partition 14, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 12.0 in stage 1.0 (TID 133) in 632 ms on namenode (executor driver) (11/121)\n",
      "  Running task 14.0 in stage 1.0 (TID 135)\n",
      "  Getting 121 (221.5 KiB) non-empty blocks including 121 (221.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Times: total = 1059, boot = 1, init = 6, finish = 1052\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000010_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000010\n",
      "  attempt_202204260806042090827804316438547_0008_m_000010_0: Committed\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Finished task 10.0 in stage 1.0 (TID 131). 2002 bytes result sent to driver\n",
      "  Starting task 15.0 in stage 1.0 (TID 136) (namenode, executor driver, partition 15, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 10.0 in stage 1.0 (TID 131) in 1096 ms on namenode (executor driver) (12/121)\n",
      "  Running task 15.0 in stage 1.0 (TID 136)\n",
      "  Getting 121 (245.0 KiB) non-empty blocks including 121 (245.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 625, boot = -2, init = 8, finish = 619\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000013_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000013\n",
      "  attempt_202204260806042090827804316438547_0008_m_000013_0: Committed\n",
      "  Finished task 13.0 in stage 1.0 (TID 134). 1916 bytes result sent to driver\n",
      "  Starting task 16.0 in stage 1.0 (TID 137) (namenode, executor driver, partition 16, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 16.0 in stage 1.0 (TID 137)\n",
      "  Finished task 13.0 in stage 1.0 (TID 134) in 662 ms on namenode (executor driver) (13/121)\n",
      "  Getting 121 (231.0 KiB) non-empty blocks including 121 (231.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 382, boot = -5, init = 14, finish = 373\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000015_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000015\n",
      "  attempt_202204260806042090827804316438547_0008_m_000015_0: Committed\n",
      "  Finished task 15.0 in stage 1.0 (TID 136). 1916 bytes result sent to driver\n",
      "  Starting task 17.0 in stage 1.0 (TID 138) (namenode, executor driver, partition 17, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 17.0 in stage 1.0 (TID 138)\n",
      "  Finished task 15.0 in stage 1.0 (TID 136) in 414 ms on namenode (executor driver) (14/121)\n",
      "  Getting 121 (272.0 KiB) non-empty blocks including 121 (272.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 501, boot = 20, init = 1, finish = 480\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000014_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000014\n",
      "  attempt_202204260806042090827804316438547_0008_m_000014_0: Committed\n",
      "  Finished task 14.0 in stage 1.0 (TID 135). 1916 bytes result sent to driver\n",
      "  Starting task 18.0 in stage 1.0 (TID 139) (namenode, executor driver, partition 18, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 18.0 in stage 1.0 (TID 139)\n",
      "  Finished task 14.0 in stage 1.0 (TID 135) in 521 ms on namenode (executor driver) (15/121)\n",
      "  Getting 121 (233.5 KiB) non-empty blocks including 121 (233.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 2704, boot = 38, init = 1, finish = 2665\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000006_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000006\n",
      "  attempt_202204260806042090827804316438547_0008_m_000006_0: Committed\n",
      "  Finished task 6.0 in stage 1.0 (TID 127). 2002 bytes result sent to driver\n",
      "  Starting task 19.0 in stage 1.0 (TID 140) (namenode, executor driver, partition 19, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 19.0 in stage 1.0 (TID 140)\n",
      "  Finished task 6.0 in stage 1.0 (TID 127) in 2740 ms on namenode (executor driver) (16/121)\n",
      "  Getting 121 (253.1 KiB) non-empty blocks including 121 (253.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Times: total = 864, boot = 35, init = 1, finish = 828\n",
      "  Started 0 remote fetches in 14 ms\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000016_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000016\n",
      "  attempt_202204260806042090827804316438547_0008_m_000016_0: Committed\n",
      "  Finished task 16.0 in stage 1.0 (TID 137). 2002 bytes result sent to driver\n",
      "  Starting task 20.0 in stage 1.0 (TID 141) (namenode, executor driver, partition 20, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 16.0 in stage 1.0 (TID 137) in 909 ms on namenode (executor driver) (17/121)\n",
      "  Running task 20.0 in stage 1.0 (TID 141)\n",
      "  Getting 121 (250.2 KiB) non-empty blocks including 121 (250.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 700, boot = 69, init = 1, finish = 630\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000018_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000018\n",
      "  attempt_202204260806042090827804316438547_0008_m_000018_0: Committed\n",
      "  Finished task 18.0 in stage 1.0 (TID 139). 2002 bytes result sent to driver\n",
      "  Starting task 21.0 in stage 1.0 (TID 142) (namenode, executor driver, partition 21, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 21.0 in stage 1.0 (TID 142)\n",
      "  Finished task 18.0 in stage 1.0 (TID 139) in 719 ms on namenode (executor driver) (18/121)\n",
      "  Getting 121 (245.4 KiB) non-empty blocks including 121 (245.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 2 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 474, boot = 5, init = 11, finish = 458\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000021_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000021\n",
      "  attempt_202204260806042090827804316438547_0008_m_000021_0: Committed\n",
      "  Finished task 21.0 in stage 1.0 (TID 142). 1916 bytes result sent to driver\n",
      "  Starting task 22.0 in stage 1.0 (TID 143) (namenode, executor driver, partition 22, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 21.0 in stage 1.0 (TID 142) in 496 ms on namenode (executor driver) (19/121)\n",
      "  Running task 22.0 in stage 1.0 (TID 143)\n",
      "  Getting 121 (284.2 KiB) non-empty blocks including 121 (284.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 695, boot = -4, init = 10, finish = 689\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000019_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000019\n",
      "  attempt_202204260806042090827804316438547_0008_m_000019_0: Committed\n",
      "  Finished task 19.0 in stage 1.0 (TID 140). 2002 bytes result sent to driver\n",
      "  Starting task 23.0 in stage 1.0 (TID 144) (namenode, executor driver, partition 23, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 23.0 in stage 1.0 (TID 144)\n",
      "  Finished task 19.0 in stage 1.0 (TID 140) in 730 ms on namenode (executor driver) (20/121)\n",
      "  Getting 121 (216.8 KiB) non-empty blocks including 121 (216.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 758, boot = -18, init = 50, finish = 726\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000020_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000020\n",
      "  attempt_202204260806042090827804316438547_0008_m_000020_0: Committed\n",
      "  Finished task 20.0 in stage 1.0 (TID 141). 2002 bytes result sent to driver\n",
      "  Starting task 24.0 in stage 1.0 (TID 145) (namenode, executor driver, partition 24, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 24.0 in stage 1.0 (TID 145)\n",
      "  Finished task 20.0 in stage 1.0 (TID 141) in 783 ms on namenode (executor driver) (21/121)\n",
      "  Getting 121 (246.1 KiB) non-empty blocks including 121 (246.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 339, boot = -12, init = 34, finish = 317\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000023_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000023\n",
      "  attempt_202204260806042090827804316438547_0008_m_000023_0: Committed\n",
      "  Finished task 23.0 in stage 1.0 (TID 144). 1916 bytes result sent to driver\n",
      "  Starting task 25.0 in stage 1.0 (TID 146) (namenode, executor driver, partition 25, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 23.0 in stage 1.0 (TID 144) in 371 ms on namenode (executor driver) (22/121)\n",
      "  Running task 25.0 in stage 1.0 (TID 146)\n",
      "  Getting 121 (229.6 KiB) non-empty blocks including 121 (229.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 10 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 2006, boot = -2, init = 20, finish = 1988\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000017_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000017\n",
      "  attempt_202204260806042090827804316438547_0008_m_000017_0: Committed\n",
      "  Finished task 17.0 in stage 1.0 (TID 138). 2045 bytes result sent to driver\n",
      "  Starting task 26.0 in stage 1.0 (TID 147) (namenode, executor driver, partition 26, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 17.0 in stage 1.0 (TID 138) in 2032 ms on namenode (executor driver) (23/121)\n",
      "  Running task 26.0 in stage 1.0 (TID 147)\n",
      "  Getting 121 (236.2 KiB) non-empty blocks including 121 (236.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 668, boot = -7, init = 9, finish = 666\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000024_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000024\n",
      "  attempt_202204260806042090827804316438547_0008_m_000024_0: Committed\n",
      "  Finished task 24.0 in stage 1.0 (TID 145). 2045 bytes result sent to driver\n",
      "  Starting task 27.0 in stage 1.0 (TID 148) (namenode, executor driver, partition 27, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 24.0 in stage 1.0 (TID 145) in 698 ms on namenode (executor driver) (24/121)\n",
      "  Running task 27.0 in stage 1.0 (TID 148)\n",
      "  Getting 121 (201.8 KiB) non-empty blocks including 121 (201.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 10 ms\n",
      "  Times: total = 366, boot = -46, init = 48, finish = 364\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000025_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000025\n",
      "  attempt_202204260806042090827804316438547_0008_m_000025_0: Committed\n",
      "  Finished task 25.0 in stage 1.0 (TID 146). 1959 bytes result sent to driver\n",
      "  Starting task 28.0 in stage 1.0 (TID 149) (namenode, executor driver, partition 28, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 28.0 in stage 1.0 (TID 149)\n",
      "  Finished task 25.0 in stage 1.0 (TID 146) in 445 ms on namenode (executor driver) (25/121)\n",
      "  Getting 121 (178.6 KiB) non-empty blocks including 121 (178.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 9 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 287, boot = 16, init = 4, finish = 267\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000028_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000028\n",
      "  attempt_202204260806042090827804316438547_0008_m_000028_0: Committed\n",
      "  Finished task 28.0 in stage 1.0 (TID 149). 1916 bytes result sent to driver\n",
      "  Starting task 29.0 in stage 1.0 (TID 150) (namenode, executor driver, partition 29, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 28.0 in stage 1.0 (TID 149) in 312 ms on namenode (executor driver) (26/121)\n",
      "  Running task 29.0 in stage 1.0 (TID 150)\n",
      "  Getting 121 (242.1 KiB) non-empty blocks including 121 (242.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 1430, boot = 15, init = 9, finish = 1406\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000022_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000022\n",
      "  attempt_202204260806042090827804316438547_0008_m_000022_0: Committed\n",
      "  Finished task 22.0 in stage 1.0 (TID 143). 2045 bytes result sent to driver\n",
      "  Starting task 30.0 in stage 1.0 (TID 151) (namenode, executor driver, partition 30, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 30.0 in stage 1.0 (TID 151)\n",
      "  Finished task 22.0 in stage 1.0 (TID 143) in 1450 ms on namenode (executor driver) (27/121)\n",
      "  Getting 121 (195.6 KiB) non-empty blocks including 121 (195.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 501, boot = 6, init = 10, finish = 485\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000029_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000029\n",
      "  attempt_202204260806042090827804316438547_0008_m_000029_0: Committed\n",
      "  Finished task 29.0 in stage 1.0 (TID 150). 1916 bytes result sent to driver\n",
      "  Starting task 31.0 in stage 1.0 (TID 152) (namenode, executor driver, partition 31, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 31.0 in stage 1.0 (TID 152)\n",
      "  Finished task 29.0 in stage 1.0 (TID 150) in 530 ms on namenode (executor driver) (28/121)\n",
      "  Getting 121 (264.3 KiB) non-empty blocks including 121 (264.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 873, boot = -4, init = 7, finish = 870\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000027_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000027\n",
      "  attempt_202204260806042090827804316438547_0008_m_000027_0: Committed\n",
      "  Finished task 27.0 in stage 1.0 (TID 148). 2002 bytes result sent to driver\n",
      "  Starting task 32.0 in stage 1.0 (TID 153) (namenode, executor driver, partition 32, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 27.0 in stage 1.0 (TID 148) in 907 ms on namenode (executor driver) (29/121)\n",
      "  Running task 32.0 in stage 1.0 (TID 153)\n",
      "  Getting 121 (239.1 KiB) non-empty blocks including 121 (239.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  Started 0 remote fetches in 8 ms\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 489, boot = 2, init = 2, finish = 485\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000030_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000030\n",
      "  attempt_202204260806042090827804316438547_0008_m_000030_0: Committed\n",
      "  Finished task 30.0 in stage 1.0 (TID 151). 2002 bytes result sent to driver\n",
      "  Starting task 33.0 in stage 1.0 (TID 154) (namenode, executor driver, partition 33, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 33.0 in stage 1.0 (TID 154)\n",
      "  Finished task 30.0 in stage 1.0 (TID 151) in 506 ms on namenode (executor driver) (30/121)\n",
      "  Getting 121 (294.6 KiB) non-empty blocks including 121 (294.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 16 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 1364, boot = 0, init = 2, finish = 1362\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000026_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000026\n",
      "  attempt_202204260806042090827804316438547_0008_m_000026_0: Committed\n",
      "  Finished task 26.0 in stage 1.0 (TID 147). 2002 bytes result sent to driver\n",
      "  Starting task 34.0 in stage 1.0 (TID 155) (namenode, executor driver, partition 34, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 26.0 in stage 1.0 (TID 147) in 1388 ms on namenode (executor driver) (31/121)\n",
      "  Running task 34.0 in stage 1.0 (TID 155)\n",
      "  Getting 121 (223.4 KiB) non-empty blocks including 121 (223.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 430, boot = 9, init = 0, finish = 421\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000032_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000032\n",
      "  attempt_202204260806042090827804316438547_0008_m_000032_0: Committed\n",
      "  Finished task 32.0 in stage 1.0 (TID 153). 1916 bytes result sent to driver\n",
      "  Starting task 35.0 in stage 1.0 (TID 156) (namenode, executor driver, partition 35, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 35.0 in stage 1.0 (TID 156)\n",
      "  Finished task 32.0 in stage 1.0 (TID 153) in 460 ms on namenode (executor driver) (32/121)\n",
      "  Getting 121 (200.6 KiB) non-empty blocks including 121 (200.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 6 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 518, boot = 8, init = 9, finish = 501\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000034_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000034\n",
      "  attempt_202204260806042090827804316438547_0008_m_000034_0: Committed\n",
      "  Finished task 34.0 in stage 1.0 (TID 155). 1916 bytes result sent to driver\n",
      "  Starting task 36.0 in stage 1.0 (TID 157) (namenode, executor driver, partition 36, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 34.0 in stage 1.0 (TID 155) in 539 ms on namenode (executor driver) (33/121)\n",
      "  Running task 36.0 in stage 1.0 (TID 157)\n",
      "  Getting 121 (277.5 KiB) non-empty blocks including 121 (277.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 673, boot = 24, init = 1, finish = 648\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000035_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000035\n",
      "  attempt_202204260806042090827804316438547_0008_m_000035_0: Committed\n",
      "  Finished task 35.0 in stage 1.0 (TID 156). 2002 bytes result sent to driver\n",
      "  Starting task 37.0 in stage 1.0 (TID 158) (namenode, executor driver, partition 37, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 37.0 in stage 1.0 (TID 158)\n",
      "  Finished task 35.0 in stage 1.0 (TID 156) in 698 ms on namenode (executor driver) (34/121)\n",
      "  Getting 121 (209.3 KiB) non-empty blocks including 121 (209.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 17 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 1672, boot = 9, init = 2, finish = 1661\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000031_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000031\n",
      "  attempt_202204260806042090827804316438547_0008_m_000031_0: Committed\n",
      "  Finished task 31.0 in stage 1.0 (TID 152). 2002 bytes result sent to driver\n",
      "  Starting task 38.0 in stage 1.0 (TID 159) (namenode, executor driver, partition 38, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 38.0 in stage 1.0 (TID 159)\n",
      "  Finished task 31.0 in stage 1.0 (TID 152) in 1700 ms on namenode (executor driver) (35/121)\n",
      "  Getting 121 (254.8 KiB) non-empty blocks including 121 (254.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 1306, boot = 6, init = 8, finish = 1292\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000036_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000036\n",
      "  attempt_202204260806042090827804316438547_0008_m_000036_0: Committed\n",
      "  Finished task 36.0 in stage 1.0 (TID 157). 2002 bytes result sent to driver\n",
      "  Starting task 39.0 in stage 1.0 (TID 160) (namenode, executor driver, partition 39, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 36.0 in stage 1.0 (TID 157) in 1342 ms on namenode (executor driver) (36/121)\n",
      "  Running task 39.0 in stage 1.0 (TID 160)\n",
      "  Getting 121 (217.4 KiB) non-empty blocks including 121 (217.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 11 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 679, boot = 8, init = 4, finish = 667\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000038_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000038\n",
      "  attempt_202204260806042090827804316438547_0008_m_000038_0: Committed\n",
      "  Finished task 38.0 in stage 1.0 (TID 159). 1916 bytes result sent to driver\n",
      "  Starting task 40.0 in stage 1.0 (TID 161) (namenode, executor driver, partition 40, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 38.0 in stage 1.0 (TID 159) in 705 ms on namenode (executor driver) (37/121)\n",
      "  Running task 40.0 in stage 1.0 (TID 161)\n",
      "  Getting 121 (227.8 KiB) non-empty blocks including 121 (227.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 11 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 1240, boot = -3, init = 8, finish = 1235\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000037_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000037\n",
      "  attempt_202204260806042090827804316438547_0008_m_000037_0: Committed\n",
      "  Finished task 37.0 in stage 1.0 (TID 158). 2002 bytes result sent to driver\n",
      "  Starting task 41.0 in stage 1.0 (TID 162) (namenode, executor driver, partition 41, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 41.0 in stage 1.0 (TID 162)\n",
      "  Finished task 37.0 in stage 1.0 (TID 158) in 1280 ms on namenode (executor driver) (38/121)\n",
      "  Getting 121 (255.2 KiB) non-empty blocks including 121 (255.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 365, boot = 6, init = 3, finish = 356\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000040_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000040\n",
      "  attempt_202204260806042090827804316438547_0008_m_000040_0: Committed\n",
      "  Finished task 40.0 in stage 1.0 (TID 161). 1916 bytes result sent to driver\n",
      "  Starting task 42.0 in stage 1.0 (TID 163) (namenode, executor driver, partition 42, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 40.0 in stage 1.0 (TID 161) in 392 ms on namenode (executor driver) (39/121)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Running task 42.0 in stage 1.0 (TID 163)\n",
      "  Getting 121 (230.9 KiB) non-empty blocks including 121 (230.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 8 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 499, boot = 25, init = 1, finish = 473\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000041_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000041\n",
      "  attempt_202204260806042090827804316438547_0008_m_000041_0: Committed\n",
      "  Finished task 41.0 in stage 1.0 (TID 162). 1916 bytes result sent to driver\n",
      "  Starting task 43.0 in stage 1.0 (TID 164) (namenode, executor driver, partition 43, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 43.0 in stage 1.0 (TID 164)\n",
      "  Finished task 41.0 in stage 1.0 (TID 162) in 512 ms on namenode (executor driver) (40/121)\n",
      "  Getting 121 (222.0 KiB) non-empty blocks including 121 (222.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 692, boot = 6, init = 16, finish = 670\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000039_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000039\n",
      "  attempt_202204260806042090827804316438547_0008_m_000039_0: Committed\n",
      "  Finished task 39.0 in stage 1.0 (TID 160). 2002 bytes result sent to driver\n",
      "  Starting task 44.0 in stage 1.0 (TID 165) (namenode, executor driver, partition 44, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 39.0 in stage 1.0 (TID 160) in 721 ms on namenode (executor driver) (41/121)\n",
      "  Running task 44.0 in stage 1.0 (TID 165)\n",
      "  Getting 121 (249.5 KiB) non-empty blocks including 121 (249.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 5 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 2864, boot = -3, init = 5, finish = 2862\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000033_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000033\n",
      "  attempt_202204260806042090827804316438547_0008_m_000033_0: Committed\n",
      "  Finished task 33.0 in stage 1.0 (TID 154). 2002 bytes result sent to driver\n",
      "  Starting task 45.0 in stage 1.0 (TID 166) (namenode, executor driver, partition 45, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 45.0 in stage 1.0 (TID 166)\n",
      "  Finished task 33.0 in stage 1.0 (TID 154) in 2895 ms on namenode (executor driver) (42/121)\n",
      "  Getting 121 (247.8 KiB) non-empty blocks including 121 (247.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 4 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 534, boot = 11, init = 14, finish = 509\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000042_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000042\n",
      "  attempt_202204260806042090827804316438547_0008_m_000042_0: Committed\n",
      "  Finished task 42.0 in stage 1.0 (TID 163). 1916 bytes result sent to driver\n",
      "  Starting task 46.0 in stage 1.0 (TID 167) (namenode, executor driver, partition 46, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 42.0 in stage 1.0 (TID 163) in 558 ms on namenode (executor driver) (43/121)\n",
      "  Running task 46.0 in stage 1.0 (TID 167)\n",
      "  Getting 121 (191.5 KiB) non-empty blocks including 121 (191.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 9 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 448, boot = 17, init = 0, finish = 431\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000043_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000043\n",
      "  attempt_202204260806042090827804316438547_0008_m_000043_0: Committed\n",
      "  Finished task 43.0 in stage 1.0 (TID 164). 1959 bytes result sent to driver\n",
      "  Starting task 47.0 in stage 1.0 (TID 168) (namenode, executor driver, partition 47, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 47.0 in stage 1.0 (TID 168)\n",
      "  Finished task 43.0 in stage 1.0 (TID 164) in 470 ms on namenode (executor driver) (44/121)\n",
      "  Getting 121 (233.0 KiB) non-empty blocks including 121 (233.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 725, boot = 28, init = 11, finish = 686\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000044_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000044\n",
      "  attempt_202204260806042090827804316438547_0008_m_000044_0: Committed\n",
      "  Finished task 44.0 in stage 1.0 (TID 165). 2045 bytes result sent to driver\n",
      "  Starting task 48.0 in stage 1.0 (TID 169) (namenode, executor driver, partition 48, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 44.0 in stage 1.0 (TID 165) in 784 ms on namenode (executor driver) (45/121)\n",
      "  Running task 48.0 in stage 1.0 (TID 169)\n",
      "  Getting 121 (171.1 KiB) non-empty blocks including 121 (171.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 3 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 448, boot = 12, init = 5, finish = 431\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000047_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000047\n",
      "  attempt_202204260806042090827804316438547_0008_m_000047_0: Committed\n",
      "  Finished task 47.0 in stage 1.0 (TID 168). 1916 bytes result sent to driver\n",
      "  Starting task 49.0 in stage 1.0 (TID 170) (namenode, executor driver, partition 49, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 49.0 in stage 1.0 (TID 170)\n",
      "  Finished task 47.0 in stage 1.0 (TID 168) in 468 ms on namenode (executor driver) (46/121)\n",
      "  Getting 121 (247.9 KiB) non-empty blocks including 121 (247.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 614, boot = 10, init = 7, finish = 597\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000046_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000046\n",
      "  attempt_202204260806042090827804316438547_0008_m_000046_0: Committed\n",
      "  Finished task 46.0 in stage 1.0 (TID 167). 2045 bytes result sent to driver\n",
      "  Starting task 50.0 in stage 1.0 (TID 171) (namenode, executor driver, partition 50, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 46.0 in stage 1.0 (TID 167) in 639 ms on namenode (executor driver) (47/121)\n",
      "  Running task 50.0 in stage 1.0 (TID 171)\n",
      "  Getting 121 (249.9 KiB) non-empty blocks including 121 (249.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 241, boot = 2, init = 2, finish = 237\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000048_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000048\n",
      "  attempt_202204260806042090827804316438547_0008_m_000048_0: Committed\n",
      "  Finished task 48.0 in stage 1.0 (TID 169). 1916 bytes result sent to driver\n",
      "  Starting task 51.0 in stage 1.0 (TID 172) (namenode, executor driver, partition 51, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 51.0 in stage 1.0 (TID 172)\n",
      "  Finished task 48.0 in stage 1.0 (TID 169) in 265 ms on namenode (executor driver) (48/121)\n",
      "  Getting 121 (238.5 KiB) non-empty blocks including 121 (238.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 997, boot = 18, init = 1, finish = 978\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000045_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000045\n",
      "  attempt_202204260806042090827804316438547_0008_m_000045_0: Committed\n",
      "  Finished task 45.0 in stage 1.0 (TID 166). 2045 bytes result sent to driver\n",
      "  Starting task 52.0 in stage 1.0 (TID 173) (namenode, executor driver, partition 52, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 45.0 in stage 1.0 (TID 166) in 1020 ms on namenode (executor driver) (49/121)\n",
      "  Running task 52.0 in stage 1.0 (TID 173)\n",
      "  Getting 121 (227.7 KiB) non-empty blocks including 121 (227.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 5 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 429, boot = 6, init = 2, finish = 421\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000050_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000050\n",
      "  attempt_202204260806042090827804316438547_0008_m_000050_0: Committed\n",
      "  Finished task 50.0 in stage 1.0 (TID 171). 1916 bytes result sent to driver\n",
      "  Starting task 53.0 in stage 1.0 (TID 174) (namenode, executor driver, partition 53, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 50.0 in stage 1.0 (TID 171) in 457 ms on namenode (executor driver) (50/121)\n",
      "  Running task 53.0 in stage 1.0 (TID 174)\n",
      "  Getting 121 (221.6 KiB) non-empty blocks including 121 (221.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 389, boot = 23, init = 0, finish = 366\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000051_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000051\n",
      "  attempt_202204260806042090827804316438547_0008_m_000051_0: Committed\n",
      "  Finished task 51.0 in stage 1.0 (TID 172). 1916 bytes result sent to driver\n",
      "  Starting task 54.0 in stage 1.0 (TID 175) (namenode, executor driver, partition 54, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 54.0 in stage 1.0 (TID 175)\n",
      "  Finished task 51.0 in stage 1.0 (TID 172) in 414 ms on namenode (executor driver) (51/121)\n",
      "  Getting 121 (278.0 KiB) non-empty blocks including 121 (278.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 650, boot = 1, init = 3, finish = 646\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000052_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000052\n",
      "  attempt_202204260806042090827804316438547_0008_m_000052_0: Committed\n",
      "  Finished task 52.0 in stage 1.0 (TID 173). 1916 bytes result sent to driver\n",
      "  Starting task 55.0 in stage 1.0 (TID 176) (namenode, executor driver, partition 55, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 52.0 in stage 1.0 (TID 173) in 672 ms on namenode (executor driver) (52/121)\n",
      "  Running task 55.0 in stage 1.0 (TID 176)\n",
      "  Getting 121 (241.4 KiB) non-empty blocks including 121 (241.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 5 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 398, boot = 9, init = 3, finish = 386\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000053_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000053\n",
      "  attempt_202204260806042090827804316438547_0008_m_000053_0: Committed\n",
      "  Finished task 53.0 in stage 1.0 (TID 174). 1916 bytes result sent to driver\n",
      "  Starting task 56.0 in stage 1.0 (TID 177) (namenode, executor driver, partition 56, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 53.0 in stage 1.0 (TID 174) in 425 ms on namenode (executor driver) (53/121)\n",
      "  Running task 56.0 in stage 1.0 (TID 177)\n",
      "  Getting 121 (286.9 KiB) non-empty blocks including 121 (286.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 8 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 725, boot = -7, init = 9, finish = 723\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000054_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000054\n",
      "  attempt_202204260806042090827804316438547_0008_m_000054_0: Committed\n",
      "  Finished task 54.0 in stage 1.0 (TID 175). 1916 bytes result sent to driver\n",
      "  Starting task 57.0 in stage 1.0 (TID 178) (namenode, executor driver, partition 57, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 54.0 in stage 1.0 (TID 175) in 747 ms on namenode (executor driver) (54/121)\n",
      "  Running task 57.0 in stage 1.0 (TID 178)\n",
      "  Getting 121 (241.0 KiB) non-empty blocks including 121 (241.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Started 0 remote fetches in 1 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 1460, boot = 18, init = 1, finish = 1441\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000049_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000049\n",
      "  attempt_202204260806042090827804316438547_0008_m_000049_0: Committed\n",
      "  Finished task 49.0 in stage 1.0 (TID 170). 2002 bytes result sent to driver\n",
      "  Starting task 58.0 in stage 1.0 (TID 179) (namenode, executor driver, partition 58, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 58.0 in stage 1.0 (TID 179)\n",
      "  Finished task 49.0 in stage 1.0 (TID 170) in 1473 ms on namenode (executor driver) (55/121)\n",
      "  Getting 121 (237.4 KiB) non-empty blocks including 121 (237.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 769, boot = 48, init = 1, finish = 720\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000055_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000055\n",
      "  attempt_202204260806042090827804316438547_0008_m_000055_0: Committed\n",
      "  Finished task 55.0 in stage 1.0 (TID 176). 2002 bytes result sent to driver\n",
      "  Starting task 59.0 in stage 1.0 (TID 180) (namenode, executor driver, partition 59, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 55.0 in stage 1.0 (TID 176) in 804 ms on namenode (executor driver) (56/121)\n",
      "  Running task 59.0 in stage 1.0 (TID 180)\n",
      "  Getting 121 (251.2 KiB) non-empty blocks including 121 (251.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 7 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 700, boot = -17, init = 24, finish = 693\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000057_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000057\n",
      "  attempt_202204260806042090827804316438547_0008_m_000057_0: Committed\n",
      "  Finished task 57.0 in stage 1.0 (TID 178). 2002 bytes result sent to driver\n",
      "  Starting task 60.0 in stage 1.0 (TID 181) (namenode, executor driver, partition 60, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 57.0 in stage 1.0 (TID 178) in 737 ms on namenode (executor driver) (57/121)\n",
      "  Running task 60.0 in stage 1.0 (TID 181)\n",
      "  Getting 121 (283.1 KiB) non-empty blocks including 121 (283.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 775, boot = 12, init = 6, finish = 757\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000058_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000058\n",
      "  attempt_202204260806042090827804316438547_0008_m_000058_0: Committed\n",
      "  Finished task 58.0 in stage 1.0 (TID 179). 2002 bytes result sent to driver\n",
      "  Starting task 61.0 in stage 1.0 (TID 182) (namenode, executor driver, partition 61, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 61.0 in stage 1.0 (TID 182)\n",
      "  Finished task 58.0 in stage 1.0 (TID 179) in 800 ms on namenode (executor driver) (58/121)\n",
      "  Getting 121 (270.6 KiB) non-empty blocks including 121 (270.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 1188, boot = -3, init = 10, finish = 1181\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000059_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000059\n",
      "  attempt_202204260806042090827804316438547_0008_m_000059_0: Committed\n",
      "  Finished task 59.0 in stage 1.0 (TID 180). 2002 bytes result sent to driver\n",
      "  Starting task 62.0 in stage 1.0 (TID 183) (namenode, executor driver, partition 62, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 59.0 in stage 1.0 (TID 180) in 1213 ms on namenode (executor driver) (59/121)\n",
      "  Running task 62.0 in stage 1.0 (TID 183)\n",
      "  Getting 121 (239.3 KiB) non-empty blocks including 121 (239.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 952, boot = -10, init = 22, finish = 940\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000060_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000060\n",
      "  attempt_202204260806042090827804316438547_0008_m_000060_0: Committed\n",
      "  Finished task 60.0 in stage 1.0 (TID 181). 1916 bytes result sent to driver\n",
      "  Starting task 63.0 in stage 1.0 (TID 184) (namenode, executor driver, partition 63, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 63.0 in stage 1.0 (TID 184)\n",
      "  Finished task 60.0 in stage 1.0 (TID 181) in 983 ms on namenode (executor driver) (60/121)\n",
      "  Getting 121 (253.8 KiB) non-empty blocks including 121 (253.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 12 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 2309, boot = 12, init = 2, finish = 2295\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000056_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000056\n",
      "  attempt_202204260806042090827804316438547_0008_m_000056_0: Committed\n",
      "  Finished task 56.0 in stage 1.0 (TID 177). 2002 bytes result sent to driver\n",
      "  Starting task 64.0 in stage 1.0 (TID 185) (namenode, executor driver, partition 64, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 56.0 in stage 1.0 (TID 177) in 2332 ms on namenode (executor driver) (61/121)\n",
      "  Running task 64.0 in stage 1.0 (TID 185)\n",
      "  Getting 121 (235.7 KiB) non-empty blocks including 121 (235.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 417, boot = -3, init = 5, finish = 415\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000062_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000062\n",
      "  attempt_202204260806042090827804316438547_0008_m_000062_0: Committed\n",
      "  Finished task 62.0 in stage 1.0 (TID 183). 1916 bytes result sent to driver\n",
      "  Starting task 65.0 in stage 1.0 (TID 186) (namenode, executor driver, partition 65, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 65.0 in stage 1.0 (TID 186)\n",
      "  Finished task 62.0 in stage 1.0 (TID 183) in 440 ms on namenode (executor driver) (62/121)\n",
      "  Getting 121 (268.7 KiB) non-empty blocks including 121 (268.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 1191, boot = 8, init = 13, finish = 1170\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000061_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000061\n",
      "  attempt_202204260806042090827804316438547_0008_m_000061_0: Committed\n",
      "  Finished task 61.0 in stage 1.0 (TID 182). 2002 bytes result sent to driver\n",
      "  Starting task 66.0 in stage 1.0 (TID 187) (namenode, executor driver, partition 66, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 66.0 in stage 1.0 (TID 187)\n",
      "  Finished task 61.0 in stage 1.0 (TID 182) in 1204 ms on namenode (executor driver) (63/121)\n",
      "  Getting 121 (244.6 KiB) non-empty blocks including 121 (244.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 5 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 323, boot = 5, init = 2, finish = 316\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000066_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000066\n",
      "  attempt_202204260806042090827804316438547_0008_m_000066_0: Committed\n",
      "  Finished task 66.0 in stage 1.0 (TID 187). 1916 bytes result sent to driver\n",
      "  Starting task 67.0 in stage 1.0 (TID 188) (namenode, executor driver, partition 67, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 67.0 in stage 1.0 (TID 188)\n",
      "  Finished task 66.0 in stage 1.0 (TID 187) in 342 ms on namenode (executor driver) (64/121)\n",
      "  Getting 121 (298.4 KiB) non-empty blocks including 121 (298.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 811, boot = 36, init = 1, finish = 774\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000063_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000063\n",
      "  attempt_202204260806042090827804316438547_0008_m_000063_0: Committed\n",
      "  Finished task 63.0 in stage 1.0 (TID 184). 2002 bytes result sent to driver\n",
      "  Starting task 68.0 in stage 1.0 (TID 189) (namenode, executor driver, partition 68, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 63.0 in stage 1.0 (TID 184) in 854 ms on namenode (executor driver) (65/121)\n",
      "  Running task 68.0 in stage 1.0 (TID 189)\n",
      "  Getting 121 (293.4 KiB) non-empty blocks including 121 (293.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 2 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 1403, boot = 13, init = 2, finish = 1388\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000064_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000064\n",
      "  attempt_202204260806042090827804316438547_0008_m_000064_0: Committed\n",
      "  Finished task 64.0 in stage 1.0 (TID 185). 2045 bytes result sent to driver\n",
      "  Starting task 69.0 in stage 1.0 (TID 190) (namenode, executor driver, partition 69, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 64.0 in stage 1.0 (TID 185) in 1423 ms on namenode (executor driver) (66/121)\n",
      "  Running task 69.0 in stage 1.0 (TID 190)\n",
      "  Getting 121 (277.8 KiB) non-empty blocks including 121 (277.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 1507, boot = 24, init = 0, finish = 1483\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000065_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000065\n",
      "  attempt_202204260806042090827804316438547_0008_m_000065_0: Committed\n",
      "  Finished task 65.0 in stage 1.0 (TID 186). 2045 bytes result sent to driver\n",
      "  Starting task 70.0 in stage 1.0 (TID 191) (namenode, executor driver, partition 70, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 70.0 in stage 1.0 (TID 191)\n",
      "  Finished task 65.0 in stage 1.0 (TID 186) in 1520 ms on namenode (executor driver) (67/121)\n",
      "  Getting 121 (242.8 KiB) non-empty blocks including 121 (242.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 1138, boot = 58, init = 1, finish = 1079\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000068_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000068\n",
      "  attempt_202204260806042090827804316438547_0008_m_000068_0: Committed\n",
      "  Finished task 68.0 in stage 1.0 (TID 189). 2045 bytes result sent to driver\n",
      "  Starting task 71.0 in stage 1.0 (TID 192) (namenode, executor driver, partition 71, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 68.0 in stage 1.0 (TID 189) in 1157 ms on namenode (executor driver) (68/121)\n",
      "  Running task 71.0 in stage 1.0 (TID 192)\n",
      "  Getting 121 (213.6 KiB) non-empty blocks including 121 (213.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 2 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 1617, boot = 6, init = 14, finish = 1597\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000067_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000067\n",
      "  attempt_202204260806042090827804316438547_0008_m_000067_0: Committed\n",
      "  Finished task 67.0 in stage 1.0 (TID 188). 2045 bytes result sent to driver\n",
      "  Starting task 72.0 in stage 1.0 (TID 193) (namenode, executor driver, partition 72, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 67.0 in stage 1.0 (TID 188) in 1632 ms on namenode (executor driver) (69/121)\n",
      "  Running task 72.0 in stage 1.0 (TID 193)\n",
      "  Getting 121 (309.7 KiB) non-empty blocks including 121 (309.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 5 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 424, boot = -16, init = 27, finish = 413\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000071_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000071\n",
      "  attempt_202204260806042090827804316438547_0008_m_000071_0: Committed\n",
      "  Finished task 71.0 in stage 1.0 (TID 192). 1916 bytes result sent to driver\n",
      "  Starting task 73.0 in stage 1.0 (TID 194) (namenode, executor driver, partition 73, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 71.0 in stage 1.0 (TID 192) in 476 ms on namenode (executor driver) (70/121)\n",
      "  Running task 73.0 in stage 1.0 (TID 194)\n",
      "  Getting 121 (251.7 KiB) non-empty blocks including 121 (251.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Started 0 remote fetches in 1 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 1024, boot = 15, init = 1, finish = 1008\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000069_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000069\n",
      "  attempt_202204260806042090827804316438547_0008_m_000069_0: Committed\n",
      "  Finished task 69.0 in stage 1.0 (TID 190). 2002 bytes result sent to driver\n",
      "  Starting task 74.0 in stage 1.0 (TID 195) (namenode, executor driver, partition 74, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 74.0 in stage 1.0 (TID 195)\n",
      "  Finished task 69.0 in stage 1.0 (TID 190) in 1043 ms on namenode (executor driver) (71/121)\n",
      "  Getting 121 (251.5 KiB) non-empty blocks including 121 (251.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 4 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 1020, boot = 11, init = 5, finish = 1004\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000070_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000070\n",
      "  attempt_202204260806042090827804316438547_0008_m_000070_0: Committed\n",
      "  Finished task 70.0 in stage 1.0 (TID 191). 1916 bytes result sent to driver\n",
      "  Starting task 75.0 in stage 1.0 (TID 196) (namenode, executor driver, partition 75, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 75.0 in stage 1.0 (TID 196)\n",
      "  Finished task 70.0 in stage 1.0 (TID 191) in 1035 ms on namenode (executor driver) (72/121)\n",
      "  Getting 121 (268.8 KiB) non-empty blocks including 121 (268.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 396, boot = 16, init = 1, finish = 379\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000075_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000075\n",
      "  attempt_202204260806042090827804316438547_0008_m_000075_0: Committed\n",
      "  Finished task 75.0 in stage 1.0 (TID 196). 1916 bytes result sent to driver\n",
      "  Starting task 76.0 in stage 1.0 (TID 197) (namenode, executor driver, partition 76, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 75.0 in stage 1.0 (TID 196) in 410 ms on namenode (executor driver) (73/121)\n",
      "  Running task 76.0 in stage 1.0 (TID 197)\n",
      "  Getting 121 (238.8 KiB) non-empty blocks including 121 (238.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 1131, boot = -13, init = 14, finish = 1130\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000073_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000073\n",
      "  attempt_202204260806042090827804316438547_0008_m_000073_0: Committed\n",
      "  Finished task 73.0 in stage 1.0 (TID 194). 2002 bytes result sent to driver\n",
      "  Starting task 77.0 in stage 1.0 (TID 198) (namenode, executor driver, partition 77, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 77.0 in stage 1.0 (TID 198)\n",
      "  Finished task 73.0 in stage 1.0 (TID 194) in 1150 ms on namenode (executor driver) (74/121)\n",
      "  Getting 121 (273.3 KiB) non-empty blocks including 121 (273.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 1306, boot = 26, init = 1, finish = 1279\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000072_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000072\n",
      "  attempt_202204260806042090827804316438547_0008_m_000072_0: Committed\n",
      "  Finished task 72.0 in stage 1.0 (TID 193). 2002 bytes result sent to driver\n",
      "  Starting task 78.0 in stage 1.0 (TID 199) (namenode, executor driver, partition 78, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 72.0 in stage 1.0 (TID 193) in 1327 ms on namenode (executor driver) (75/121)\n",
      "  Running task 78.0 in stage 1.0 (TID 199)\n",
      "  Getting 121 (250.7 KiB) non-empty blocks including 121 (250.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 839, boot = 8, init = 3, finish = 828\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000076_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000076\n",
      "  attempt_202204260806042090827804316438547_0008_m_000076_0: Committed\n",
      "  Finished task 76.0 in stage 1.0 (TID 197). 2002 bytes result sent to driver\n",
      "  Starting task 79.0 in stage 1.0 (TID 200) (namenode, executor driver, partition 79, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 79.0 in stage 1.0 (TID 200)\n",
      "  Finished task 76.0 in stage 1.0 (TID 197) in 854 ms on namenode (executor driver) (76/121)\n",
      "  Getting 121 (257.8 KiB) non-empty blocks including 121 (257.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 1543, boot = 14, init = 1, finish = 1528\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000074_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000074\n",
      "  attempt_202204260806042090827804316438547_0008_m_000074_0: Committed\n",
      "  Finished task 74.0 in stage 1.0 (TID 195). 2002 bytes result sent to driver\n",
      "  Starting task 80.0 in stage 1.0 (TID 201) (namenode, executor driver, partition 80, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 74.0 in stage 1.0 (TID 195) in 1562 ms on namenode (executor driver) (77/121)\n",
      "  Running task 80.0 in stage 1.0 (TID 201)\n",
      "  Getting 121 (194.9 KiB) non-empty blocks including 121 (194.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 10 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 375, boot = 11, init = 1, finish = 363\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000080_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000080\n",
      "  attempt_202204260806042090827804316438547_0008_m_000080_0: Committed\n",
      "  Finished task 80.0 in stage 1.0 (TID 201). 1916 bytes result sent to driver\n",
      "  Starting task 81.0 in stage 1.0 (TID 202) (namenode, executor driver, partition 81, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 80.0 in stage 1.0 (TID 201) in 399 ms on namenode (executor driver) (78/121)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Running task 81.0 in stage 1.0 (TID 202)\n",
      "  Getting 121 (234.2 KiB) non-empty blocks including 121 (234.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 1225, boot = 3, init = 9, finish = 1213\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000077_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000077\n",
      "  attempt_202204260806042090827804316438547_0008_m_000077_0: Committed\n",
      "  Finished task 77.0 in stage 1.0 (TID 198). 2002 bytes result sent to driver\n",
      "  Starting task 82.0 in stage 1.0 (TID 203) (namenode, executor driver, partition 82, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 82.0 in stage 1.0 (TID 203)\n",
      "  Finished task 77.0 in stage 1.0 (TID 198) in 1244 ms on namenode (executor driver) (79/121)\n",
      "  Getting 121 (229.6 KiB) non-empty blocks including 121 (229.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 1211, boot = 6, init = 8, finish = 1197\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000078_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000078\n",
      "  attempt_202204260806042090827804316438547_0008_m_000078_0: Committed\n",
      "  Finished task 78.0 in stage 1.0 (TID 199). 2002 bytes result sent to driver\n",
      "  Starting task 83.0 in stage 1.0 (TID 204) (namenode, executor driver, partition 83, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 83.0 in stage 1.0 (TID 204)\n",
      "  Finished task 78.0 in stage 1.0 (TID 199) in 1225 ms on namenode (executor driver) (80/121)\n",
      "  Getting 121 (292.0 KiB) non-empty blocks including 121 (292.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 854, boot = 8, init = 2, finish = 844\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000079_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000079\n",
      "  attempt_202204260806042090827804316438547_0008_m_000079_0: Committed\n",
      "  Finished task 79.0 in stage 1.0 (TID 200). 2002 bytes result sent to driver\n",
      "  Starting task 84.0 in stage 1.0 (TID 205) (namenode, executor driver, partition 84, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 79.0 in stage 1.0 (TID 200) in 873 ms on namenode (executor driver) (81/121)\n",
      "  Running task 84.0 in stage 1.0 (TID 205)\n",
      "  Getting 121 (242.9 KiB) non-empty blocks including 121 (242.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 500, boot = 17, init = 2, finish = 481\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000081_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000081\n",
      "  attempt_202204260806042090827804316438547_0008_m_000081_0: Committed\n",
      "  Finished task 81.0 in stage 1.0 (TID 202). 1916 bytes result sent to driver\n",
      "  Starting task 85.0 in stage 1.0 (TID 206) (namenode, executor driver, partition 85, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 81.0 in stage 1.0 (TID 202) in 514 ms on namenode (executor driver) (82/121)\n",
      "  Running task 85.0 in stage 1.0 (TID 206)\n",
      "  Getting 121 (198.9 KiB) non-empty blocks including 121 (198.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 277, boot = 21, init = 1, finish = 255\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000085_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000085\n",
      "  attempt_202204260806042090827804316438547_0008_m_000085_0: Committed\n",
      "  Finished task 85.0 in stage 1.0 (TID 206). 1916 bytes result sent to driver\n",
      "  Starting task 86.0 in stage 1.0 (TID 207) (namenode, executor driver, partition 86, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 85.0 in stage 1.0 (TID 206) in 292 ms on namenode (executor driver) (83/121)\n",
      "  Running task 86.0 in stage 1.0 (TID 207)\n",
      "  Getting 121 (233.6 KiB) non-empty blocks including 121 (233.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 478, boot = 6, init = 2, finish = 470\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000084_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000084\n",
      "  attempt_202204260806042090827804316438547_0008_m_000084_0: Committed\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Finished task 84.0 in stage 1.0 (TID 205). 2002 bytes result sent to driver\n",
      "  Starting task 87.0 in stage 1.0 (TID 208) (namenode, executor driver, partition 87, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 87.0 in stage 1.0 (TID 208)\n",
      "  Finished task 84.0 in stage 1.0 (TID 205) in 501 ms on namenode (executor driver) (84/121)\n",
      "  Getting 121 (292.5 KiB) non-empty blocks including 121 (292.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 847, boot = 8, init = 4, finish = 835\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000082_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000082\n",
      "  attempt_202204260806042090827804316438547_0008_m_000082_0: Committed\n",
      "  Finished task 82.0 in stage 1.0 (TID 203). 2002 bytes result sent to driver\n",
      "  Starting task 88.0 in stage 1.0 (TID 209) (namenode, executor driver, partition 88, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 82.0 in stage 1.0 (TID 203) in 870 ms on namenode (executor driver) (85/121)\n",
      "  Running task 88.0 in stage 1.0 (TID 209)\n",
      "  Getting 121 (246.5 KiB) non-empty blocks including 121 (246.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 9 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 941, boot = 8, init = 10, finish = 923\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000083_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000083\n",
      "  attempt_202204260806042090827804316438547_0008_m_000083_0: Committed\n",
      "  Finished task 83.0 in stage 1.0 (TID 204). 1916 bytes result sent to driver\n",
      "  Starting task 89.0 in stage 1.0 (TID 210) (namenode, executor driver, partition 89, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 83.0 in stage 1.0 (TID 204) in 955 ms on namenode (executor driver) (86/121)\n",
      "  Running task 89.0 in stage 1.0 (TID 210)\n",
      "  Getting 121 (199.7 KiB) non-empty blocks including 121 (199.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 641, boot = 23, init = 1, finish = 617\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000086_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000086\n",
      "  attempt_202204260806042090827804316438547_0008_m_000086_0: Committed\n",
      "  Finished task 86.0 in stage 1.0 (TID 207). 2002 bytes result sent to driver\n",
      "  Starting task 90.0 in stage 1.0 (TID 211) (namenode, executor driver, partition 90, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 86.0 in stage 1.0 (TID 207) in 657 ms on namenode (executor driver) (87/121)\n",
      "  Running task 90.0 in stage 1.0 (TID 211)\n",
      "  Getting 121 (206.5 KiB) non-empty blocks including 121 (206.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 309, boot = 6, init = 9, finish = 294\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000089_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000089\n",
      "  attempt_202204260806042090827804316438547_0008_m_000089_0: Committed\n",
      "  Finished task 89.0 in stage 1.0 (TID 210). 1959 bytes result sent to driver\n",
      "  Starting task 91.0 in stage 1.0 (TID 212) (namenode, executor driver, partition 91, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 91.0 in stage 1.0 (TID 212)\n",
      "  Finished task 89.0 in stage 1.0 (TID 210) in 325 ms on namenode (executor driver) (88/121)\n",
      "  Getting 121 (257.3 KiB) non-empty blocks including 121 (257.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 1 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 397, boot = -20, init = 22, finish = 395\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000090_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000090\n",
      "  attempt_202204260806042090827804316438547_0008_m_000090_0: Committed\n",
      "  Finished task 90.0 in stage 1.0 (TID 211). 1959 bytes result sent to driver\n",
      "  Starting task 92.0 in stage 1.0 (TID 213) (namenode, executor driver, partition 92, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 90.0 in stage 1.0 (TID 211) in 441 ms on namenode (executor driver) (89/121)\n",
      "  Running task 92.0 in stage 1.0 (TID 213)\n",
      "  Getting 121 (253.3 KiB) non-empty blocks including 121 (253.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 889, boot = -2, init = 4, finish = 887\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000088_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000088\n",
      "  attempt_202204260806042090827804316438547_0008_m_000088_0: Committed\n",
      "  Finished task 88.0 in stage 1.0 (TID 209). 2045 bytes result sent to driver\n",
      "  Starting task 93.0 in stage 1.0 (TID 214) (namenode, executor driver, partition 93, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 88.0 in stage 1.0 (TID 209) in 922 ms on namenode (executor driver) (90/121)\n",
      "  Running task 93.0 in stage 1.0 (TID 214)\n",
      "  Getting 121 (260.3 KiB) non-empty blocks including 121 (260.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 670, boot = 0, init = 2, finish = 668\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000092_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000092\n",
      "  attempt_202204260806042090827804316438547_0008_m_000092_0: Committed\n",
      "  Finished task 92.0 in stage 1.0 (TID 213). 2002 bytes result sent to driver\n",
      "  Starting task 94.0 in stage 1.0 (TID 215) (namenode, executor driver, partition 94, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 92.0 in stage 1.0 (TID 213) in 694 ms on namenode (executor driver) (91/121)\n",
      "  Running task 94.0 in stage 1.0 (TID 215)\n",
      "  Getting 121 (250.3 KiB) non-empty blocks including 121 (250.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 7 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 1832, boot = 19, init = 1, finish = 1812\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000087_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000087\n",
      "  attempt_202204260806042090827804316438547_0008_m_000087_0: Committed\n",
      "  Finished task 87.0 in stage 1.0 (TID 208). 2045 bytes result sent to driver\n",
      "  Starting task 95.0 in stage 1.0 (TID 216) (namenode, executor driver, partition 95, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 95.0 in stage 1.0 (TID 216)\n",
      "  Finished task 87.0 in stage 1.0 (TID 208) in 1865 ms on namenode (executor driver) (92/121)\n",
      "  Getting 121 (488.5 KiB) non-empty blocks including 121 (488.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 563, boot = -1, init = 3, finish = 561\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000094_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000094\n",
      "  attempt_202204260806042090827804316438547_0008_m_000094_0: Committed\n",
      "  Finished task 94.0 in stage 1.0 (TID 215). 1916 bytes result sent to driver\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Starting task 96.0 in stage 1.0 (TID 217) (namenode, executor driver, partition 96, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 96.0 in stage 1.0 (TID 217)\n",
      "  Finished task 94.0 in stage 1.0 (TID 215) in 583 ms on namenode (executor driver) (93/121)\n",
      "  Getting 121 (207.0 KiB) non-empty blocks including 121 (207.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 4 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 1283, boot = -6, init = 8, finish = 1281\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000093_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000093\n",
      "  attempt_202204260806042090827804316438547_0008_m_000093_0: Committed\n",
      "  Finished task 93.0 in stage 1.0 (TID 214). 2002 bytes result sent to driver\n",
      "  Starting task 97.0 in stage 1.0 (TID 218) (namenode, executor driver, partition 97, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 93.0 in stage 1.0 (TID 214) in 1302 ms on namenode (executor driver) (94/121)\n",
      "  Running task 97.0 in stage 1.0 (TID 218)\n",
      "  Getting 121 (255.0 KiB) non-empty blocks including 121 (255.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 3 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 282, boot = -2, init = 4, finish = 280\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000096_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000096\n",
      "  attempt_202204260806042090827804316438547_0008_m_000096_0: Committed\n",
      "  Finished task 96.0 in stage 1.0 (TID 217). 1916 bytes result sent to driver\n",
      "  Starting task 98.0 in stage 1.0 (TID 219) (namenode, executor driver, partition 98, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 96.0 in stage 1.0 (TID 217) in 318 ms on namenode (executor driver) (95/121)\n",
      "  Running task 98.0 in stage 1.0 (TID 219)\n",
      "  Getting 121 (206.1 KiB) non-empty blocks including 121 (206.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 573, boot = -2, init = 3, finish = 572\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000097_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000097\n",
      "  attempt_202204260806042090827804316438547_0008_m_000097_0: Committed\n",
      "  Finished task 97.0 in stage 1.0 (TID 218). 1916 bytes result sent to driver\n",
      "  Starting task 99.0 in stage 1.0 (TID 220) (namenode, executor driver, partition 99, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 97.0 in stage 1.0 (TID 218) in 599 ms on namenode (executor driver) (96/121)\n",
      "  Running task 99.0 in stage 1.0 (TID 220)\n",
      "  Getting 121 (229.7 KiB) non-empty blocks including 121 (229.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 4 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 2457, boot = 6, init = 4, finish = 2447\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000091_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000091\n",
      "  attempt_202204260806042090827804316438547_0008_m_000091_0: Committed\n",
      "  Finished task 91.0 in stage 1.0 (TID 212). 2002 bytes result sent to driver\n",
      "  Starting task 100.0 in stage 1.0 (TID 221) (namenode, executor driver, partition 100, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 91.0 in stage 1.0 (TID 212) in 2472 ms on namenode (executor driver) (97/121)\n",
      "  Running task 100.0 in stage 1.0 (TID 221)\n",
      "  Getting 121 (254.1 KiB) non-empty blocks including 121 (254.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 10 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 605, boot = 11, init = 2, finish = 592\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000098_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000098\n",
      "  attempt_202204260806042090827804316438547_0008_m_000098_0: Committed\n",
      "  Finished task 98.0 in stage 1.0 (TID 219). 2002 bytes result sent to driver\n",
      "  Starting task 101.0 in stage 1.0 (TID 222) (namenode, executor driver, partition 101, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 98.0 in stage 1.0 (TID 219) in 627 ms on namenode (executor driver) (98/121)\n",
      "  Running task 101.0 in stage 1.0 (TID 222)\n",
      "  Getting 121 (250.5 KiB) non-empty blocks including 121 (250.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 493, boot = 14, init = 3, finish = 476\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000099_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000099\n",
      "  attempt_202204260806042090827804316438547_0008_m_000099_0: Committed\n",
      "  Finished task 99.0 in stage 1.0 (TID 220). 2002 bytes result sent to driver\n",
      "  Starting task 102.0 in stage 1.0 (TID 223) (namenode, executor driver, partition 102, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 99.0 in stage 1.0 (TID 220) in 512 ms on namenode (executor driver) (99/121)\n",
      "  Running task 102.0 in stage 1.0 (TID 223)\n",
      "  Getting 121 (233.7 KiB) non-empty blocks including 121 (233.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 670, boot = -4, init = 6, finish = 668\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000100_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000100\n",
      "  attempt_202204260806042090827804316438547_0008_m_000100_0: Committed\n",
      "  Finished task 100.0 in stage 1.0 (TID 221). 2002 bytes result sent to driver\n",
      "  Starting task 103.0 in stage 1.0 (TID 224) (namenode, executor driver, partition 103, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 100.0 in stage 1.0 (TID 221) in 696 ms on namenode (executor driver) (100/121)\n",
      "  Running task 103.0 in stage 1.0 (TID 224)\n",
      "  Getting 121 (247.6 KiB) non-empty blocks including 121 (247.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Times: total = 337, boot = 19, init = 1, finish = 317\n",
      "  Started 0 remote fetches in 10 ms\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000102_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000102\n",
      "  attempt_202204260806042090827804316438547_0008_m_000102_0: Committed\n",
      "  Finished task 102.0 in stage 1.0 (TID 223). 1916 bytes result sent to driver\n",
      "  Starting task 104.0 in stage 1.0 (TID 225) (namenode, executor driver, partition 104, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 104.0 in stage 1.0 (TID 225)\n",
      "  Finished task 102.0 in stage 1.0 (TID 223) in 354 ms on namenode (executor driver) (101/121)\n",
      "  Getting 121 (266.1 KiB) non-empty blocks including 121 (266.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 511, boot = 10, init = 5, finish = 496\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000103_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000103\n",
      "  attempt_202204260806042090827804316438547_0008_m_000103_0: Committed\n",
      "  Finished task 103.0 in stage 1.0 (TID 224). 1916 bytes result sent to driver\n",
      "  Starting task 105.0 in stage 1.0 (TID 226) (namenode, executor driver, partition 105, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 105.0 in stage 1.0 (TID 226)\n",
      "  Finished task 103.0 in stage 1.0 (TID 224) in 534 ms on namenode (executor driver) (102/121)\n",
      "  Getting 121 (270.2 KiB) non-empty blocks including 121 (270.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 3 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 584, boot = 12, init = 7, finish = 565\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000104_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000104\n",
      "  attempt_202204260806042090827804316438547_0008_m_000104_0: Committed\n",
      "  Finished task 104.0 in stage 1.0 (TID 225). 1916 bytes result sent to driver\n",
      "  Starting task 106.0 in stage 1.0 (TID 227) (namenode, executor driver, partition 106, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 104.0 in stage 1.0 (TID 225) in 602 ms on namenode (executor driver) (103/121)\n",
      "  Running task 106.0 in stage 1.0 (TID 227)\n",
      "  Getting 121 (302.0 KiB) non-empty blocks including 121 (302.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 4 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 1391, boot = 18, init = 8, finish = 1365\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000101_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000101\n",
      "  attempt_202204260806042090827804316438547_0008_m_000101_0: Committed\n",
      "  Finished task 101.0 in stage 1.0 (TID 222). 2002 bytes result sent to driver\n",
      "  Starting task 107.0 in stage 1.0 (TID 228) (namenode, executor driver, partition 107, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 107.0 in stage 1.0 (TID 228)\n",
      "  Finished task 101.0 in stage 1.0 (TID 222) in 1405 ms on namenode (executor driver) (104/121)\n",
      "  Getting 121 (229.3 KiB) non-empty blocks including 121 (229.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 264, boot = 8, init = 6, finish = 250\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000107_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000107\n",
      "  attempt_202204260806042090827804316438547_0008_m_000107_0: Committed\n",
      "  Finished task 107.0 in stage 1.0 (TID 228). 1916 bytes result sent to driver\n",
      "  Starting task 108.0 in stage 1.0 (TID 229) (namenode, executor driver, partition 108, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 107.0 in stage 1.0 (TID 228) in 278 ms on namenode (executor driver) (105/121)\n",
      "  Running task 108.0 in stage 1.0 (TID 229)\n",
      "  Getting 121 (226.8 KiB) non-empty blocks including 121 (226.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 936, boot = 17, init = 1, finish = 918\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000105_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000105\n",
      "  attempt_202204260806042090827804316438547_0008_m_000105_0: Committed\n",
      "  Finished task 105.0 in stage 1.0 (TID 226). 1916 bytes result sent to driver\n",
      "  Starting task 109.0 in stage 1.0 (TID 230) (namenode, executor driver, partition 109, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 109.0 in stage 1.0 (TID 230)\n",
      "  Finished task 105.0 in stage 1.0 (TID 226) in 955 ms on namenode (executor driver) (106/121)\n",
      "  Getting 121 (244.9 KiB) non-empty blocks including 121 (244.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 528, boot = 7, init = 2, finish = 519\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000109_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000109\n",
      "  attempt_202204260806042090827804316438547_0008_m_000109_0: Committed\n",
      "  Finished task 109.0 in stage 1.0 (TID 230). 1959 bytes result sent to driver\n",
      "  Starting task 110.0 in stage 1.0 (TID 231) (namenode, executor driver, partition 110, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 109.0 in stage 1.0 (TID 230) in 544 ms on namenode (executor driver) (107/121)\n",
      "  Running task 110.0 in stage 1.0 (TID 231)\n",
      "  Getting 121 (240.7 KiB) non-empty blocks including 121 (240.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 14 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 1556, boot = -1, init = 2, finish = 1555\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000108_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000108\n",
      "  attempt_202204260806042090827804316438547_0008_m_000108_0: Committed\n",
      "  Finished task 108.0 in stage 1.0 (TID 229). 2045 bytes result sent to driver\n",
      "  Starting task 111.0 in stage 1.0 (TID 232) (namenode, executor driver, partition 111, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 111.0 in stage 1.0 (TID 232)\n",
      "  Finished task 108.0 in stage 1.0 (TID 229) in 1580 ms on namenode (executor driver) (108/121)\n",
      "  Getting 121 (220.6 KiB) non-empty blocks including 121 (220.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 621, boot = -9, init = 12, finish = 618\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000110_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  attempt_202204260806042090827804316438547_0008_m_000110_0: Committed\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Finished task 110.0 in stage 1.0 (TID 231). 2002 bytes result sent to driver\n",
      "  Starting task 112.0 in stage 1.0 (TID 233) (namenode, executor driver, partition 112, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 112.0 in stage 1.0 (TID 233)\n",
      "  Finished task 110.0 in stage 1.0 (TID 231) in 653 ms on namenode (executor driver) (109/121)\n",
      "  Getting 121 (241.1 KiB) non-empty blocks including 121 (241.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 2 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 359, boot = 6, init = 9, finish = 344\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000111_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000111\n",
      "  attempt_202204260806042090827804316438547_0008_m_000111_0: Committed\n",
      "  Finished task 111.0 in stage 1.0 (TID 232). 1916 bytes result sent to driver\n",
      "  Starting task 113.0 in stage 1.0 (TID 234) (namenode, executor driver, partition 113, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 111.0 in stage 1.0 (TID 232) in 374 ms on namenode (executor driver) (110/121)\n",
      "  Running task 113.0 in stage 1.0 (TID 234)\n",
      "  Getting 121 (282.0 KiB) non-empty blocks including 121 (282.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 9 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 571, boot = 17, init = 1, finish = 553\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000112_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000112\n",
      "  attempt_202204260806042090827804316438547_0008_m_000112_0: Committed\n",
      "  Finished task 112.0 in stage 1.0 (TID 233). 2002 bytes result sent to driver\n",
      "  Starting task 114.0 in stage 1.0 (TID 235) (namenode, executor driver, partition 114, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 112.0 in stage 1.0 (TID 233) in 590 ms on namenode (executor driver) (111/121)\n",
      "  Running task 114.0 in stage 1.0 (TID 235)\n",
      "  Getting 121 (250.3 KiB) non-empty blocks including 121 (250.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 2945, boot = 1, init = 2, finish = 2942\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000106_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000106\n",
      "  attempt_202204260806042090827804316438547_0008_m_000106_0: Committed\n",
      "  Finished task 106.0 in stage 1.0 (TID 227). 2045 bytes result sent to driver\n",
      "  Starting task 115.0 in stage 1.0 (TID 236) (namenode, executor driver, partition 115, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 106.0 in stage 1.0 (TID 227) in 2963 ms on namenode (executor driver) (112/121)\n",
      "  Running task 115.0 in stage 1.0 (TID 236)\n",
      "  Getting 121 (251.6 KiB) non-empty blocks including 121 (251.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 9 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 515, boot = 18, init = 1, finish = 496\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000114_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000114\n",
      "  attempt_202204260806042090827804316438547_0008_m_000114_0: Committed\n",
      "  Finished task 114.0 in stage 1.0 (TID 235). 1916 bytes result sent to driver\n",
      "  Starting task 116.0 in stage 1.0 (TID 237) (namenode, executor driver, partition 116, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 116.0 in stage 1.0 (TID 237)\n",
      "  Finished task 114.0 in stage 1.0 (TID 235) in 535 ms on namenode (executor driver) (113/121)\n",
      "  Getting 121 (248.3 KiB) non-empty blocks including 121 (248.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 4 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 948, boot = 8, init = 7, finish = 933\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000113_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000113\n",
      "  attempt_202204260806042090827804316438547_0008_m_000113_0: Committed\n",
      "  Finished task 113.0 in stage 1.0 (TID 234). 2002 bytes result sent to driver\n",
      "  Starting task 117.0 in stage 1.0 (TID 238) (namenode, executor driver, partition 117, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 113.0 in stage 1.0 (TID 234) in 970 ms on namenode (executor driver) (114/121)\n",
      "  Running task 117.0 in stage 1.0 (TID 238)\n",
      "  Getting 121 (280.1 KiB) non-empty blocks including 121 (280.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 10 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 703, boot = 12, init = 1, finish = 690\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000116_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000116\n",
      "  attempt_202204260806042090827804316438547_0008_m_000116_0: Committed\n",
      "  Finished task 116.0 in stage 1.0 (TID 237). 2002 bytes result sent to driver\n",
      "  Starting task 118.0 in stage 1.0 (TID 239) (namenode, executor driver, partition 118, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 116.0 in stage 1.0 (TID 237) in 722 ms on namenode (executor driver) (115/121)\n",
      "  Running task 118.0 in stage 1.0 (TID 239)\n",
      "  Getting 121 (195.2 KiB) non-empty blocks including 121 (195.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 24 ms\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Times: total = 264, boot = -9, init = 11, finish = 262\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000118_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000118\n",
      "  attempt_202204260806042090827804316438547_0008_m_000118_0: Committed\n",
      "  Finished task 118.0 in stage 1.0 (TID 239). 1916 bytes result sent to driver\n",
      "  Starting task 119.0 in stage 1.0 (TID 240) (namenode, executor driver, partition 119, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Finished task 118.0 in stage 1.0 (TID 239) in 304 ms on namenode (executor driver) (116/121)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Running task 119.0 in stage 1.0 (TID 240)\n",
      "  Getting 121 (220.3 KiB) non-empty blocks including 121 (220.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 835, boot = 10, init = 4, finish = 821\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000117_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000117\n",
      "  attempt_202204260806042090827804316438547_0008_m_000117_0: Committed\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Finished task 117.0 in stage 1.0 (TID 238). 1916 bytes result sent to driver\n",
      "  Starting task 120.0 in stage 1.0 (TID 241) (namenode, executor driver, partition 120, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "  Running task 120.0 in stage 1.0 (TID 241)\n",
      "  Finished task 117.0 in stage 1.0 (TID 238) in 871 ms on namenode (executor driver) (117/121)\n",
      "  Getting 121 (261.0 KiB) non-empty blocks including 121 (261.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "  Started 0 remote fetches in 0 ms\n",
      "  Times: total = 1280, boot = -2, init = 4, finish = 1278\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000115_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000115\n",
      "  attempt_202204260806042090827804316438547_0008_m_000115_0: Committed\n",
      "  Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\n",
      "  File Output Committer Algorithm version is 1\n",
      "  FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "  Finished task 115.0 in stage 1.0 (TID 236). 2002 bytes result sent to driver\n",
      "  Finished task 115.0 in stage 1.0 (TID 236) in 1311 ms on namenode (executor driver) (118/121)\n",
      "  Times: total = 304, boot = -3, init = 5, finish = 302\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000120_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000120\n",
      "  attempt_202204260806042090827804316438547_0008_m_000120_0: Committed\n",
      "  Finished task 120.0 in stage 1.0 (TID 241). 1916 bytes result sent to driver\n",
      "  Finished task 120.0 in stage 1.0 (TID 241) in 320 ms on namenode (executor driver) (119/121)\n",
      "  Times: total = 663, boot = 37, init = 1, finish = 625\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000119_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000119\n",
      "  attempt_202204260806042090827804316438547_0008_m_000119_0: Committed\n",
      "  Finished task 119.0 in stage 1.0 (TID 240). 2002 bytes result sent to driver\n",
      "  Finished task 119.0 in stage 1.0 (TID 240) in 682 ms on namenode (executor driver) (120/121)\n",
      "  Times: total = 10210, boot = 8, init = 5, finish = 10197\n",
      "  Saved output of task 'attempt_202204260806042090827804316438547_0008_m_000095_0' to file:/tmp/popular.ubuntu.20220426.080555.284224-spark/output/_temporary/0/task_202204260806042090827804316438547_0008_m_000095\n",
      "  attempt_202204260806042090827804316438547_0008_m_000095_0: Committed\n",
      "  Finished task 95.0 in stage 1.0 (TID 216). 2045 bytes result sent to driver\n",
      "  Finished task 95.0 in stage 1.0 (TID 216) in 10225 ms on namenode (executor driver) (121/121)\n",
      "  Removed TaskSet 1.0, whose tasks have all completed, from pool \n",
      "  ResultStage 1 (runJob at SparkHadoopWriter.scala:83) finished in 30.925 s\n",
      "  Job 0 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "  Killing all running tasks in stage 1: Stage finished\n",
      "  Job 0 finished: runJob at SparkHadoopWriter.scala:83, took 216.880986 s\n",
      "  Start to commit write Job job_202204260806042090827804316438547_0008.\n",
      "  Write Job job_202204260806042090827804316438547_0008 committed. Elapsed time: 93 ms.\n",
      "  Invoking stop() from shutdown hook\n",
      "  Stopped Spark@54b480aa{HTTP/1.1, (http/1.1)}{0.0.0.0:4041}\n",
      "  Stopped Spark web UI at http://namenode:4041\n",
      "  MapOutputTrackerMasterEndpoint stopped!\n",
      "  MemoryStore cleared\n",
      "  BlockManager stopped\n",
      "  BlockManagerMaster stopped\n",
      "  OutputCommitCoordinator stopped!\n",
      "  Successfully stopped SparkContext\n",
      "  Shutdown hook called\n",
      "  Deleting directory /tmp/spark-f87f59ae-9b82-4993-9c69-672451a73d34\n",
      "  Deleting directory /tmp/spark-30229df0-a1d7-4e2b-b0e0-c1675d0a2e51\n",
      "  Deleting directory /tmp/spark-30229df0-a1d7-4e2b-b0e0-c1675d0a2e51/pyspark-3d262d47-064e-4bc0-b3ad-1710b3b5e67f\n",
      "job output is in /tmp/popular.ubuntu.20220426.080555.284224-spark/output\n",
      "Streaming final output from /tmp/popular.ubuntu.20220426.080555.284224-spark/output...\n",
      "Removing temp directory /tmp/popular.ubuntu.20220426.080555.284224...\n"
     ]
    }
   ],
   "source": [
    "!python3 popular.py -r spark hdfs://namenode:9000/dis_materials/data_reddit.csv >pops3.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "edb45257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "No configs specified for hadoop runner\n",
      "Looking for hadoop binary in /usr/local/hadoop/bin...\n",
      "Found hadoop binary: /usr/local/hadoop/bin/hadoop\n",
      "Using Hadoop version 3.2.1\n",
      "Looking for Hadoop streaming jar in /usr/local/hadoop...\n",
      "Found Hadoop streaming jar: /usr/local/hadoop/share/hadoop/tools/lib/hadoop-streaming-3.2.1.jar\n",
      "Creating temp directory /tmp/popularsort.ubuntu.20220426.093529.004608\n",
      "uploading working dir files to hdfs:///user/ubuntu/tmp/mrjob/popularsort.ubuntu.20220426.093529.004608/files/wd...\n",
      "Copying other local files to hdfs:///user/ubuntu/tmp/mrjob/popularsort.ubuntu.20220426.093529.004608/files/\n",
      "Running step 1 of 2...\n",
      "  packageJobJar: [/tmp/hadoop-unjar7874126254457460152/] [] /tmp/streamjob7929162695543915836.jar tmpDir=null\n",
      "  Connecting to ResourceManager at namenode/10.10.22.25:8032\n",
      "  Connecting to ResourceManager at namenode/10.10.22.25:8032\n",
      "  Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1644567623435_0221\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Total input files to process : 1\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  number of splits:121\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Submitting tokens for job: job_1644567623435_0221\n",
      "  Executing with tokens: []\n",
      "  resource-types.xml not found\n",
      "  Unable to find 'resource-types.xml'.\n",
      "  Submitted application application_1644567623435_0221\n",
      "  The url to track the job: http://namenode:8088/proxy/application_1644567623435_0221/\n",
      "  Running job: job_1644567623435_0221\n",
      "  Job job_1644567623435_0221 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "  Task Id : attempt_1644567623435_0221_m_000010_0, Status : FAILED\n",
      "Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:326)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:539)\n",
      "\tat org.apache.hadoop.streaming.PipeMapper.close(PipeMapper.java:130)\n",
      "\tat org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:61)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:465)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:349)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)\n",
      "\n",
      "  Task Id : attempt_1644567623435_0221_m_000016_0, Status : FAILED\n",
      "Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:326)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:539)\n",
      "\tat org.apache.hadoop.streaming.PipeMapper.close(PipeMapper.java:130)\n",
      "\tat org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:61)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:465)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:349)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)\n",
      "\n",
      "  Task Id : attempt_1644567623435_0221_m_000012_0, Status : FAILED\n",
      "Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:326)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:539)\n",
      "\tat org.apache.hadoop.streaming.PipeMapper.close(PipeMapper.java:130)\n",
      "\tat org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:61)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:465)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:349)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)\n",
      "\n",
      "  Task Id : attempt_1644567623435_0221_m_000011_0, Status : FAILED\n",
      "Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:326)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:539)\n",
      "\tat org.apache.hadoop.streaming.PipeMapper.close(PipeMapper.java:130)\n",
      "\tat org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:61)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:465)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:349)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)\n",
      "\n",
      "  Task Id : attempt_1644567623435_0221_m_000017_0, Status : FAILED\n",
      "Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:326)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:539)\n",
      "\tat org.apache.hadoop.streaming.PipeMapper.close(PipeMapper.java:130)\n",
      "\tat org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:61)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:465)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:349)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)\n",
      "\n",
      "  Task Id : attempt_1644567623435_0221_m_000021_0, Status : FAILED\n",
      "Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:326)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:539)\n",
      "\tat org.apache.hadoop.streaming.PipeMapper.close(PipeMapper.java:130)\n",
      "\tat org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:61)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:465)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:349)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)\n",
      "\n",
      "  Task Id : attempt_1644567623435_0221_m_000018_0, Status : FAILED\n",
      "Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:326)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:539)\n",
      "\tat org.apache.hadoop.streaming.PipeMapper.close(PipeMapper.java:130)\n",
      "\tat org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:61)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:465)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:349)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Task Id : attempt_1644567623435_0221_m_000022_0, Status : FAILED\n",
      "Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:326)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:539)\n",
      "\tat org.apache.hadoop.streaming.PipeMapper.close(PipeMapper.java:130)\n",
      "\tat org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:61)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:465)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:349)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)\n",
      "\n",
      "  Task Id : attempt_1644567623435_0221_m_000003_0, Status : FAILED\n",
      "Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:326)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:539)\n",
      "\tat org.apache.hadoop.streaming.PipeMapper.close(PipeMapper.java:130)\n",
      "\tat org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:61)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:465)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:349)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)\n",
      "\n",
      "  Task Id : attempt_1644567623435_0221_m_000001_0, Status : FAILED\n",
      "Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:326)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:539)\n",
      "\tat org.apache.hadoop.streaming.PipeMapper.close(PipeMapper.java:130)\n",
      "\tat org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:61)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:465)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:349)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)\n",
      "\n",
      "  Task Id : attempt_1644567623435_0221_m_000005_0, Status : FAILED\n",
      "Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:326)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:539)\n",
      "\tat org.apache.hadoop.streaming.PipeMapper.close(PipeMapper.java:130)\n",
      "\tat org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:61)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:465)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:349)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)\n",
      "\n",
      "  Task Id : attempt_1644567623435_0221_m_000006_0, Status : FAILED\n",
      "Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:326)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:539)\n",
      "\tat org.apache.hadoop.streaming.PipeMapper.close(PipeMapper.java:130)\n",
      "\tat org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:61)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:465)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:349)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)\n",
      "\n",
      "  Task Id : attempt_1644567623435_0221_m_000004_0, Status : FAILED\n",
      "Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:326)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:539)\n",
      "\tat org.apache.hadoop.streaming.PipeMapper.close(PipeMapper.java:130)\n",
      "\tat org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:61)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:465)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:349)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)\n",
      "\n",
      "  Task Id : attempt_1644567623435_0221_m_000000_0, Status : FAILED\n",
      "Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:326)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:539)\n",
      "\tat org.apache.hadoop.streaming.PipeMapper.close(PipeMapper.java:130)\n",
      "\tat org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:61)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:465)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:349)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)\n",
      "\n",
      "  Task Id : attempt_1644567623435_0221_m_000002_0, Status : FAILED\n",
      "Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:326)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:539)\n",
      "\tat org.apache.hadoop.streaming.PipeMapper.close(PipeMapper.java:130)\n",
      "\tat org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:61)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:465)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:349)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)\n",
      "\n",
      "  Task Id : attempt_1644567623435_0221_m_000011_1, Status : FAILED\n",
      "Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:326)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:539)\n",
      "\tat org.apache.hadoop.streaming.PipeMapper.close(PipeMapper.java:130)\n",
      "\tat org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:61)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:465)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:349)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)\n",
      "\n",
      "  Task Id : attempt_1644567623435_0221_m_000010_1, Status : FAILED\n",
      "Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:326)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:539)\n",
      "\tat org.apache.hadoop.streaming.PipeMapper.close(PipeMapper.java:130)\n",
      "\tat org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:61)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:465)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:349)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)\n",
      "\n",
      "  Task Id : attempt_1644567623435_0221_m_000012_1, Status : FAILED\n",
      "Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:326)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:539)\n",
      "\tat org.apache.hadoop.streaming.PipeMapper.close(PipeMapper.java:130)\n",
      "\tat org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:61)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:465)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:349)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)\n",
      "\n",
      "  Task Id : attempt_1644567623435_0221_m_000016_1, Status : FAILED\n",
      "Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:326)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:539)\n",
      "\tat org.apache.hadoop.streaming.PipeMapper.close(PipeMapper.java:130)\n",
      "\tat org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:61)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:465)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:349)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)\n",
      "\n",
      "  Task Id : attempt_1644567623435_0221_m_000013_0, Status : FAILED\n",
      "Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:326)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:539)\n",
      "\tat org.apache.hadoop.streaming.PipeMapper.close(PipeMapper.java:130)\n",
      "\tat org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:61)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:465)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:349)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)\n",
      "\n",
      "  Task Id : attempt_1644567623435_0221_m_000014_0, Status : FAILED\n",
      "Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:326)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:539)\n",
      "\tat org.apache.hadoop.streaming.PipeMapper.close(PipeMapper.java:130)\n",
      "\tat org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:61)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:465)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:349)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)\n",
      "\n",
      "  Task Id : attempt_1644567623435_0221_m_000007_0, Status : FAILED\n",
      "Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:326)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:539)\n",
      "\tat org.apache.hadoop.streaming.PipeMapper.close(PipeMapper.java:130)\n",
      "\tat org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:61)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:465)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:349)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)\n",
      "\n",
      "  Task Id : attempt_1644567623435_0221_m_000009_0, Status : FAILED\n",
      "Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:326)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:539)\n",
      "\tat org.apache.hadoop.streaming.PipeMapper.close(PipeMapper.java:130)\n",
      "\tat org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:61)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:465)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:349)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Task Id : attempt_1644567623435_0221_m_000008_0, Status : FAILED\n",
      "Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:326)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:539)\n",
      "\tat org.apache.hadoop.streaming.PipeMapper.close(PipeMapper.java:130)\n",
      "\tat org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:61)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:465)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:349)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)\n",
      "\n",
      "  Task Id : attempt_1644567623435_0221_m_000004_1, Status : FAILED\n",
      "Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:326)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:539)\n",
      "\tat org.apache.hadoop.streaming.PipeMapper.close(PipeMapper.java:130)\n",
      "\tat org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:61)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:465)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:349)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)\n",
      "\n",
      "  Task Id : attempt_1644567623435_0221_m_000005_1, Status : FAILED\n",
      "Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:326)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:539)\n",
      "\tat org.apache.hadoop.streaming.PipeMapper.close(PipeMapper.java:130)\n",
      "\tat org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:61)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:465)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:349)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)\n",
      "\n",
      "  Task Id : attempt_1644567623435_0221_m_000006_1, Status : FAILED\n",
      "Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:326)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:539)\n",
      "\tat org.apache.hadoop.streaming.PipeMapper.close(PipeMapper.java:130)\n",
      "\tat org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:61)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:465)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:349)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)\n",
      "\n",
      "  Task Id : attempt_1644567623435_0221_m_000000_1, Status : FAILED\n",
      "Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:326)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:539)\n",
      "\tat org.apache.hadoop.streaming.PipeMapper.close(PipeMapper.java:130)\n",
      "\tat org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:61)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:465)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:349)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)\n",
      "\n",
      "  Task Id : attempt_1644567623435_0221_m_000015_0, Status : FAILED\n",
      "Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:326)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:539)\n",
      "\tat org.apache.hadoop.streaming.PipeMapper.close(PipeMapper.java:130)\n",
      "\tat org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:61)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:465)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:349)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)\n",
      "\n",
      "  Task Id : attempt_1644567623435_0221_m_000016_2, Status : FAILED\n",
      "Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:326)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:539)\n",
      "\tat org.apache.hadoop.streaming.PipeMapper.close(PipeMapper.java:130)\n",
      "\tat org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:61)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:465)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:349)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)\n",
      "\n",
      "  Task Id : attempt_1644567623435_0221_m_000010_2, Status : FAILED\n",
      "Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:326)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:539)\n",
      "\tat org.apache.hadoop.streaming.PipeMapper.close(PipeMapper.java:130)\n",
      "\tat org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:61)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:465)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:349)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)\n",
      "\n",
      "  Task Id : attempt_1644567623435_0221_m_000011_2, Status : FAILED\n",
      "Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:326)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:539)\n",
      "\tat org.apache.hadoop.streaming.PipeMapper.close(PipeMapper.java:130)\n",
      "\tat org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:61)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:465)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:349)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)\n",
      "\n",
      "  Task Id : attempt_1644567623435_0221_m_000013_1, Status : FAILED\n",
      "Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:326)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:539)\n",
      "\tat org.apache.hadoop.streaming.PipeMapper.close(PipeMapper.java:130)\n",
      "\tat org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:61)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:465)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:349)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Task Id : attempt_1644567623435_0221_m_000012_2, Status : FAILED\n",
      "Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:326)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:539)\n",
      "\tat org.apache.hadoop.streaming.PipeMapper.close(PipeMapper.java:130)\n",
      "\tat org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:61)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:465)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:349)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)\n",
      "\n",
      "  Task Id : attempt_1644567623435_0221_m_000009_1, Status : FAILED\n",
      "Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:326)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:539)\n",
      "\tat org.apache.hadoop.streaming.PipeMapper.close(PipeMapper.java:130)\n",
      "\tat org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:61)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:465)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:349)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)\n",
      "\n",
      "  Task Id : attempt_1644567623435_0221_m_000008_1, Status : FAILED\n",
      "Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:326)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:539)\n",
      "\tat org.apache.hadoop.streaming.PipeMapper.close(PipeMapper.java:130)\n",
      "\tat org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:61)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:465)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:349)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)\n",
      "\n",
      "  Task Id : attempt_1644567623435_0221_m_000007_1, Status : FAILED\n",
      "Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:326)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:539)\n",
      "\tat org.apache.hadoop.streaming.PipeMapper.close(PipeMapper.java:130)\n",
      "\tat org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:61)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:465)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:349)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)\n",
      "\n",
      "  Task Id : attempt_1644567623435_0221_m_000014_1, Status : FAILED\n",
      "Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:326)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:539)\n",
      "\tat org.apache.hadoop.streaming.PipeMapper.close(PipeMapper.java:130)\n",
      "\tat org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:61)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:465)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:349)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)\n",
      "\n",
      "  Task Id : attempt_1644567623435_0221_m_000004_2, Status : FAILED\n",
      "Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:326)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:539)\n",
      "\tat org.apache.hadoop.streaming.PipeMapper.close(PipeMapper.java:130)\n",
      "\tat org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:61)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:465)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:349)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)\n",
      "\n",
      "  Task Id : attempt_1644567623435_0221_m_000017_1, Status : FAILED\n",
      "Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:326)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:539)\n",
      "\tat org.apache.hadoop.streaming.PipeMapper.close(PipeMapper.java:130)\n",
      "\tat org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:61)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:465)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:349)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)\n",
      "\n",
      "  Task Id : attempt_1644567623435_0221_m_000021_1, Status : FAILED\n",
      "Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:326)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:539)\n",
      "\tat org.apache.hadoop.streaming.PipeMapper.close(PipeMapper.java:130)\n",
      "\tat org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:61)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:465)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:349)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)\n",
      "\n",
      "  Task Id : attempt_1644567623435_0221_m_000018_1, Status : FAILED\n",
      "Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:326)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:539)\n",
      "\tat org.apache.hadoop.streaming.PipeMapper.close(PipeMapper.java:130)\n",
      "\tat org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:61)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:465)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:349)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)\n",
      "\n",
      "  Task Id : attempt_1644567623435_0221_m_000003_1, Status : FAILED\n",
      "Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:326)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:539)\n",
      "\tat org.apache.hadoop.streaming.PipeMapper.close(PipeMapper.java:130)\n",
      "\tat org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:61)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:465)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:349)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)\n",
      "\n",
      "  Task Id : attempt_1644567623435_0221_m_000022_1, Status : FAILED\n",
      "Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:326)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:539)\n",
      "\tat org.apache.hadoop.streaming.PipeMapper.close(PipeMapper.java:130)\n",
      "\tat org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:61)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:465)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:349)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)\n",
      "\n",
      "  Task Id : attempt_1644567623435_0221_m_000002_1, Status : FAILED\n",
      "Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:326)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:539)\n",
      "\tat org.apache.hadoop.streaming.PipeMapper.close(PipeMapper.java:130)\n",
      "\tat org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:61)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:465)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:349)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Task Id : attempt_1644567623435_0221_m_000001_1, Status : FAILED\n",
      "Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:326)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:539)\n",
      "\tat org.apache.hadoop.streaming.PipeMapper.close(PipeMapper.java:130)\n",
      "\tat org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:61)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:465)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:349)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)\n",
      "\n",
      "  Task Id : attempt_1644567623435_0221_m_000015_1, Status : FAILED\n",
      "Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:326)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:539)\n",
      "\tat org.apache.hadoop.streaming.PipeMapper.close(PipeMapper.java:130)\n",
      "\tat org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:61)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:465)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:349)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)\n",
      "\n",
      "  Task Id : attempt_1644567623435_0221_m_000006_2, Status : FAILED\n",
      "Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:326)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:539)\n",
      "\tat org.apache.hadoop.streaming.PipeMapper.close(PipeMapper.java:130)\n",
      "\tat org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:61)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:465)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:349)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)\n",
      "\n",
      "  Task Id : attempt_1644567623435_0221_m_000005_2, Status : FAILED\n",
      "Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:326)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:539)\n",
      "\tat org.apache.hadoop.streaming.PipeMapper.close(PipeMapper.java:130)\n",
      "\tat org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:61)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:465)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:349)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)\n",
      "\n",
      "  Task Id : attempt_1644567623435_0221_m_000000_2, Status : FAILED\n",
      "Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:326)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:539)\n",
      "\tat org.apache.hadoop.streaming.PipeMapper.close(PipeMapper.java:130)\n",
      "\tat org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:61)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:465)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:349)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)\n",
      "\n",
      "   map 100% reduce 100%\n",
      "  Job job_1644567623435_0221 failed with state FAILED due to: Task failed task_1644567623435_0221_m_000010\n",
      "Job failed as tasks failed. failedMaps:1 failedReduces:0 killedMaps:0 killedReduces: 0\n",
      "\n",
      "  Job not successful!\n",
      "  Streaming Command Failed!\n",
      "Counters: 14\n",
      "\tJob Counters \n",
      "\t\tData-local map tasks=21\n",
      "\t\tFailed map tasks=51\n",
      "\t\tKilled map tasks=120\n",
      "\t\tKilled reduce tasks=1\n",
      "\t\tLaunched map tasks=63\n",
      "\t\tOther local map tasks=42\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=683587584\n",
      "\t\tTotal time spent by all map tasks (ms)=667566\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=667566\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=0\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=667566\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=0\n",
      "\t\tPhysical memory (bytes) snapshot=0\n",
      "\t\tVirtual memory (bytes) snapshot=0\n",
      "Scanning logs for probable cause of failure...\n",
      "Looking for history log in hdfs:///tmp/hadoop-yarn/staging...\n",
      "Looking for history log in /usr/local/hadoop/logs...\n",
      "\n",
      "Probable cause of failure:\n",
      "\n",
      "Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:326)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:539)\n",
      "\tat org.apache.hadoop.streaming.PipeMapper.close(PipeMapper.java:130)\n",
      "\tat org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:61)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:465)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:349)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)\n",
      "\n",
      "\n",
      "Step 1 of 2 failed: Command '['/usr/local/hadoop/bin/hadoop', 'jar', '/usr/local/hadoop/share/hadoop/tools/lib/hadoop-streaming-3.2.1.jar', '-files', 'hdfs:///user/ubuntu/tmp/mrjob/popularsort.ubuntu.20220426.093529.004608/files/wd/mrjob.zip#mrjob.zip,hdfs:///user/ubuntu/tmp/mrjob/popularsort.ubuntu.20220426.093529.004608/files/wd/popularsort.py#popularsort.py,hdfs:///user/ubuntu/tmp/mrjob/popularsort.ubuntu.20220426.093529.004608/files/wd/setup-wrapper.sh#setup-wrapper.sh', '-input', 'hdfs://namenode:9000/dis_materials/data_reddit.csv', '-output', 'hdfs:///user/ubuntu/tmp/mrjob/popularsort.ubuntu.20220426.093529.004608/step-output/0000', '-mapper', '/bin/sh -ex setup-wrapper.sh python3 popularsort.py --step-num=0 --mapper', '-reducer', '/bin/sh -ex setup-wrapper.sh python3 popularsort.py --step-num=0 --reducer']' returned non-zero exit status 256.\n"
     ]
    }
   ],
   "source": [
    "!python3 popularsort.py -r hadoop hdfs://namenode:9000/dis_materials/data_reddit.csv >popsh4.txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c61fee5b",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (702516171.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [11]\u001b[0;36m\u001b[0m\n\u001b[0;31m    dataproc', 'emr', 'hadoop', 'inline', 'local', 'spark')\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "dataproc', 'emr', 'hadoop', 'inline', 'local', 'spark')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62309f94",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "2022-04-24 14:07:31,924 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "2022-04-24 14:07:33,077 WARN util.Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "No configs found; falling back on auto-configuration\n",
      "No configs specified for hadoop runner\n",
      "Looking for hadoop binary in /usr/local/hadoop/bin...\n",
      "Found hadoop binary: /usr/local/hadoop/bin/hadoop\n",
      "Using Hadoop version 3.2.1\n",
      "Looking for Hadoop streaming jar in /usr/local/hadoop...\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"popular.py\", line 44, in <module>\n",
      "    MostPopular.run()\n",
      "  File \"/home/ubuntu/.local/lib/python3.8/site-packages/mrjob/job.py\", line 616, in run\n",
      "    cls().execute()\n",
      "  File \"/home/ubuntu/.local/lib/python3.8/site-packages/mrjob/job.py\", line 687, in execute\n",
      "    self.run_job()\n",
      "  File \"/home/ubuntu/.local/lib/python3.8/site-packages/mrjob/job.py\", line 636, in run_job\n",
      "    runner.run()\n",
      "  File \"/home/ubuntu/.local/lib/python3.8/site-packages/mrjob/runner.py\", line 503, in run\n",
      "    self._run()\n",
      "  File \"/home/ubuntu/.local/lib/python3.8/site-packages/mrjob/hadoop.py\", line 325, in _run\n",
      "    self._find_binaries_and_jars()\n",
      "  File \"/home/ubuntu/.local/lib/python3.8/site-packages/mrjob/hadoop.py\", line 342, in _find_binaries_and_jars\n",
      "    self.get_hadoop_streaming_jar()\n",
      "  File \"/home/ubuntu/.local/lib/python3.8/site-packages/mrjob/hadoop.py\", line 221, in get_hadoop_streaming_jar\n",
      "    self._hadoop_streaming_jar = self._find_hadoop_streaming_jar()\n",
      "  File \"/home/ubuntu/.local/lib/python3.8/site-packages/mrjob/hadoop.py\", line 241, in _find_hadoop_streaming_jar\n",
      "    for path in self.fs.ls(path):\n",
      "  File \"/home/ubuntu/.local/lib/python3.8/site-packages/mrjob/fs/local.py\", line 46, in ls\n",
      "    for dirname, _, filenames in os.walk(path, followlinks=True):\n",
      "  File \"/usr/lib/python3.8/os.py\", line 413, in walk\n",
      "    yield from walk(new_path, topdown, onerror, followlinks)\n",
      "  File \"/usr/lib/python3.8/os.py\", line 413, in walk\n",
      "    yield from walk(new_path, topdown, onerror, followlinks)\n",
      "  File \"/usr/lib/python3.8/os.py\", line 413, in walk\n",
      "    yield from walk(new_path, topdown, onerror, followlinks)\n",
      "  [Previous line repeated 7 more times]\n",
      "  File \"/usr/lib/python3.8/os.py\", line 362, in walk\n",
      "    entry = next(scandir_it)\n",
      "  File \"/home/ubuntu/.local/lib/python3.8/site-packages/pyspark/context.py\", line 293, in signal_handler\n",
      "    raise KeyboardInterrupt()\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python3 popular.py -r hadoop pandas.txt > otting.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7acc748",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark-submit popular.py hdfs://namenode:9000/dis_materials/data_reddit.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6cf136",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdfs://namenode:9000/dis_materials/data_reddit.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
