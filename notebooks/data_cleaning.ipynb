{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "a = time.time()\n",
    "import os\n",
    "# Overwrite Pyspark driver\n",
    "os.environ['PYSPARK_PYTHON'] = \"./environment/bin/python\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyspark.sql import SparkSession\n",
    "from langdetect import detect\n",
    "import pyspark as ps\n",
    "import datetime\n",
    "from pyspark.sql import functions as f\n",
    "from pyspark.sql import types as t\n",
    "from sparknlp.pretrained import PretrainedPipeline\n",
    "import re\n",
    "# from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "TEXT_CLEANING_RE = \"@\\S+|https?:\\S+|http?:\\S|[^A-Za-z0-9]+\"  \n",
    "def cleanText(text):\n",
    "    return re.sub(TEXT_CLEANING_RE, ' ', str(text).lower()).strip()\n",
    "# Convert function to UDF\n",
    "cleanTextDF = f.udf(lambda z: cleanText(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "2022-05-01 15:29:37,917 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "2022-05-01 15:29:40,894 WARN yarn.Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Redit Summarization App\")\\\n",
    "    .master(\"yarn\")\\\n",
    "    .config(\"spark.executor.memoryOverhead\",\"2048\")\\\n",
    "    .config(\"spark.driver.maxResultSize\", \"0\") \\\n",
    "    .config(\"spark.kryoserializer.buffer.max\", \"2000M\")\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://namenode:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Redit Summarization App</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f9f86190850>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get spark configurations\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Read data\n",
    "df = spark.read.format(\"csv\").option(\"header\",\"true\").load(\"hdfs://namenode:9000/dis_materials/data_reddit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop duplicates\n",
    "df2 = df.dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('created_utc', 'string'),\n",
       " ('ups', 'string'),\n",
       " ('subreddit_id', 'string'),\n",
       " ('link_id', 'string'),\n",
       " ('name', 'string'),\n",
       " ('score_hidden', 'string'),\n",
       " ('author_flair_css_class', 'string'),\n",
       " ('author_flair_text', 'string'),\n",
       " ('subreddit', 'string'),\n",
       " ('id', 'string'),\n",
       " ('removal_reason', 'string'),\n",
       " ('gilded', 'string'),\n",
       " ('downs', 'string'),\n",
       " ('archived', 'string'),\n",
       " ('author', 'string'),\n",
       " ('score', 'string'),\n",
       " ('retrieved_on', 'string'),\n",
       " ('body', 'string'),\n",
       " ('distinguished', 'string'),\n",
       " ('edited', 'string'),\n",
       " ('controversiality', 'string'),\n",
       " ('parent_id', 'string')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2= df2.withColumn('created_utc', f.from_unixtime('created_utc').cast(t.DateType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop null values\n",
    "df2 = df2.na.drop(subset=[\"subreddit\",\"subreddit_id\",\"body\",\"created_utc\",\"ups\",\"parent_id\",\"link_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.withColumn(\"ups\", df2[\"ups\"].cast(t.IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Remove comments belonging to moderators\n",
    "\"\"\"\n",
    "df2 = df2.filter((df2.distinguished != \"moderator\")|(df2.body!=\"[deleted]\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Use CleantTextDf to clean body column\n",
    "\"\"\"\n",
    "df2 = df2.withColumn(\"clean_body\",cleanTextDF(f.col(\"body\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.na.drop(subset=[\"clean_body\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.drop(\"name\",\"author_flair_css_class\",\"author_flair_text\",\"score_hidden\",\"id\",\"distinguished\",\"body\",\"removal_reason\",\"downs\",\"archived\",\"gilded\",\"retrieved_on\",\"edited\",\"controversiality\",\"author\",\"score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.where(f.length(f.col(\"parent_id\")) <= 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.persist(ps.StorageLevel.DISK_ONLY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.write.option(\"header\",\"true\").csv(\"hdfs://namenode:9000/cleaned_data_01.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "b = time.time()\n",
    "b-a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
